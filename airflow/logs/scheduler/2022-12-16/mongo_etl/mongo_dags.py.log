[2022-12-16T13:11:28.841+0000] {processor.py:154} INFO - Started process (PID=205) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:28.852+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:11:28.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:28.859+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:30.479+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:31.375+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:31.374+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:11:32.153+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:32.153+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:11:32.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.832 seconds
[2022-12-16T13:11:42.820+0000] {processor.py:154} INFO - Started process (PID=216) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:42.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:11:42.827+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:42.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:42.937+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:43.290+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:43.289+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:11:43.430+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:43.429+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:11:43.747+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.944 seconds
[2022-12-16T13:11:54.058+0000] {processor.py:154} INFO - Started process (PID=234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:54.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:11:54.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:54.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:54.291+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:11:55.148+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:55.147+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:11:55.351+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:11:55.350+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:11:55.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.844 seconds
[2022-12-16T13:12:06.382+0000] {processor.py:154} INFO - Started process (PID=244) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:06.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:12:06.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:06.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:06.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:06.773+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:06.772+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:12:06.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:06.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:12:07.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-16T13:12:17.452+0000] {processor.py:154} INFO - Started process (PID=254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:17.456+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:12:17.464+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:17.458+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:17.654+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:18.866+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:12:30.024+0000] {processor.py:154} INFO - Started process (PID=264) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:30.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:12:30.033+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:30.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:30.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:30.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:30.691+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:12:31.474+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:31.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:12:31.884+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.876 seconds
[2022-12-16T13:12:42.303+0000] {processor.py:154} INFO - Started process (PID=282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:42.307+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:12:42.311+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:42.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:42.441+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:42.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:42.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:12:43.274+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:43.237+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:12:43.834+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.554 seconds
[2022-12-16T13:12:54.585+0000] {processor.py:154} INFO - Started process (PID=292) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:54.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:12:54.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:54.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:54.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:12:57.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:57.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:12:57.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:12:57.726+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:12:58.377+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.807 seconds
[2022-12-16T13:13:09.476+0000] {processor.py:154} INFO - Started process (PID=305) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:09.515+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:13:09.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:09.518+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:10.014+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:11.732+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:11.731+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:13:11.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:11.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:13:12.210+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.926 seconds
[2022-12-16T13:13:23.754+0000] {processor.py:154} INFO - Started process (PID=323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:23.876+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:13:23.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:23.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:25.008+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:26.205+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:26.204+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:13:26.399+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:26.398+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:13:26.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.248 seconds
[2022-12-16T13:13:37.222+0000] {processor.py:154} INFO - Started process (PID=330) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:37.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:13:37.239+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:37.238+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:37.414+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:38.681+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:13:49.123+0000] {processor.py:154} INFO - Started process (PID=340) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:49.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:13:49.131+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:49.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:49.286+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:13:50.749+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:50.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:13:50.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:13:50.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:13:51.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.185 seconds
[2022-12-16T13:14:01.899+0000] {processor.py:154} INFO - Started process (PID=355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:01.956+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:14:01.960+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:01.959+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:02.219+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:02.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:02.952+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:14:03.130+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:03.129+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:14:03.335+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.457 seconds
[2022-12-16T13:14:13.923+0000] {processor.py:154} INFO - Started process (PID=371) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:13.933+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:14:13.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:13.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:14.481+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:15.581+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:14:26.116+0000] {processor.py:154} INFO - Started process (PID=378) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:26.120+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:14:26.125+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:26.124+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:26.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:27.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:27.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:14:27.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:27.775+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:14:28.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.989 seconds
[2022-12-16T13:14:38.522+0000] {processor.py:154} INFO - Started process (PID=388) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:38.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:14:38.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:38.546+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:38.947+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:39.523+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:39.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:14:39.898+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:39.897+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:14:40.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.801 seconds
[2022-12-16T13:14:50.616+0000] {processor.py:154} INFO - Started process (PID=398) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:50.620+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:14:50.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:50.624+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:51.112+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:14:51.553+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:51.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:14:51.705+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:14:51.705+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:14:51.925+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.326 seconds
[2022-12-16T13:15:02.393+0000] {processor.py:154} INFO - Started process (PID=415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:02.488+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:15:02.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:02.502+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:02.722+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:03.678+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:03.677+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:15:04.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:04.190+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:15:04.494+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.119 seconds
[2022-12-16T13:15:15.060+0000] {processor.py:154} INFO - Started process (PID=425) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:15.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:15:15.069+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:15.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:15.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:17.607+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:17.606+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:15:18.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:18.257+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:15:18.589+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.546 seconds
[2022-12-16T13:15:29.447+0000] {processor.py:154} INFO - Started process (PID=438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:29.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:15:29.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:29.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:30.065+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:30.914+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:30.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:15:31.805+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:31.804+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:15:32.293+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.930 seconds
[2022-12-16T13:15:42.619+0000] {processor.py:154} INFO - Started process (PID=458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:42.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:15:42.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:42.673+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:42.902+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:43.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:43.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:15:43.785+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:43.784+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:15:44.006+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.417 seconds
[2022-12-16T13:15:54.284+0000] {processor.py:154} INFO - Started process (PID=468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:54.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:15:54.291+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:15:54.290+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:54.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:15:55.605+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:16:05.912+0000] {processor.py:154} INFO - Started process (PID=478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:05.958+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:16:05.962+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:05.961+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:06.057+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:06.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:06.364+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:16:06.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:06.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:16:06.654+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.756 seconds
[2022-12-16T13:16:17.468+0000] {processor.py:154} INFO - Started process (PID=488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:17.472+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:16:17.476+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:17.474+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:17.574+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:17.897+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:17.896+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:16:18.067+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:18.066+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:16:18.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.723 seconds
[2022-12-16T13:16:28.877+0000] {processor.py:154} INFO - Started process (PID=506) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:28.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:16:28.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:28.895+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:28.988+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:29.226+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:29.225+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:16:29.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:29.391+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:16:29.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.686 seconds
[2022-12-16T13:16:39.801+0000] {processor.py:154} INFO - Started process (PID=516) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:39.821+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:16:39.825+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:39.824+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:39.909+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:40.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:40.133+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:16:40.306+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:40.306+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:16:40.448+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-16T13:16:50.686+0000] {processor.py:154} INFO - Started process (PID=526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:50.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:16:50.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:50.692+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:50.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:16:51.266+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:51.265+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:16:51.410+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:16:51.409+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:16:51.553+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.881 seconds
[2022-12-16T13:17:01.897+0000] {processor.py:154} INFO - Started process (PID=544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:01.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:01.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:01.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:02.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:03.105+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:17:13.676+0000] {processor.py:154} INFO - Started process (PID=554) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:13.679+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:13.683+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:13.682+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:13.765+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:14.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:14.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:17:14.250+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:14.249+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:17:14.379+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-16T13:17:24.691+0000] {processor.py:154} INFO - Started process (PID=564) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:24.695+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:24.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:24.698+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:24.795+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:25.013+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:25.012+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:17:25.190+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:25.189+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:17:25.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-16T13:17:35.441+0000] {processor.py:154} INFO - Started process (PID=574) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:35.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:35.458+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:35.457+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:35.549+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:35.794+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:35.793+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:17:36.164+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:36.163+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:17:36.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.907 seconds
[2022-12-16T13:17:46.758+0000] {processor.py:154} INFO - Started process (PID=590) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:46.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:46.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:46.811+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:46.933+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:47.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:47.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:17:47.446+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:47.445+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:17:47.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.822 seconds
[2022-12-16T13:17:57.861+0000] {processor.py:154} INFO - Started process (PID=600) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:57.865+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:17:57.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:57.870+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:57.989+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:17:58.655+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:58.654+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:17:58.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:17:58.864+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:17:59.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.320 seconds
[2022-12-16T13:18:09.379+0000] {processor.py:154} INFO - Started process (PID=612) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:09.410+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:18:09.414+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:09.413+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:09.510+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:10.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:10.980+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:18:11.217+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:11.217+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:18:11.445+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.080 seconds
[2022-12-16T13:18:22.153+0000] {processor.py:154} INFO - Started process (PID=627) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:22.217+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:18:22.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:22.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:22.355+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:23.326+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:18:33.869+0000] {processor.py:154} INFO - Started process (PID=638) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:33.888+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:18:33.909+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:33.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:34.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:34.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:34.768+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:18:34.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:34.930+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:18:35.152+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.360 seconds
[2022-12-16T13:18:45.865+0000] {processor.py:154} INFO - Started process (PID=648) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:45.904+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:18:45.913+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:45.907+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:46.212+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:47.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:47.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:18:47.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:47.664+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:18:47.922+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.095 seconds
[2022-12-16T13:18:58.276+0000] {processor.py:154} INFO - Started process (PID=655) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:58.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:18:58.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:18:58.327+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:18:59.020+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:00.448+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:19:11.425+0000] {processor.py:154} INFO - Started process (PID=673) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:11.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:19:11.439+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:11.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:11.750+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:13.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:13.493+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:19:14.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:14.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:19:14.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.320 seconds
[2022-12-16T13:19:25.257+0000] {processor.py:154} INFO - Started process (PID=683) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:25.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:19:25.290+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:25.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:25.641+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:26.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:26.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:19:27.243+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:27.242+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:19:27.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.586 seconds
[2022-12-16T13:19:38.524+0000] {processor.py:154} INFO - Started process (PID=693) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:38.539+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:19:38.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:38.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:38.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:39.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:39.573+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:19:39.889+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:39.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:19:40.180+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.730 seconds
[2022-12-16T13:19:50.626+0000] {processor.py:154} INFO - Started process (PID=703) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:50.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:19:50.635+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:50.633+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:50.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:19:51.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:51.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:19:52.102+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:19:52.101+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:19:52.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.849 seconds
[2022-12-16T13:20:03.159+0000] {processor.py:154} INFO - Started process (PID=721) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:03.211+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:20:03.218+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:03.214+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:03.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:05.753+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:20:16.313+0000] {processor.py:154} INFO - Started process (PID=731) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:16.321+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:20:16.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:16.325+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:16.514+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:17.455+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:17.454+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:20:17.959+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:17.958+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:20:18.253+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.980 seconds
[2022-12-16T13:20:28.604+0000] {processor.py:154} INFO - Started process (PID=741) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:28.608+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:20:28.612+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:28.611+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:28.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:29.343+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:29.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:20:29.621+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:29.616+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:20:30.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.441 seconds
[2022-12-16T13:20:40.654+0000] {processor.py:154} INFO - Started process (PID=751) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:40.666+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:20:40.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:40.688+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:40.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:42.161+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:42.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:20:42.511+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:42.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:20:42.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.351 seconds
[2022-12-16T13:20:53.807+0000] {processor.py:154} INFO - Started process (PID=769) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:53.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:20:53.869+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:53.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:54.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:20:55.126+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:55.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:20:55.620+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:20:55.619+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:20:55.977+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.202 seconds
[2022-12-16T13:21:06.635+0000] {processor.py:154} INFO - Started process (PID=779) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:06.638+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:21:06.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:06.649+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:06.794+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:07.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:07.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:21:07.451+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:07.450+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:21:07.648+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.033 seconds
[2022-12-16T13:21:18.091+0000] {processor.py:154} INFO - Started process (PID=789) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:18.094+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:21:18.098+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:18.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:18.260+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:19.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:19.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:21:19.387+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:19.385+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:21:19.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.494 seconds
[2022-12-16T13:21:30.067+0000] {processor.py:154} INFO - Started process (PID=799) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:30.091+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:21:30.095+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:30.094+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:30.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:30.404+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:30.403+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:21:30.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:30.543+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:21:30.684+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.633 seconds
[2022-12-16T13:21:41.057+0000] {processor.py:154} INFO - Started process (PID=817) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:41.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:21:41.160+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:41.143+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:41.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:42.641+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:42.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:21:43.083+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:43.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:21:43.309+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.366 seconds
[2022-12-16T13:21:53.609+0000] {processor.py:154} INFO - Started process (PID=827) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:53.613+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:21:53.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:53.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:53.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:21:54.044+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:54.043+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:21:54.204+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:21:54.203+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:21:54.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.752 seconds
[2022-12-16T13:22:04.856+0000] {processor.py:154} INFO - Started process (PID=837) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:04.905+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:22:04.912+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:04.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:05.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:06.376+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:22:16.697+0000] {processor.py:154} INFO - Started process (PID=847) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:16.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:22:16.754+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:16.752+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:16.848+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:17.398+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:17.397+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:22:17.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:17.545+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:22:17.706+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.023 seconds
[2022-12-16T13:22:28.100+0000] {processor.py:154} INFO - Started process (PID=865) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:28.117+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:22:28.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:28.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:28.488+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:30.046+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:30.045+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:22:30.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:30.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:22:30.813+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.787 seconds
[2022-12-16T13:22:41.273+0000] {processor.py:154} INFO - Started process (PID=875) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:41.301+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:22:41.309+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:41.308+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:41.473+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:43.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:43.166+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:22:43.465+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:43.464+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:22:43.663+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.406 seconds
[2022-12-16T13:22:54.033+0000] {processor.py:154} INFO - Started process (PID=885) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:54.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:22:54.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:22:54.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:54.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:22:56.002+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:23:06.386+0000] {processor.py:154} INFO - Started process (PID=903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:06.409+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:23:06.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:06.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:06.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:06.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:06.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:23:07.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:07.169+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:23:07.581+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.221 seconds
[2022-12-16T13:23:18.212+0000] {processor.py:154} INFO - Started process (PID=913) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:18.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:23:18.227+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:18.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:18.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:18.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:18.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:23:19.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:19.005+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:23:19.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.981 seconds
[2022-12-16T13:23:29.641+0000] {processor.py:154} INFO - Started process (PID=923) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:29.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:23:29.674+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:29.671+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:29.890+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:30.262+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:30.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:23:30.483+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:30.482+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:23:30.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.982 seconds
[2022-12-16T13:23:40.947+0000] {processor.py:154} INFO - Started process (PID=933) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:41.003+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:23:41.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:41.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:41.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:41.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:41.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:23:41.452+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:41.451+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:23:41.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-16T13:23:51.917+0000] {processor.py:154} INFO - Started process (PID=951) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:51.973+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:23:51.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:51.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:52.150+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:23:52.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:52.906+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:23:53.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:23:53.271+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:23:53.511+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.635 seconds
[2022-12-16T13:24:04.166+0000] {processor.py:154} INFO - Started process (PID=961) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:04.194+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:24:04.203+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:04.202+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:04.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:04.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:04.536+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:24:04.876+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:04.863+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:24:05.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.145 seconds
[2022-12-16T13:24:15.707+0000] {processor.py:154} INFO - Started process (PID=971) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:15.751+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:24:15.763+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:15.760+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:15.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:16.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:16.275+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:24:16.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:16.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:24:16.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.228 seconds
[2022-12-16T13:24:27.220+0000] {processor.py:154} INFO - Started process (PID=981) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:27.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:24:27.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:27.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:27.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:27.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:27.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:24:27.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:27.849+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:24:28.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T13:24:38.612+0000] {processor.py:154} INFO - Started process (PID=999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:38.668+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:24:38.678+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:38.676+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:38.979+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:39.942+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:24:50.587+0000] {processor.py:154} INFO - Started process (PID=1009) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:50.591+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:24:50.596+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:50.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:50.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:24:50.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:50.983+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:24:51.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:24:51.257+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:24:51.750+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.177 seconds
[2022-12-16T13:25:02.105+0000] {processor.py:154} INFO - Started process (PID=1019) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:02.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:25:02.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:02.114+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:02.380+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:03.346+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:03.345+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:25:03.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:03.541+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:25:04.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.174 seconds
[2022-12-16T13:25:14.677+0000] {processor.py:154} INFO - Started process (PID=1029) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:14.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:25:14.771+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:14.766+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:14.908+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:15.144+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:15.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:25:15.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:15.293+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:25:15.490+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.828 seconds
[2022-12-16T13:25:25.697+0000] {processor.py:154} INFO - Started process (PID=1046) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:25.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:25:25.763+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:25.756+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:25.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:26.419+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:26.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:25:26.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:26.726+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:25:27.050+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.407 seconds
[2022-12-16T13:25:37.355+0000] {processor.py:154} INFO - Started process (PID=1056) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:37.364+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:25:37.369+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:37.367+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:37.502+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:37.763+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:37.762+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:25:37.923+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:37.922+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:25:38.184+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.863 seconds
[2022-12-16T13:25:48.578+0000] {processor.py:154} INFO - Started process (PID=1066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:48.583+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:25:48.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:48.587+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:48.740+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:25:49.010+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:49.009+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:25:49.213+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:25:49.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:25:49.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.811 seconds
[2022-12-16T13:26:00.186+0000] {processor.py:154} INFO - Started process (PID=1076) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:00.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:00.229+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:00.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:00.323+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:00.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:00.585+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:00.736+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:00.735+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:00.868+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-16T13:26:11.341+0000] {processor.py:154} INFO - Started process (PID=1093) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:11.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:11.352+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:11.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:11.522+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:11.914+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:11.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:12.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:12.393+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:12.597+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.307 seconds
[2022-12-16T13:26:22.987+0000] {processor.py:154} INFO - Started process (PID=1103) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:22.991+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:22.995+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:22.994+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:23.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:23.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:23.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:23.891+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:23.890+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:24.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.100 seconds
[2022-12-16T13:26:34.500+0000] {processor.py:154} INFO - Started process (PID=1113) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:34.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:34.509+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:34.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:34.639+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:34.958+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:34.957+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:35.117+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:35.116+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:35.251+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.767 seconds
[2022-12-16T13:26:45.375+0000] {processor.py:154} INFO - Started process (PID=1129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:45.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:45.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:45.385+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:45.502+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:45.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:45.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:46.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:46.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:46.184+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.825 seconds
[2022-12-16T13:26:56.574+0000] {processor.py:154} INFO - Started process (PID=1140) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:56.577+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:26:56.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:56.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:56.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:26:56.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:56.936+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:26:57.115+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:26:57.114+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:26:57.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.734 seconds
[2022-12-16T13:27:08.005+0000] {processor.py:154} INFO - Started process (PID=1148) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:08.020+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:27:08.033+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:08.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:08.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:09.160+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:09.159+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:27:09.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:09.575+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:27:10.039+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.165 seconds
[2022-12-16T13:27:20.163+0000] {processor.py:154} INFO - Started process (PID=1160) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:20.194+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:27:20.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:20.198+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:20.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:21.167+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:27:31.653+0000] {processor.py:154} INFO - Started process (PID=1178) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:31.663+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:27:31.678+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:31.677+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:31.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:33.144+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:33.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:27:33.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:33.334+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:27:33.648+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.070 seconds
[2022-12-16T13:27:43.961+0000] {processor.py:154} INFO - Started process (PID=1188) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:43.965+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:27:43.969+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:43.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:44.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:44.321+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:44.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:27:44.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:44.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:27:44.706+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.759 seconds
[2022-12-16T13:27:55.016+0000] {processor.py:154} INFO - Started process (PID=1198) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:55.020+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:27:55.025+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:55.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:55.141+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:27:56.274+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:56.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:27:56.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:27:56.412+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:27:56.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.563 seconds
[2022-12-16T13:28:06.966+0000] {processor.py:154} INFO - Started process (PID=1215) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:06.974+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:28:06.982+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:06.979+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:07.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:07.922+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:07.922+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:28:08.107+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:08.106+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:28:08.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.361 seconds
[2022-12-16T13:28:18.749+0000] {processor.py:154} INFO - Started process (PID=1226) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:18.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:28:18.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:18.802+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:19.461+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:20.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:20.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:28:20.511+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:20.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:28:20.785+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.101 seconds
[2022-12-16T13:28:31.177+0000] {processor.py:154} INFO - Started process (PID=1236) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:31.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:28:31.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:31.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:31.337+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:31.687+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:31.686+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:28:32.033+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:32.032+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:28:32.214+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.060 seconds
[2022-12-16T13:28:42.682+0000] {processor.py:154} INFO - Started process (PID=1246) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:42.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:28:42.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:42.692+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:43.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:43.587+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:43.586+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:28:43.823+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:43.822+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:28:44.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.362 seconds
[2022-12-16T13:28:54.428+0000] {processor.py:154} INFO - Started process (PID=1264) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:54.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:28:54.453+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:54.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:55.056+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:28:55.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:55.612+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:28:55.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:28:55.886+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:28:56.128+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.782 seconds
[2022-12-16T13:29:06.739+0000] {processor.py:154} INFO - Started process (PID=1274) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:06.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:29:06.774+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:06.773+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:06.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:07.550+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:07.549+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:29:07.739+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:07.738+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:29:07.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.205 seconds
[2022-12-16T13:29:18.378+0000] {processor.py:154} INFO - Started process (PID=1284) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:18.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:29:18.412+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:18.410+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:18.506+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:18.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:18.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:29:18.935+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:18.934+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:29:19.311+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.954 seconds
[2022-12-16T13:29:29.811+0000] {processor.py:154} INFO - Started process (PID=1294) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:29.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:29:29.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:29.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:29.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:31.183+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:29:41.613+0000] {processor.py:154} INFO - Started process (PID=1311) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:41.646+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:29:41.654+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:41.653+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:41.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:42.073+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:42.072+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:29:42.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:42.316+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:29:42.575+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.009 seconds
[2022-12-16T13:29:53.062+0000] {processor.py:154} INFO - Started process (PID=1321) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:53.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:29:53.157+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:53.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:53.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:29:54.034+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:54.033+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:29:54.189+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:29:54.188+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:29:54.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.314 seconds
[2022-12-16T13:30:04.768+0000] {processor.py:154} INFO - Started process (PID=1331) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:04.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:30:04.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:04.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:04.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:05.275+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:05.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:30:05.473+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:05.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:30:05.627+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.877 seconds
[2022-12-16T13:30:16.033+0000] {processor.py:154} INFO - Started process (PID=1341) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:16.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:30:16.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:16.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:16.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:17.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:17.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:30:17.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:17.870+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:30:18.766+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.772 seconds
[2022-12-16T13:30:29.556+0000] {processor.py:154} INFO - Started process (PID=1359) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:29.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:30:29.572+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:29.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:29.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:30.712+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:30.711+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:30:31.010+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:31.010+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:30:31.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.771 seconds
[2022-12-16T13:30:41.673+0000] {processor.py:154} INFO - Started process (PID=1369) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:41.677+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:30:41.681+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:41.680+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:41.801+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:42.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:42.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:30:42.627+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:42.615+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:30:42.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.270 seconds
[2022-12-16T13:30:53.416+0000] {processor.py:154} INFO - Started process (PID=1379) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:53.420+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:30:53.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:30:53.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:53.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:30:55.078+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:31:05.698+0000] {processor.py:154} INFO - Started process (PID=1396) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:05.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:31:05.723+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:05.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:06.146+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:08.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:08.492+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:31:08.724+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:08.722+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:31:08.932+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.286 seconds
[2022-12-16T13:31:19.359+0000] {processor.py:154} INFO - Started process (PID=1406) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:19.373+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:31:19.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:19.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:19.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:20.414+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:31:30.752+0000] {processor.py:154} INFO - Started process (PID=1416) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:30.803+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:31:30.807+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:30.806+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:31.001+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:31.895+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:31.894+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:31:32.037+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:32.036+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:31:32.199+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.482 seconds
[2022-12-16T13:31:42.712+0000] {processor.py:154} INFO - Started process (PID=1426) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:42.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:31:42.819+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:42.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:43.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:43.845+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:43.844+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:31:44.019+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:44.017+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:31:44.337+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.687 seconds
[2022-12-16T13:31:54.858+0000] {processor.py:154} INFO - Started process (PID=1444) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:54.875+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:31:54.879+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:54.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:55.026+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:31:56.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:56.005+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:31:56.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:31:56.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:31:56.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.685 seconds
[2022-12-16T13:32:07.308+0000] {processor.py:154} INFO - Started process (PID=1454) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:07.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:32:07.340+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:07.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:07.456+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:08.528+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:32:18.882+0000] {processor.py:154} INFO - Started process (PID=1464) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:18.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:32:18.919+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:18.917+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:19.003+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:19.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:19.361+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:32:19.496+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:19.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:32:19.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.793 seconds
[2022-12-16T13:32:30.252+0000] {processor.py:154} INFO - Started process (PID=1482) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:30.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:32:30.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:30.284+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:30.678+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:32.026+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:32:43.303+0000] {processor.py:154} INFO - Started process (PID=1492) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:43.325+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:32:43.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:43.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:43.466+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:43.741+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:43.740+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:32:43.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:43.919+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:32:44.111+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.858 seconds
[2022-12-16T13:32:54.838+0000] {processor.py:154} INFO - Started process (PID=1502) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:54.860+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:32:54.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:54.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:54.952+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:32:55.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:55.158+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:32:55.354+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:32:55.353+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:32:55.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.688 seconds
[2022-12-16T13:33:05.867+0000] {processor.py:154} INFO - Started process (PID=1512) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:05.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:33:05.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:05.915+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:06.250+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:07.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:07.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:33:07.370+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:07.369+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:33:07.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.727 seconds
[2022-12-16T13:33:18.557+0000] {processor.py:154} INFO - Started process (PID=1529) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:18.576+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:33:18.596+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:18.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:19.101+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:20.381+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:20.380+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:33:20.913+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:20.912+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:33:21.432+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.963 seconds
[2022-12-16T13:33:32.034+0000] {processor.py:154} INFO - Started process (PID=1539) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:32.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:33:32.058+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:32.057+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:32.353+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:33.005+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:33.004+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:33:33.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:33.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:33:33.628+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.669 seconds
[2022-12-16T13:33:44.228+0000] {processor.py:154} INFO - Started process (PID=1549) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:44.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:33:44.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:44.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:44.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:44.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:44.924+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:33:45.152+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:45.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:33:45.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.349 seconds
[2022-12-16T13:33:56.063+0000] {processor.py:154} INFO - Started process (PID=1559) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:56.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:33:56.158+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:56.154+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:56.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:33:56.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:56.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:33:56.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:33:56.835+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:33:57.018+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.016 seconds
[2022-12-16T13:34:07.666+0000] {processor.py:154} INFO - Started process (PID=1577) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:07.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:34:07.705+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:07.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:08.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:08.846+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:08.845+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:34:09.075+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:09.074+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:34:09.422+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.834 seconds
[2022-12-16T13:34:20.341+0000] {processor.py:154} INFO - Started process (PID=1587) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:20.413+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:34:20.450+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:20.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:20.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:22.770+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:22.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:34:23.215+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:23.214+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:34:23.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.313 seconds
[2022-12-16T13:34:34.190+0000] {processor.py:154} INFO - Started process (PID=1597) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:34.194+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:34:34.214+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:34.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:34.771+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:36.335+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:34:46.523+0000] {processor.py:154} INFO - Started process (PID=1607) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:46.532+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:34:46.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:46.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:46.874+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:47.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:47.810+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:34:48.327+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:48.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:34:48.648+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.145 seconds
[2022-12-16T13:34:59.235+0000] {processor.py:154} INFO - Started process (PID=1625) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:59.265+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:34:59.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:34:59.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:34:59.629+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:00.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:00.827+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:35:01.352+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:01.351+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:35:01.919+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.764 seconds
[2022-12-16T13:35:12.625+0000] {processor.py:154} INFO - Started process (PID=1638) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:12.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:35:12.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:12.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:12.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:13.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:13.996+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:35:14.579+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:14.578+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:35:15.257+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.681 seconds
[2022-12-16T13:35:25.875+0000] {processor.py:154} INFO - Started process (PID=1650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:25.898+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:35:25.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:25.901+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:26.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:26.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:26.327+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:35:26.634+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:26.633+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:35:26.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.054 seconds
[2022-12-16T13:35:37.370+0000] {processor.py:154} INFO - Started process (PID=1666) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:37.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:35:37.445+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:37.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:37.694+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:38.404+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:38.403+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:35:38.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:38.833+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:35:39.489+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.159 seconds
[2022-12-16T13:35:50.037+0000] {processor.py:154} INFO - Started process (PID=1677) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:50.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:35:50.046+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:50.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:50.148+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:35:50.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:50.391+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:35:50.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:35:50.555+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:35:50.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.694 seconds
[2022-12-16T13:36:01.128+0000] {processor.py:154} INFO - Started process (PID=1685) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:01.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:36:01.138+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:01.137+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:01.399+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:01.648+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:01.647+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:36:01.811+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:01.810+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:36:02.000+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.891 seconds
[2022-12-16T13:36:12.436+0000] {processor.py:154} INFO - Started process (PID=1695) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:12.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:36:12.469+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:12.468+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:12.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:13.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:13.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:36:13.718+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:13.717+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:36:14.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.622 seconds
[2022-12-16T13:36:24.551+0000] {processor.py:154} INFO - Started process (PID=1710) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:24.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:36:24.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:24.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:24.801+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:26.476+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:36:37.056+0000] {processor.py:154} INFO - Started process (PID=1720) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:37.089+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:36:37.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:37.095+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:37.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:38.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:38.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:36:39.126+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:39.125+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:36:39.539+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.502 seconds
[2022-12-16T13:36:50.078+0000] {processor.py:154} INFO - Started process (PID=1730) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:50.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:36:50.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:50.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:50.234+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:36:50.497+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:50.496+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:36:50.704+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:36:50.704+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:36:50.841+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.779 seconds
[2022-12-16T13:37:01.179+0000] {processor.py:154} INFO - Started process (PID=1740) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:01.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:01.188+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:01.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:01.275+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:02.126+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:02.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:02.264+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:02.263+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:37:02.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.223 seconds
[2022-12-16T13:37:12.877+0000] {processor.py:154} INFO - Started process (PID=1758) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:12.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:12.947+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:12.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:13.232+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:14.110+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:14.109+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:14.287+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:14.286+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:37:14.930+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.069 seconds
[2022-12-16T13:37:25.245+0000] {processor.py:154} INFO - Started process (PID=1768) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:25.270+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:25.275+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:25.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:25.361+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:25.579+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:25.578+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:25.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:25.708+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:37:25.851+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.620 seconds
[2022-12-16T13:37:36.032+0000] {processor.py:154} INFO - Started process (PID=1778) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:36.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:36.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:36.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:36.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:37.019+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:37.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:37.155+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:37.154+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:37:37.268+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.255 seconds
[2022-12-16T13:37:47.620+0000] {processor.py:154} INFO - Started process (PID=1795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:47.648+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:47.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:47.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:47.816+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:48.212+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:48.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:48.526+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:48.523+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:37:48.816+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.212 seconds
[2022-12-16T13:37:59.213+0000] {processor.py:154} INFO - Started process (PID=1806) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:59.217+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:37:59.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:59.220+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:59.307+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:37:59.725+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:59.724+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:37:59.883+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:37:59.882+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:38:00.054+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.856 seconds
[2022-12-16T13:38:10.258+0000] {processor.py:154} INFO - Started process (PID=1816) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:10.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:38:10.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:10.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:10.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:10.820+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:10.818+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:38:11.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:11.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:38:11.325+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.085 seconds
[2022-12-16T13:38:21.735+0000] {processor.py:154} INFO - Started process (PID=1826) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:21.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:38:21.776+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:21.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:22.052+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:22.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:22.346+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:38:22.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:22.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:38:22.656+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.071 seconds
[2022-12-16T13:38:32.972+0000] {processor.py:154} INFO - Started process (PID=1844) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:32.982+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:38:32.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:32.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:33.226+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:34.630+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:34.629+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:38:35.104+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:35.103+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:38:35.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.508 seconds
[2022-12-16T13:38:46.202+0000] {processor.py:154} INFO - Started process (PID=1854) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:46.230+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:38:46.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:46.233+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:46.487+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:47.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:47.538+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:38:47.947+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:47.938+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:38:48.304+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.150 seconds
[2022-12-16T13:38:58.698+0000] {processor.py:154} INFO - Started process (PID=1864) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:58.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:38:58.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:38:58.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:38:59.003+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:00.389+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:39:10.808+0000] {processor.py:154} INFO - Started process (PID=1874) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:10.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:39:10.817+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:10.816+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:10.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:11.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:11.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:39:11.298+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:11.297+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:39:11.459+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-16T13:39:22.007+0000] {processor.py:154} INFO - Started process (PID=1892) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:22.050+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:39:22.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:22.110+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:22.687+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:23.154+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:23.146+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:39:23.337+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:23.336+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:39:23.579+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.676 seconds
[2022-12-16T13:39:33.981+0000] {processor.py:154} INFO - Started process (PID=1902) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:34.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:39:34.233+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:34.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:34.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:34.905+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:34.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:39:35.044+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:35.043+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:39:35.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.278 seconds
[2022-12-16T13:39:45.534+0000] {processor.py:154} INFO - Started process (PID=1912) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:45.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:39:45.575+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:45.574+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:45.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:46.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:46.424+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:39:46.568+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:46.567+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:39:46.679+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.200 seconds
[2022-12-16T13:39:57.114+0000] {processor.py:154} INFO - Started process (PID=1931) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:57.131+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:39:57.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:57.134+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:57.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:39:57.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:57.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:39:58.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:39:58.170+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:39:58.489+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.415 seconds
[2022-12-16T13:40:08.829+0000] {processor.py:154} INFO - Started process (PID=1941) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:08.834+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:40:08.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:08.837+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:08.949+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:10.559+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:40:21.127+0000] {processor.py:154} INFO - Started process (PID=1951) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:21.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:40:21.143+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:21.140+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:21.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:21.870+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:21.869+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:40:22.057+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:22.056+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:40:22.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.283 seconds
[2022-12-16T13:40:33.037+0000] {processor.py:154} INFO - Started process (PID=1961) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:33.043+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:40:33.047+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:33.046+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:33.179+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:33.757+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:33.756+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:40:34.115+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:34.113+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:40:34.317+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.298 seconds
[2022-12-16T13:40:44.919+0000] {processor.py:154} INFO - Started process (PID=1979) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:44.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:40:44.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:44.934+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:45.145+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:46.806+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:40:57.522+0000] {processor.py:154} INFO - Started process (PID=1989) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:57.529+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:40:57.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:57.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:57.718+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:40:58.168+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:58.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:40:58.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:40:58.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:40:58.491+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.008 seconds
[2022-12-16T13:41:08.846+0000] {processor.py:154} INFO - Started process (PID=1999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:08.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:41:08.855+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:08.854+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:08.950+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:09.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:09.319+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:41:09.555+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:09.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:41:09.695+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-16T13:41:20.149+0000] {processor.py:154} INFO - Started process (PID=2009) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:20.180+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:41:20.190+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:20.189+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:20.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:22.233+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:41:32.613+0000] {processor.py:154} INFO - Started process (PID=2027) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:32.638+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:41:32.648+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:32.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:32.749+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:33.779+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:41:44.215+0000] {processor.py:154} INFO - Started process (PID=2037) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:44.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:41:44.223+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:44.222+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:44.343+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:45.374+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:45.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:41:45.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:45.536+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:41:45.704+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.506 seconds
[2022-12-16T13:41:56.392+0000] {processor.py:154} INFO - Started process (PID=2047) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:56.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:41:56.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:56.424+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:56.578+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:41:57.098+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:57.097+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:41:57.745+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:41:57.744+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:41:58.128+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.849 seconds
[2022-12-16T13:42:08.913+0000] {processor.py:154} INFO - Started process (PID=2065) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:08.917+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:42:08.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:08.936+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:09.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:10.789+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:42:21.348+0000] {processor.py:154} INFO - Started process (PID=2075) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:21.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:42:21.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:21.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:21.462+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:22.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:22.233+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:42:22.655+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:22.642+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:42:22.944+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.636 seconds
[2022-12-16T13:42:33.328+0000] {processor.py:154} INFO - Started process (PID=2085) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:33.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:42:33.337+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:33.336+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:33.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:33.870+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:33.869+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:42:34.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:34.026+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:42:34.152+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.845 seconds
[2022-12-16T13:42:44.944+0000] {processor.py:154} INFO - Started process (PID=2095) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:44.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:42:44.953+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:44.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:45.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:45.455+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:45.454+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:42:45.670+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:45.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:42:45.864+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.939 seconds
[2022-12-16T13:42:56.507+0000] {processor.py:154} INFO - Started process (PID=2113) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:56.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:42:56.569+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:56.568+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:56.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:42:57.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:57.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:42:58.453+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:42:58.452+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:42:58.923+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.433 seconds
[2022-12-16T13:43:09.698+0000] {processor.py:154} INFO - Started process (PID=2123) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:09.706+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:43:09.710+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:09.709+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:09.843+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:10.109+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:10.108+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:43:10.259+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:10.258+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:43:10.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.728 seconds
[2022-12-16T13:43:20.702+0000] {processor.py:154} INFO - Started process (PID=2133) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:20.714+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:43:20.719+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:20.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:20.920+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:21.344+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:21.343+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:43:21.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:21.542+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:43:21.728+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.068 seconds
[2022-12-16T13:43:32.143+0000] {processor.py:154} INFO - Started process (PID=2151) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:32.168+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:43:32.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:32.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:32.373+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:33.632+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:43:44.139+0000] {processor.py:154} INFO - Started process (PID=2162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:44.143+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:43:44.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:44.147+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:44.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:44.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:44.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:43:45.140+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:45.139+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:43:45.281+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.161 seconds
[2022-12-16T13:43:55.635+0000] {processor.py:154} INFO - Started process (PID=2172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:55.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:43:55.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:55.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:55.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:43:55.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:55.962+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:43:56.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:43:56.095+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:43:56.246+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.627 seconds
[2022-12-16T13:44:07.113+0000] {processor.py:154} INFO - Started process (PID=2182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:07.139+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:44:07.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:07.142+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:07.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:07.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:07.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:44:07.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:07.734+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:44:07.886+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.797 seconds
[2022-12-16T13:44:18.591+0000] {processor.py:154} INFO - Started process (PID=2200) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:18.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:44:18.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:18.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:18.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:19.334+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:19.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:44:19.785+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:19.784+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:44:20.088+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.532 seconds
[2022-12-16T13:44:30.345+0000] {processor.py:154} INFO - Started process (PID=2210) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:30.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:44:30.353+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:30.352+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:30.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:31.189+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:31.188+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:44:31.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:31.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:44:31.581+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.252 seconds
[2022-12-16T13:44:41.724+0000] {processor.py:154} INFO - Started process (PID=2220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:41.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:44:41.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:41.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:41.878+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:42.271+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:42.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:44:42.435+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:42.434+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:44:42.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.847 seconds
[2022-12-16T13:44:53.236+0000] {processor.py:154} INFO - Started process (PID=2230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:53.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:44:53.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:53.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:53.439+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:44:53.972+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:53.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:44:54.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:44:54.196+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:44:54.318+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.116 seconds
[2022-12-16T13:45:04.572+0000] {processor.py:154} INFO - Started process (PID=2248) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:04.596+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:45:04.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:04.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:04.825+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:05.713+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:05.712+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:45:06.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:06.424+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:45:07.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.590 seconds
[2022-12-16T13:45:17.672+0000] {processor.py:154} INFO - Started process (PID=2258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:17.677+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:45:17.685+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:17.684+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:17.832+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:18.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:18.095+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:45:18.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:18.269+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:45:18.514+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.872 seconds
[2022-12-16T13:45:29.024+0000] {processor.py:154} INFO - Started process (PID=2268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:29.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:45:29.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:29.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:29.347+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:30.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:30.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:45:30.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:30.277+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:45:30.490+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.503 seconds
[2022-12-16T13:45:40.674+0000] {processor.py:154} INFO - Started process (PID=2278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:40.679+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:45:40.683+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:40.682+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:40.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:41.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:41.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:45:41.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:41.279+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:45:41.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.009 seconds
[2022-12-16T13:45:52.202+0000] {processor.py:154} INFO - Started process (PID=2296) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:52.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:45:52.217+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:52.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:52.390+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:45:52.994+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:52.993+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:45:53.346+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:45:53.346+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:45:53.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.442 seconds
[2022-12-16T13:46:03.898+0000] {processor.py:154} INFO - Started process (PID=2306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:03.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:46:03.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:03.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:04.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:05.067+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:46:15.403+0000] {processor.py:154} INFO - Started process (PID=2316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:15.408+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:46:15.412+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:15.411+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:15.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:16.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:16.147+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:46:16.299+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:16.298+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:46:16.419+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.032 seconds
[2022-12-16T13:46:26.935+0000] {processor.py:154} INFO - Started process (PID=2332) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:26.952+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:46:26.959+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:26.958+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:27.106+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:28.029+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:46:38.746+0000] {processor.py:154} INFO - Started process (PID=2343) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:38.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:46:38.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:38.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:39.087+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:39.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:39.432+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:46:39.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:39.601+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:46:39.848+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.155 seconds
[2022-12-16T13:46:50.338+0000] {processor.py:154} INFO - Started process (PID=2353) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:50.377+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:46:50.409+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:50.398+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:50.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:46:51.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:51.327+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:46:51.457+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:46:51.456+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:46:51.611+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.339 seconds
[2022-12-16T13:47:02.086+0000] {processor.py:154} INFO - Started process (PID=2363) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:02.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:47:02.110+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:02.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:02.210+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:03.034+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:03.033+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:47:03.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:03.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:47:03.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.282 seconds
[2022-12-16T13:47:14.411+0000] {processor.py:154} INFO - Started process (PID=2381) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:14.455+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:47:14.476+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:14.462+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:15.167+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:16.655+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:16.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:47:17.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:17.121+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:47:17.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.182 seconds
[2022-12-16T13:47:28.032+0000] {processor.py:154} INFO - Started process (PID=2391) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:28.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:47:28.046+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:28.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:28.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:28.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:28.531+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:47:28.730+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:28.729+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:47:28.911+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.914 seconds
[2022-12-16T13:47:39.554+0000] {processor.py:154} INFO - Started process (PID=2401) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:39.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:47:39.565+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:39.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:39.699+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:39.962+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:39.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:47:40.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:40.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:47:40.422+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.895 seconds
[2022-12-16T13:47:50.968+0000] {processor.py:154} INFO - Started process (PID=2411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:50.995+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:47:51.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:50.999+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:51.146+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:47:51.682+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:51.681+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:47:51.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:47:51.868+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:47:52.006+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.074 seconds
[2022-12-16T13:48:02.695+0000] {processor.py:154} INFO - Started process (PID=2430) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:02.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:48:02.743+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:02.741+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:03.041+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:03.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:03.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:48:03.902+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:03.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:48:04.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.501 seconds
[2022-12-16T13:48:14.503+0000] {processor.py:154} INFO - Started process (PID=2440) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:14.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:48:14.570+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:14.569+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:14.783+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:16.185+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:16.184+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:48:16.371+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:16.370+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:48:16.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.085 seconds
[2022-12-16T13:48:27.004+0000] {processor.py:154} INFO - Started process (PID=2450) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:27.046+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:48:27.058+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:27.057+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:27.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:27.949+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:27.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:48:28.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:28.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:48:28.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.448 seconds
[2022-12-16T13:48:38.850+0000] {processor.py:154} INFO - Started process (PID=2460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:38.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:48:38.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:38.867+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:38.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:39.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:39.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:48:39.751+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:39.750+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:48:39.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.065 seconds
[2022-12-16T13:48:50.478+0000] {processor.py:154} INFO - Started process (PID=2478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:50.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:48:50.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:48:50.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:50.849+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:48:51.769+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:49:02.372+0000] {processor.py:154} INFO - Started process (PID=2488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:02.378+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:49:02.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:02.386+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:02.643+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:03.341+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:03.340+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:49:03.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:03.720+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:49:03.832+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.514 seconds
[2022-12-16T13:49:14.503+0000] {processor.py:154} INFO - Started process (PID=2498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:14.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:49:14.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:14.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:14.619+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:15.203+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:15.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:49:15.367+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:15.366+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:49:15.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.047 seconds
[2022-12-16T13:49:25.889+0000] {processor.py:154} INFO - Started process (PID=2508) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:25.934+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:49:25.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:25.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:26.135+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:26.409+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:26.408+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:49:26.571+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:26.570+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:49:26.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.836 seconds
[2022-12-16T13:49:37.377+0000] {processor.py:154} INFO - Started process (PID=2526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:37.466+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:49:37.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:37.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:37.913+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:38.624+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:38.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:49:38.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:38.843+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:49:39.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.785 seconds
[2022-12-16T13:49:49.552+0000] {processor.py:154} INFO - Started process (PID=2536) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:49.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:49:49.560+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:49.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:49.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:49:49.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:49.990+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:49:50.160+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:49:50.160+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:49:50.359+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.836 seconds
[2022-12-16T13:50:00.790+0000] {processor.py:154} INFO - Started process (PID=2546) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:00.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:50:00.835+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:00.834+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:01.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:02.083+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:02.082+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:50:02.246+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:02.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:50:02.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.661 seconds
[2022-12-16T13:50:12.770+0000] {processor.py:154} INFO - Started process (PID=2556) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:12.792+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:50:12.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:12.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:13.052+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:13.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:13.827+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:50:14.019+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:14.018+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:50:14.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.791 seconds
[2022-12-16T13:50:25.485+0000] {processor.py:154} INFO - Started process (PID=2575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:25.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:50:25.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:25.528+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:25.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:26.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:26.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:50:27.306+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:27.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:50:27.535+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.216 seconds
[2022-12-16T13:50:38.042+0000] {processor.py:154} INFO - Started process (PID=2585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:38.100+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:50:38.105+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:38.103+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:38.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:38.541+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:38.540+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:50:38.707+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:38.706+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:50:38.843+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.823 seconds
[2022-12-16T13:50:49.177+0000] {processor.py:154} INFO - Started process (PID=2595) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:49.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:50:49.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:50:49.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:49.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:50:50.468+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:51:01.269+0000] {processor.py:154} INFO - Started process (PID=2612) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:01.372+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:51:01.387+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:01.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:02.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:02.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:02.587+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:51:03.213+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:03.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:51:03.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.416 seconds
[2022-12-16T13:51:13.855+0000] {processor.py:154} INFO - Started process (PID=2623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:13.865+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:51:13.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:13.871+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:14.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:15.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:15.006+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:51:15.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:15.643+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:51:15.985+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.195 seconds
[2022-12-16T13:51:26.625+0000] {processor.py:154} INFO - Started process (PID=2633) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:26.653+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:51:26.658+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:26.657+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:26.849+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:27.722+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:27.721+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:51:28.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:28.053+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:51:28.324+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.737 seconds
[2022-12-16T13:51:38.784+0000] {processor.py:154} INFO - Started process (PID=2643) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:38.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:51:38.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:38.853+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:39.008+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:39.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:39.675+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:51:39.924+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:39.923+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:51:40.624+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.888 seconds
[2022-12-16T13:51:51.122+0000] {processor.py:154} INFO - Started process (PID=2661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:51.171+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:51:51.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:51:51.175+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:51.434+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:51:53.055+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:52:03.771+0000] {processor.py:154} INFO - Started process (PID=2671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:03.778+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:52:03.783+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:03.781+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:03.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:04.759+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:52:15.245+0000] {processor.py:154} INFO - Started process (PID=2681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:15.254+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:52:15.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:15.257+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:15.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:15.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:15.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:52:16.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:16.026+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:52:16.227+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.043 seconds
[2022-12-16T13:52:26.698+0000] {processor.py:154} INFO - Started process (PID=2691) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:26.711+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:52:26.715+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:26.714+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:26.809+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:27.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:27.134+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:52:27.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:27.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:52:27.516+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.855 seconds
[2022-12-16T13:52:38.103+0000] {processor.py:154} INFO - Started process (PID=2708) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:38.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:52:38.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:38.119+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:38.221+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:39.332+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:52:50.045+0000] {processor.py:154} INFO - Started process (PID=2716) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:50.048+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:52:50.057+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:50.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:50.258+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:52:50.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:50.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:52:50.714+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:52:50.713+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:52:50.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.840 seconds
[2022-12-16T13:53:01.466+0000] {processor.py:154} INFO - Started process (PID=2726) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:01.481+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:53:01.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:01.530+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:02.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:02.595+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:02.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:53:02.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:02.936+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:53:03.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.772 seconds
[2022-12-16T13:53:13.597+0000] {processor.py:154} INFO - Started process (PID=2736) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:13.624+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:53:13.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:13.627+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:13.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:14.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:14.515+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:53:14.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:14.710+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:53:15.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.495 seconds
[2022-12-16T13:53:26.043+0000] {processor.py:154} INFO - Started process (PID=2754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:26.046+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:53:26.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:26.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:26.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:27.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:27.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:53:27.603+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:27.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:53:27.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.922 seconds
[2022-12-16T13:53:38.612+0000] {processor.py:154} INFO - Started process (PID=2764) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:38.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:53:38.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:38.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:39.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:40.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:40.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:53:40.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:40.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:53:41.055+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.521 seconds
[2022-12-16T13:53:51.570+0000] {processor.py:154} INFO - Started process (PID=2776) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:51.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:53:51.604+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:53:51.603+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:51.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:53:52.779+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:54:03.392+0000] {processor.py:154} INFO - Started process (PID=2792) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:03.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:54:03.430+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:03.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:03.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:04.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:04.585+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:54:04.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:04.997+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:54:05.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.979 seconds
[2022-12-16T13:54:15.799+0000] {processor.py:154} INFO - Started process (PID=2805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:15.802+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:54:15.806+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:15.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:15.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:16.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:16.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:54:16.406+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:16.405+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:54:16.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-16T13:54:27.065+0000] {processor.py:154} INFO - Started process (PID=2815) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:27.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:54:27.157+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:27.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:27.336+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:27.687+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:27.686+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:54:27.850+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:27.849+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:54:27.995+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.957 seconds
[2022-12-16T13:54:38.448+0000] {processor.py:154} INFO - Started process (PID=2823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:38.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:54:38.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:38.466+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:38.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:40.459+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:40.458+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:54:40.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:40.649+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:54:40.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.383 seconds
[2022-12-16T13:54:51.426+0000] {processor.py:154} INFO - Started process (PID=2841) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:51.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:54:51.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:51.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:51.859+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:54:52.572+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:52.571+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:54:52.820+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:54:52.819+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:54:53.085+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.686 seconds
[2022-12-16T13:55:03.570+0000] {processor.py:154} INFO - Started process (PID=2851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:03.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:55:03.629+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:03.626+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:03.844+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:04.399+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:04.397+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:55:04.714+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:04.713+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:55:04.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.478 seconds
[2022-12-16T13:55:15.667+0000] {processor.py:154} INFO - Started process (PID=2863) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:15.683+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:55:15.707+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:15.694+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:16.010+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:16.438+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:16.437+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:55:16.603+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:16.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:55:16.740+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.155 seconds
[2022-12-16T13:55:27.124+0000] {processor.py:154} INFO - Started process (PID=2871) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:27.186+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:55:27.190+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:27.189+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:27.480+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:27.945+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:27.944+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:55:28.109+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:28.108+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:55:28.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.147 seconds
[2022-12-16T13:55:38.709+0000] {processor.py:154} INFO - Started process (PID=2888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:38.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:55:38.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:38.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:39.009+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:40.004+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:40.003+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:55:40.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:40.299+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:55:40.558+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.931 seconds
[2022-12-16T13:55:51.145+0000] {processor.py:154} INFO - Started process (PID=2898) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:51.203+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:55:51.210+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:51.209+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:51.550+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:55:52.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:52.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:55:53.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:55:53.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:55:53.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.181 seconds
[2022-12-16T13:56:03.766+0000] {processor.py:154} INFO - Started process (PID=2908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:03.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:56:03.806+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:03.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:04.005+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:04.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:04.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:56:04.498+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:04.497+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:56:04.662+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.943 seconds
[2022-12-16T13:56:14.984+0000] {processor.py:154} INFO - Started process (PID=2925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:15.044+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:56:15.053+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:15.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:15.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:15.752+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:15.751+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:56:16.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:16.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:56:16.701+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.736 seconds
[2022-12-16T13:56:27.596+0000] {processor.py:154} INFO - Started process (PID=2933) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:27.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:56:27.615+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:27.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:27.809+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:29.069+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:56:40.007+0000] {processor.py:154} INFO - Started process (PID=2943) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:40.055+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:56:40.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:40.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:40.176+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:41.476+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T13:56:52.101+0000] {processor.py:154} INFO - Started process (PID=2956) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:52.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:56:52.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:52.135+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:52.273+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:56:53.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:53.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:56:54.196+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:56:54.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:56:54.561+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.479 seconds
[2022-12-16T13:57:05.054+0000] {processor.py:154} INFO - Started process (PID=2973) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:05.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:57:05.076+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:05.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:05.285+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:06.268+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:06.267+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:57:07.132+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:07.131+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:57:07.662+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.646 seconds
[2022-12-16T13:57:18.157+0000] {processor.py:154} INFO - Started process (PID=2980) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:18.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:57:18.167+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:18.166+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:18.324+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:19.811+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:19.810+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:57:20.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:20.120+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:57:20.390+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.250 seconds
[2022-12-16T13:57:30.801+0000] {processor.py:154} INFO - Started process (PID=2990) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:30.825+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:57:30.829+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:30.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:30.986+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:31.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:31.393+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:57:31.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:31.597+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:57:31.961+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.211 seconds
[2022-12-16T13:57:42.562+0000] {processor.py:154} INFO - Started process (PID=3007) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:42.577+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:57:42.582+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:42.581+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:42.760+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:43.088+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:43.087+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:57:43.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:43.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:57:43.588+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.109 seconds
[2022-12-16T13:57:53.993+0000] {processor.py:154} INFO - Started process (PID=3018) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:53.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:57:54.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:54.000+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:54.098+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:57:54.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:54.321+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:57:54.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:57:54.483+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:57:54.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.677 seconds
[2022-12-16T13:58:05.078+0000] {processor.py:154} INFO - Started process (PID=3028) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:05.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:58:05.140+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:05.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:05.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:06.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:06.013+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:58:06.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:06.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:58:06.411+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.366 seconds
[2022-12-16T13:58:16.732+0000] {processor.py:154} INFO - Started process (PID=3038) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:16.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:58:16.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:16.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:16.925+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:17.275+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:17.274+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:58:17.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:17.538+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:58:17.722+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-16T13:58:28.010+0000] {processor.py:154} INFO - Started process (PID=3056) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:28.034+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:58:28.051+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:28.042+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:28.286+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:28.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:28.905+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:58:29.153+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:29.152+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:58:29.497+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-16T13:58:40.141+0000] {processor.py:154} INFO - Started process (PID=3066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:40.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:58:40.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:40.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:40.718+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:41.670+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:41.669+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:58:41.861+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:41.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:58:41.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.868 seconds
[2022-12-16T13:58:52.454+0000] {processor.py:154} INFO - Started process (PID=3079) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:52.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:58:52.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:52.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:52.862+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:58:53.490+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:53.489+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:58:53.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:58:53.683+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:58:53.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.469 seconds
[2022-12-16T13:59:04.213+0000] {processor.py:154} INFO - Started process (PID=3093) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:04.217+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:59:04.237+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:04.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:04.561+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:05.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:05.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:59:05.514+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:05.513+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:59:05.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.592 seconds
[2022-12-16T13:59:16.631+0000] {processor.py:154} INFO - Started process (PID=3104) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:16.636+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:59:16.642+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:16.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:16.834+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:17.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:17.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:59:17.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:17.382+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:59:17.572+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-16T13:59:27.803+0000] {processor.py:154} INFO - Started process (PID=3114) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:27.856+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:59:27.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:27.859+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:28.048+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:28.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:28.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:59:28.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:28.536+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:59:28.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.892 seconds
[2022-12-16T13:59:39.045+0000] {processor.py:154} INFO - Started process (PID=3124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:39.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:59:39.098+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:39.096+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:39.188+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:39.432+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:39.431+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:59:39.633+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:39.632+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:59:39.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.760 seconds
[2022-12-16T13:59:50.314+0000] {processor.py:154} INFO - Started process (PID=3142) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:50.372+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T13:59:50.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:50.380+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:50.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T13:59:51.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:51.809+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T13:59:52.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T13:59:52.342+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T13:59:52.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.544 seconds
[2022-12-16T14:00:03.233+0000] {processor.py:154} INFO - Started process (PID=3152) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:03.270+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:00:03.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:03.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:03.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:04.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:04.492+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:00:05.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:05.214+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:00:05.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.634 seconds
[2022-12-16T14:00:16.432+0000] {processor.py:154} INFO - Started process (PID=3162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:16.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:00:16.481+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:16.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:16.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:17.138+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:17.137+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:00:17.705+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:17.704+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:00:18.132+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.717 seconds
[2022-12-16T14:00:28.641+0000] {processor.py:154} INFO - Started process (PID=3172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:28.661+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:00:28.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:28.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:29.022+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:29.523+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:29.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:00:29.705+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:29.704+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:00:29.921+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.312 seconds
[2022-12-16T14:00:40.416+0000] {processor.py:154} INFO - Started process (PID=3190) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:40.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:00:40.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:40.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:40.797+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:42.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:42.127+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:00:42.325+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:42.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:00:42.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.129 seconds
[2022-12-16T14:00:52.891+0000] {processor.py:154} INFO - Started process (PID=3203) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:52.898+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:00:52.909+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:52.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:53.014+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:00:53.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:53.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:00:53.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:00:53.414+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:00:53.554+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.695 seconds
[2022-12-16T14:01:03.838+0000] {processor.py:154} INFO - Started process (PID=3213) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:03.863+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:01:03.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:03.866+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:03.985+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:04.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:04.785+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:01:05.100+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:05.099+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:01:05.266+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.444 seconds
[2022-12-16T14:01:15.841+0000] {processor.py:154} INFO - Started process (PID=3228) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:15.888+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:01:15.922+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:15.912+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:16.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:16.977+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:16.976+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:01:17.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:17.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:01:17.776+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.050 seconds
[2022-12-16T14:01:28.315+0000] {processor.py:154} INFO - Started process (PID=3238) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:28.329+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:01:28.340+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:28.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:28.695+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:30.298+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:30.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:01:30.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:30.591+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:01:30.728+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.486 seconds
[2022-12-16T14:01:41.195+0000] {processor.py:154} INFO - Started process (PID=3253) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:41.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:01:41.221+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:41.219+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:41.393+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:41.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:41.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:01:41.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:41.943+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:01:42.673+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.497 seconds
[2022-12-16T14:01:53.221+0000] {processor.py:154} INFO - Started process (PID=3261) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:53.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:01:53.235+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:53.234+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:53.434+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:01:53.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:53.723+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:01:53.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:01:53.985+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:01:54.147+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.994 seconds
[2022-12-16T14:02:04.733+0000] {processor.py:154} INFO - Started process (PID=3278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:04.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:02:04.749+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:04.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:05.009+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:06.939+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:02:17.573+0000] {processor.py:154} INFO - Started process (PID=3288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:17.624+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:02:17.640+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:17.639+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:17.936+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:18.558+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:18.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:02:18.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:18.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:02:19.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.578 seconds
[2022-12-16T14:02:29.554+0000] {processor.py:154} INFO - Started process (PID=3298) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:29.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:02:29.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:29.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:29.740+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:30.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:30.005+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:02:30.356+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:30.355+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:02:30.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.229 seconds
[2022-12-16T14:02:41.197+0000] {processor.py:154} INFO - Started process (PID=3308) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:41.201+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:02:41.206+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:41.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:41.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:42.304+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:42.303+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:02:42.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:42.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:02:43.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.874 seconds
[2022-12-16T14:02:53.392+0000] {processor.py:154} INFO - Started process (PID=3323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:53.441+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:02:53.453+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:53.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:53.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:02:55.331+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:55.321+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:02:55.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:02:55.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:02:56.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.036 seconds
[2022-12-16T14:03:06.737+0000] {processor.py:154} INFO - Started process (PID=3336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:06.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:03:06.771+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:06.770+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:06.867+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:08.645+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:08.644+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:03:09.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:09.119+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:03:09.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.636 seconds
[2022-12-16T14:03:19.779+0000] {processor.py:154} INFO - Started process (PID=3343) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:19.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:03:19.813+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:19.812+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:20.215+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:22.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:22.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:03:22.370+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:22.370+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:03:22.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.957 seconds
[2022-12-16T14:03:33.497+0000] {processor.py:154} INFO - Started process (PID=3361) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:33.559+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:03:33.627+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:33.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:34.182+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:34.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:34.974+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:03:35.398+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:35.397+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:03:35.753+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.439 seconds
[2022-12-16T14:03:46.093+0000] {processor.py:154} INFO - Started process (PID=3371) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:46.099+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:03:46.119+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:46.118+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:46.363+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:48.037+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:03:58.738+0000] {processor.py:154} INFO - Started process (PID=3384) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:58.769+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:03:58.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:03:58.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:03:59.176+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:00.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:00.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:04:00.850+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:00.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:04:01.042+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.368 seconds
[2022-12-16T14:04:11.501+0000] {processor.py:154} INFO - Started process (PID=3396) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:11.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:04:11.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:11.510+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:11.798+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:12.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:12.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:04:12.448+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:12.446+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:04:12.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.149 seconds
[2022-12-16T14:04:23.130+0000] {processor.py:154} INFO - Started process (PID=3412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:23.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:04:23.166+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:23.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:23.443+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:24.800+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:04:35.230+0000] {processor.py:154} INFO - Started process (PID=3422) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:35.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:04:35.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:35.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:35.422+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:35.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:35.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:04:36.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:36.127+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:04:36.247+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.074 seconds
[2022-12-16T14:04:46.409+0000] {processor.py:154} INFO - Started process (PID=3432) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:46.413+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:04:46.418+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:46.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:46.526+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:46.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:46.768+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:04:46.914+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:46.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:04:47.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.920 seconds
[2022-12-16T14:04:57.841+0000] {processor.py:154} INFO - Started process (PID=3439) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:57.957+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:04:57.970+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:57.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:58.408+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:04:58.750+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:58.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:04:58.991+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:04:58.990+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:04:59.221+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.496 seconds
[2022-12-16T14:05:09.733+0000] {processor.py:154} INFO - Started process (PID=3456) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:09.757+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:05:09.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:09.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:09.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:11.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:11.759+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:05:12.107+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:12.106+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:05:12.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.764 seconds
[2022-12-16T14:05:22.940+0000] {processor.py:154} INFO - Started process (PID=3469) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:22.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:05:22.969+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:22.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:23.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:24.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:24.692+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:05:24.898+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:24.896+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:05:25.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.222 seconds
[2022-12-16T14:05:35.482+0000] {processor.py:154} INFO - Started process (PID=3476) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:35.497+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:05:35.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:35.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:35.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:37.191+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:05:47.588+0000] {processor.py:154} INFO - Started process (PID=3495) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:47.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:05:47.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:05:47.635+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:47.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:05:49.357+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:06:00.522+0000] {processor.py:154} INFO - Started process (PID=3505) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:00.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:06:00.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:00.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:00.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:00.973+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:00.972+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:06:01.367+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:01.366+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:06:01.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.372 seconds
[2022-12-16T14:06:12.387+0000] {processor.py:154} INFO - Started process (PID=3515) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:12.414+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:06:12.419+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:12.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:12.552+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:13.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:13.664+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:06:13.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:13.894+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:06:14.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.914 seconds
[2022-12-16T14:06:24.714+0000] {processor.py:154} INFO - Started process (PID=3525) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:24.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:06:24.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:24.780+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:24.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:25.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:25.389+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:06:25.612+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:25.611+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:06:25.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.209 seconds
[2022-12-16T14:06:36.611+0000] {processor.py:154} INFO - Started process (PID=3543) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:36.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:06:36.646+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:36.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:36.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:37.459+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:37.458+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:06:37.639+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:37.638+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:06:37.865+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.298 seconds
[2022-12-16T14:06:48.416+0000] {processor.py:154} INFO - Started process (PID=3553) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:48.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:06:48.426+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:48.425+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:48.534+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:06:49.881+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:49.880+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:06:50.079+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:06:50.078+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:06:50.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.797 seconds
[2022-12-16T14:07:00.451+0000] {processor.py:154} INFO - Started process (PID=3563) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:00.506+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:00.514+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:00.513+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:00.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:00.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:00.832+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:00.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:00.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:01.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.688 seconds
[2022-12-16T14:07:12.097+0000] {processor.py:154} INFO - Started process (PID=3580) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:12.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:12.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:12.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:12.219+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:12.492+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:12.491+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:12.653+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:12.652+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:12.829+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.750 seconds
[2022-12-16T14:07:23.374+0000] {processor.py:154} INFO - Started process (PID=3591) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:23.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:23.396+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:23.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:23.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:24.117+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:24.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:24.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:24.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:24.411+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.063 seconds
[2022-12-16T14:07:34.822+0000] {processor.py:154} INFO - Started process (PID=3601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:34.877+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:34.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:34.882+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:35.021+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:35.345+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:35.344+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:35.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:35.583+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:35.703+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.900 seconds
[2022-12-16T14:07:46.252+0000] {processor.py:154} INFO - Started process (PID=3611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:46.301+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:46.305+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:46.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:46.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:46.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:46.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:46.881+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:46.880+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:47.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.829 seconds
[2022-12-16T14:07:57.658+0000] {processor.py:154} INFO - Started process (PID=3630) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:57.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:07:57.687+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:57.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:57.825+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:07:58.410+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:58.409+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:07:58.722+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:07:58.721+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:07:59.012+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.468 seconds
[2022-12-16T14:08:09.793+0000] {processor.py:154} INFO - Started process (PID=3640) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:09.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:08:09.821+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:09.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:10.122+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:10.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:10.707+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:08:11.066+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:11.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:08:11.390+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.687 seconds
[2022-12-16T14:08:22.269+0000] {processor.py:154} INFO - Started process (PID=3650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:22.302+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:08:22.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:22.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:22.694+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:23.348+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:23.347+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:08:23.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:23.555+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:08:23.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.579 seconds
[2022-12-16T14:08:34.766+0000] {processor.py:154} INFO - Started process (PID=3660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:34.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:08:34.862+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:34.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:35.121+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:36.490+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:36.489+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:08:36.679+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:36.678+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:08:36.862+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.121 seconds
[2022-12-16T14:08:47.177+0000] {processor.py:154} INFO - Started process (PID=3677) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:47.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:08:47.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:47.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:47.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:48.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:48.341+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:08:48.731+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:48.730+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:08:49.050+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.919 seconds
[2022-12-16T14:08:59.448+0000] {processor.py:154} INFO - Started process (PID=3687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:59.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:08:59.456+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:08:59.455+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:08:59.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:01.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:01.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:09:01.221+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:01.220+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:09:01.331+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.910 seconds
[2022-12-16T14:09:11.610+0000] {processor.py:154} INFO - Started process (PID=3697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:11.651+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:09:11.655+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:11.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:11.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:12.771+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:09:23.083+0000] {processor.py:154} INFO - Started process (PID=3707) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:23.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:09:23.113+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:23.112+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:23.258+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:25.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:25.227+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:09:25.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:25.531+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:09:25.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.622 seconds
[2022-12-16T14:09:36.076+0000] {processor.py:154} INFO - Started process (PID=3724) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:36.098+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:09:36.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:36.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:36.570+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:37.997+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:09:48.580+0000] {processor.py:154} INFO - Started process (PID=3734) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:48.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:09:48.589+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:48.588+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:48.690+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:09:48.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:48.974+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:09:49.186+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:09:49.185+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:09:49.600+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.042 seconds
[2022-12-16T14:10:00.224+0000] {processor.py:154} INFO - Started process (PID=3744) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:00.242+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:00.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:00.257+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:00.545+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:00.848+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:00.848+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:10:01.004+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:01.003+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:10:01.118+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.006 seconds
[2022-12-16T14:10:11.611+0000] {processor.py:154} INFO - Started process (PID=3761) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:11.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:11.649+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:11.649+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:11.855+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:12.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:12.233+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:10:12.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:12.493+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:10:12.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.190 seconds
[2022-12-16T14:10:23.186+0000] {processor.py:154} INFO - Started process (PID=3772) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:23.242+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:23.246+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:23.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:23.444+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:24.970+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:10:35.598+0000] {processor.py:154} INFO - Started process (PID=3782) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:35.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:35.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:35.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:35.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:36.340+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:36.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:10:36.470+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:36.469+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:10:36.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.031 seconds
[2022-12-16T14:10:46.897+0000] {processor.py:154} INFO - Started process (PID=3792) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:46.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:46.943+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:46.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:47.044+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:47.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:47.281+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:10:47.410+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:47.410+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:10:47.523+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.643 seconds
[2022-12-16T14:10:57.836+0000] {processor.py:154} INFO - Started process (PID=3810) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:57.869+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:10:57.877+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:57.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:58.033+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:10:58.962+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:58.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:10:59.176+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:10:59.175+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:10:59.337+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.518 seconds
[2022-12-16T14:11:09.822+0000] {processor.py:154} INFO - Started process (PID=3820) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:09.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:11:09.856+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:09.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:10.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:10.560+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:10.559+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:11:10.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:10.688+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:11:10.848+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.053 seconds
[2022-12-16T14:11:21.148+0000] {processor.py:154} INFO - Started process (PID=3830) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:21.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:11:21.156+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:21.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:21.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:11:21.453+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:21.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:11:21.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:11:21.580+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:11:21.742+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.608 seconds
[2022-12-16T14:12:11.752+0000] {processor.py:154} INFO - Started process (PID=167) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:11.805+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:12:11.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:11.809+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:12.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:13.600+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:12:24.014+0000] {processor.py:154} INFO - Started process (PID=182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:24.019+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:12:24.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:24.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:24.158+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:24.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:24.786+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:12:25.100+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:25.097+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:12:25.319+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.323 seconds
[2022-12-16T14:12:35.657+0000] {processor.py:154} INFO - Started process (PID=192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:35.661+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:12:35.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:35.672+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:35.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:36.590+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:36.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:12:36.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:36.802+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:12:36.968+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.325 seconds
[2022-12-16T14:12:47.448+0000] {processor.py:154} INFO - Started process (PID=202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:47.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:12:47.478+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:47.477+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:47.668+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:48.767+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:48.766+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:12:48.910+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:48.909+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:12:49.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.626 seconds
[2022-12-16T14:12:59.295+0000] {processor.py:154} INFO - Started process (PID=217) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:59.302+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:12:59.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:12:59.316+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:12:59.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:00.450+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:00.448+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:13:00.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:00.649+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:13:00.864+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.590 seconds
[2022-12-16T14:13:11.087+0000] {processor.py:154} INFO - Started process (PID=227) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:11.242+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:13:11.246+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:11.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:11.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:12.406+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:12.405+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:13:12.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:12.590+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:13:12.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.704 seconds
[2022-12-16T14:13:23.016+0000] {processor.py:154} INFO - Started process (PID=237) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:23.042+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:13:23.047+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:23.046+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:23.472+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:24.123+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:24.122+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:13:24.252+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:24.251+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:13:24.400+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.406 seconds
[2022-12-16T14:13:34.932+0000] {processor.py:154} INFO - Started process (PID=255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:34.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:13:34.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:34.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:35.192+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:35.510+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:35.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:13:35.839+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:35.837+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:13:35.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.144 seconds
[2022-12-16T14:13:46.609+0000] {processor.py:154} INFO - Started process (PID=265) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:46.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:13:46.642+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:46.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:46.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:48.132+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:48.114+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:13:48.653+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:48.653+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:13:49.086+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.559 seconds
[2022-12-16T14:13:59.363+0000] {processor.py:154} INFO - Started process (PID=275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:59.411+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:13:59.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:13:59.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:13:59.517+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:00.019+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:00.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:14:00.157+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:00.156+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:14:00.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.954 seconds
[2022-12-16T14:14:10.547+0000] {processor.py:154} INFO - Started process (PID=285) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:10.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:14:10.562+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:10.561+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:10.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:10.846+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:10.845+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:14:10.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:10.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:14:11.112+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.579 seconds
[2022-12-16T14:14:21.802+0000] {processor.py:154} INFO - Started process (PID=302) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:21.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:14:21.831+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:21.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:22.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:22.271+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:22.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:14:22.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:22.441+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:14:22.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.848 seconds
[2022-12-16T14:14:33.216+0000] {processor.py:154} INFO - Started process (PID=312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:33.240+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:14:33.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:33.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:33.326+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:34.261+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:14:44.625+0000] {processor.py:154} INFO - Started process (PID=322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:44.655+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:14:44.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:44.658+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:44.743+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:45.081+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:45.080+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:14:45.227+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:45.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:14:45.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-16T14:14:55.780+0000] {processor.py:154} INFO - Started process (PID=340) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:55.825+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:14:55.829+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:55.828+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:56.094+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:14:56.747+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:56.746+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:14:57.039+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:14:57.037+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:14:57.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.466 seconds
[2022-12-16T14:15:07.714+0000] {processor.py:154} INFO - Started process (PID=350) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:07.746+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:15:07.750+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:07.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:07.863+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:08.165+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:15:18.654+0000] {processor.py:154} INFO - Started process (PID=360) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:18.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:15:18.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:18.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:18.925+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:19.206+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:19.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:15:19.900+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:19.899+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:15:20.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.550 seconds
[2022-12-16T14:15:30.919+0000] {processor.py:154} INFO - Started process (PID=370) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:30.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:15:30.938+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:30.937+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:31.050+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:32.353+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:15:42.793+0000] {processor.py:154} INFO - Started process (PID=391) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:42.798+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:15:42.802+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:42.801+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:42.913+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:43.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:43.722+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:15:44.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:44.086+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:15:44.228+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.454 seconds
[2022-12-16T14:15:54.671+0000] {processor.py:154} INFO - Started process (PID=401) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:54.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:15:54.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:54.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:54.832+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:15:55.093+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:55.092+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:15:55.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:15:55.254+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:15:55.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.753 seconds
[2022-12-16T14:16:05.754+0000] {processor.py:154} INFO - Started process (PID=411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:05.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:16:05.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:05.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:05.873+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:06.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:06.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:16:06.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:06.379+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:16:06.502+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.769 seconds
[2022-12-16T14:16:17.100+0000] {processor.py:154} INFO - Started process (PID=428) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:17.113+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:16:17.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:17.127+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:17.379+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:19.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:19.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:16:19.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:19.728+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:16:19.941+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.920 seconds
[2022-12-16T14:16:30.472+0000] {processor.py:154} INFO - Started process (PID=440) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:30.477+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:16:30.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:30.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:30.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:30.914+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:30.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:16:31.049+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:31.048+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:16:31.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.851 seconds
[2022-12-16T14:16:41.817+0000] {processor.py:154} INFO - Started process (PID=450) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:41.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:16:41.825+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:41.824+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:41.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:42.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:42.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:16:42.477+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:42.476+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:16:42.631+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.829 seconds
[2022-12-16T14:16:52.790+0000] {processor.py:154} INFO - Started process (PID=460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:52.794+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:16:52.798+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:52.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:52.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:16:53.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:53.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:16:54.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:16:54.058+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:16:54.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.504 seconds
[2022-12-16T14:17:04.698+0000] {processor.py:154} INFO - Started process (PID=478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:04.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:17:04.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:04.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:05.091+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:06.554+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:17:17.050+0000] {processor.py:154} INFO - Started process (PID=488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:17.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:17:17.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:17.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:17.153+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:17.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:17.383+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:17:17.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:17.523+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:17:17.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.709 seconds
[2022-12-16T14:17:28.044+0000] {processor.py:154} INFO - Started process (PID=498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:28.048+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:17:28.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:28.051+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:28.134+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:29.236+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:17:39.641+0000] {processor.py:154} INFO - Started process (PID=515) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:39.645+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:17:39.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:39.649+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:39.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:40.221+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:40.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:17:40.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:40.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:17:40.676+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.050 seconds
[2022-12-16T14:17:51.093+0000] {processor.py:154} INFO - Started process (PID=526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:51.125+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:17:51.130+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:51.128+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:51.214+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:17:51.753+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:51.752+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:17:51.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:17:51.886+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:17:51.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.918 seconds
[2022-12-16T14:18:02.409+0000] {processor.py:154} INFO - Started process (PID=536) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:02.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:18:02.455+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:02.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:02.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:02.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:02.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:18:02.974+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:02.973+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:18:03.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-16T14:18:13.292+0000] {processor.py:154} INFO - Started process (PID=546) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:13.303+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:18:13.332+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:13.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:13.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:14.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:14.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:18:14.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:14.200+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:18:14.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.084 seconds
[2022-12-16T14:18:24.850+0000] {processor.py:154} INFO - Started process (PID=564) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:24.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:18:24.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:24.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:24.958+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:26.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:26.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:18:27.119+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:27.118+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:18:27.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.443 seconds
[2022-12-16T14:18:37.446+0000] {processor.py:154} INFO - Started process (PID=574) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:37.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:18:37.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:37.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:37.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:37.902+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:37.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:18:38.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:38.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:18:38.237+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.809 seconds
[2022-12-16T14:18:48.585+0000] {processor.py:154} INFO - Started process (PID=584) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:48.589+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:18:48.594+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:48.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:48.794+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:18:49.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:49.548+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:18:49.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:18:49.716+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:18:49.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.259 seconds
[2022-12-16T14:19:00.434+0000] {processor.py:154} INFO - Started process (PID=601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:00.492+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:00.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:00.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:00.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:01.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:01.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:19:02.182+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:02.181+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:19:02.851+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.500 seconds
[2022-12-16T14:19:13.301+0000] {processor.py:154} INFO - Started process (PID=612) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:13.322+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:13.330+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:13.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:13.417+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:13.627+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:13.626+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:19:13.753+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:13.753+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:19:13.900+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.612 seconds
[2022-12-16T14:19:24.180+0000] {processor.py:154} INFO - Started process (PID=622) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:24.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:24.188+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:24.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:24.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:24.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:24.898+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:19:25.093+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:25.092+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:19:25.298+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.132 seconds
[2022-12-16T14:19:35.606+0000] {processor.py:154} INFO - Started process (PID=632) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:35.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:35.646+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:35.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:35.811+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:36.256+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:36.255+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:19:36.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:36.389+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:19:36.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.972 seconds
[2022-12-16T14:19:46.960+0000] {processor.py:154} INFO - Started process (PID=650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:47.005+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:47.010+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:47.009+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:47.153+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:47.508+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:47.507+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:19:47.719+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:47.718+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:19:47.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.003 seconds
[2022-12-16T14:19:58.395+0000] {processor.py:154} INFO - Started process (PID=660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:58.442+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:19:58.446+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:19:58.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:58.585+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:19:59.711+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:20:10.253+0000] {processor.py:154} INFO - Started process (PID=670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:10.276+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:20:10.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:10.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:10.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:10.710+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:10.709+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:20:10.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:10.886+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:20:11.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.780 seconds
[2022-12-16T14:20:22.213+0000] {processor.py:154} INFO - Started process (PID=685) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:22.246+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:20:22.251+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:22.250+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:22.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:22.728+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:22.727+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:20:23.023+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:23.022+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:20:23.311+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.114 seconds
[2022-12-16T14:20:33.876+0000] {processor.py:154} INFO - Started process (PID=697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:33.899+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:20:33.903+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:33.902+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:33.995+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:34.619+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:34.618+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:20:34.758+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:34.758+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:20:34.899+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.040 seconds
[2022-12-16T14:20:45.205+0000] {processor.py:154} INFO - Started process (PID=707) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:45.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:20:45.233+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:45.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:45.438+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:46.321+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:20:56.529+0000] {processor.py:154} INFO - Started process (PID=717) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:56.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:20:56.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:20:56.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:56.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:20:57.706+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:21:08.507+0000] {processor.py:154} INFO - Started process (PID=735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:08.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:21:08.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:08.587+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:08.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:09.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:09.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:21:09.858+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:09.857+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:21:10.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.025 seconds
[2022-12-16T14:21:20.768+0000] {processor.py:154} INFO - Started process (PID=745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:20.772+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:21:20.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:20.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:20.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:21.126+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:21.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:21:21.274+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:21.273+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:21:21.399+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.645 seconds
[2022-12-16T14:21:31.920+0000] {processor.py:154} INFO - Started process (PID=755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:31.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:21:31.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:31.927+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:32.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:32.230+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:32.229+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:21:32.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:32.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:21:32.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.770 seconds
[2022-12-16T14:21:42.990+0000] {processor.py:154} INFO - Started process (PID=765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:43.069+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:21:43.075+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:43.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:43.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:43.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:43.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:21:43.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:43.974+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:21:44.079+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.111 seconds
[2022-12-16T14:21:54.737+0000] {processor.py:154} INFO - Started process (PID=783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:54.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:21:54.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:54.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:54.957+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:21:56.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:56.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:21:56.473+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:21:56.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:21:56.659+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.955 seconds
[2022-12-16T14:22:06.939+0000] {processor.py:154} INFO - Started process (PID=793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:07.000+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:22:07.005+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:07.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:07.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:07.344+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:07.343+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:22:07.472+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:07.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:22:07.626+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.701 seconds
[2022-12-16T14:22:17.904+0000] {processor.py:154} INFO - Started process (PID=803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:17.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:22:17.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:17.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:18.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:19.138+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:22:29.586+0000] {processor.py:154} INFO - Started process (PID=820) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:29.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:22:29.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:29.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:29.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:30.242+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:30.241+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:22:30.399+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:30.398+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:22:30.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.973 seconds
[2022-12-16T14:22:40.905+0000] {processor.py:154} INFO - Started process (PID=830) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:40.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:22:40.964+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:40.963+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:41.101+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:42.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:42.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:22:42.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:42.527+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:22:42.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.760 seconds
[2022-12-16T14:22:53.738+0000] {processor.py:154} INFO - Started process (PID=840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:53.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:22:53.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:22:53.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:53.861+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:22:54.652+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:23:04.893+0000] {processor.py:154} INFO - Started process (PID=850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:04.900+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:23:04.909+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:04.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:05.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:05.791+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:05.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:23:05.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:05.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:23:06.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.250 seconds
[2022-12-16T14:23:16.716+0000] {processor.py:154} INFO - Started process (PID=867) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:16.749+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:23:16.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:16.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:16.948+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:18.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:18.777+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:23:19.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:19.625+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:23:19.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.171 seconds
[2022-12-16T14:23:30.220+0000] {processor.py:154} INFO - Started process (PID=877) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:30.244+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:23:30.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:30.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:30.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:31.483+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:31.482+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:23:31.618+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:31.617+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:23:31.760+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.566 seconds
[2022-12-16T14:23:41.886+0000] {processor.py:154} INFO - Started process (PID=887) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:41.890+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:23:41.895+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:41.894+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:41.995+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:42.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:42.200+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:23:42.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:42.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:23:42.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.605 seconds
[2022-12-16T14:23:52.854+0000] {processor.py:154} INFO - Started process (PID=904) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:52.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:23:52.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:23:52.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:53.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:23:54.334+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:24:04.521+0000] {processor.py:154} INFO - Started process (PID=915) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:04.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:24:04.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:04.528+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:04.612+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:04.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:04.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:24:04.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:04.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:24:05.079+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.572 seconds
[2022-12-16T14:24:15.381+0000] {processor.py:154} INFO - Started process (PID=925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:15.395+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:24:15.404+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:15.398+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:15.606+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:16.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:16.848+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:24:17.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:17.092+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:24:17.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.148 seconds
[2022-12-16T14:24:27.788+0000] {processor.py:154} INFO - Started process (PID=935) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:27.792+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:24:27.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:27.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:27.878+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:28.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:28.853+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:24:28.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:28.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:24:29.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.340 seconds
[2022-12-16T14:24:39.276+0000] {processor.py:154} INFO - Started process (PID=952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:39.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:24:39.293+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:39.292+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:39.410+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:39.988+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:24:50.457+0000] {processor.py:154} INFO - Started process (PID=962) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:50.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:24:50.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:50.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:50.597+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:24:50.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:50.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:24:50.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:24:50.955+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:24:51.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.622 seconds
[2022-12-16T14:25:01.337+0000] {processor.py:154} INFO - Started process (PID=972) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:01.340+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:01.345+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:01.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:01.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:01.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:01.668+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:25:01.808+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:01.807+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:25:01.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.593 seconds
[2022-12-16T14:25:12.717+0000] {processor.py:154} INFO - Started process (PID=988) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:12.721+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:12.725+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:12.724+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:12.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:13.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:13.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:25:14.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:14.076+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:25:14.248+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.549 seconds
[2022-12-16T14:25:24.897+0000] {processor.py:154} INFO - Started process (PID=999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:24.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:24.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:24.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:25.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:26.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:26.460+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:25:26.732+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:26.731+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:25:26.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.068 seconds
[2022-12-16T14:25:37.320+0000] {processor.py:154} INFO - Started process (PID=1009) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:37.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:37.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:37.327+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:37.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:37.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:37.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:25:37.793+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:37.792+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:25:37.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-16T14:25:48.036+0000] {processor.py:154} INFO - Started process (PID=1019) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:48.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:48.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:48.067+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:48.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:48.411+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:48.410+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:25:48.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:48.548+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:25:48.683+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.664 seconds
[2022-12-16T14:25:59.140+0000] {processor.py:154} INFO - Started process (PID=1036) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:59.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:25:59.165+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:25:59.164+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:59.327+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:25:59.726+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:26:10.209+0000] {processor.py:154} INFO - Started process (PID=1046) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:10.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:26:10.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:10.264+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:10.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:11.205+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:26:21.603+0000] {processor.py:154} INFO - Started process (PID=1056) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:21.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:26:21.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:21.631+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:21.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:22.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:22.493+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:26:22.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:22.760+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:26:23.231+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.650 seconds
[2022-12-16T14:26:33.557+0000] {processor.py:154} INFO - Started process (PID=1066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:33.573+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:26:33.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:33.580+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:33.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:33.866+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:33.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:26:34.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:34.006+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:26:34.150+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.607 seconds
[2022-12-16T14:26:44.655+0000] {processor.py:154} INFO - Started process (PID=1085) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:44.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:26:44.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:44.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:44.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:45.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:45.747+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:26:45.897+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:45.896+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:26:46.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.403 seconds
[2022-12-16T14:26:56.308+0000] {processor.py:154} INFO - Started process (PID=1095) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:56.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:26:56.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:26:56.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:56.423+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:26:57.496+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:27:07.871+0000] {processor.py:154} INFO - Started process (PID=1105) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:07.901+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:27:07.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:07.905+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:07.987+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:09.492+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:27:19.756+0000] {processor.py:154} INFO - Started process (PID=1124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:19.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:27:19.809+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:19.808+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:19.927+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:20.154+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:20.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:27:20.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:20.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:27:20.466+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.737 seconds
[2022-12-16T14:27:30.731+0000] {processor.py:154} INFO - Started process (PID=1134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:30.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:27:30.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:30.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:30.968+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:31.331+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:31.330+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:27:31.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:31.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:27:31.601+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.952 seconds
[2022-12-16T14:27:41.866+0000] {processor.py:154} INFO - Started process (PID=1144) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:41.870+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:27:41.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:41.873+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:41.974+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:42.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:42.573+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:27:42.754+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:42.753+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:27:42.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.021 seconds
[2022-12-16T14:27:53.132+0000] {processor.py:154} INFO - Started process (PID=1154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:53.196+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:27:53.200+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:53.198+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:53.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:27:53.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:53.566+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:27:54.005+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:27:54.004+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:27:54.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.123 seconds
[2022-12-16T14:28:04.805+0000] {processor.py:154} INFO - Started process (PID=1171) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:04.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:28:04.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:04.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:04.958+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:06.062+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:06.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:28:06.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:06.467+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:28:06.775+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.001 seconds
[2022-12-16T14:28:17.407+0000] {processor.py:154} INFO - Started process (PID=1181) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:17.433+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:28:17.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:17.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:17.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:17.919+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:17.918+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:28:18.053+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:18.052+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:28:18.162+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.769 seconds
[2022-12-16T14:28:28.486+0000] {processor.py:154} INFO - Started process (PID=1191) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:28.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:28:28.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:28.528+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:28.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:29.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:29.759+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:28:30.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:30.030+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:28:30.208+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.746 seconds
[2022-12-16T14:28:40.511+0000] {processor.py:154} INFO - Started process (PID=1209) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:40.574+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:28:40.578+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:40.577+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:41.057+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:41.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:41.383+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:28:41.558+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:41.557+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:28:41.724+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.242 seconds
[2022-12-16T14:28:52.166+0000] {processor.py:154} INFO - Started process (PID=1220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:52.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:28:52.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:52.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:52.297+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:28:52.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:52.692+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:28:52.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:28:52.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:28:53.047+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.895 seconds
[2022-12-16T14:29:03.576+0000] {processor.py:154} INFO - Started process (PID=1230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:03.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:29:03.611+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:03.609+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:03.724+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:04.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:04.133+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:29:04.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:04.332+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:29:04.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.924 seconds
[2022-12-16T14:29:14.755+0000] {processor.py:154} INFO - Started process (PID=1240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:14.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:29:14.813+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:14.812+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:14.897+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:16.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:16.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:29:16.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:16.675+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:29:16.817+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.078 seconds
[2022-12-16T14:29:27.407+0000] {processor.py:154} INFO - Started process (PID=1259) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:27.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:29:27.620+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:27.618+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:27.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:28.237+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:28.236+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:29:28.404+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:28.403+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:29:28.616+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.250 seconds
[2022-12-16T14:29:39.010+0000] {processor.py:154} INFO - Started process (PID=1269) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:39.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:29:39.067+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:39.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:39.166+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:39.405+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:39.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:29:39.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:39.535+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:29:39.671+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.684 seconds
[2022-12-16T14:29:49.999+0000] {processor.py:154} INFO - Started process (PID=1279) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:50.044+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:29:50.049+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:50.048+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:50.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:29:50.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:50.334+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:29:50.469+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:29:50.468+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:29:50.621+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.634 seconds
[2022-12-16T14:30:00.992+0000] {processor.py:154} INFO - Started process (PID=1295) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:01.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:01.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:01.021+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:01.130+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:01.374+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:01.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:01.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:01.530+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:01.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.713 seconds
[2022-12-16T14:30:11.969+0000] {processor.py:154} INFO - Started process (PID=1306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:12.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:12.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:12.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:12.199+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:12.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:12.470+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:12.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:12.643+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:12.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.800 seconds
[2022-12-16T14:30:23.493+0000] {processor.py:154} INFO - Started process (PID=1316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:23.542+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:23.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:23.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:23.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:23.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:23.858+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:24.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:24.000+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:24.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-16T14:30:34.459+0000] {processor.py:154} INFO - Started process (PID=1326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:34.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:34.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:34.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:34.629+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:34.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:34.907+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:35.127+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:35.126+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:35.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.081 seconds
[2022-12-16T14:30:45.873+0000] {processor.py:154} INFO - Started process (PID=1345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:45.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:45.936+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:45.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:46.036+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:46.348+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:46.344+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:46.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:46.535+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:46.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.874 seconds
[2022-12-16T14:30:57.268+0000] {processor.py:154} INFO - Started process (PID=1355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:57.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:30:57.297+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:57.296+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:57.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:30:57.846+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:57.845+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:30:57.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:30:57.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:30:58.098+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.845 seconds
[2022-12-16T14:31:08.371+0000] {processor.py:154} INFO - Started process (PID=1365) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:08.464+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:31:08.474+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:08.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:08.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:09.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:09.127+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:31:09.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:09.275+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:31:09.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.040 seconds
[2022-12-16T14:31:19.682+0000] {processor.py:154} INFO - Started process (PID=1375) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:19.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:31:19.749+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:19.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:19.849+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:20.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:20.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:31:20.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:20.583+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:31:20.702+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.035 seconds
[2022-12-16T14:31:30.918+0000] {processor.py:154} INFO - Started process (PID=1393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:30.969+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:31:30.978+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:30.977+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:31.221+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:31.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:31.688+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:31:31.830+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:31.829+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:31:31.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.059 seconds
[2022-12-16T14:31:42.136+0000] {processor.py:154} INFO - Started process (PID=1403) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:42.160+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:31:42.164+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:42.162+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:42.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:43.273+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:31:53.607+0000] {processor.py:154} INFO - Started process (PID=1413) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:53.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:31:53.657+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:53.656+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:53.751+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:31:53.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:53.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:31:54.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:31:54.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:31:54.300+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.707 seconds
[2022-12-16T14:32:04.669+0000] {processor.py:154} INFO - Started process (PID=1431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:04.753+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:32:04.758+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:04.756+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:04.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:05.486+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:05.485+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:32:05.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:05.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:32:05.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.316 seconds
[2022-12-16T14:32:16.497+0000] {processor.py:154} INFO - Started process (PID=1441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:16.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:32:16.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:16.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:16.619+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:16.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:16.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:32:16.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:16.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:32:17.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.675 seconds
[2022-12-16T14:32:27.559+0000] {processor.py:154} INFO - Started process (PID=1451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:27.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:32:27.608+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:27.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:27.715+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:27.929+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:27.928+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:32:28.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:28.059+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:32:28.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-16T14:32:38.905+0000] {processor.py:154} INFO - Started process (PID=1461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:38.958+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:32:38.967+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:38.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:39.506+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:41.446+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:41.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:32:41.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:41.667+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:32:41.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.057 seconds
[2022-12-16T14:32:52.484+0000] {processor.py:154} INFO - Started process (PID=1479) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:52.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:32:52.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:52.527+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:52.704+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:32:53.168+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:53.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:32:53.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:32:53.474+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:32:53.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.218 seconds
[2022-12-16T14:33:03.969+0000] {processor.py:154} INFO - Started process (PID=1489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:04.025+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:33:04.029+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:04.028+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:04.114+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:04.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:04.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:33:04.470+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:04.469+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:33:04.623+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.668 seconds
[2022-12-16T14:33:14.903+0000] {processor.py:154} INFO - Started process (PID=1499) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:14.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:33:14.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:14.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:15.013+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:16.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:16.278+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:33:16.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:16.424+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:33:16.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.701 seconds
[2022-12-16T14:33:27.076+0000] {processor.py:154} INFO - Started process (PID=1518) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:27.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:33:27.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:27.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:27.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:27.585+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:27.584+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:33:27.766+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:27.765+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:33:27.912+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.856 seconds
[2022-12-16T14:33:38.253+0000] {processor.py:154} INFO - Started process (PID=1528) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:38.284+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:33:38.289+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:38.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:38.373+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:38.804+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:38.803+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:33:38.960+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:38.960+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:33:39.082+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.842 seconds
[2022-12-16T14:33:49.214+0000] {processor.py:154} INFO - Started process (PID=1538) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:49.242+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:33:49.247+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:49.246+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:49.335+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:33:49.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:49.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:33:49.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:33:49.700+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:33:49.807+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T14:34:00.252+0000] {processor.py:154} INFO - Started process (PID=1548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:00.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:00.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:00.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:00.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:00.922+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:00.921+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:34:01.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:01.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:34:01.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.030 seconds
[2022-12-16T14:34:11.516+0000] {processor.py:154} INFO - Started process (PID=1567) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:11.547+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:11.563+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:11.550+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:11.933+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:12.541+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:12.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:34:12.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:12.720+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:34:12.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.444 seconds
[2022-12-16T14:34:23.209+0000] {processor.py:154} INFO - Started process (PID=1577) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:23.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:23.248+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:23.247+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:23.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:24.878+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:34:35.213+0000] {processor.py:154} INFO - Started process (PID=1587) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:35.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:35.242+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:35.241+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:35.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:35.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:35.579+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:34:35.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:35.735+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:34:35.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.729 seconds
[2022-12-16T14:34:46.606+0000] {processor.py:154} INFO - Started process (PID=1605) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:46.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:46.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:46.667+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:47.043+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:47.534+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:47.533+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:34:48.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:48.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:34:48.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.245 seconds
[2022-12-16T14:34:59.209+0000] {processor.py:154} INFO - Started process (PID=1616) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:59.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:34:59.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:34:59.215+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:34:59.311+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:00.766+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:35:11.694+0000] {processor.py:154} INFO - Started process (PID=1626) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:11.724+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:35:11.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:11.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:11.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:12.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:12.055+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:35:12.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:12.264+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:35:12.374+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.694 seconds
[2022-12-16T14:35:22.509+0000] {processor.py:154} INFO - Started process (PID=1636) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:22.539+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:35:22.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:22.542+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:22.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:23.062+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:23.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:35:23.273+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:23.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:35:23.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.899 seconds
[2022-12-16T14:35:33.617+0000] {processor.py:154} INFO - Started process (PID=1655) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:33.653+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:35:33.661+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:33.660+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:33.880+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:34.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:34.595+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:35:34.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:34.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:35:35.196+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.607 seconds
[2022-12-16T14:35:45.566+0000] {processor.py:154} INFO - Started process (PID=1665) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:45.587+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:35:45.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:45.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:45.678+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:47.492+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:47.490+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:35:47.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:47.732+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:35:47.907+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.354 seconds
[2022-12-16T14:35:58.888+0000] {processor.py:154} INFO - Started process (PID=1675) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:58.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:35:58.918+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:58.918+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:58.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:35:59.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:59.566+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:35:59.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:35:59.692+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:35:59.835+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.961 seconds
[2022-12-16T14:36:10.154+0000] {processor.py:154} INFO - Started process (PID=1685) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:10.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:36:10.188+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:10.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:10.274+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:10.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:10.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:36:10.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:10.864+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:36:11.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.871 seconds
[2022-12-16T14:36:21.716+0000] {processor.py:154} INFO - Started process (PID=1702) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:21.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:36:21.750+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:21.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:22.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:22.681+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:22.680+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:36:23.192+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:23.191+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:36:23.370+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.728 seconds
[2022-12-16T14:36:33.742+0000] {processor.py:154} INFO - Started process (PID=1712) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:33.763+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:36:33.766+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:33.765+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:33.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:34.719+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:34.718+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:36:34.929+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:34.928+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:36:35.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.349 seconds
[2022-12-16T14:36:45.268+0000] {processor.py:154} INFO - Started process (PID=1722) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:45.320+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:36:45.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:45.323+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:45.419+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:45.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:45.688+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:36:45.866+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:45.865+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:36:46.025+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-16T14:36:56.876+0000] {processor.py:154} INFO - Started process (PID=1738) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:56.935+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:36:56.942+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:36:56.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:57.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:36:59.143+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:37:09.525+0000] {processor.py:154} INFO - Started process (PID=1749) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:09.549+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:37:09.554+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:09.553+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:09.641+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:11.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:11.219+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:37:11.363+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:11.362+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:37:11.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.990 seconds
[2022-12-16T14:37:21.837+0000] {processor.py:154} INFO - Started process (PID=1759) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:21.859+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:37:21.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:21.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:21.949+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:22.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:22.158+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:37:22.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:22.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:37:22.393+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.569 seconds
[2022-12-16T14:37:33.126+0000] {processor.py:154} INFO - Started process (PID=1769) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:33.177+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:37:33.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:33.180+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:33.412+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:33.762+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:33.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:37:33.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:33.938+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:37:34.101+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.997 seconds
[2022-12-16T14:37:44.693+0000] {processor.py:154} INFO - Started process (PID=1787) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:44.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:37:44.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:44.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:45.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:46.341+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:37:56.767+0000] {processor.py:154} INFO - Started process (PID=1797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:56.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:37:56.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:56.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:56.952+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:37:57.254+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:57.253+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:37:57.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:37:57.412+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:37:57.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.789 seconds
[2022-12-16T14:38:07.867+0000] {processor.py:154} INFO - Started process (PID=1807) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:07.915+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:38:07.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:07.919+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:08.111+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:08.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:08.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:38:08.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:08.691+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:38:08.808+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.956 seconds
[2022-12-16T14:38:19.152+0000] {processor.py:154} INFO - Started process (PID=1817) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:19.209+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:38:19.213+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:19.212+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:19.308+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:19.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:19.530+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:38:19.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:19.809+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:38:19.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T14:38:30.272+0000] {processor.py:154} INFO - Started process (PID=1835) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:30.364+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:38:30.368+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:30.367+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:30.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:31.628+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:31.627+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:38:32.434+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:32.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:38:32.647+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.408 seconds
[2022-12-16T14:38:42.836+0000] {processor.py:154} INFO - Started process (PID=1845) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:42.862+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:38:42.866+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:42.865+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:42.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:44.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:44.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:38:44.678+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:44.677+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:38:44.809+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.987 seconds
[2022-12-16T14:38:55.334+0000] {processor.py:154} INFO - Started process (PID=1855) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:55.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:38:55.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:55.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:55.733+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:38:56.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:56.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:38:56.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:38:56.933+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:38:57.171+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.894 seconds
[2022-12-16T14:39:07.884+0000] {processor.py:154} INFO - Started process (PID=1873) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:07.917+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:39:07.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:07.920+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:08.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:09.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:09.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:39:10.074+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:10.073+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:39:10.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.394 seconds
[2022-12-16T14:39:20.626+0000] {processor.py:154} INFO - Started process (PID=1883) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:20.657+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:39:20.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:20.660+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:20.746+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:21.968+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:39:32.296+0000] {processor.py:154} INFO - Started process (PID=1893) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:32.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:39:32.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:32.327+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:32.412+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:33.034+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:33.033+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:39:33.182+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:33.181+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:39:33.310+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.028 seconds
[2022-12-16T14:39:43.633+0000] {processor.py:154} INFO - Started process (PID=1903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:43.691+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:39:43.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:43.695+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:43.786+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:44.039+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:44.038+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:39:44.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:44.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:39:44.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-16T14:39:54.814+0000] {processor.py:154} INFO - Started process (PID=1920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:54.861+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:39:54.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:54.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:55.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:39:55.327+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:55.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:39:55.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:39:55.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:39:55.694+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.922 seconds
[2022-12-16T14:40:06.057+0000] {processor.py:154} INFO - Started process (PID=1930) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:06.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:40:06.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:06.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:06.210+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:06.704+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:06.703+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:40:06.897+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:06.896+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:40:07.036+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.994 seconds
[2022-12-16T14:40:17.196+0000] {processor.py:154} INFO - Started process (PID=1940) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:17.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:40:17.236+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:17.235+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:17.347+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:18.483+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:40:28.915+0000] {processor.py:154} INFO - Started process (PID=1957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:28.962+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:40:28.966+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:28.965+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:29.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:30.129+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:40:40.486+0000] {processor.py:154} INFO - Started process (PID=1967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:40.509+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:40:40.514+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:40.512+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:40.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:41.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:41.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:40:41.914+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:41.913+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:40:42.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.650 seconds
[2022-12-16T14:40:52.885+0000] {processor.py:154} INFO - Started process (PID=1977) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:52.929+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:40:52.933+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:40:52.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:53.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:40:54.333+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:41:04.757+0000] {processor.py:154} INFO - Started process (PID=1987) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:04.821+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:41:04.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:04.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:05.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:05.541+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:05.540+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:41:05.670+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:05.669+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:41:06.060+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.321 seconds
[2022-12-16T14:41:16.431+0000] {processor.py:154} INFO - Started process (PID=2005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:16.485+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:41:16.501+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:16.500+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:16.721+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:17.912+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:17.911+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:41:18.215+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:18.213+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:41:18.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.079 seconds
[2022-12-16T14:41:28.638+0000] {processor.py:154} INFO - Started process (PID=2015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:28.662+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:41:28.667+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:28.666+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:28.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:29.254+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:29.253+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:41:29.434+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:29.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:41:29.568+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.943 seconds
[2022-12-16T14:41:39.913+0000] {processor.py:154} INFO - Started process (PID=2025) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:39.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:41:39.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:39.970+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:40.059+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:40.364+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:40.363+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:41:40.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:40.643+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:41:40.821+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.954 seconds
[2022-12-16T14:41:51.136+0000] {processor.py:154} INFO - Started process (PID=2043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:51.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:41:51.202+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:41:51.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:51.355+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:41:52.401+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:42:03.041+0000] {processor.py:154} INFO - Started process (PID=2053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:03.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:42:03.107+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:03.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:03.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:03.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:03.747+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:42:04.024+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:04.023+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:42:04.170+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.154 seconds
[2022-12-16T14:42:13.686+0000] {processor.py:154} INFO - Started process (PID=2068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:13.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:42:13.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:13.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:13.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:14.726+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:42:24.980+0000] {processor.py:154} INFO - Started process (PID=2078) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:25.009+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:42:25.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:25.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:25.120+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:25.710+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:25.709+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:42:25.949+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:25.948+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:42:26.106+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.148 seconds
[2022-12-16T14:42:36.307+0000] {processor.py:154} INFO - Started process (PID=2097) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:36.355+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:42:36.364+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:36.363+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:36.562+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:36.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:36.874+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:42:37.090+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:37.089+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:42:37.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.944 seconds
[2022-12-16T14:42:47.592+0000] {processor.py:154} INFO - Started process (PID=2107) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:47.613+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:42:47.622+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:47.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:47.736+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:42:49.461+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:49.460+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:42:49.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:42:49.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:42:49.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.338 seconds
[2022-12-16T14:43:00.291+0000] {processor.py:154} INFO - Started process (PID=2122) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:00.325+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:00.334+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:00.330+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:00.433+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:01.368+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:43:12.030+0000] {processor.py:154} INFO - Started process (PID=2139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:12.088+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:12.098+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:12.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:12.304+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:14.192+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:14.191+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:43:14.389+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:14.388+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:43:14.593+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.601 seconds
[2022-12-16T14:43:25.060+0000] {processor.py:154} INFO - Started process (PID=2150) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:25.273+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:25.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:25.279+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:25.430+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:26.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:26.013+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:43:26.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:26.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:43:26.249+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.234 seconds
[2022-12-16T14:43:36.599+0000] {processor.py:154} INFO - Started process (PID=2160) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:36.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:36.635+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:36.634+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:36.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:36.966+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:36.965+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:43:37.152+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:37.152+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:43:37.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.696 seconds
[2022-12-16T14:43:47.562+0000] {processor.py:154} INFO - Started process (PID=2170) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:47.612+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:47.616+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:47.615+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:47.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:47.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:47.930+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:43:48.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:48.279+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:43:48.548+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.017 seconds
[2022-12-16T14:43:59.182+0000] {processor.py:154} INFO - Started process (PID=2188) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:59.235+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:43:59.250+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:43:59.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:43:59.488+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:00.053+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:00.042+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:44:00.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:00.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:44:00.634+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.469 seconds
[2022-12-16T14:44:11.530+0000] {processor.py:154} INFO - Started process (PID=2198) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:11.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:44:11.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:11.566+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:11.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:13.156+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:44:23.460+0000] {processor.py:154} INFO - Started process (PID=2208) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:23.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:44:23.523+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:23.522+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:23.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:24.089+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:24.088+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:44:24.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:24.200+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:44:24.313+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.868 seconds
[2022-12-16T14:44:34.929+0000] {processor.py:154} INFO - Started process (PID=2226) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:34.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:44:35.002+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:35.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:35.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:36.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:36.186+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:44:36.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:36.321+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:44:36.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.603 seconds
[2022-12-16T14:44:46.711+0000] {processor.py:154} INFO - Started process (PID=2236) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:46.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:44:46.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:46.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:47.094+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:47.241+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:47.240+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:44:47.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:47.383+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:44:47.499+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.807 seconds
[2022-12-16T14:44:58.194+0000] {processor.py:154} INFO - Started process (PID=2246) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:58.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:44:58.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:58.218+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:58.562+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:44:58.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:58.746+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:44:58.890+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:44:58.889+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:44:59.006+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.852 seconds
[2022-12-16T14:45:09.447+0000] {processor.py:154} INFO - Started process (PID=2256) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:09.469+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:45:09.474+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:09.472+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:09.575+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:09.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:09.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:45:10.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:10.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:45:10.313+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.879 seconds
[2022-12-16T14:45:20.893+0000] {processor.py:154} INFO - Started process (PID=2275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:20.953+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:45:20.961+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:20.960+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:21.121+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:21.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:21.407+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:45:21.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:21.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:45:21.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.037 seconds
[2022-12-16T14:45:32.217+0000] {processor.py:154} INFO - Started process (PID=2285) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:32.244+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:45:32.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:32.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:32.336+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:32.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:32.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:45:32.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:32.580+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:45:32.726+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.523 seconds
[2022-12-16T14:45:43.013+0000] {processor.py:154} INFO - Started process (PID=2295) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:43.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:45:43.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:43.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:43.149+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:44.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:44.520+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:45:44.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:44.636+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:45:44.772+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.772 seconds
[2022-12-16T14:45:55.178+0000] {processor.py:154} INFO - Started process (PID=2312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:55.236+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:45:55.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:55.285+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:55.400+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:45:55.570+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:55.569+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:45:55.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:45:55.697+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:45:55.845+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.694 seconds
[2022-12-16T14:46:06.620+0000] {processor.py:154} INFO - Started process (PID=2323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:06.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:46:06.654+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:06.653+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:06.743+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:08.018+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:46:18.317+0000] {processor.py:154} INFO - Started process (PID=2333) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:18.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:46:18.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:18.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:18.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:19.262+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:19.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:46:19.481+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:19.480+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:46:19.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.363 seconds
[2022-12-16T14:46:29.796+0000] {processor.py:154} INFO - Started process (PID=2343) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:29.836+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:46:29.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:29.841+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:29.924+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:30.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:30.500+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:46:30.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:30.613+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:46:30.752+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.973 seconds
[2022-12-16T14:46:41.122+0000] {processor.py:154} INFO - Started process (PID=2361) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:41.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:46:41.161+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:41.160+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:41.264+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:41.776+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:41.775+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:46:41.907+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:41.906+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:46:42.038+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.931 seconds
[2022-12-16T14:46:52.401+0000] {processor.py:154} INFO - Started process (PID=2371) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:52.463+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:46:52.467+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:52.466+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:52.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:46:52.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:52.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:46:53.051+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:46:53.050+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:46:53.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.821 seconds
[2022-12-16T14:47:03.585+0000] {processor.py:154} INFO - Started process (PID=2381) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:03.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:47:03.604+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:03.603+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:03.703+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:04.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:04.006+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:47:04.279+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:04.279+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:47:04.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.826 seconds
[2022-12-16T14:47:14.870+0000] {processor.py:154} INFO - Started process (PID=2398) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:14.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:47:14.929+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:14.927+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:15.036+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:16.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:16.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:47:16.850+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:16.849+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:47:16.976+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.141 seconds
[2022-12-16T14:47:27.503+0000] {processor.py:154} INFO - Started process (PID=2409) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:27.532+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:47:27.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:27.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:27.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:28.166+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:47:38.506+0000] {processor.py:154} INFO - Started process (PID=2419) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:38.531+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:47:38.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:38.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:38.620+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:38.757+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:38.756+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:47:38.869+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:38.869+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:47:39.000+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.507 seconds
[2022-12-16T14:47:49.752+0000] {processor.py:154} INFO - Started process (PID=2429) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:49.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:47:49.804+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:49.803+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:49.917+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:47:50.057+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:50.056+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:47:50.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:47:50.169+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:47:50.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-16T14:48:00.526+0000] {processor.py:154} INFO - Started process (PID=2446) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:00.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:00.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:00.575+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:00.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:00.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:00.939+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:01.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:01.067+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:01.191+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.704 seconds
[2022-12-16T14:48:11.337+0000] {processor.py:154} INFO - Started process (PID=2456) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:11.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:11.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:11.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:11.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:11.641+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:11.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:11.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:11.840+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:12.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-16T14:48:22.385+0000] {processor.py:154} INFO - Started process (PID=2466) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:22.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:22.417+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:22.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:22.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:23.048+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:23.047+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:23.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:23.196+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:23.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.295 seconds
[2022-12-16T14:48:33.989+0000] {processor.py:154} INFO - Started process (PID=2476) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:34.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:34.018+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:34.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:34.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:34.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:34.786+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:34.915+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:34.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:35.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.059 seconds
[2022-12-16T14:48:45.474+0000] {processor.py:154} INFO - Started process (PID=2494) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:45.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:45.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:45.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:45.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:45.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:45.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:45.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:45.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:46.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.645 seconds
[2022-12-16T14:48:56.372+0000] {processor.py:154} INFO - Started process (PID=2504) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:56.497+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:48:56.501+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:56.500+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:56.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:48:57.023+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:57.022+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:48:57.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:48:57.186+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:48:57.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.938 seconds
[2022-12-16T14:49:07.525+0000] {processor.py:154} INFO - Started process (PID=2514) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:07.555+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:49:07.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:07.562+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:07.646+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:07.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:07.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:49:07.901+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:07.900+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:49:08.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.522 seconds
[2022-12-16T14:49:18.348+0000] {processor.py:154} INFO - Started process (PID=2533) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:18.370+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:49:18.379+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:18.378+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:18.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:18.667+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:18.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:49:18.894+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:18.893+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:49:19.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.741 seconds
[2022-12-16T14:49:29.574+0000] {processor.py:154} INFO - Started process (PID=2544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:29.607+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:49:29.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:29.615+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:29.813+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:30.153+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:30.152+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:49:30.302+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:30.301+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:49:30.540+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.986 seconds
[2022-12-16T14:49:40.806+0000] {processor.py:154} INFO - Started process (PID=2554) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:40.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:49:40.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:40.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:40.918+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:41.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:41.068+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:49:41.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:41.179+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:49:41.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.529 seconds
[2022-12-16T14:49:51.687+0000] {processor.py:154} INFO - Started process (PID=2564) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:51.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:49:51.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:51.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:51.827+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:49:52.018+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:52.017+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:49:52.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:49:52.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:49:52.263+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.594 seconds
[2022-12-16T14:50:03.035+0000] {processor.py:154} INFO - Started process (PID=2582) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:03.070+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:50:03.074+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:03.073+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:03.215+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:03.426+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:03.425+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:50:03.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:03.590+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:50:03.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.860 seconds
[2022-12-16T14:50:14.548+0000] {processor.py:154} INFO - Started process (PID=2592) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:14.572+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:50:14.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:14.576+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:14.710+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:14.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:14.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:50:14.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:14.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:50:15.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.566 seconds
[2022-12-16T14:50:25.364+0000] {processor.py:154} INFO - Started process (PID=2602) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:25.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:50:25.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:25.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:25.629+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:26.520+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:26.519+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:50:26.757+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:26.756+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:50:26.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.623 seconds
[2022-12-16T14:50:37.358+0000] {processor.py:154} INFO - Started process (PID=2612) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:37.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:50:37.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:37.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:37.478+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:37.620+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:37.619+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:50:37.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:37.764+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:50:38.057+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.712 seconds
[2022-12-16T14:50:48.588+0000] {processor.py:154} INFO - Started process (PID=2629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:48.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:50:48.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:48.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:48.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:50:49.298+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:49.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:50:49.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:50:49.718+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:50:50.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.482 seconds
[2022-12-16T14:51:00.447+0000] {processor.py:154} INFO - Started process (PID=2639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:00.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:00.495+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:00.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:00.591+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:00.948+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:00.947+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:01.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:01.079+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:01.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.392 seconds
[2022-12-16T14:51:12.645+0000] {processor.py:154} INFO - Started process (PID=2649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:12.701+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:12.706+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:12.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:12.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:12.926+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:12.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:13.042+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:13.041+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:13.158+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.527 seconds
[2022-12-16T14:51:23.441+0000] {processor.py:154} INFO - Started process (PID=2666) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:23.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:23.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:23.501+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:23.709+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:23.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:23.949+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:24.213+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:24.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:24.443+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-16T14:51:35.067+0000] {processor.py:154} INFO - Started process (PID=2677) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:35.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:35.169+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:35.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:35.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:35.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:35.642+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:35.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:35.782+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:35.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.898 seconds
[2022-12-16T14:51:46.226+0000] {processor.py:154} INFO - Started process (PID=2687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:46.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:46.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:46.256+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:46.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:47.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:47.002+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:47.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:47.117+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:47.252+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.040 seconds
[2022-12-16T14:51:57.410+0000] {processor.py:154} INFO - Started process (PID=2697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:57.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:51:57.429+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:57.428+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:57.513+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:51:58.117+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:58.116+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:51:58.231+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:51:58.230+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:51:58.367+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.971 seconds
[2022-12-16T14:52:08.789+0000] {processor.py:154} INFO - Started process (PID=2715) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:08.847+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:52:08.862+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:08.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:08.963+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:09.594+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:09.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:52:09.751+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:09.749+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:52:09.948+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.186 seconds
[2022-12-16T14:52:20.293+0000] {processor.py:154} INFO - Started process (PID=2725) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:20.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:52:20.353+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:20.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:20.466+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:21.102+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:21.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:52:21.232+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:21.231+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:52:21.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.067 seconds
[2022-12-16T14:52:31.670+0000] {processor.py:154} INFO - Started process (PID=2735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:31.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:52:31.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:31.699+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:31.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:33.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:33.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:52:33.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:33.252+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:52:33.373+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.717 seconds
[2022-12-16T14:52:43.758+0000] {processor.py:154} INFO - Started process (PID=2745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:43.806+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:52:43.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:43.809+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:43.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:44.917+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:44.916+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:52:45.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:45.170+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:52:45.315+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.572 seconds
[2022-12-16T14:52:55.732+0000] {processor.py:154} INFO - Started process (PID=2763) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:55.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:52:55.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:55.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:55.957+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:52:56.277+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:56.276+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:52:56.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:52:56.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:52:56.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.953 seconds
[2022-12-16T14:53:06.817+0000] {processor.py:154} INFO - Started process (PID=2773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:06.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:53:06.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:06.858+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:06.947+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:07.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:07.631+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:53:07.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:07.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:53:08.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.452 seconds
[2022-12-16T14:53:18.506+0000] {processor.py:154} INFO - Started process (PID=2783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:18.532+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:53:18.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:18.536+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:18.619+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:18.761+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:18.760+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:53:18.874+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:18.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:53:18.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.489 seconds
[2022-12-16T14:53:29.364+0000] {processor.py:154} INFO - Started process (PID=2799) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:29.402+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:53:29.415+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:29.410+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:29.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:29.691+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:29.690+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:53:29.822+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:29.821+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:53:29.964+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.650 seconds
[2022-12-16T14:53:40.343+0000] {processor.py:154} INFO - Started process (PID=2810) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:40.682+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:53:40.686+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:40.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:40.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:40.967+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:40.966+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:53:41.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:41.170+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:53:41.465+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.136 seconds
[2022-12-16T14:53:51.824+0000] {processor.py:154} INFO - Started process (PID=2820) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:51.852+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:53:51.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:53:51.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:51.942+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:53:53.313+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:54:03.783+0000] {processor.py:154} INFO - Started process (PID=2830) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:03.830+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:03.835+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:03.833+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:04.002+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:04.191+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:04.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:04.306+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:04.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:04.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.700 seconds
[2022-12-16T14:54:14.648+0000] {processor.py:154} INFO - Started process (PID=2848) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:14.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:14.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:14.692+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:14.809+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:15.259+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:15.258+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:15.400+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:15.399+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:15.548+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.931 seconds
[2022-12-16T14:54:25.711+0000] {processor.py:154} INFO - Started process (PID=2858) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:25.793+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:25.797+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:25.796+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:25.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:26.021+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:26.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:26.131+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:26.130+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:26.240+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.543 seconds
[2022-12-16T14:54:36.524+0000] {processor.py:154} INFO - Started process (PID=2868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:36.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:36.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:36.579+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:36.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:36.807+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:36.805+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:36.941+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:36.941+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:37.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.546 seconds
[2022-12-16T14:54:47.386+0000] {processor.py:154} INFO - Started process (PID=2878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:47.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:47.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:47.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:47.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:47.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:47.664+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:47.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:47.787+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:47.912+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-16T14:54:58.471+0000] {processor.py:154} INFO - Started process (PID=2895) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:58.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:54:58.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:58.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:58.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:54:58.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:58.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:54:59.139+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:54:59.138+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:54:59.373+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.918 seconds
[2022-12-16T14:55:09.800+0000] {processor.py:154} INFO - Started process (PID=2905) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:09.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:55:09.855+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:09.854+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:09.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:10.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:10.132+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:55:10.273+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:10.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:55:10.468+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.697 seconds
[2022-12-16T14:55:20.653+0000] {processor.py:154} INFO - Started process (PID=2915) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:20.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:55:20.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:20.683+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:20.775+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:20.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:20.929+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:55:21.093+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:21.086+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:55:21.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.633 seconds
[2022-12-16T14:55:31.614+0000] {processor.py:154} INFO - Started process (PID=2932) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:31.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:55:31.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:31.630+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:31.787+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:32.084+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:32.082+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:55:32.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:32.332+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:55:32.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.935 seconds
[2022-12-16T14:55:42.838+0000] {processor.py:154} INFO - Started process (PID=2943) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:42.883+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:55:42.888+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:42.886+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:43.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:43.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:43.905+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:55:44.163+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:44.158+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:55:44.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.599 seconds
[2022-12-16T14:55:55.279+0000] {processor.py:154} INFO - Started process (PID=2953) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:55.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:55:55.312+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:55.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:55.425+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:55:55.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:55.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:55:55.690+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:55:55.689+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:55:55.831+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.568 seconds
[2022-12-16T14:56:06.089+0000] {processor.py:154} INFO - Started process (PID=2963) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:06.145+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:56:06.153+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:06.152+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:06.242+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:07.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:07.332+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:56:07.461+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:07.460+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:56:07.676+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.603 seconds
[2022-12-16T14:56:18.185+0000] {processor.py:154} INFO - Started process (PID=2981) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:18.229+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:56:18.238+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:18.237+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:18.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:18.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:18.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:56:18.982+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:18.981+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:56:19.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.061 seconds
[2022-12-16T14:56:29.604+0000] {processor.py:154} INFO - Started process (PID=2991) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:29.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:56:29.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:29.636+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:29.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:29.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:29.959+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:56:30.112+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:30.111+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:56:30.223+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.663 seconds
[2022-12-16T14:56:40.820+0000] {processor.py:154} INFO - Started process (PID=3001) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:40.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:56:40.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:40.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:41.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:41.341+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:41.340+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:56:41.479+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:41.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:56:41.656+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.850 seconds
[2022-12-16T14:56:52.167+0000] {processor.py:154} INFO - Started process (PID=3016) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:52.197+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:56:52.227+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:56:52.212+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:52.435+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:56:53.571+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:57:03.881+0000] {processor.py:154} INFO - Started process (PID=3028) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:03.959+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:57:03.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:03.962+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:04.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:04.186+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:04.185+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:57:04.297+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:04.296+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:57:04.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-16T14:57:14.543+0000] {processor.py:154} INFO - Started process (PID=3038) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:14.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:57:14.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:14.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:14.879+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:15.698+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:57:26.046+0000] {processor.py:154} INFO - Started process (PID=3048) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:26.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:57:26.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:26.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:26.174+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:26.389+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:26.388+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:57:26.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:26.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:57:26.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.663 seconds
[2022-12-16T14:57:37.134+0000] {processor.py:154} INFO - Started process (PID=3066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:37.158+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:57:37.175+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:37.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:37.306+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:37.766+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:37.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:57:37.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:37.895+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:57:38.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.933 seconds
[2022-12-16T14:57:48.373+0000] {processor.py:154} INFO - Started process (PID=3076) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:48.401+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:57:48.405+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:48.404+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:48.503+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:57:49.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:49.720+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:57:49.927+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:57:49.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:57:50.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.886 seconds
[2022-12-16T14:58:00.923+0000] {processor.py:154} INFO - Started process (PID=3086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:00.985+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:00.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:00.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:01.094+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:01.261+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:01.260+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:01.376+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:01.375+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:01.542+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.647 seconds
[2022-12-16T14:58:11.818+0000] {processor.py:154} INFO - Started process (PID=3096) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:11.839+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:11.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:11.843+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:11.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:12.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:12.591+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:12.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:12.707+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:12.857+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.055 seconds
[2022-12-16T14:58:23.410+0000] {processor.py:154} INFO - Started process (PID=3115) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:23.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:23.645+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:23.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:23.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:24.226+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:24.225+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:24.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:24.348+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:24.569+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.181 seconds
[2022-12-16T14:58:34.879+0000] {processor.py:154} INFO - Started process (PID=3125) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:34.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:34.935+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:34.934+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:35.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:35.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:35.248+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:35.371+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:35.370+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:35.479+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.615 seconds
[2022-12-16T14:58:45.629+0000] {processor.py:154} INFO - Started process (PID=3135) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:45.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:45.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:45.683+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:45.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:46.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:46.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:46.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:46.867+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:46.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.379 seconds
[2022-12-16T14:58:57.243+0000] {processor.py:154} INFO - Started process (PID=3152) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:57.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:58:57.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:57.292+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:57.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:58:57.774+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:57.773+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:58:57.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:58:57.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:58:58.092+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.869 seconds
[2022-12-16T14:59:08.559+0000] {processor.py:154} INFO - Started process (PID=3162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:08.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:59:08.624+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:08.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:08.711+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:08.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:08.846+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:59:09.016+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:09.015+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:59:09.160+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.622 seconds
[2022-12-16T14:59:19.389+0000] {processor.py:154} INFO - Started process (PID=3172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:19.409+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:59:19.420+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:19.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:19.549+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:20.670+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T14:59:31.025+0000] {processor.py:154} INFO - Started process (PID=3182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:31.055+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:59:31.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:31.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:31.148+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:31.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:31.459+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:59:31.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:31.624+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:59:31.796+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.787 seconds
[2022-12-16T14:59:42.229+0000] {processor.py:154} INFO - Started process (PID=3199) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:42.254+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:59:42.262+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:42.261+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:42.569+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:43.414+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:43.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T14:59:43.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:43.539+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T14:59:43.760+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.552 seconds
[2022-12-16T14:59:54.348+0000] {processor.py:154} INFO - Started process (PID=3209) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:54.383+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T14:59:54.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T14:59:54.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:54.570+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T14:59:55.986+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:00:06.737+0000] {processor.py:154} INFO - Started process (PID=3219) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:06.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:00:06.791+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:06.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:06.906+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:08.142+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:00:18.549+0000] {processor.py:154} INFO - Started process (PID=3238) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:18.598+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:00:18.603+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:18.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:18.711+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:18.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:18.995+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:00:19.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:19.170+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:00:19.309+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.776 seconds
[2022-12-16T15:00:29.520+0000] {processor.py:154} INFO - Started process (PID=3248) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:29.546+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:00:29.550+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:29.549+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:29.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:29.821+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:29.820+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:00:29.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:29.955+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:00:30.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-16T15:00:40.819+0000] {processor.py:154} INFO - Started process (PID=3258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:40.840+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:00:40.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:40.846+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:40.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:41.405+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:41.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:00:41.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:41.515+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:00:41.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.855 seconds
[2022-12-16T15:00:52.136+0000] {processor.py:154} INFO - Started process (PID=3268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:52.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:00:52.169+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:52.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:52.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:00:52.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:52.393+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:00:52.506+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:00:52.505+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:00:52.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.545 seconds
[2022-12-16T15:01:02.863+0000] {processor.py:154} INFO - Started process (PID=3286) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:02.880+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:01:02.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:02.890+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:03.094+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:03.626+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:03.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:01:03.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:03.886+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:01:04.270+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.450 seconds
[2022-12-16T15:01:14.966+0000] {processor.py:154} INFO - Started process (PID=3296) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:15.001+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:01:15.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:15.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:15.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:16.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:16.415+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:01:16.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:16.555+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:01:16.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.756 seconds
[2022-12-16T15:01:27.456+0000] {processor.py:154} INFO - Started process (PID=3306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:27.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:01:27.513+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:27.510+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:27.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:27.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:27.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:01:28.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:28.053+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:01:28.173+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.745 seconds
[2022-12-16T15:01:38.756+0000] {processor.py:154} INFO - Started process (PID=3316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:38.777+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:01:38.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:38.780+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:38.884+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:39.214+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:39.213+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:01:39.436+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:39.435+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:01:39.579+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.840 seconds
[2022-12-16T15:01:50.175+0000] {processor.py:154} INFO - Started process (PID=3335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:50.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:01:50.208+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:01:50.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:50.362+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:01:51.502+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:02:01.824+0000] {processor.py:154} INFO - Started process (PID=3345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:01.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:01.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:01.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:02.161+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:03.189+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:03.188+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:03.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:03.321+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:02:03.542+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.762 seconds
[2022-12-16T15:02:13.854+0000] {processor.py:154} INFO - Started process (PID=3355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:13.905+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:13.910+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:13.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:14.001+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:14.582+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:14.581+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:14.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:14.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:02:14.833+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.993 seconds
[2022-12-16T15:02:25.456+0000] {processor.py:154} INFO - Started process (PID=3373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:25.485+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:25.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:25.492+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:25.606+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:25.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:25.776+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:25.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:25.907+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:02:26.035+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.601 seconds
[2022-12-16T15:02:36.384+0000] {processor.py:154} INFO - Started process (PID=3383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:36.420+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:36.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:36.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:36.535+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:37.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:37.053+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:37.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:37.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:02:37.356+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.989 seconds
[2022-12-16T15:02:47.755+0000] {processor.py:154} INFO - Started process (PID=3393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:47.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:47.794+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:47.793+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:47.885+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:48.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:48.956+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:49.084+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:49.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:02:49.234+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.493 seconds
[2022-12-16T15:02:59.565+0000] {processor.py:154} INFO - Started process (PID=3403) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:59.592+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:02:59.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:59.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:59.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:02:59.817+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:59.816+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:02:59.933+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:02:59.932+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:03:00.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.512 seconds
[2022-12-16T15:03:10.717+0000] {processor.py:154} INFO - Started process (PID=3421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:10.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:03:10.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:10.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:10.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:11.458+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:11.457+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:03:11.879+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:11.878+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:03:12.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.335 seconds
[2022-12-16T15:03:22.633+0000] {processor.py:154} INFO - Started process (PID=3431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:22.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:03:22.674+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:22.673+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:22.889+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:23.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:23.257+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:03:23.402+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:23.401+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:03:23.512+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.918 seconds
[2022-12-16T15:03:33.866+0000] {processor.py:154} INFO - Started process (PID=3441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:33.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:03:33.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:33.895+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:34.008+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:35.560+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:03:45.905+0000] {processor.py:154} INFO - Started process (PID=3451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:45.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:03:45.965+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:45.964+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:46.281+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:46.499+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:46.498+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:03:46.638+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:46.637+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:03:46.786+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.901 seconds
[2022-12-16T15:03:57.518+0000] {processor.py:154} INFO - Started process (PID=3469) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:57.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:03:57.608+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:57.598+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:57.875+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:03:58.044+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:58.042+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:03:58.158+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:03:58.157+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:03:58.269+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.819 seconds
[2022-12-16T15:04:08.568+0000] {processor.py:154} INFO - Started process (PID=3479) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:08.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:04:08.633+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:08.633+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:08.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:08.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:08.936+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:04:09.062+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:09.061+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:04:09.362+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.809 seconds
[2022-12-16T15:04:19.936+0000] {processor.py:154} INFO - Started process (PID=3489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:19.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:04:19.993+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:19.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:20.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:20.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:20.363+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:04:20.560+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:20.559+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:04:20.811+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.891 seconds
[2022-12-16T15:04:31.232+0000] {processor.py:154} INFO - Started process (PID=3507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:31.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:04:31.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:31.286+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:31.473+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:31.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:31.668+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:04:31.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:31.802+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:04:31.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.712 seconds
[2022-12-16T15:04:42.290+0000] {processor.py:154} INFO - Started process (PID=3517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:42.315+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:04:42.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:42.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:42.399+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:43.382+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:04:53.714+0000] {processor.py:154} INFO - Started process (PID=3527) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:53.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:04:53.739+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:53.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:53.820+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:04:53.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:53.949+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:04:54.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:04:54.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:04:54.228+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-16T15:05:04.941+0000] {processor.py:154} INFO - Started process (PID=3537) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:04.959+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:05:04.969+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:04.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:05.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:05.248+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:05.248+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:05:05.370+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:05.370+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:05:05.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.593 seconds
[2022-12-16T15:05:16.046+0000] {processor.py:154} INFO - Started process (PID=3555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:16.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:05:16.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:16.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:16.258+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:16.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:16.592+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:05:16.742+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:16.734+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:05:16.904+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.898 seconds
[2022-12-16T15:05:27.555+0000] {processor.py:154} INFO - Started process (PID=3565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:27.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:05:27.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:27.592+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:27.829+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:28.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:28.284+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:05:28.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:28.438+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:05:28.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.074 seconds
[2022-12-16T15:05:38.966+0000] {processor.py:154} INFO - Started process (PID=3575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:39.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:05:39.024+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:39.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:39.151+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:39.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:39.328+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:05:39.554+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:39.549+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:05:39.722+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.770 seconds
[2022-12-16T15:05:50.060+0000] {processor.py:154} INFO - Started process (PID=3585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:50.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:05:50.107+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:50.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:50.411+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:05:50.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:50.697+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:05:50.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:05:50.825+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:05:51.168+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.144 seconds
[2022-12-16T15:06:01.526+0000] {processor.py:154} INFO - Started process (PID=3603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:01.534+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:06:01.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:01.550+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:01.991+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:03.329+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:06:13.820+0000] {processor.py:154} INFO - Started process (PID=3613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:13.858+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:06:13.877+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:13.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:14.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:14.728+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:14.727+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:06:14.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:14.863+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:06:15.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.479 seconds
[2022-12-16T15:06:25.648+0000] {processor.py:154} INFO - Started process (PID=3623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:25.703+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:06:25.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:25.710+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:26.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:26.332+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:26.331+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:06:26.508+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:26.507+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:06:26.619+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-16T15:06:37.099+0000] {processor.py:154} INFO - Started process (PID=3641) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:37.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:06:37.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:37.141+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:37.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:38.214+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:38.213+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:06:38.422+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:38.421+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:06:38.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.735 seconds
[2022-12-16T15:06:49.330+0000] {processor.py:154} INFO - Started process (PID=3651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:49.381+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:06:49.389+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:49.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:49.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:06:50.011+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:50.010+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:06:50.148+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:06:50.147+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:06:50.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.957 seconds
[2022-12-16T15:07:00.548+0000] {processor.py:154} INFO - Started process (PID=3661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:00.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:00.598+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:00.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:00.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:00.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:00.934+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:01.243+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:01.242+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:01.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.931 seconds
[2022-12-16T15:07:11.824+0000] {processor.py:154} INFO - Started process (PID=3671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:11.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:11.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:11.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:11.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:12.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:12.177+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:12.308+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:12.308+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:12.542+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.732 seconds
[2022-12-16T15:07:22.866+0000] {processor.py:154} INFO - Started process (PID=3689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:22.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:22.935+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:22.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:23.049+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:23.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:23.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:23.513+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:23.512+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:23.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.804 seconds
[2022-12-16T15:07:34.019+0000] {processor.py:154} INFO - Started process (PID=3699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:34.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:34.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:34.049+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:34.141+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:34.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:34.668+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:34.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:34.785+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:34.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.912 seconds
[2022-12-16T15:07:45.292+0000] {processor.py:154} INFO - Started process (PID=3709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:45.358+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:45.364+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:45.362+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:45.448+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:45.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:45.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:45.728+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:45.727+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:45.856+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.579 seconds
[2022-12-16T15:07:56.150+0000] {processor.py:154} INFO - Started process (PID=3719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:56.196+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:07:56.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:56.200+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:56.292+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:07:56.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:56.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:07:56.922+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:07:56.921+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:07:57.210+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.074 seconds
[2022-12-16T15:08:07.784+0000] {processor.py:154} INFO - Started process (PID=3737) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:07.832+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:08:07.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:07.835+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:07.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:08.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:08.135+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:08:08.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:08.268+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:08:08.434+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.668 seconds
[2022-12-16T15:08:18.771+0000] {processor.py:154} INFO - Started process (PID=3747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:18.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:08:18.813+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:18.812+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:18.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:19.442+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:08:29.871+0000] {processor.py:154} INFO - Started process (PID=3757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:29.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:08:29.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:29.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:30.042+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:30.553+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:30.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:08:30.682+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:30.681+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:08:30.810+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.954 seconds
[2022-12-16T15:08:41.329+0000] {processor.py:154} INFO - Started process (PID=3775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:41.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:08:41.385+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:41.385+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:41.612+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:43.151+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:08:53.372+0000] {processor.py:154} INFO - Started process (PID=3785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:53.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:08:53.402+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:08:53.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:53.506+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:08:53.877+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:09:04.178+0000] {processor.py:154} INFO - Started process (PID=3795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:04.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:09:04.213+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:04.212+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:04.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:05.672+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:05.670+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:09:05.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:05.787+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:09:05.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.739 seconds
[2022-12-16T15:09:16.245+0000] {processor.py:154} INFO - Started process (PID=3805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:16.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:09:16.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:16.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:16.579+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:17.796+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:09:27.972+0000] {processor.py:154} INFO - Started process (PID=3822) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:28.024+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:09:28.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:28.026+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:28.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:29.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:29.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:09:29.259+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:29.258+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:09:29.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.485 seconds
[2022-12-16T15:09:39.763+0000] {processor.py:154} INFO - Started process (PID=3832) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:39.861+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:09:39.900+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:39.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:40.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:40.651+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:40.650+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:09:40.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:40.866+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:09:40.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.231 seconds
[2022-12-16T15:09:51.139+0000] {processor.py:154} INFO - Started process (PID=3842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:51.143+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:09:51.147+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:51.146+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:51.245+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:09:51.395+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:51.394+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:09:51.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:09:51.667+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:09:51.855+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.731 seconds
[2022-12-16T15:10:02.550+0000] {processor.py:154} INFO - Started process (PID=3859) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:02.603+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:10:02.607+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:02.606+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:02.902+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:03.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:03.348+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:10:03.821+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:03.820+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:10:04.019+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-16T15:10:14.482+0000] {processor.py:154} INFO - Started process (PID=3870) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:14.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:10:14.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:14.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:14.725+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:15.352+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:15.350+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:10:15.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:15.530+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:10:15.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.186 seconds
[2022-12-16T15:10:26.047+0000] {processor.py:154} INFO - Started process (PID=3880) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:26.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:10:26.085+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:26.085+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:26.212+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:26.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:26.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:10:26.966+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:26.965+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:10:27.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.132 seconds
[2022-12-16T15:10:37.439+0000] {processor.py:154} INFO - Started process (PID=3890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:37.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:10:37.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:37.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:37.587+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:38.306+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:38.304+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:10:38.452+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:38.451+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:10:38.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.160 seconds
[2022-12-16T15:10:49.097+0000] {processor.py:154} INFO - Started process (PID=3907) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:49.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:10:49.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:49.149+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:49.625+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:10:50.355+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:50.354+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:10:50.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:10:50.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:10:50.644+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.600 seconds
[2022-12-16T15:11:01.101+0000] {processor.py:154} INFO - Started process (PID=3917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:01.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:01.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:01.148+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:01.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:01.590+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:01.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:01.883+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:01.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:02.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.066 seconds
[2022-12-16T15:11:12.600+0000] {processor.py:154} INFO - Started process (PID=3927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:12.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:12.626+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:12.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:12.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:13.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:13.169+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:13.296+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:13.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:13.589+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.048 seconds
[2022-12-16T15:11:24.005+0000] {processor.py:154} INFO - Started process (PID=3944) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:24.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:24.047+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:24.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:24.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:24.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:24.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:25.072+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:25.071+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:25.408+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.449 seconds
[2022-12-16T15:11:35.898+0000] {processor.py:154} INFO - Started process (PID=3955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:35.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:35.952+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:35.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:36.041+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:36.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:36.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:36.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:36.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:36.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-16T15:11:47.128+0000] {processor.py:154} INFO - Started process (PID=3965) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:47.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:47.165+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:47.164+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:47.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:47.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:47.420+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:47.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:47.540+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:47.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-16T15:11:57.966+0000] {processor.py:154} INFO - Started process (PID=3975) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:58.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:11:58.024+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:58.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:58.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:11:58.897+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:58.896+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:11:59.025+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:11:59.024+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:11:59.301+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.352 seconds
[2022-12-16T15:12:09.737+0000] {processor.py:154} INFO - Started process (PID=3994) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:09.788+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:12:09.805+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:09.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:09.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:10.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:10.169+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:12:10.305+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:10.304+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:12:10.813+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.110 seconds
[2022-12-16T15:12:15.821+0000] {processor.py:154} INFO - Started process (PID=4004) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:15.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:12:15.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:15.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:15.978+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:16.321+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:16.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:12:17.072+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:17.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:12:17.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.653 seconds
[2022-12-16T15:12:27.702+0000] {processor.py:154} INFO - Started process (PID=4014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:27.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:12:27.743+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:27.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:27.988+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:28.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:28.411+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:12:28.839+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:28.838+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:12:29.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.791 seconds
[2022-12-16T15:12:39.809+0000] {processor.py:154} INFO - Started process (PID=4024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:39.834+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:12:39.846+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:39.841+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:39.957+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:40.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:40.259+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:12:40.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:40.559+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:12:40.908+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.116 seconds
[2022-12-16T15:12:51.225+0000] {processor.py:154} INFO - Started process (PID=4041) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:51.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:12:51.273+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:51.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:51.554+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:12:51.794+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:51.793+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:12:52.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:12:52.342+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:12:52.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.632 seconds
[2022-12-16T15:13:03.198+0000] {processor.py:154} INFO - Started process (PID=4051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:03.390+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:13:03.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:03.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:03.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:03.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:03.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:13:04.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:04.170+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:13:04.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.130 seconds
[2022-12-16T15:13:14.581+0000] {processor.py:154} INFO - Started process (PID=4061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:14.593+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:13:14.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:14.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:14.688+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:14.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:14.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:13:14.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:14.985+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:13:15.230+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.662 seconds
[2022-12-16T15:13:26.417+0000] {processor.py:154} INFO - Started process (PID=4071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:26.450+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:13:26.463+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:26.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:26.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:27.578+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:27.577+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:13:27.874+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:27.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:13:28.028+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.670 seconds
[2022-12-16T15:13:38.494+0000] {processor.py:154} INFO - Started process (PID=4090) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:38.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:13:38.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:38.527+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:38.651+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:39.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:39.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:13:39.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:39.453+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:13:39.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.149 seconds
[2022-12-16T15:13:49.953+0000] {processor.py:154} INFO - Started process (PID=4100) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:50.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:13:50.010+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:50.009+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:50.162+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:13:50.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:50.462+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:13:50.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:13:50.785+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:13:51.122+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.203 seconds
[2022-12-16T15:14:01.433+0000] {processor.py:154} INFO - Started process (PID=4110) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:01.473+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:14:01.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:01.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:01.593+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:02.081+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:14:12.962+0000] {processor.py:154} INFO - Started process (PID=4128) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:13.002+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:14:13.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:13.005+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:13.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:14.102+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:14.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:14:14.634+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:14.634+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:14:14.984+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.054 seconds
[2022-12-16T15:14:25.600+0000] {processor.py:154} INFO - Started process (PID=4138) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:25.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:14:25.643+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:25.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:25.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:26.145+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:26.144+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:14:26.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:26.275+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:14:26.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.884 seconds
[2022-12-16T15:14:36.742+0000] {processor.py:154} INFO - Started process (PID=4148) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:36.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:14:36.797+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:36.796+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:37.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:37.962+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:37.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:14:38.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:38.119+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:14:38.262+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.567 seconds
[2022-12-16T15:14:48.543+0000] {processor.py:154} INFO - Started process (PID=4158) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:48.587+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:14:48.591+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:48.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:48.878+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:14:49.610+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:49.608+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:14:49.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:14:49.754+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:14:49.896+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.383 seconds
[2022-12-16T15:15:00.179+0000] {processor.py:154} INFO - Started process (PID=4175) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:00.233+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:00.237+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:00.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:00.359+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:00.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:00.517+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:00.794+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:00.793+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:00.970+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.806 seconds
[2022-12-16T15:15:11.273+0000] {processor.py:154} INFO - Started process (PID=4185) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:11.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:11.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:11.321+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:11.445+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:12.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:12.248+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:12.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:12.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:12.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.320 seconds
[2022-12-16T15:15:22.922+0000] {processor.py:154} INFO - Started process (PID=4195) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:22.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:22.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:22.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:23.042+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:23.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:23.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:23.315+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:23.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:23.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.549 seconds
[2022-12-16T15:15:33.763+0000] {processor.py:154} INFO - Started process (PID=4214) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:33.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:33.820+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:33.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:33.937+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:34.119+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:34.110+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:34.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:34.356+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:34.474+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.726 seconds
[2022-12-16T15:15:44.788+0000] {processor.py:154} INFO - Started process (PID=4224) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:44.811+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:44.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:44.814+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:44.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:45.355+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:45.354+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:45.485+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:45.484+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:45.594+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.821 seconds
[2022-12-16T15:15:56.468+0000] {processor.py:154} INFO - Started process (PID=4234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:56.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:15:56.495+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:56.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:56.583+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:15:56.712+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:56.711+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:15:56.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:15:56.826+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:15:56.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.513 seconds
[2022-12-16T15:16:07.250+0000] {processor.py:154} INFO - Started process (PID=4244) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:07.284+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:16:07.289+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:07.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:07.385+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:08.643+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:08.642+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:16:08.759+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:08.758+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:16:08.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.637 seconds
[2022-12-16T15:16:19.425+0000] {processor.py:154} INFO - Started process (PID=4262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:19.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:16:19.486+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:19.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:19.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:19.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:19.841+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:16:19.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:19.985+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:16:20.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.726 seconds
[2022-12-16T15:16:30.411+0000] {processor.py:154} INFO - Started process (PID=4272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:30.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:16:30.457+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:30.456+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:30.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:31.048+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:31.047+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:16:31.167+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:31.166+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:16:31.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.879 seconds
[2022-12-16T15:16:41.547+0000] {processor.py:154} INFO - Started process (PID=4282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:41.567+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:16:41.571+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:41.570+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:41.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:41.952+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:41.951+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:16:42.102+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:42.101+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:16:42.294+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.761 seconds
[2022-12-16T15:16:52.729+0000] {processor.py:154} INFO - Started process (PID=4301) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:52.781+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:16:52.785+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:52.784+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:52.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:16:53.511+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:53.510+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:16:53.827+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:16:53.826+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:16:54.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.289 seconds
[2022-12-16T15:17:04.436+0000] {processor.py:154} INFO - Started process (PID=4311) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:04.459+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:17:04.464+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:04.463+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:04.546+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:04.680+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:04.679+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:17:04.795+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:04.794+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:17:04.933+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.510 seconds
[2022-12-16T15:17:15.059+0000] {processor.py:154} INFO - Started process (PID=4321) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:15.086+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:17:15.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:15.091+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:15.174+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:15.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:15.787+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:17:15.901+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:15.900+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:17:16.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.260 seconds
[2022-12-16T15:17:26.588+0000] {processor.py:154} INFO - Started process (PID=4331) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:26.614+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:17:26.623+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:26.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:26.728+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:27.387+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:17:38.048+0000] {processor.py:154} INFO - Started process (PID=4349) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:38.093+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:17:38.101+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:38.100+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:38.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:38.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:38.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:17:38.974+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:38.973+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:17:39.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.141 seconds
[2022-12-16T15:17:49.472+0000] {processor.py:154} INFO - Started process (PID=4359) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:49.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:17:49.500+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:49.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:49.600+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:17:49.768+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:49.767+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:17:49.882+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:17:49.881+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:17:49.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.543 seconds
[2022-12-16T15:18:00.306+0000] {processor.py:154} INFO - Started process (PID=4369) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:00.355+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:00.360+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:00.359+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:00.445+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:00.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:00.664+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:18:00.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:00.905+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:18:01.036+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.742 seconds
[2022-12-16T15:18:11.198+0000] {processor.py:154} INFO - Started process (PID=4379) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:11.248+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:11.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:11.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:11.338+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:13.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:13.038+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:18:13.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:13.176+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:18:13.327+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.144 seconds
[2022-12-16T15:18:23.652+0000] {processor.py:154} INFO - Started process (PID=4398) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:23.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:23.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:23.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:23.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:24.973+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:24.972+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:18:25.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:25.141+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:18:25.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.678 seconds
[2022-12-16T15:18:36.000+0000] {processor.py:154} INFO - Started process (PID=4408) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:36.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:36.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:36.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:36.155+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:36.307+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:36.306+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:18:36.418+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:36.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:18:36.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.544 seconds
[2022-12-16T15:18:46.902+0000] {processor.py:154} INFO - Started process (PID=4418) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:46.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:46.948+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:46.947+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:47.298+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:47.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:47.523+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:18:47.657+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:47.656+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:18:47.779+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.917 seconds
[2022-12-16T15:18:58.580+0000] {processor.py:154} INFO - Started process (PID=4435) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:58.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:18:58.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:18:58.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:18:58.817+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:00.214+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:19:10.752+0000] {processor.py:154} INFO - Started process (PID=4445) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:10.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:19:10.848+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:10.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:11.059+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:11.901+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:11.899+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:19:12.091+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:12.090+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:19:12.557+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.839 seconds
[2022-12-16T15:19:23.145+0000] {processor.py:154} INFO - Started process (PID=4458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:23.181+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:19:23.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:23.185+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:23.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:24.575+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:19:35.143+0000] {processor.py:154} INFO - Started process (PID=4477) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:35.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:19:35.162+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:35.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:35.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:35.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:35.478+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:19:35.651+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:35.650+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:19:35.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.790 seconds
[2022-12-16T15:19:46.121+0000] {processor.py:154} INFO - Started process (PID=4486) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:46.125+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:19:46.129+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:46.128+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:46.216+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:46.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:46.389+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:19:46.566+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:46.565+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:19:46.694+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.586 seconds
[2022-12-16T15:19:57.045+0000] {processor.py:154} INFO - Started process (PID=4493) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:57.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:19:57.129+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:57.128+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:57.446+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:19:58.891+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:58.890+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:19:59.090+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:19:59.089+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:19:59.234+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.317 seconds
[2022-12-16T15:20:09.488+0000] {processor.py:154} INFO - Started process (PID=4503) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:09.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:20:09.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:09.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:09.607+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:10.314+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:10.313+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:20:10.507+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:10.506+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:20:10.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.162 seconds
[2022-12-16T15:20:20.980+0000] {processor.py:154} INFO - Started process (PID=4523) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:20.984+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:20:20.993+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:20.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:21.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:21.361+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:20:31.759+0000] {processor.py:154} INFO - Started process (PID=4530) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:31.774+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:20:31.784+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:31.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:31.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:32.467+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:32.466+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:20:32.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:32.600+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:20:32.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.972 seconds
[2022-12-16T15:20:43.001+0000] {processor.py:154} INFO - Started process (PID=4540) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:43.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:20:43.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:43.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:43.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:43.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:43.281+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:20:43.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:43.561+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:20:43.705+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.718 seconds
[2022-12-16T15:20:54.116+0000] {processor.py:154} INFO - Started process (PID=4556) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:54.146+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:20:54.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:54.149+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:54.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:20:55.724+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:55.718+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:20:56.153+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:20:56.152+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:20:57.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.994 seconds
[2022-12-16T15:21:07.492+0000] {processor.py:154} INFO - Started process (PID=4568) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:07.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:21:07.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:07.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:07.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:07.743+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:07.742+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:21:07.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:07.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:21:07.986+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.508 seconds
[2022-12-16T15:21:18.389+0000] {processor.py:154} INFO - Started process (PID=4578) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:18.405+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:21:18.410+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:18.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:18.553+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:18.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:18.688+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:21:18.800+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:18.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:21:18.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-16T15:21:29.246+0000] {processor.py:154} INFO - Started process (PID=4588) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:29.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:21:29.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:29.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:29.481+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:29.799+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:29.798+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:21:30.033+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:30.032+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:21:30.153+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.923 seconds
[2022-12-16T15:21:41.174+0000] {processor.py:154} INFO - Started process (PID=4606) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:41.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:21:41.239+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:41.222+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:41.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:42.076+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:42.071+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:21:42.266+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:42.261+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:21:42.393+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.266 seconds
[2022-12-16T15:21:52.675+0000] {processor.py:154} INFO - Started process (PID=4616) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:52.695+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:21:52.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:52.698+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:52.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:21:53.926+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:53.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:21:54.062+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:21:54.061+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:21:54.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.517 seconds
[2022-12-16T15:22:04.434+0000] {processor.py:154} INFO - Started process (PID=4626) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:04.438+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:22:04.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:04.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:04.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:05.892+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:05.891+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:22:06.017+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:06.017+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:22:06.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.736 seconds
[2022-12-16T15:22:16.523+0000] {processor.py:154} INFO - Started process (PID=4643) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:16.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:22:16.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:16.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:16.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:16.779+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:16.778+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:22:16.970+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:16.969+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:22:17.187+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.680 seconds
[2022-12-16T15:22:28.362+0000] {processor.py:154} INFO - Started process (PID=4654) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:28.395+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:22:28.399+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:28.398+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:28.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:28.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:28.827+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:22:28.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:28.974+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:22:29.137+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.830 seconds
[2022-12-16T15:22:39.537+0000] {processor.py:154} INFO - Started process (PID=4664) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:39.565+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:22:39.570+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:39.569+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:39.652+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:39.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:39.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:22:39.893+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:39.893+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:22:40.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.575 seconds
[2022-12-16T15:22:51.177+0000] {processor.py:154} INFO - Started process (PID=4674) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:51.185+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:22:51.190+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:22:51.188+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:51.306+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:22:52.015+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:23:02.694+0000] {processor.py:154} INFO - Started process (PID=4692) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:02.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:23:02.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:02.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:02.946+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:03.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:03.441+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:23:03.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:03.743+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:23:03.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.313 seconds
[2022-12-16T15:23:14.377+0000] {processor.py:154} INFO - Started process (PID=4705) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:14.381+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:23:14.385+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:14.384+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:14.469+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:14.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:14.871+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:23:14.993+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:14.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:23:15.137+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.774 seconds
[2022-12-16T15:23:25.453+0000] {processor.py:154} INFO - Started process (PID=4712) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:25.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:23:25.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:25.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:25.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:26.235+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:26.234+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:23:26.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:26.385+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:23:26.706+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.269 seconds
[2022-12-16T15:23:37.014+0000] {processor.py:154} INFO - Started process (PID=4722) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:37.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:23:37.073+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:37.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:37.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:37.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:37.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:23:38.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:38.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:23:38.570+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.574 seconds
[2022-12-16T15:23:49.129+0000] {processor.py:154} INFO - Started process (PID=4743) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:49.179+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:23:49.182+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:49.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:49.326+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:23:50.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:50.277+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:23:50.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:23:50.390+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:23:50.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.411 seconds
[2022-12-16T15:24:00.776+0000] {processor.py:154} INFO - Started process (PID=4753) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:00.813+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:00.816+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:00.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:01.005+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:01.327+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:01.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:01.738+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:01.737+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:02.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.329 seconds
[2022-12-16T15:24:12.413+0000] {processor.py:154} INFO - Started process (PID=4760) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:12.438+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:12.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:12.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:12.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:13.108+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:13.107+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:13.256+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:13.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:13.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.024 seconds
[2022-12-16T15:24:23.757+0000] {processor.py:154} INFO - Started process (PID=4777) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:23.805+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:23.809+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:23.808+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:24.021+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:24.388+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:24.378+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:24.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:24.599+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:24.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.105 seconds
[2022-12-16T15:24:35.152+0000] {processor.py:154} INFO - Started process (PID=4787) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:35.240+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:35.246+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:35.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:35.362+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:35.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:35.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:35.679+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:35.677+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:35.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.769 seconds
[2022-12-16T15:24:46.179+0000] {processor.py:154} INFO - Started process (PID=4797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:46.233+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:46.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:46.244+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:46.347+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:46.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:46.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:46.645+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:46.644+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:46.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.632 seconds
[2022-12-16T15:24:57.211+0000] {processor.py:154} INFO - Started process (PID=4807) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:57.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:24:57.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:57.233+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:57.448+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:24:59.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:59.407+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:24:59.629+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:24:59.628+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:24:59.839+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.688 seconds
[2022-12-16T15:25:10.855+0000] {processor.py:154} INFO - Started process (PID=4830) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:10.901+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:25:10.905+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:10.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:10.995+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:11.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:11.170+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:25:11.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:11.361+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:25:11.535+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.692 seconds
[2022-12-16T15:25:22.057+0000] {processor.py:154} INFO - Started process (PID=4840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:22.067+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:25:22.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:22.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:22.157+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:22.304+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:22.303+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:25:22.428+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:22.427+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:25:22.537+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.499 seconds
[2022-12-16T15:25:32.818+0000] {processor.py:154} INFO - Started process (PID=4850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:32.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:25:32.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:32.867+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:32.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:33.098+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:33.097+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:25:33.212+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:33.211+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:25:33.341+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.537 seconds
[2022-12-16T15:25:43.752+0000] {processor.py:154} INFO - Started process (PID=4868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:43.796+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:25:43.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:43.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:44.039+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:44.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:44.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:25:44.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:44.658+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:25:45.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.600 seconds
[2022-12-16T15:25:56.122+0000] {processor.py:154} INFO - Started process (PID=4878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:56.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:25:56.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:56.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:56.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:25:56.738+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:56.737+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:25:56.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:25:56.864+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:25:56.996+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.981 seconds
[2022-12-16T15:26:07.304+0000] {processor.py:154} INFO - Started process (PID=4888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:07.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:26:07.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:07.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:07.900+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:08.553+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:08.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:26:08.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:08.771+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:26:08.925+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.644 seconds
[2022-12-16T15:26:19.811+0000] {processor.py:154} INFO - Started process (PID=4898) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:19.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:26:19.893+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:19.892+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:20.058+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:20.210+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:20.209+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:26:20.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:20.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:26:20.445+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.648 seconds
[2022-12-16T15:26:31.590+0000] {processor.py:154} INFO - Started process (PID=4915) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:31.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:26:31.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:31.605+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:31.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:32.967+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:26:43.274+0000] {processor.py:154} INFO - Started process (PID=4925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:43.369+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:26:43.374+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:43.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:43.455+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:43.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:43.605+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:26:43.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:43.776+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:26:43.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-16T15:26:54.368+0000] {processor.py:154} INFO - Started process (PID=4935) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:54.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:26:54.402+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:54.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:54.586+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:26:55.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:55.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:26:55.419+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:26:55.418+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:26:55.559+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.225 seconds
[2022-12-16T15:27:05.964+0000] {processor.py:154} INFO - Started process (PID=4952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:05.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:27:05.991+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:05.990+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:06.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:06.709+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:06.708+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:27:06.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:06.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:27:07.109+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.162 seconds
[2022-12-16T15:27:17.650+0000] {processor.py:154} INFO - Started process (PID=4962) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:17.673+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:27:17.677+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:17.676+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:17.878+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:18.447+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:18.446+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:27:18.566+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:18.565+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:27:18.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.116 seconds
[2022-12-16T15:27:29.116+0000] {processor.py:154} INFO - Started process (PID=4972) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:29.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:27:29.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:29.226+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:29.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:30.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:30.777+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:27:30.938+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:30.937+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:27:31.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.981 seconds
[2022-12-16T15:27:41.358+0000] {processor.py:154} INFO - Started process (PID=4982) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:41.391+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:27:41.400+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:41.395+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:41.597+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:41.848+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:41.847+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:27:41.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:41.983+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:27:42.145+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.800 seconds
[2022-12-16T15:27:52.370+0000] {processor.py:154} INFO - Started process (PID=5000) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:52.418+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:27:52.451+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:52.446+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:52.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:27:53.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:53.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:27:53.259+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:27:53.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:27:53.585+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.235 seconds
[2022-12-16T15:28:03.985+0000] {processor.py:154} INFO - Started process (PID=5010) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:04.012+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:28:04.025+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:04.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:04.249+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:05.421+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:28:16.029+0000] {processor.py:154} INFO - Started process (PID=5020) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:16.034+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:28:16.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:16.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:16.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:16.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:16.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:28:16.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:16.631+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:28:16.938+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.965 seconds
[2022-12-16T15:28:27.464+0000] {processor.py:154} INFO - Started process (PID=5038) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:27.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:28:27.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:27.498+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:27.633+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:29.141+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:28:39.708+0000] {processor.py:154} INFO - Started process (PID=5048) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:39.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:28:39.736+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:39.734+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:39.848+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:40.296+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:40.294+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:28:40.409+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:40.408+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:28:40.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.844 seconds
[2022-12-16T15:28:50.785+0000] {processor.py:154} INFO - Started process (PID=5058) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:50.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:28:50.850+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:50.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:50.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:28:51.730+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:51.729+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:28:51.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:28:51.841+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:28:51.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.213 seconds
[2022-12-16T15:29:02.257+0000] {processor.py:154} INFO - Started process (PID=5068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:02.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:29:02.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:02.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:02.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:02.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:02.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:29:02.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:02.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:29:03.017+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.774 seconds
[2022-12-16T15:29:13.615+0000] {processor.py:154} INFO - Started process (PID=5086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:13.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:29:13.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:13.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:13.766+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:14.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:14.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:29:14.450+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:14.449+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:29:14.588+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.989 seconds
[2022-12-16T15:29:25.110+0000] {processor.py:154} INFO - Started process (PID=5096) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:25.166+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:29:25.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:25.170+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:25.256+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:25.862+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:25.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:29:25.982+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:25.981+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:29:26.092+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.998 seconds
[2022-12-16T15:29:36.208+0000] {processor.py:154} INFO - Started process (PID=5106) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:36.235+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:29:36.242+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:36.241+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:36.326+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:36.978+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:36.977+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:29:37.250+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:37.249+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:29:37.359+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.165 seconds
[2022-12-16T15:29:47.536+0000] {processor.py:154} INFO - Started process (PID=5124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:47.582+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:29:47.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:47.585+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:47.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:29:49.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:49.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:29:49.405+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:29:49.404+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:29:49.516+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.996 seconds
[2022-12-16T15:30:00.022+0000] {processor.py:154} INFO - Started process (PID=5134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:00.058+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:00.066+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:00.065+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:00.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:00.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:00.630+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:00.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:00.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:00.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.921 seconds
[2022-12-16T15:30:11.488+0000] {processor.py:154} INFO - Started process (PID=5144) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:11.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:11.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:11.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:11.638+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:11.987+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:11.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:12.287+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:12.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:12.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.961 seconds
[2022-12-16T15:30:22.938+0000] {processor.py:154} INFO - Started process (PID=5154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:22.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:23.002+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:23.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:23.467+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:23.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:23.795+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:24.050+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:24.049+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:24.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.618 seconds
[2022-12-16T15:30:34.728+0000] {processor.py:154} INFO - Started process (PID=5172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:34.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:34.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:34.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:34.951+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:36.457+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:36.456+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:36.604+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:36.603+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:36.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.072 seconds
[2022-12-16T15:30:47.107+0000] {processor.py:154} INFO - Started process (PID=5182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:47.133+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:47.138+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:47.137+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:47.376+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:47.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:47.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:47.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:47.788+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:47.922+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.846 seconds
[2022-12-16T15:30:58.210+0000] {processor.py:154} INFO - Started process (PID=5192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:58.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:30:58.264+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:58.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:58.350+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:30:58.497+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:58.495+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:30:58.771+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:30:58.770+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:30:59.020+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.824 seconds
[2022-12-16T15:31:09.414+0000] {processor.py:154} INFO - Started process (PID=5211) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:09.461+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:31:09.470+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:09.469+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:09.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:09.850+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:09.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:31:09.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:09.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:31:10.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.889 seconds
[2022-12-16T15:31:20.876+0000] {processor.py:154} INFO - Started process (PID=5221) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:20.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:31:20.967+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:20.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:21.060+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:21.268+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:21.267+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:31:21.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:21.419+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:31:21.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.663 seconds
[2022-12-16T15:31:31.697+0000] {processor.py:154} INFO - Started process (PID=5231) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:31.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:31:31.749+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:31.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:31.842+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:32.317+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:31:42.667+0000] {processor.py:154} INFO - Started process (PID=5241) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:42.683+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:31:42.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:42.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:42.794+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:42.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:42.949+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:31:43.071+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:43.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:31:43.200+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-16T15:31:53.658+0000] {processor.py:154} INFO - Started process (PID=5258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:53.668+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:31:53.680+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:53.671+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:53.866+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:31:54.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:54.198+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:31:54.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:31:54.392+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:31:54.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.961 seconds
[2022-12-16T15:32:04.823+0000] {processor.py:154} INFO - Started process (PID=5268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:04.859+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:32:04.866+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:04.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:05.037+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:05.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:05.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:32:05.319+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:05.318+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:32:05.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.648 seconds
[2022-12-16T15:32:15.677+0000] {processor.py:154} INFO - Started process (PID=5278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:15.726+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:32:15.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:15.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:15.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:16.002+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:16.002+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:32:16.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:16.127+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:32:16.349+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.687 seconds
[2022-12-16T15:32:26.786+0000] {processor.py:154} INFO - Started process (PID=5294) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:26.818+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:32:26.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:26.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:27.047+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:28.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:28.022+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:32:28.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:28.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:32:28.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.138 seconds
[2022-12-16T15:32:39.492+0000] {processor.py:154} INFO - Started process (PID=5305) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:39.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:32:39.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:39.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:39.654+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:39.830+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:39.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:32:39.952+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:39.951+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:32:40.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.580 seconds
[2022-12-16T15:32:50.308+0000] {processor.py:154} INFO - Started process (PID=5312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:50.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:32:50.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:50.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:50.421+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:32:51.302+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:51.300+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:32:51.452+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:32:51.451+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:32:51.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.283 seconds
[2022-12-16T15:33:01.908+0000] {processor.py:154} INFO - Started process (PID=5322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:01.932+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:01.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:01.938+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:02.078+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:02.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:02.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:02.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:02.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:33:02.853+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.987 seconds
[2022-12-16T15:33:13.458+0000] {processor.py:154} INFO - Started process (PID=5339) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:13.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:13.520+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:13.518+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:13.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:15.233+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:15.232+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:15.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:15.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:33:15.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.315 seconds
[2022-12-16T15:33:26.056+0000] {processor.py:154} INFO - Started process (PID=5354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:26.086+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:26.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:26.090+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:26.179+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:26.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:26.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:26.457+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:26.456+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:33:26.561+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.519 seconds
[2022-12-16T15:33:36.964+0000] {processor.py:154} INFO - Started process (PID=5364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:36.968+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:36.972+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:36.971+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:37.061+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:37.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:37.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:37.414+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:37.413+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:33:37.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.653 seconds
[2022-12-16T15:33:48.021+0000] {processor.py:154} INFO - Started process (PID=5379) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:48.027+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:48.030+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:48.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:48.213+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:48.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:48.481+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:48.677+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:48.676+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:33:48.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-16T15:33:59.208+0000] {processor.py:154} INFO - Started process (PID=5389) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:59.212+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:33:59.218+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:59.217+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:59.301+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:33:59.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:59.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:33:59.889+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:33:59.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:00.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.835 seconds
[2022-12-16T15:34:10.311+0000] {processor.py:154} INFO - Started process (PID=5399) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:10.334+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:34:10.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:10.337+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:10.434+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:10.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:10.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:34:10.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:10.755+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:10.900+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.602 seconds
[2022-12-16T15:34:21.199+0000] {processor.py:154} INFO - Started process (PID=5406) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:21.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:34:21.217+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:21.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:21.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:21.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:21.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:34:21.623+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:21.622+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:21.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.575 seconds
[2022-12-16T15:34:32.824+0000] {processor.py:154} INFO - Started process (PID=5424) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:32.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:34:32.973+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:32.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:33.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:33.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:33.858+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:34:34.193+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:34.192+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:34.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.771 seconds
[2022-12-16T15:34:44.691+0000] {processor.py:154} INFO - Started process (PID=5434) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:44.717+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:34:44.723+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:44.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:44.837+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:45.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:45.324+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:34:45.434+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:45.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:45.570+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.892 seconds
[2022-12-16T15:34:55.827+0000] {processor.py:154} INFO - Started process (PID=5444) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:55.875+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:34:55.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:55.924+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:56.010+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:34:56.446+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:56.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:34:56.557+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:34:56.556+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:34:56.736+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.924 seconds
[2022-12-16T15:35:07.013+0000] {processor.py:154} INFO - Started process (PID=5454) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:07.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:35:07.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:07.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:07.304+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:08.670+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:35:19.578+0000] {processor.py:154} INFO - Started process (PID=5472) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:19.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:35:19.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:19.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:20.130+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:20.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:20.279+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:35:20.401+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:20.400+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:35:20.522+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.051 seconds
[2022-12-16T15:35:30.795+0000] {processor.py:154} INFO - Started process (PID=5482) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:30.823+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:35:30.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:30.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:30.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:31.360+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:31.354+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:35:31.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:31.627+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:35:31.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.988 seconds
[2022-12-16T15:35:41.996+0000] {processor.py:154} INFO - Started process (PID=5492) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:42.047+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:35:42.105+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:42.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:42.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:43.623+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:43.622+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:35:43.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:43.759+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:35:43.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.894 seconds
[2022-12-16T15:35:54.389+0000] {processor.py:154} INFO - Started process (PID=5511) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:54.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:35:54.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:54.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:54.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:35:55.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:55.518+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:35:55.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:35:55.659+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:35:55.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.521 seconds
[2022-12-16T15:36:06.094+0000] {processor.py:154} INFO - Started process (PID=5521) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:06.107+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:36:06.115+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:06.110+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:06.211+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:07.478+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:07.477+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:36:07.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:07.608+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:36:07.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.667 seconds
[2022-12-16T15:36:17.991+0000] {processor.py:154} INFO - Started process (PID=5534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:17.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:36:17.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:17.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:18.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:19.072+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:19.071+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:36:19.190+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:19.190+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:36:19.331+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.353 seconds
[2022-12-16T15:36:29.543+0000] {processor.py:154} INFO - Started process (PID=5546) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:29.548+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:36:29.552+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:29.551+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:29.664+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:30.530+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:30.529+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:36:30.764+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:30.763+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:36:30.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.444 seconds
[2022-12-16T15:36:41.690+0000] {processor.py:154} INFO - Started process (PID=5561) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:41.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:36:41.999+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:41.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:42.160+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:42.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:42.442+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:36:42.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:42.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:36:42.810+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.152 seconds
[2022-12-16T15:36:53.180+0000] {processor.py:154} INFO - Started process (PID=5573) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:53.206+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:36:53.210+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:53.209+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:53.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:36:53.666+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:53.665+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:36:53.801+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:36:53.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:36:53.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.794 seconds
[2022-12-16T15:37:04.197+0000] {processor.py:154} INFO - Started process (PID=5583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:04.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:37:04.204+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:04.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:04.319+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:04.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:04.730+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:37:05.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:05.117+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:37:05.413+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.230 seconds
[2022-12-16T15:37:15.981+0000] {processor.py:154} INFO - Started process (PID=5602) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:15.992+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:37:16.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:16.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:16.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:17.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:17.055+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:37:17.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:17.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:37:17.544+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.601 seconds
[2022-12-16T15:37:28.292+0000] {processor.py:154} INFO - Started process (PID=5612) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:28.307+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:37:28.313+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:28.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:28.410+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:28.791+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:28.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:37:29.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:29.026+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:37:29.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.038 seconds
[2022-12-16T15:37:39.578+0000] {processor.py:154} INFO - Started process (PID=5622) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:39.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:37:39.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:39.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:39.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:39.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:39.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:37:39.994+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:39.993+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:37:40.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.764 seconds
[2022-12-16T15:37:50.743+0000] {processor.py:154} INFO - Started process (PID=5632) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:50.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:37:50.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:50.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:50.866+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:37:51.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:51.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:37:51.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:37:51.233+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:37:51.384+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.653 seconds
[2022-12-16T15:38:02.144+0000] {processor.py:154} INFO - Started process (PID=5650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:02.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:38:02.163+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:02.159+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:02.341+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:03.979+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:03.978+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:38:04.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:04.198+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:38:04.333+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.217 seconds
[2022-12-16T15:38:14.553+0000] {processor.py:154} INFO - Started process (PID=5660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:14.570+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:38:14.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:14.573+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:14.689+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:14.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:14.839+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:38:14.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:14.962+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:38:15.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.701 seconds
[2022-12-16T15:38:25.861+0000] {processor.py:154} INFO - Started process (PID=5670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:25.893+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:38:25.897+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:25.896+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:26.005+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:26.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:26.158+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:38:26.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:26.281+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:38:26.417+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.571 seconds
[2022-12-16T15:38:37.022+0000] {processor.py:154} INFO - Started process (PID=5688) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:37.118+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:38:37.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:37.121+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:37.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:38.231+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:38.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:38:38.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:38.538+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:38:38.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.818 seconds
[2022-12-16T15:38:49.095+0000] {processor.py:154} INFO - Started process (PID=5698) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:49.118+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:38:49.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:49.121+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:49.228+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:38:49.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:49.382+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:38:49.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:38:49.517+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:38:49.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.626 seconds
[2022-12-16T15:39:00.717+0000] {processor.py:154} INFO - Started process (PID=5708) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:00.785+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:00.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:00.788+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:00.875+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:01.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:01.021+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:39:01.141+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:01.140+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:39:01.282+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.580 seconds
[2022-12-16T15:39:11.586+0000] {processor.py:154} INFO - Started process (PID=5718) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:11.634+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:11.638+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:11.637+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:11.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:11.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:11.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:39:12.020+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:12.019+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:39:12.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.606 seconds
[2022-12-16T15:39:22.653+0000] {processor.py:154} INFO - Started process (PID=5735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:22.682+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:22.690+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:22.689+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:22.801+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:23.322+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:39:33.921+0000] {processor.py:154} INFO - Started process (PID=5745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:33.951+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:33.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:33.954+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:34.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:34.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:34.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:39:34.435+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:34.434+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:39:34.627+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.723 seconds
[2022-12-16T15:39:44.970+0000] {processor.py:154} INFO - Started process (PID=5755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:45.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:45.038+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:45.037+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:45.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:45.520+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:45.520+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:39:45.694+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:45.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:39:45.864+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.913 seconds
[2022-12-16T15:39:56.190+0000] {processor.py:154} INFO - Started process (PID=5765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:56.234+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:39:56.238+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:56.237+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:56.340+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:39:56.672+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:56.671+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:39:56.973+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:39:56.972+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:39:57.198+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.023 seconds
[2022-12-16T15:40:07.595+0000] {processor.py:154} INFO - Started process (PID=5783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:07.603+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:40:07.608+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:07.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:07.695+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:08.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:08.141+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:40:08.275+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:08.274+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:40:08.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.849 seconds
[2022-12-16T15:40:18.757+0000] {processor.py:154} INFO - Started process (PID=5793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:18.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:40:18.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:18.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:18.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:19.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:19.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:40:19.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:19.252+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:40:19.368+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.634 seconds
[2022-12-16T15:40:29.545+0000] {processor.py:154} INFO - Started process (PID=5803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:29.566+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:40:29.570+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:29.570+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:29.664+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:29.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:29.885+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:40:30.015+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:30.014+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:40:30.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.596 seconds
[2022-12-16T15:40:40.623+0000] {processor.py:154} INFO - Started process (PID=5821) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:40.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:40:40.663+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:40.650+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:40.816+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:41.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:41.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:40:41.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:41.809+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:40:42.061+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.468 seconds
[2022-12-16T15:40:52.250+0000] {processor.py:154} INFO - Started process (PID=5831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:52.264+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:40:52.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:52.268+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:52.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:40:52.700+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:52.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:40:52.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:40:52.840+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:40:53.334+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.098 seconds
[2022-12-16T15:41:03.651+0000] {processor.py:154} INFO - Started process (PID=5841) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:03.672+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:41:03.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:03.676+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:03.767+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:04.565+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:04.564+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:41:04.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:04.695+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:41:04.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.187 seconds
[2022-12-16T15:41:15.010+0000] {processor.py:154} INFO - Started process (PID=5851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:15.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:41:15.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:15.067+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:15.268+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:15.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:15.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:41:15.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:15.858+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:41:15.996+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.002 seconds
[2022-12-16T15:41:26.479+0000] {processor.py:154} INFO - Started process (PID=5868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:26.510+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:41:26.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:26.521+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:26.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:26.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:26.950+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:41:27.139+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:27.138+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:41:27.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.803 seconds
[2022-12-16T15:41:37.889+0000] {processor.py:154} INFO - Started process (PID=5878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:37.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:41:37.933+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:37.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:38.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:38.348+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:38.347+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:41:38.469+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:38.468+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:41:38.585+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.779 seconds
[2022-12-16T15:41:48.852+0000] {processor.py:154} INFO - Started process (PID=5888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:48.882+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:41:48.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:41:48.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:48.974+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:41:49.898+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:42:00.314+0000] {processor.py:154} INFO - Started process (PID=5906) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:00.362+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:00.370+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:00.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:00.515+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:01.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:01.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:01.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:01.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:02.153+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.855 seconds
[2022-12-16T15:42:12.670+0000] {processor.py:154} INFO - Started process (PID=5916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:12.723+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:12.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:12.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:12.885+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:13.470+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:13.469+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:13.666+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:13.665+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:13.798+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.154 seconds
[2022-12-16T15:42:24.306+0000] {processor.py:154} INFO - Started process (PID=5926) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:24.328+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:24.332+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:24.331+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:24.562+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:25.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:25.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:25.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:25.461+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:25.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.287 seconds
[2022-12-16T15:42:35.853+0000] {processor.py:154} INFO - Started process (PID=5936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:35.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:35.890+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:35.889+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:36.122+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:36.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:36.583+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:36.768+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:36.767+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:36.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.045 seconds
[2022-12-16T15:42:47.236+0000] {processor.py:154} INFO - Started process (PID=5955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:47.265+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:47.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:47.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:47.400+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:47.615+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:47.614+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:47.814+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:47.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:48.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.035 seconds
[2022-12-16T15:42:58.796+0000] {processor.py:154} INFO - Started process (PID=5965) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:58.877+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:42:58.881+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:58.880+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:58.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:42:59.155+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:59.154+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:42:59.354+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:42:59.353+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:42:59.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.234 seconds
[2022-12-16T15:43:10.356+0000] {processor.py:154} INFO - Started process (PID=5975) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:10.390+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:43:10.395+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:10.394+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:10.490+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:12.009+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:12.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:43:12.125+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:12.124+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:43:12.240+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.897 seconds
[2022-12-16T15:43:22.646+0000] {processor.py:154} INFO - Started process (PID=5994) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:22.704+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:43:22.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:22.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:22.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:23.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:23.591+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:43:23.775+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:23.774+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:43:23.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.340 seconds
[2022-12-16T15:43:34.249+0000] {processor.py:154} INFO - Started process (PID=6004) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:34.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:43:34.256+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:34.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:34.342+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:35.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:35.407+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:43:35.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:35.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:43:35.654+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.419 seconds
[2022-12-16T15:43:46.165+0000] {processor.py:154} INFO - Started process (PID=6014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:46.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:43:46.201+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:46.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:46.345+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:46.951+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:46.950+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:43:47.125+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:47.124+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:43:47.269+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.209 seconds
[2022-12-16T15:43:57.489+0000] {processor.py:154} INFO - Started process (PID=6024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:57.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:43:57.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:57.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:57.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:43:58.020+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:58.010+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:43:58.490+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:43:58.489+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:43:58.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.476 seconds
[2022-12-16T15:44:09.460+0000] {processor.py:154} INFO - Started process (PID=6043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:09.464+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:44:09.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:09.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:09.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:09.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:09.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:44:09.972+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:09.971+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:44:10.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.733 seconds
[2022-12-16T15:44:20.776+0000] {processor.py:154} INFO - Started process (PID=6053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:20.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:44:20.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:20.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:20.926+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:21.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:21.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:44:21.266+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:21.265+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:44:21.496+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.748 seconds
[2022-12-16T15:44:32.244+0000] {processor.py:154} INFO - Started process (PID=6063) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:32.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:44:32.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:32.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:32.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:32.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:32.726+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:44:32.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:32.840+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:44:33.451+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.221 seconds
[2022-12-16T15:44:43.795+0000] {processor.py:154} INFO - Started process (PID=6073) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:43.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:44:43.829+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:43.823+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:43.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:44.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:44.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:44:44.598+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:44.597+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:44:45.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.230 seconds
[2022-12-16T15:44:55.745+0000] {processor.py:154} INFO - Started process (PID=6091) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:55.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:44:55.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:55.789+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:55.937+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:44:56.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:56.318+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:44:56.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:44:56.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:44:56.664+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.935 seconds
[2022-12-16T15:45:07.005+0000] {processor.py:154} INFO - Started process (PID=6101) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:07.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:45:07.063+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:07.062+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:07.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:07.289+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:07.288+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:45:07.401+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:07.400+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:45:07.510+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.520 seconds
[2022-12-16T15:45:18.171+0000] {processor.py:154} INFO - Started process (PID=6111) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:18.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:45:18.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:18.218+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:18.303+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:18.464+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:18.463+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:45:18.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:18.596+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:45:18.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-16T15:45:29.061+0000] {processor.py:154} INFO - Started process (PID=6129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:29.107+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:45:29.113+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:29.112+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:29.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:29.486+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:45:39.833+0000] {processor.py:154} INFO - Started process (PID=6139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:39.889+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:45:39.893+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:39.892+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:39.994+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:40.212+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:40.211+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:45:40.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:40.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:45:40.444+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.625 seconds
[2022-12-16T15:45:50.778+0000] {processor.py:154} INFO - Started process (PID=6149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:50.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:45:50.831+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:45:50.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:50.915+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:45:51.765+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:46:02.191+0000] {processor.py:154} INFO - Started process (PID=6159) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:02.217+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:46:02.223+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:02.221+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:02.306+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:02.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:02.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:46:02.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:02.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:46:03.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-16T15:46:14.018+0000] {processor.py:154} INFO - Started process (PID=6177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:14.050+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:46:14.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:14.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:14.196+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:14.915+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:14.914+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:46:15.162+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:15.161+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:46:15.386+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.426 seconds
[2022-12-16T15:46:25.713+0000] {processor.py:154} INFO - Started process (PID=6187) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:25.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:46:25.745+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:25.744+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:25.842+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:26.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:26.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:46:26.450+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:26.449+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:46:26.584+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.895 seconds
[2022-12-16T15:46:36.814+0000] {processor.py:154} INFO - Started process (PID=6197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:36.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:46:36.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:36.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:36.955+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:37.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:37.385+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:46:37.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:37.517+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:46:38.079+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.281 seconds
[2022-12-16T15:46:48.511+0000] {processor.py:154} INFO - Started process (PID=6214) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:48.534+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:46:48.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:48.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:48.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:46:49.978+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:49.977+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:46:50.175+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:46:50.174+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:46:50.302+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.834 seconds
[2022-12-16T15:47:01.307+0000] {processor.py:154} INFO - Started process (PID=6225) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:01.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:01.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:01.316+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:01.425+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:01.566+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:01.565+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:47:01.677+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:01.676+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:47:01.785+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.492 seconds
[2022-12-16T15:47:12.620+0000] {processor.py:154} INFO - Started process (PID=6235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:12.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:12.627+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:12.626+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:12.713+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:13.233+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:47:24.114+0000] {processor.py:154} INFO - Started process (PID=6245) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:24.122+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:24.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:24.124+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:24.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:24.590+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:24.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:47:24.725+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:24.724+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:47:24.865+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.799 seconds
[2022-12-16T15:47:35.650+0000] {processor.py:154} INFO - Started process (PID=6264) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:35.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:35.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:35.667+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:35.795+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:36.381+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:36.380+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:47:36.506+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:36.506+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:47:36.701+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.101 seconds
[2022-12-16T15:47:47.191+0000] {processor.py:154} INFO - Started process (PID=6274) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:47.326+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:47.332+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:47.331+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:47.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:47.926+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:47.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:47:48.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:48.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:47:48.167+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.015 seconds
[2022-12-16T15:47:58.522+0000] {processor.py:154} INFO - Started process (PID=6284) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:58.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:47:58.558+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:47:58.557+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:47:58.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:00.055+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:00.054+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:00.166+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:00.165+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:00.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.775 seconds
[2022-12-16T15:48:10.810+0000] {processor.py:154} INFO - Started process (PID=6301) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:10.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:48:10.863+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:10.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:10.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:11.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:11.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:12.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:12.135+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:12.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.135 seconds
[2022-12-16T15:48:23.421+0000] {processor.py:154} INFO - Started process (PID=6312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:23.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:48:23.430+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:23.429+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:23.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:23.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:23.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:24.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:24.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:24.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.794 seconds
[2022-12-16T15:48:34.666+0000] {processor.py:154} INFO - Started process (PID=6322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:34.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:48:34.690+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:34.689+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:34.774+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:34.938+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:34.936+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:35.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:35.121+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:35.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.608 seconds
[2022-12-16T15:48:46.067+0000] {processor.py:154} INFO - Started process (PID=6332) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:46.088+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:48:46.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:46.091+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:46.175+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:46.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:46.328+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:46.490+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:46.490+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:46.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-16T15:48:57.634+0000] {processor.py:154} INFO - Started process (PID=6351) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:57.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:48:57.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:57.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:57.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:48:58.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:58.346+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:48:58.558+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:48:58.557+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:48:58.723+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.123 seconds
[2022-12-16T15:49:09.017+0000] {processor.py:154} INFO - Started process (PID=6361) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:09.069+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:49:09.079+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:09.078+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:09.162+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:09.304+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:09.303+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:49:09.463+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:09.462+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:49:09.795+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-16T15:49:20.259+0000] {processor.py:154} INFO - Started process (PID=6371) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:20.316+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:49:20.331+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:20.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:20.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:20.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:20.573+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:49:20.694+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:20.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:49:20.863+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.650 seconds
[2022-12-16T15:49:31.377+0000] {processor.py:154} INFO - Started process (PID=6388) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:31.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:49:31.417+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:31.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:31.649+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:31.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:31.810+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:49:31.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:31.974+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:49:32.118+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.790 seconds
[2022-12-16T15:49:42.893+0000] {processor.py:154} INFO - Started process (PID=6399) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:42.920+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:49:42.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:42.923+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:43.124+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:43.277+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:43.276+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:49:43.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:43.390+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:49:43.517+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.643 seconds
[2022-12-16T15:49:53.889+0000] {processor.py:154} INFO - Started process (PID=6409) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:53.913+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:49:53.918+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:53.917+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:54.058+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:49:54.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:54.389+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:49:54.891+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:49:54.878+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:49:55.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.445 seconds
[2022-12-16T15:50:05.639+0000] {processor.py:154} INFO - Started process (PID=6419) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:05.692+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:50:05.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:05.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:05.813+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:05.968+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:05.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:50:06.089+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:06.088+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:50:06.221+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-16T15:50:16.775+0000] {processor.py:154} INFO - Started process (PID=6437) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:16.796+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:50:16.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:16.802+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:17.170+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:18.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:18.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:50:18.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:18.493+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:50:19.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.474 seconds
[2022-12-16T15:50:30.446+0000] {processor.py:154} INFO - Started process (PID=6447) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:30.476+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:50:30.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:30.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:30.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:30.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:30.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:50:31.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:31.114+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:50:31.345+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.922 seconds
[2022-12-16T15:50:41.691+0000] {processor.py:154} INFO - Started process (PID=6457) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:41.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:50:41.739+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:41.738+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:41.849+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:42.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:42.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:50:42.303+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:42.302+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:50:42.490+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T15:50:52.924+0000] {processor.py:154} INFO - Started process (PID=6467) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:52.981+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:50:52.989+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:52.984+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:53.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:50:53.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:53.385+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:50:53.500+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:50:53.499+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:50:54.091+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.181 seconds
[2022-12-16T15:51:04.318+0000] {processor.py:154} INFO - Started process (PID=6485) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:04.345+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:51:04.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:04.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:04.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:04.665+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:04.665+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:51:04.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:04.789+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:51:04.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.625 seconds
[2022-12-16T15:51:15.755+0000] {processor.py:154} INFO - Started process (PID=6495) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:15.758+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:51:15.762+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:15.761+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:15.855+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:16.504+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:51:27.195+0000] {processor.py:154} INFO - Started process (PID=6505) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:27.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:51:27.226+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:27.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:27.326+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:28.597+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:51:39.150+0000] {processor.py:154} INFO - Started process (PID=6515) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:39.172+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:51:39.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:39.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:39.438+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:40.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:40.000+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:51:40.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:40.382+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:51:40.543+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.453 seconds
[2022-12-16T15:51:51.636+0000] {processor.py:154} INFO - Started process (PID=6533) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:51.642+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:51:51.646+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:51.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:51.842+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:51:53.011+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:53.010+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:51:53.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:51:53.516+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:51:54.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.529 seconds
[2022-12-16T15:52:04.569+0000] {processor.py:154} INFO - Started process (PID=6543) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:04.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:52:04.585+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:04.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:04.881+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:05.422+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:52:16.129+0000] {processor.py:154} INFO - Started process (PID=6553) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:16.138+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:52:16.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:16.149+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:16.342+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:17.085+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:52:27.964+0000] {processor.py:154} INFO - Started process (PID=6563) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:28.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:52:28.261+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:28.260+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:28.421+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:28.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:28.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:52:29.023+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:29.022+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:52:29.591+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.652 seconds
[2022-12-16T15:52:40.202+0000] {processor.py:154} INFO - Started process (PID=6581) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:40.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:52:40.231+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:40.217+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:40.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:41.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:41.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:52:41.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:41.927+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:52:42.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.357 seconds
[2022-12-16T15:52:53.028+0000] {processor.py:154} INFO - Started process (PID=6591) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:53.094+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:52:53.126+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:53.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:53.547+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:52:54.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:54.630+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:52:55.038+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:52:55.036+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:52:55.353+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.422 seconds
[2022-12-16T15:53:06.121+0000] {processor.py:154} INFO - Started process (PID=6601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:06.401+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:53:06.405+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:06.404+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:06.533+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:07.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:07.848+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:53:07.999+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:07.998+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:53:08.391+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.334 seconds
[2022-12-16T15:53:18.748+0000] {processor.py:154} INFO - Started process (PID=6611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:18.752+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:53:18.759+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:18.754+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:18.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:19.191+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:19.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:53:19.494+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:19.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:53:20.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.312 seconds
[2022-12-16T15:53:30.490+0000] {processor.py:154} INFO - Started process (PID=6621) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:30.494+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:53:30.500+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:30.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:30.672+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:31.739+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:31.738+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:53:32.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:32.511+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:53:32.846+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.377 seconds
[2022-12-16T15:53:43.988+0000] {processor.py:154} INFO - Started process (PID=6639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:43.997+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:53:44.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:44.000+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:44.539+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:45.856+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:45.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:53:46.409+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:46.392+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:53:46.847+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.933 seconds
[2022-12-16T15:53:57.812+0000] {processor.py:154} INFO - Started process (PID=6649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:57.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:53:57.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:57.843+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:58.219+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:53:59.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:59.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:53:59.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:53:59.599+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:54:00.207+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.460 seconds
[2022-12-16T15:54:11.077+0000] {processor.py:154} INFO - Started process (PID=6659) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:11.119+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:54:11.123+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:11.122+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:11.272+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:11.871+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:11.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:54:12.344+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:12.343+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:54:12.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.535 seconds
[2022-12-16T15:54:23.086+0000] {processor.py:154} INFO - Started process (PID=6669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:23.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:54:23.113+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:23.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:23.317+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:23.814+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:23.813+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:54:23.994+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:23.988+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:54:24.266+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.212 seconds
[2022-12-16T15:54:35.432+0000] {processor.py:154} INFO - Started process (PID=6685) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:35.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:54:35.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:35.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:36.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:36.679+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:36.678+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:54:37.435+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:37.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:54:37.889+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.619 seconds
[2022-12-16T15:54:48.885+0000] {processor.py:154} INFO - Started process (PID=6696) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:48.907+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:54:48.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:48.922+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:49.270+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:54:49.705+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:49.704+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:54:50.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:54:50.056+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:54:50.566+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.722 seconds
[2022-12-16T15:55:01.528+0000] {processor.py:154} INFO - Started process (PID=6706) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:01.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:55:01.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:01.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:01.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:02.466+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:02.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:55:02.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:02.772+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:55:03.146+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.645 seconds
[2022-12-16T15:55:13.681+0000] {processor.py:154} INFO - Started process (PID=6716) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:13.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:55:13.754+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:13.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:13.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:14.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:14.126+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:55:14.356+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:14.352+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:55:14.563+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.916 seconds
[2022-12-16T15:55:25.257+0000] {processor.py:154} INFO - Started process (PID=6726) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:25.264+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:55:25.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:25.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:25.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:25.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:25.995+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:55:26.293+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:26.292+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:55:26.724+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.509 seconds
[2022-12-16T15:55:37.431+0000] {processor.py:154} INFO - Started process (PID=6745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:37.443+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:55:37.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:37.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:37.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:38.912+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:38.911+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:55:39.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:39.599+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:55:39.932+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.539 seconds
[2022-12-16T15:55:50.248+0000] {processor.py:154} INFO - Started process (PID=6755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:50.318+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:55:50.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:50.323+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:50.445+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:55:51.314+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:51.309+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:55:51.554+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:55:51.553+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:55:51.863+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.634 seconds
[2022-12-16T15:56:03.041+0000] {processor.py:154} INFO - Started process (PID=6765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:03.074+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:56:03.078+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:03.077+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:03.214+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:03.919+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T15:56:14.444+0000] {processor.py:154} INFO - Started process (PID=6775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:14.803+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:56:14.823+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:14.822+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:15.171+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:15.530+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:15.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:56:15.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:15.861+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:56:16.404+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.013 seconds
[2022-12-16T15:56:27.473+0000] {processor.py:154} INFO - Started process (PID=6794) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:27.477+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:56:27.508+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:27.507+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:27.985+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:28.943+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:28.942+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:56:29.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:29.669+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:56:29.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.663 seconds
[2022-12-16T15:56:40.549+0000] {processor.py:154} INFO - Started process (PID=6804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:40.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:56:40.591+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:40.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:40.773+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:41.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:41.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:56:41.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:41.542+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:56:41.766+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.288 seconds
[2022-12-16T15:56:52.344+0000] {processor.py:154} INFO - Started process (PID=6814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:52.355+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:56:52.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:52.364+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:52.673+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:56:53.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:53.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:56:53.825+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:56:53.824+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:56:54.116+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.815 seconds
[2022-12-16T15:57:04.744+0000] {processor.py:154} INFO - Started process (PID=6824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:04.774+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:57:04.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:04.781+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:04.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:05.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:05.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:57:05.375+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:05.374+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:57:05.580+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.875 seconds
[2022-12-16T15:57:16.596+0000] {processor.py:154} INFO - Started process (PID=6842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:16.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:57:16.686+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:16.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:17.260+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:17.794+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:17.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:57:18.156+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:18.153+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:57:18.487+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.999 seconds
[2022-12-16T15:57:29.225+0000] {processor.py:154} INFO - Started process (PID=6852) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:29.229+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:57:29.238+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:29.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:29.404+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:29.819+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:29.815+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:57:30.154+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:30.149+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:57:30.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.443 seconds
[2022-12-16T15:57:41.681+0000] {processor.py:154} INFO - Started process (PID=6862) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:41.692+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:57:41.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:41.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:41.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:42.612+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:42.611+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:57:42.968+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:42.967+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:57:43.147+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.492 seconds
[2022-12-16T15:57:53.737+0000] {processor.py:154} INFO - Started process (PID=6872) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:53.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:57:53.805+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:53.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:53.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:57:54.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:54.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:57:54.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:57:54.981+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:57:55.540+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.821 seconds
[2022-12-16T15:58:05.909+0000] {processor.py:154} INFO - Started process (PID=6890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:05.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:58:05.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:05.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:06.287+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:06.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:06.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:58:07.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:07.248+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:58:08.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.490 seconds
[2022-12-16T15:58:18.822+0000] {processor.py:154} INFO - Started process (PID=6900) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:18.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:58:18.874+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:18.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:19.235+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:20.161+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:20.154+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:58:20.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:20.583+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:58:21.143+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.390 seconds
[2022-12-16T15:58:31.835+0000] {processor.py:154} INFO - Started process (PID=6910) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:31.858+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:58:31.863+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:31.862+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:32.037+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:32.422+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:32.412+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:58:32.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:32.812+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:58:33.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.779 seconds
[2022-12-16T15:58:44.148+0000] {processor.py:154} INFO - Started process (PID=6920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:44.190+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:58:44.194+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:44.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:44.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:45.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:45.091+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:58:45.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:45.895+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:58:46.586+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.444 seconds
[2022-12-16T15:58:57.127+0000] {processor.py:154} INFO - Started process (PID=6937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:57.146+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:58:57.155+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:57.154+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:57.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:58:58.102+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:58.088+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:58:59.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:58:59.019+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:58:59.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.710 seconds
[2022-12-16T15:59:10.328+0000] {processor.py:154} INFO - Started process (PID=6947) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:10.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:59:10.344+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:10.343+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:10.579+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:11.167+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:11.166+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:59:11.775+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:11.760+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:59:12.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.287 seconds
[2022-12-16T15:59:23.128+0000] {processor.py:154} INFO - Started process (PID=6957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:23.134+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:59:23.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:23.141+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:23.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:23.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:23.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:59:24.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:24.115+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:59:24.550+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.445 seconds
[2022-12-16T15:59:35.957+0000] {processor.py:154} INFO - Started process (PID=6967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:36.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:59:36.023+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:36.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:36.297+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:36.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:36.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:59:36.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:36.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:59:37.234+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.422 seconds
[2022-12-16T15:59:47.824+0000] {processor.py:154} INFO - Started process (PID=6985) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:47.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T15:59:47.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:47.844+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:48.111+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T15:59:48.526+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:48.517+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T15:59:48.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T15:59:48.788+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T15:59:49.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.356 seconds
[2022-12-16T16:00:00.154+0000] {processor.py:154} INFO - Started process (PID=6995) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:00.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:00:00.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:00.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:00.578+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:01.111+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:01.109+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:00:01.603+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:01.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:00:02.215+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.126 seconds
[2022-12-16T16:00:12.732+0000] {processor.py:154} INFO - Started process (PID=7005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:12.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:00:12.750+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:12.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:12.946+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:13.646+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:13.644+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:00:14.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:14.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:00:14.228+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.517 seconds
[2022-12-16T16:00:25.237+0000] {processor.py:154} INFO - Started process (PID=7015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:25.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:00:25.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:25.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:25.486+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:26.341+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:26.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:00:26.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:26.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:00:26.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.785 seconds
[2022-12-16T16:00:37.598+0000] {processor.py:154} INFO - Started process (PID=7033) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:37.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:00:37.652+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:37.651+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:37.905+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:38.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:38.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:00:39.017+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:39.016+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:00:39.496+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.940 seconds
[2022-12-16T16:00:50.568+0000] {processor.py:154} INFO - Started process (PID=7043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:50.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:00:50.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:50.595+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:50.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:00:53.069+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:53.067+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:00:53.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:00:53.375+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:00:53.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.489 seconds
[2022-12-16T16:01:04.340+0000] {processor.py:154} INFO - Started process (PID=7053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:04.344+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:01:04.354+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:04.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:04.576+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:06.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:06.259+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:01:07.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:07.147+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:01:07.504+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.204 seconds
[2022-12-16T16:01:18.031+0000] {processor.py:154} INFO - Started process (PID=7063) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:18.067+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:01:18.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:18.076+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:18.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:19.140+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:19.139+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:01:19.572+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:19.570+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:01:19.734+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.759 seconds
[2022-12-16T16:01:30.607+0000] {processor.py:154} INFO - Started process (PID=7080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:30.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:01:30.663+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:30.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:31.500+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:33.152+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:01:44.283+0000] {processor.py:154} INFO - Started process (PID=7090) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:44.347+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:01:44.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:44.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:44.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:45.732+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:45.731+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:01:46.418+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:46.397+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:01:47.026+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.890 seconds
[2022-12-16T16:01:57.535+0000] {processor.py:154} INFO - Started process (PID=7100) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:57.618+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:01:57.628+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:57.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:57.952+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:01:58.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:58.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:01:59.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:01:59.224+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:01:59.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.219 seconds
[2022-12-16T16:02:10.133+0000] {processor.py:154} INFO - Started process (PID=7110) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:10.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:02:10.164+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:10.163+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:10.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:12.712+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:12.711+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:02:13.061+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:13.060+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:02:13.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.331 seconds
[2022-12-16T16:02:24.326+0000] {processor.py:154} INFO - Started process (PID=7132) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:24.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:02:24.367+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:24.366+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:24.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:25.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:25.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:02:25.700+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:25.699+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:02:26.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.076 seconds
[2022-12-16T16:02:36.956+0000] {processor.py:154} INFO - Started process (PID=7139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:36.998+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:02:37.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:37.006+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:37.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:37.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:37.624+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:02:38.048+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:38.047+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:02:38.494+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.594 seconds
[2022-12-16T16:02:48.953+0000] {processor.py:154} INFO - Started process (PID=7149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:49.010+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:02:49.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:49.020+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:49.386+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:02:49.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:49.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:02:49.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:02:49.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:02:50.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.232 seconds
[2022-12-16T16:03:00.875+0000] {processor.py:154} INFO - Started process (PID=7159) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:00.885+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:03:00.889+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:00.888+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:01.127+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:01.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:01.573+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:03:02.017+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:02.009+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:03:02.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.711 seconds
[2022-12-16T16:03:13.085+0000] {processor.py:154} INFO - Started process (PID=7177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:13.123+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:03:13.145+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:13.140+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:13.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:14.137+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:14.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:03:14.620+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:14.619+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:03:15.082+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.045 seconds
[2022-12-16T16:03:25.688+0000] {processor.py:154} INFO - Started process (PID=7187) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:25.691+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:03:25.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:25.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:25.854+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:26.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:26.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:03:26.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:26.432+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:03:26.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.981 seconds
[2022-12-16T16:03:37.169+0000] {processor.py:154} INFO - Started process (PID=7197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:37.175+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:03:37.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:37.179+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:37.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:38.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:38.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:03:38.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:38.268+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:03:38.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.329 seconds
[2022-12-16T16:03:49.064+0000] {processor.py:154} INFO - Started process (PID=7207) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:49.110+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:03:49.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:49.117+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:49.310+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:03:49.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:49.771+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:03:50.066+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:03:50.052+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:03:50.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.393 seconds
[2022-12-16T16:04:00.969+0000] {processor.py:154} INFO - Started process (PID=7225) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:00.981+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:04:00.994+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:00.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:01.208+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:02.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:02.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:04:02.752+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:02.744+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:04:03.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.331 seconds
[2022-12-16T16:04:14.158+0000] {processor.py:154} INFO - Started process (PID=7235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:14.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:04:14.176+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:14.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:14.377+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:15.123+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:15.122+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:04:15.364+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:15.363+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:04:15.666+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.543 seconds
[2022-12-16T16:04:26.395+0000] {processor.py:154} INFO - Started process (PID=7245) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:26.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:04:26.422+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:26.420+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:26.614+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:26.900+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:26.899+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:04:27.178+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:27.175+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:04:27.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.141 seconds
[2022-12-16T16:04:38.052+0000] {processor.py:154} INFO - Started process (PID=7255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:38.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:04:38.063+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:38.062+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:38.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:38.409+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:38.408+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:04:38.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:38.583+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:04:38.944+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.924 seconds
[2022-12-16T16:04:49.604+0000] {processor.py:154} INFO - Started process (PID=7274) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:49.645+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:04:49.659+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:49.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:49.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:04:50.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:50.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:04:51.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:04:51.091+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:04:51.527+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.018 seconds
[2022-12-16T16:05:02.512+0000] {processor.py:154} INFO - Started process (PID=7284) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:02.524+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:05:02.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:02.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:02.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:03.316+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:03.315+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:05:03.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:03.667+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:05:04.122+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.645 seconds
[2022-12-16T16:05:15.038+0000] {processor.py:154} INFO - Started process (PID=7294) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:15.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:05:15.076+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:15.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:15.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:16.127+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:05:26.766+0000] {processor.py:154} INFO - Started process (PID=7304) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:26.769+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:05:26.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:26.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:26.947+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:27.218+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:27.217+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:05:27.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:27.453+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:05:27.805+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.061 seconds
[2022-12-16T16:05:38.514+0000] {processor.py:154} INFO - Started process (PID=7322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:38.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:05:38.565+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:38.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:39.090+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:40.358+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:40.348+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:05:40.679+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:40.678+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:05:40.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.560 seconds
[2022-12-16T16:05:51.913+0000] {processor.py:154} INFO - Started process (PID=7332) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:51.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:05:51.951+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:05:51.950+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:52.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:05:53.040+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:06:03.928+0000] {processor.py:154} INFO - Started process (PID=7342) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:03.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:06:03.943+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:03.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:04.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:04.423+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:04.416+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:06:04.653+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:04.649+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:06:05.004+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.112 seconds
[2022-12-16T16:06:15.607+0000] {processor.py:154} INFO - Started process (PID=7352) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:15.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:06:15.626+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:15.624+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:15.800+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:16.181+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:16.180+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:06:16.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:16.587+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:06:16.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.310 seconds
[2022-12-16T16:06:27.495+0000] {processor.py:154} INFO - Started process (PID=7368) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:27.522+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:06:27.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:27.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:27.948+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:28.779+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:28.778+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:06:29.173+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:29.171+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:06:29.574+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.146 seconds
[2022-12-16T16:06:40.364+0000] {processor.py:154} INFO - Started process (PID=7380) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:40.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:06:40.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:40.383+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:40.611+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:41.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:41.133+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:06:41.587+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:41.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:06:41.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.620 seconds
[2022-12-16T16:06:52.976+0000] {processor.py:154} INFO - Started process (PID=7390) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:53.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:06:53.231+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:06:53.230+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:53.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:06:54.330+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:07:04.848+0000] {processor.py:154} INFO - Started process (PID=7400) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:04.856+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:07:04.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:04.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:05.050+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:05.314+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:05.313+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:07:05.650+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:05.649+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:07:05.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.056 seconds
[2022-12-16T16:07:16.402+0000] {processor.py:154} INFO - Started process (PID=7410) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:16.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:07:16.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:16.462+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:16.625+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:17.261+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:07:28.465+0000] {processor.py:154} INFO - Started process (PID=7428) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:28.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:07:28.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:28.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:28.889+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:29.656+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:29.655+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:07:30.109+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:30.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:07:30.451+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.105 seconds
[2022-12-16T16:07:41.463+0000] {processor.py:154} INFO - Started process (PID=7438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:41.480+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:07:41.491+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:41.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:41.835+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:42.206+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:42.204+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:07:42.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:42.381+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:07:42.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.257 seconds
[2022-12-16T16:07:52.923+0000] {processor.py:154} INFO - Started process (PID=7448) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:52.958+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:07:52.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:52.961+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:53.176+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:07:53.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:53.954+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:07:54.178+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:07:54.174+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:07:54.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.497 seconds
[2022-12-16T16:08:05.390+0000] {processor.py:154} INFO - Started process (PID=7458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:05.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:08:05.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:05.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:05.571+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:06.286+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:06.284+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:08:06.587+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:06.587+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:08:06.855+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.494 seconds
[2022-12-16T16:08:17.928+0000] {processor.py:154} INFO - Started process (PID=7476) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:17.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:08:17.967+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:17.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:18.303+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:19.622+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:19.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:08:19.946+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:19.944+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:08:20.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.407 seconds
[2022-12-16T16:08:31.064+0000] {processor.py:154} INFO - Started process (PID=7486) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:31.080+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:08:31.084+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:31.083+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:31.458+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:32.212+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:32.206+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:08:32.465+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:32.464+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:08:32.662+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.644 seconds
[2022-12-16T16:08:43.258+0000] {processor.py:154} INFO - Started process (PID=7496) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:43.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:08:43.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:43.265+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:43.626+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:44.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:44.334+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:08:44.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:44.572+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:08:44.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.631 seconds
[2022-12-16T16:08:55.778+0000] {processor.py:154} INFO - Started process (PID=7506) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:55.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:08:55.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:55.835+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:56.073+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:08:56.492+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:56.491+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:08:56.761+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:08:56.760+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:08:56.996+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.260 seconds
[2022-12-16T16:09:07.710+0000] {processor.py:154} INFO - Started process (PID=7524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:07.774+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:09:07.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:07.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:08.043+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:09.171+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:09:20.020+0000] {processor.py:154} INFO - Started process (PID=7534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:20.024+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:09:20.028+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:20.027+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:20.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:20.551+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:20.548+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:09:20.919+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:20.918+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:09:21.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.330 seconds
[2022-12-16T16:09:31.964+0000] {processor.py:154} INFO - Started process (PID=7544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:31.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:09:31.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:31.970+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:32.183+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:32.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:32.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:09:32.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:32.983+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:09:33.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.335 seconds
[2022-12-16T16:09:43.921+0000] {processor.py:154} INFO - Started process (PID=7554) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:43.950+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:09:43.961+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:43.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:44.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:44.451+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:44.449+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:09:44.659+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:44.657+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:09:44.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.089 seconds
[2022-12-16T16:09:55.951+0000] {processor.py:154} INFO - Started process (PID=7570) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:55.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:09:55.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:55.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:56.743+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:09:58.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:58.531+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:09:58.856+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:09:58.855+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:09:59.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.529 seconds
[2022-12-16T16:10:10.106+0000] {processor.py:154} INFO - Started process (PID=7581) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:10.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:10:10.131+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:10.127+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:10.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:11.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:11.158+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:10:11.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:11.512+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:10:11.870+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.817 seconds
[2022-12-16T16:10:22.617+0000] {processor.py:154} INFO - Started process (PID=7591) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:22.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:10:22.642+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:22.637+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:22.835+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:23.573+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:10:34.301+0000] {processor.py:154} INFO - Started process (PID=7601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:34.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:10:34.319+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:34.317+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:34.492+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:35.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:35.336+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:10:35.585+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:35.583+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:10:35.831+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.583 seconds
[2022-12-16T16:10:46.554+0000] {processor.py:154} INFO - Started process (PID=7618) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:46.574+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:10:46.578+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:46.577+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:46.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:47.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:47.743+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:10:47.878+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:47.877+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:10:48.058+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.525 seconds
[2022-12-16T16:10:58.327+0000] {processor.py:154} INFO - Started process (PID=7629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:58.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:10:58.379+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:58.378+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:58.495+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:10:58.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:58.984+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:10:59.099+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:10:59.098+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:10:59.205+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.893 seconds
[2022-12-16T16:11:09.638+0000] {processor.py:154} INFO - Started process (PID=7639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:09.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:11:09.948+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:09.947+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:10.037+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:10.595+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:10.594+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:11:10.714+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:10.714+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:11:10.820+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.196 seconds
[2022-12-16T16:11:21.105+0000] {processor.py:154} INFO - Started process (PID=7649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:21.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:11:21.229+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:21.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:21.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:22.792+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:11:34.049+0000] {processor.py:154} INFO - Started process (PID=7667) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:34.090+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:11:34.111+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:34.110+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:34.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:35.013+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:35.012+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:11:35.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:35.524+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:11:35.915+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.970 seconds
[2022-12-16T16:11:46.704+0000] {processor.py:154} INFO - Started process (PID=7677) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:46.758+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:11:46.801+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:46.760+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:47.101+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:47.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:47.886+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:11:48.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:48.134+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:11:48.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.164 seconds
[2022-12-16T16:11:59.022+0000] {processor.py:154} INFO - Started process (PID=7687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:59.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:11:59.076+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:11:59.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:11:59.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:12:00.137+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:12:00.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:12:00.247+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:12:00.246+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:12:00.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.412 seconds
[2022-12-16T16:12:10.913+0000] {processor.py:154} INFO - Started process (PID=7697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:12:10.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:12:10.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:12:10.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:12:11.036+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:12:11.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:12:11.907+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:12:12.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:12:12.035+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:12:12.152+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.256 seconds
[2022-12-16T16:13:09.385+0000] {processor.py:154} INFO - Started process (PID=173) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:09.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:13:09.440+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:09.439+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:09.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:11.323+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:13:21.936+0000] {processor.py:154} INFO - Started process (PID=183) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:21.991+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:13:21.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:21.995+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:22.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:22.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:22.788+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:13:23.570+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:23.569+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:13:23.721+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.799 seconds
[2022-12-16T16:13:34.070+0000] {processor.py:154} INFO - Started process (PID=193) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:34.099+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:13:34.103+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:34.102+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:34.269+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:35.636+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:13:46.556+0000] {processor.py:154} INFO - Started process (PID=209) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:46.603+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:13:46.651+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:46.650+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:47.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:47.905+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:47.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:13:48.297+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:48.296+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:13:48.504+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.102 seconds
[2022-12-16T16:13:58.921+0000] {processor.py:154} INFO - Started process (PID=220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:58.961+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:13:58.966+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:58.964+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:59.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:13:59.401+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:59.400+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:13:59.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:13:59.527+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:13:59.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.830 seconds
[2022-12-16T16:14:10.053+0000] {processor.py:154} INFO - Started process (PID=230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:10.077+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:14:10.085+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:10.084+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:10.201+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:10.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:10.362+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:14:10.472+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:10.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:14:10.622+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.585 seconds
[2022-12-16T16:14:21.405+0000] {processor.py:154} INFO - Started process (PID=240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:21.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:14:21.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:21.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:21.527+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:22.066+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:22.065+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:14:22.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:22.176+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:14:22.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-16T16:14:33.184+0000] {processor.py:154} INFO - Started process (PID=258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:33.220+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:14:33.224+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:33.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:33.421+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:33.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:33.683+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:14:33.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:33.867+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:14:34.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.879 seconds
[2022-12-16T16:14:44.923+0000] {processor.py:154} INFO - Started process (PID=268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:44.934+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:14:44.945+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:44.944+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:45.414+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:45.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:45.786+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:14:46.143+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:46.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:14:46.558+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.702 seconds
[2022-12-16T16:14:57.133+0000] {processor.py:154} INFO - Started process (PID=278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:57.207+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:14:57.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:57.219+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:57.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:14:57.545+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:57.544+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:14:57.663+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:14:57.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:14:57.778+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-16T16:15:08.240+0000] {processor.py:154} INFO - Started process (PID=295) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:08.294+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:15:08.313+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:08.297+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:08.828+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:09.700+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:09.699+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:15:10.189+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:10.188+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:15:10.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.333 seconds
[2022-12-16T16:15:20.884+0000] {processor.py:154} INFO - Started process (PID=306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:20.922+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:15:20.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:20.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:21.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:21.430+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:21.429+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:15:21.598+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:21.596+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:15:21.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.921 seconds
[2022-12-16T16:15:32.123+0000] {processor.py:154} INFO - Started process (PID=316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:32.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:15:32.176+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:32.175+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:32.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:32.420+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:32.419+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:15:32.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:32.532+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:15:32.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-16T16:15:43.027+0000] {processor.py:154} INFO - Started process (PID=326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:43.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:15:43.112+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:43.111+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:43.408+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:43.591+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:43.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:15:43.749+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:43.748+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:15:43.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.882 seconds
[2022-12-16T16:15:54.358+0000] {processor.py:154} INFO - Started process (PID=344) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:54.406+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:15:54.415+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:54.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:54.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:15:54.723+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:54.722+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:15:54.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:15:54.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:15:55.012+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.668 seconds
[2022-12-16T16:16:05.833+0000] {processor.py:154} INFO - Started process (PID=354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:05.860+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:16:05.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:05.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:05.956+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:06.154+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:06.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:16:06.279+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:06.278+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:16:06.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.595 seconds
[2022-12-16T16:16:16.771+0000] {processor.py:154} INFO - Started process (PID=364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:16.783+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:16:16.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:16.786+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:16.875+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:17.049+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:17.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:16:17.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:17.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:16:17.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.569 seconds
[2022-12-16T16:16:27.734+0000] {processor.py:154} INFO - Started process (PID=374) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:27.783+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:16:27.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:27.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:27.874+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:28.481+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:28.480+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:16:28.590+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:28.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:16:28.700+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.979 seconds
[2022-12-16T16:16:39.245+0000] {processor.py:154} INFO - Started process (PID=392) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:39.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:16:39.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:39.282+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:39.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:40.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:40.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:16:41.105+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:41.101+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:16:41.432+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.220 seconds
[2022-12-16T16:16:52.041+0000] {processor.py:154} INFO - Started process (PID=402) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:52.196+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:16:52.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:52.290+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:52.468+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:16:53.143+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:53.142+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:16:53.263+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:16:53.262+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:16:53.382+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.359 seconds
[2022-12-16T16:17:03.920+0000] {processor.py:154} INFO - Started process (PID=412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:03.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:17:03.980+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:03.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:04.092+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:04.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:04.281+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:17:04.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:04.423+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:17:04.572+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.665 seconds
[2022-12-16T16:17:15.319+0000] {processor.py:154} INFO - Started process (PID=428) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:15.347+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:17:15.359+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:15.358+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:15.479+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:16.502+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:17:27.038+0000] {processor.py:154} INFO - Started process (PID=439) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:27.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:17:27.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:27.076+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:27.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:27.610+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:27.609+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:17:27.767+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:27.766+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:17:27.977+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.973 seconds
[2022-12-16T16:17:38.405+0000] {processor.py:154} INFO - Started process (PID=449) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:38.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:17:38.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:38.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:38.534+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:39.400+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:39.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:17:39.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:39.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:17:39.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.275 seconds
[2022-12-16T16:17:50.009+0000] {processor.py:154} INFO - Started process (PID=459) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:50.035+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:17:50.045+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:50.044+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:50.137+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:17:50.273+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:50.272+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:17:50.498+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:17:50.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:17:50.647+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.659 seconds
[2022-12-16T16:18:01.027+0000] {processor.py:154} INFO - Started process (PID=477) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:01.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:01.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:01.055+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:01.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:01.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:01.915+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:02.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:02.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:18:02.691+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.698 seconds
[2022-12-16T16:18:13.212+0000] {processor.py:154} INFO - Started process (PID=487) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:13.264+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:13.290+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:13.267+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:13.454+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:13.685+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:13.684+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:14.032+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:14.031+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:18:14.330+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.133 seconds
[2022-12-16T16:18:24.693+0000] {processor.py:154} INFO - Started process (PID=497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:24.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:24.723+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:24.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:24.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:25.412+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:25.411+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:25.569+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:25.568+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:18:25.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.028 seconds
[2022-12-16T16:18:35.988+0000] {processor.py:154} INFO - Started process (PID=507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:36.030+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:36.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:36.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:36.142+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:36.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:36.279+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:36.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:36.412+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:18:36.665+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-16T16:18:47.348+0000] {processor.py:154} INFO - Started process (PID=524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:47.384+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:47.388+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:47.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:47.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:47.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:47.867+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:48.104+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:48.101+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:18:48.391+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.061 seconds
[2022-12-16T16:18:59.220+0000] {processor.py:154} INFO - Started process (PID=534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:59.261+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:18:59.277+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:59.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:59.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:18:59.714+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:59.712+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:18:59.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:18:59.919+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:19:00.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.916 seconds
[2022-12-16T16:19:10.629+0000] {processor.py:154} INFO - Started process (PID=544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:10.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:19:10.655+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:10.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:10.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:10.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:10.887+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:19:11.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:11.001+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:19:11.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.521 seconds
[2022-12-16T16:19:21.473+0000] {processor.py:154} INFO - Started process (PID=562) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:21.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:19:21.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:21.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:21.771+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:22.546+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:19:33.367+0000] {processor.py:154} INFO - Started process (PID=573) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:33.374+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:19:33.378+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:33.377+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:33.473+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:33.836+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:19:44.741+0000] {processor.py:154} INFO - Started process (PID=583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:44.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:19:44.806+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:44.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:44.975+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:45.356+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:45.355+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:19:45.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:45.545+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:19:45.738+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.021 seconds
[2022-12-16T16:19:56.863+0000] {processor.py:154} INFO - Started process (PID=593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:56.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:19:56.927+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:19:56.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:19:58.026+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:00.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:00.044+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:20:00.929+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:00.928+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:20:01.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 4.974 seconds
[2022-12-16T16:20:13.482+0000] {processor.py:154} INFO - Started process (PID=611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:13.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:20:13.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:13.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:14.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:15.753+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:20:26.697+0000] {processor.py:154} INFO - Started process (PID=621) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:26.750+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:20:26.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:26.786+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:27.759+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:29.376+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:29.375+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:20:29.816+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:29.815+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:20:30.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.693 seconds
[2022-12-16T16:20:41.279+0000] {processor.py:154} INFO - Started process (PID=631) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:41.307+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:20:41.311+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:41.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:41.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:42.181+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:42.180+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:20:42.434+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:42.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:20:42.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.321 seconds
[2022-12-16T16:20:52.955+0000] {processor.py:154} INFO - Started process (PID=641) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:52.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:20:53.005+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:20:53.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:53.281+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:20:54.667+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:21:05.316+0000] {processor.py:154} INFO - Started process (PID=658) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:05.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:21:05.366+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:05.357+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:05.599+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:06.654+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:21:17.437+0000] {processor.py:154} INFO - Started process (PID=669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:17.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:21:17.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:17.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:17.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:17.861+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:17.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:21:18.099+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:18.098+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:21:18.282+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.861 seconds
[2022-12-16T16:21:28.764+0000] {processor.py:154} INFO - Started process (PID=679) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:28.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:21:28.793+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:28.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:28.964+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:29.476+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:29.475+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:21:29.738+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:29.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:21:29.936+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.189 seconds
[2022-12-16T16:21:40.508+0000] {processor.py:154} INFO - Started process (PID=689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:40.543+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:21:40.547+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:40.546+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:40.728+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:41.358+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:41.357+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:21:41.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:41.575+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:21:41.804+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.321 seconds
[2022-12-16T16:21:52.661+0000] {processor.py:154} INFO - Started process (PID=707) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:52.710+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:21:52.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:52.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:53.140+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:21:54.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:54.055+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:21:54.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:21:54.348+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:21:54.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.084 seconds
[2022-12-16T16:22:04.824+0000] {processor.py:154} INFO - Started process (PID=717) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:04.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:22:04.832+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:04.831+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:04.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:05.247+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:05.245+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:22:05.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:05.530+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:22:05.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.111 seconds
[2022-12-16T16:22:16.165+0000] {processor.py:154} INFO - Started process (PID=727) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:16.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:22:16.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:16.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:16.352+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:16.799+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:16.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:22:16.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:16.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:22:17.113+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.981 seconds
[2022-12-16T16:22:27.509+0000] {processor.py:154} INFO - Started process (PID=737) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:27.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:22:27.571+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:27.569+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:27.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:28.353+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:22:38.852+0000] {processor.py:154} INFO - Started process (PID=755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:38.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:22:38.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:38.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:39.098+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:39.403+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:39.402+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:22:39.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:39.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:22:40.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.280 seconds
[2022-12-16T16:22:50.360+0000] {processor.py:154} INFO - Started process (PID=765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:50.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:22:50.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:50.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:50.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:22:50.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:50.636+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:22:50.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:22:50.754+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:22:50.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-16T16:23:01.553+0000] {processor.py:154} INFO - Started process (PID=775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:01.618+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:01.624+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:01.623+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:01.715+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:02.115+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:02.114+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:23:02.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:02.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:23:02.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.935 seconds
[2022-12-16T16:23:12.970+0000] {processor.py:154} INFO - Started process (PID=785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:13.004+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:13.010+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:13.008+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:13.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:13.311+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:13.310+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:23:13.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:13.448+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:23:13.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-16T16:23:24.757+0000] {processor.py:154} INFO - Started process (PID=803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:24.778+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:24.787+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:24.786+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:24.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:25.207+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:25.199+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:23:25.497+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:25.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:23:25.763+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.073 seconds
[2022-12-16T16:23:36.240+0000] {processor.py:154} INFO - Started process (PID=813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:36.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:36.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:36.292+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:36.411+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:36.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:36.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:23:36.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:36.795+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:23:36.948+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.722 seconds
[2022-12-16T16:23:47.105+0000] {processor.py:154} INFO - Started process (PID=823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:47.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:47.140+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:47.139+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:47.238+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:48.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:48.764+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:23:48.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:48.887+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:23:49.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.216 seconds
[2022-12-16T16:23:59.787+0000] {processor.py:154} INFO - Started process (PID=840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:23:59.806+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:23:59.819+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:23:59.809+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:00.020+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:00.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:00.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:24:01.053+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:01.049+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:24:01.304+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.533 seconds
[2022-12-16T16:24:12.029+0000] {processor.py:154} INFO - Started process (PID=851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:12.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:24:12.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:12.036+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:12.298+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:12.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:12.659+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:24:12.894+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:12.893+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:24:13.177+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.174 seconds
[2022-12-16T16:24:23.570+0000] {processor.py:154} INFO - Started process (PID=861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:23.598+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:24:23.604+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:23.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:23.689+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:23.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:23.835+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:24:23.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:23.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:24:24.204+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.648 seconds
[2022-12-16T16:24:34.474+0000] {processor.py:154} INFO - Started process (PID=871) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:34.498+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:24:34.505+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:34.504+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:34.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:35.505+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:24:45.987+0000] {processor.py:154} INFO - Started process (PID=887) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:46.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:24:46.041+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:46.040+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:46.266+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:46.414+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:46.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:24:46.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:46.616+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:24:46.815+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.842 seconds
[2022-12-16T16:24:57.472+0000] {processor.py:154} INFO - Started process (PID=898) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:57.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:24:57.508+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:57.507+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:57.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:24:58.148+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:58.148+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:24:58.271+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:24:58.270+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:24:58.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.967 seconds
[2022-12-16T16:25:08.586+0000] {processor.py:154} INFO - Started process (PID=908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:08.627+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:25:08.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:08.630+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:08.733+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:08.923+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:08.922+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:25:09.193+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:09.192+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:25:09.344+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.772 seconds
[2022-12-16T16:25:19.583+0000] {processor.py:154} INFO - Started process (PID=918) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:19.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:25:19.621+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:19.620+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:19.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:20.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:20.243+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:25:20.400+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:20.399+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:25:20.566+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.030 seconds
[2022-12-16T16:25:30.903+0000] {processor.py:154} INFO - Started process (PID=936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:30.957+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:25:30.982+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:30.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:31.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:32.708+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:25:43.308+0000] {processor.py:154} INFO - Started process (PID=946) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:43.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:25:43.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:43.320+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:43.504+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:43.737+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:43.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:25:44.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:44.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:25:44.978+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.689 seconds
[2022-12-16T16:25:55.736+0000] {processor.py:154} INFO - Started process (PID=956) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:55.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:25:55.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:55.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:55.861+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:25:56.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:56.095+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:25:56.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:25:56.340+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:25:56.539+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.816 seconds
[2022-12-16T16:26:07.169+0000] {processor.py:154} INFO - Started process (PID=966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:07.220+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:26:07.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:07.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:07.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:07.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:07.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:26:07.884+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:07.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:26:08.181+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.053 seconds
[2022-12-16T16:26:18.522+0000] {processor.py:154} INFO - Started process (PID=983) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:18.579+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:26:18.595+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:18.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:18.813+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:19.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:19.119+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:26:19.389+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:19.384+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:26:19.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.094 seconds
[2022-12-16T16:26:30.038+0000] {processor.py:154} INFO - Started process (PID=993) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:30.081+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:26:30.090+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:30.085+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:30.220+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:30.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:30.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:26:30.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:30.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:26:30.838+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T16:26:41.214+0000] {processor.py:154} INFO - Started process (PID=1003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:41.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:26:41.226+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:41.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:41.316+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:41.497+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:41.496+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:26:41.641+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:41.639+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:26:41.806+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.606 seconds
[2022-12-16T16:26:52.217+0000] {processor.py:154} INFO - Started process (PID=1020) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:52.243+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:26:52.250+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:52.249+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:52.590+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:26:52.904+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:52.903+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:26:53.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:26:53.268+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:26:53.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.449 seconds
[2022-12-16T16:27:04.320+0000] {processor.py:154} INFO - Started process (PID=1031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:04.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:27:04.341+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:04.340+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:04.590+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:04.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:04.895+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:27:05.376+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:05.375+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:27:05.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.392 seconds
[2022-12-16T16:27:16.161+0000] {processor.py:154} INFO - Started process (PID=1041) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:16.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:27:16.182+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:16.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:16.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:16.620+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:16.619+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:27:16.757+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:16.756+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:27:16.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.793 seconds
[2022-12-16T16:27:27.243+0000] {processor.py:154} INFO - Started process (PID=1051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:27.295+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:27:27.299+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:27.298+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:27.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:27.560+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:27.559+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:27:27.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:27.728+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:27:27.840+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T16:27:38.261+0000] {processor.py:154} INFO - Started process (PID=1068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:38.290+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:27:38.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:38.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:38.434+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:39.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:39.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:27:39.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:39.516+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:27:39.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.550 seconds
[2022-12-16T16:27:50.574+0000] {processor.py:154} INFO - Started process (PID=1079) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:50.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:27:50.589+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:50.587+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:50.837+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:27:51.156+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:51.155+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:27:51.310+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:27:51.309+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:27:51.532+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.980 seconds
[2022-12-16T16:28:01.820+0000] {processor.py:154} INFO - Started process (PID=1089) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:01.861+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:28:01.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:01.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:01.987+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:02.595+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:28:13.150+0000] {processor.py:154} INFO - Started process (PID=1099) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:13.197+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:28:13.202+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:13.200+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:13.288+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:13.429+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:13.428+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:28:13.555+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:13.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:28:13.692+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.557 seconds
[2022-12-16T16:28:24.150+0000] {processor.py:154} INFO - Started process (PID=1117) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:24.180+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:28:24.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:24.183+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:24.390+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:25.594+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:25.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:28:25.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:25.826+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:28:26.106+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.005 seconds
[2022-12-16T16:28:36.742+0000] {processor.py:154} INFO - Started process (PID=1127) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:36.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:28:36.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:36.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:36.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:37.089+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:37.088+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:28:37.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:37.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:28:37.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-16T16:28:47.929+0000] {processor.py:154} INFO - Started process (PID=1137) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:47.972+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:28:47.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:47.975+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:48.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:28:49.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:49.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:28:49.641+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:28:49.640+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:28:49.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.012 seconds
[2022-12-16T16:29:00.394+0000] {processor.py:154} INFO - Started process (PID=1147) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:00.416+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:00.420+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:00.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:00.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:00.707+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:00.707+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:00.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:00.859+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:01.050+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.671 seconds
[2022-12-16T16:29:11.560+0000] {processor.py:154} INFO - Started process (PID=1165) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:11.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:11.591+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:11.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:11.781+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:12.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:12.559+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:13.030+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:13.025+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:13.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.752 seconds
[2022-12-16T16:29:23.827+0000] {processor.py:154} INFO - Started process (PID=1175) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:23.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:23.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:23.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:23.975+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:24.161+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:24.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:24.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:24.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:24.616+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.819 seconds
[2022-12-16T16:29:34.922+0000] {processor.py:154} INFO - Started process (PID=1185) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:34.946+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:34.951+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:34.950+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:35.039+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:35.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:35.170+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:35.285+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:35.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:35.443+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.535 seconds
[2022-12-16T16:29:45.898+0000] {processor.py:154} INFO - Started process (PID=1203) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:45.942+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:45.953+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:45.952+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:46.246+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:47.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:47.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:47.751+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:47.750+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:48.515+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.675 seconds
[2022-12-16T16:29:58.897+0000] {processor.py:154} INFO - Started process (PID=1214) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:58.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:29:58.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:58.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:59.038+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:29:59.175+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:59.174+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:29:59.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:29:59.294+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:29:59.642+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.759 seconds
[2022-12-16T16:30:09.895+0000] {processor.py:154} INFO - Started process (PID=1224) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:09.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:30:09.912+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:09.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:10.004+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:10.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:10.583+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:30:10.712+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:10.711+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:30:10.845+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.964 seconds
[2022-12-16T16:30:21.190+0000] {processor.py:154} INFO - Started process (PID=1234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:21.233+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:30:21.236+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:21.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:21.325+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:21.767+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:21.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:30:21.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:21.905+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:30:22.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.837 seconds
[2022-12-16T16:30:32.207+0000] {processor.py:154} INFO - Started process (PID=1252) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:32.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:30:32.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:32.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:32.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:33.124+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:33.123+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:30:33.297+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:33.296+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:30:33.438+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.259 seconds
[2022-12-16T16:30:43.792+0000] {processor.py:154} INFO - Started process (PID=1262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:43.840+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:30:43.845+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:43.844+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:43.951+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:44.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:44.218+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:30:44.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:44.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:30:44.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.730 seconds
[2022-12-16T16:30:54.856+0000] {processor.py:154} INFO - Started process (PID=1272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:54.879+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:30:54.884+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:54.882+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:54.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:30:55.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:55.224+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:30:55.388+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:30:55.387+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:30:55.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.795 seconds
[2022-12-16T16:31:06.266+0000] {processor.py:154} INFO - Started process (PID=1282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:06.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:31:06.305+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:06.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:06.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:06.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:06.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:31:06.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:06.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:31:07.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.122 seconds
[2022-12-16T16:31:17.747+0000] {processor.py:154} INFO - Started process (PID=1300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:17.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:31:17.783+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:17.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:17.986+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:18.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:18.283+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:31:18.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:18.516+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:31:18.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.048 seconds
[2022-12-16T16:31:28.988+0000] {processor.py:154} INFO - Started process (PID=1310) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:29.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:31:29.042+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:29.041+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:29.162+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:30.381+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:30.380+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:31:30.496+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:30.495+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:31:30.642+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.671 seconds
[2022-12-16T16:31:41.425+0000] {processor.py:154} INFO - Started process (PID=1320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:41.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:31:41.461+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:41.460+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:41.554+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:42.590+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:31:53.076+0000] {processor.py:154} INFO - Started process (PID=1337) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:53.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:31:53.112+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:53.111+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:53.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:31:53.965+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:53.964+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:31:54.237+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:31:54.231+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:31:54.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.459 seconds
[2022-12-16T16:32:05.102+0000] {processor.py:154} INFO - Started process (PID=1347) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:05.118+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:32:05.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:05.121+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:05.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:05.657+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:05.653+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:32:05.823+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:05.822+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:32:05.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.868 seconds
[2022-12-16T16:32:16.300+0000] {processor.py:154} INFO - Started process (PID=1357) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:16.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:32:16.423+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:16.422+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:16.611+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:17.351+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:17.350+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:32:17.465+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:17.464+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:32:17.649+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.371 seconds
[2022-12-16T16:32:28.012+0000] {processor.py:154} INFO - Started process (PID=1367) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:28.066+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:32:28.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:28.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:28.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:28.523+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:28.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:32:28.681+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:28.680+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:32:28.868+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-16T16:32:39.313+0000] {processor.py:154} INFO - Started process (PID=1385) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:39.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:32:39.348+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:39.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:39.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:39.641+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:39.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:32:39.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:39.764+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:32:39.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.617 seconds
[2022-12-16T16:32:50.311+0000] {processor.py:154} INFO - Started process (PID=1395) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:50.358+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:32:50.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:32:50.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:50.465+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:32:51.196+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:33:01.532+0000] {processor.py:154} INFO - Started process (PID=1405) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:01.542+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:01.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:01.546+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:01.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:01.762+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:01.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:01.873+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:01.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:02.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.493 seconds
[2022-12-16T16:33:12.450+0000] {processor.py:154} INFO - Started process (PID=1415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:12.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:12.497+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:12.496+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:12.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:12.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:12.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:13.063+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:13.062+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:13.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.865 seconds
[2022-12-16T16:33:23.997+0000] {processor.py:154} INFO - Started process (PID=1433) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:24.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:24.037+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:24.036+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:24.120+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:24.356+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:24.355+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:24.467+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:24.466+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:24.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T16:33:34.988+0000] {processor.py:154} INFO - Started process (PID=1443) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:35.046+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:35.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:35.050+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:35.143+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:35.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:35.275+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:35.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:35.412+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:35.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-16T16:33:45.794+0000] {processor.py:154} INFO - Started process (PID=1453) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:45.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:45.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:45.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:45.949+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:46.110+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:46.109+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:46.241+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:46.240+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:46.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.574 seconds
[2022-12-16T16:33:56.943+0000] {processor.py:154} INFO - Started process (PID=1471) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:56.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:33:56.995+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:56.994+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:57.451+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:33:57.904+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:57.903+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:33:58.301+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:33:58.300+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:33:58.527+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.649 seconds
[2022-12-16T16:34:09.089+0000] {processor.py:154} INFO - Started process (PID=1481) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:09.121+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:34:09.128+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:09.127+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:09.296+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:09.960+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:09.959+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:34:10.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:10.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:34:10.299+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-16T16:34:20.654+0000] {processor.py:154} INFO - Started process (PID=1491) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:20.687+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:34:20.694+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:20.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:20.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:21.470+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:21.469+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:34:21.628+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:21.626+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:34:21.736+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.112 seconds
[2022-12-16T16:34:32.023+0000] {processor.py:154} INFO - Started process (PID=1501) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:32.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:34:32.043+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:32.042+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:32.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:32.553+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:32.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:34:32.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:32.698+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:34:32.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.835 seconds
[2022-12-16T16:34:43.341+0000] {processor.py:154} INFO - Started process (PID=1519) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:43.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:34:43.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:43.407+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:43.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:44.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:44.523+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:34:44.731+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:44.730+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:34:45.035+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.730 seconds
[2022-12-16T16:34:55.300+0000] {processor.py:154} INFO - Started process (PID=1529) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:55.329+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:34:55.334+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:55.333+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:55.424+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:34:55.793+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:55.791+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:34:55.969+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:34:55.968+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:34:56.150+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.867 seconds
[2022-12-16T16:35:06.827+0000] {processor.py:154} INFO - Started process (PID=1539) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:06.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:35:06.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:06.858+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:06.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:07.123+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:07.122+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:35:07.387+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:07.386+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:35:07.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.749 seconds
[2022-12-16T16:35:18.479+0000] {processor.py:154} INFO - Started process (PID=1556) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:18.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:35:18.520+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:18.519+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:18.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:19.332+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:19.331+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:35:19.812+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:19.811+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:35:20.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.631 seconds
[2022-12-16T16:35:30.310+0000] {processor.py:154} INFO - Started process (PID=1566) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:30.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:35:30.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:30.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:30.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:30.599+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:30.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:35:30.718+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:30.717+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:35:30.865+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.581 seconds
[2022-12-16T16:35:41.595+0000] {processor.py:154} INFO - Started process (PID=1576) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:41.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:35:41.622+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:41.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:41.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:41.852+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:41.851+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:35:41.965+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:41.964+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:35:42.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.523 seconds
[2022-12-16T16:35:52.414+0000] {processor.py:154} INFO - Started process (PID=1586) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:52.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:35:52.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:52.474+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:52.563+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:35:52.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:52.699+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:35:52.818+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:35:52.817+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:35:52.964+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-16T16:36:03.418+0000] {processor.py:154} INFO - Started process (PID=1603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:03.473+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:36:03.477+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:03.476+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:03.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:04.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:04.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:36:04.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:04.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:36:04.984+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.590 seconds
[2022-12-16T16:36:15.289+0000] {processor.py:154} INFO - Started process (PID=1613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:15.306+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:36:15.314+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:15.313+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:15.425+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:17.132+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:36:27.629+0000] {processor.py:154} INFO - Started process (PID=1623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:27.651+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:36:27.656+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:27.655+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:27.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:28.368+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:28.367+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:36:28.561+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:28.560+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:36:28.711+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.106 seconds
[2022-12-16T16:36:39.025+0000] {processor.py:154} INFO - Started process (PID=1633) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:39.077+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:36:39.081+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:39.080+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:39.220+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:39.373+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:39.372+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:36:39.487+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:39.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:36:39.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.633 seconds
[2022-12-16T16:36:49.893+0000] {processor.py:154} INFO - Started process (PID=1650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:49.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:36:49.913+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:49.912+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:50.020+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:36:50.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:50.244+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:36:50.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:36:50.461+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:36:50.668+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.835 seconds
[2022-12-16T16:37:01.062+0000] {processor.py:154} INFO - Started process (PID=1660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:01.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:37:01.091+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:01.090+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:01.189+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:01.354+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:01.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:37:01.471+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:01.471+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:37:01.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.558 seconds
[2022-12-16T16:37:11.885+0000] {processor.py:154} INFO - Started process (PID=1670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:11.935+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:37:11.938+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:11.937+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:12.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:13.108+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:37:23.619+0000] {processor.py:154} INFO - Started process (PID=1687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:23.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:37:23.651+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:23.650+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:23.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:25.184+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:37:35.789+0000] {processor.py:154} INFO - Started process (PID=1698) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:35.796+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:37:35.802+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:35.801+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:35.911+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:37.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:37.360+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:37:37.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:37.555+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:37:37.698+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.932 seconds
[2022-12-16T16:37:48.600+0000] {processor.py:154} INFO - Started process (PID=1708) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:48.619+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:37:48.623+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:48.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:48.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:37:48.999+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:48.998+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:37:49.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:37:49.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:37:49.377+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.797 seconds
[2022-12-16T16:38:00.055+0000] {processor.py:154} INFO - Started process (PID=1718) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:00.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:38:00.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:00.117+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:00.237+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:01.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:01.582+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:38:01.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:01.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:38:02.084+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.059 seconds
[2022-12-16T16:38:12.688+0000] {processor.py:154} INFO - Started process (PID=1736) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:12.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:38:12.745+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:12.744+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:13.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:14.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:14.514+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:38:14.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:14.659+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:38:14.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.325 seconds
[2022-12-16T16:38:25.406+0000] {processor.py:154} INFO - Started process (PID=1746) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:25.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:38:25.452+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:25.451+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:25.565+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:25.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:25.886+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:38:26.093+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:26.091+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:38:26.309+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.961 seconds
[2022-12-16T16:38:36.735+0000] {processor.py:154} INFO - Started process (PID=1756) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:36.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:38:36.770+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:36.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:36.877+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:37.024+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:37.023+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:38:37.151+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:37.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:38:37.362+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.643 seconds
[2022-12-16T16:38:47.796+0000] {processor.py:154} INFO - Started process (PID=1766) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:47.867+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:38:47.871+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:47.870+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:48.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:38:48.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:48.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:38:48.979+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:38:48.978+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:38:49.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.435 seconds
[2022-12-16T16:39:00.028+0000] {processor.py:154} INFO - Started process (PID=1785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:00.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:00.055+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:00.054+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:00.246+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:00.624+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:00.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:39:00.917+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:00.915+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:39:01.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.560 seconds
[2022-12-16T16:39:12.454+0000] {processor.py:154} INFO - Started process (PID=1795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:12.509+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:12.526+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:12.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:12.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:13.169+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:13.168+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:39:13.293+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:13.292+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:39:13.468+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-16T16:39:23.784+0000] {processor.py:154} INFO - Started process (PID=1805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:23.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:23.816+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:23.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:23.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:24.081+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:24.080+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:39:24.200+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:24.199+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:39:24.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.590 seconds
[2022-12-16T16:39:34.867+0000] {processor.py:154} INFO - Started process (PID=1822) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:34.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:34.917+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:34.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:35.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:35.429+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:35.428+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:39:35.599+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:35.598+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:39:35.775+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.932 seconds
[2022-12-16T16:39:46.240+0000] {processor.py:154} INFO - Started process (PID=1831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:46.285+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:46.289+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:46.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:46.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:46.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:46.585+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:39:46.707+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:46.706+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:39:46.885+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-16T16:39:57.490+0000] {processor.py:154} INFO - Started process (PID=1838) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:57.517+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:39:57.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:39:57.520+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:57.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:39:58.499+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:40:08.817+0000] {processor.py:154} INFO - Started process (PID=1848) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:08.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:40:08.852+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:08.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:08.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:09.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:09.587+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:40:09.720+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:09.719+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:40:10.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.264 seconds
[2022-12-16T16:40:20.497+0000] {processor.py:154} INFO - Started process (PID=1866) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:20.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:40:20.561+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:20.560+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:20.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:21.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:21.227+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:40:21.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:21.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:40:21.731+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.250 seconds
[2022-12-16T16:40:32.188+0000] {processor.py:154} INFO - Started process (PID=1876) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:32.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:40:32.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:32.222+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:32.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:32.477+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:32.476+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:40:32.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:32.624+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:40:32.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.680 seconds
[2022-12-16T16:40:43.762+0000] {processor.py:154} INFO - Started process (PID=1886) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:43.802+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:40:43.807+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:43.806+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:43.935+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:44.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:44.391+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:40:44.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:44.600+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:40:44.791+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.047 seconds
[2022-12-16T16:40:55.147+0000] {processor.py:154} INFO - Started process (PID=1896) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:55.191+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:40:55.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:55.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:55.669+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:40:56.011+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:56.010+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:40:56.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:40:56.197+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:40:56.473+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.385 seconds
[2022-12-16T16:41:06.987+0000] {processor.py:154} INFO - Started process (PID=1914) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:07.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:41:07.044+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:07.043+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:07.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:08.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:08.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:41:08.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:08.836+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:41:08.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.986 seconds
[2022-12-16T16:41:19.199+0000] {processor.py:154} INFO - Started process (PID=1929) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:19.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:41:19.230+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:19.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:19.342+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:19.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:19.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:41:19.652+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:19.650+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:41:19.794+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T16:41:30.105+0000] {processor.py:154} INFO - Started process (PID=1937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:30.147+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:41:30.152+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:30.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:30.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:30.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:30.542+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:41:30.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:30.692+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:41:30.804+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.721 seconds
[2022-12-16T16:41:41.105+0000] {processor.py:154} INFO - Started process (PID=1954) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:41.169+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:41:41.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:41.173+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:41.291+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:41.906+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:41.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:41:42.039+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:42.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:41:42.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.078 seconds
[2022-12-16T16:41:52.377+0000] {processor.py:154} INFO - Started process (PID=1961) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:52.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:41:52.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:52.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:52.629+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:41:52.791+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:52.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:41:53.012+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:41:53.011+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:41:53.559+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.196 seconds
[2022-12-16T16:42:03.959+0000] {processor.py:154} INFO - Started process (PID=1971) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:03.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:42:04.004+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:04.003+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:04.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:04.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:04.264+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:42:04.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:04.474+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:42:04.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.662 seconds
[2022-12-16T16:42:15.404+0000] {processor.py:154} INFO - Started process (PID=1981) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:15.432+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:42:15.438+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:15.437+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:15.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:17.259+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:17.258+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:42:17.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:17.612+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:42:17.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.428 seconds
[2022-12-16T16:42:28.588+0000] {processor.py:154} INFO - Started process (PID=2003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:28.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:42:28.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:28.648+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:29.426+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:29.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:29.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:42:30.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:30.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:42:30.735+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.199 seconds
[2022-12-16T16:42:41.144+0000] {processor.py:154} INFO - Started process (PID=2015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:41.163+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:42:41.168+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:41.167+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:41.298+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:41.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:41.612+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:42:41.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:41.764+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:42:42.039+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.912 seconds
[2022-12-16T16:42:52.261+0000] {processor.py:154} INFO - Started process (PID=2025) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:52.283+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:42:52.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:42:52.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:52.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:42:53.196+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:43:03.796+0000] {processor.py:154} INFO - Started process (PID=2039) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:03.840+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:03.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:03.843+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:04.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:04.568+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:04.567+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:43:04.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:04.785+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:43:04.938+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.186 seconds
[2022-12-16T16:43:10.669+0000] {processor.py:154} INFO - Started process (PID=2052) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:10.714+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:10.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:10.721+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:10.863+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:11.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:11.841+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:43:12.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:12.132+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:43:12.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.720 seconds
[2022-12-16T16:43:22.699+0000] {processor.py:154} INFO - Started process (PID=2065) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:22.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:22.736+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:22.735+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:22.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:24.203+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:24.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:43:24.361+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:24.360+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:43:24.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.972 seconds
[2022-12-16T16:43:35.053+0000] {processor.py:154} INFO - Started process (PID=2077) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:35.083+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:35.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:35.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:35.196+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:35.793+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:43:46.284+0000] {processor.py:154} INFO - Started process (PID=2095) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:46.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:46.350+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:46.340+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:46.546+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:48.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:48.215+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:43:48.505+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:48.500+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:43:48.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.461 seconds
[2022-12-16T16:43:58.964+0000] {processor.py:154} INFO - Started process (PID=2105) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:58.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:43:58.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:58.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:59.065+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:43:59.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:59.219+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:43:59.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:43:59.379+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:43:59.635+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-16T16:44:10.016+0000] {processor.py:154} INFO - Started process (PID=2115) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:10.048+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:44:10.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:10.051+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:10.149+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:10.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:10.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:44:10.431+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:10.430+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:44:10.556+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-16T16:44:20.847+0000] {processor.py:154} INFO - Started process (PID=2125) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:20.873+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:44:20.881+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:20.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:20.993+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:21.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:21.179+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:44:21.299+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:21.298+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:44:21.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.591 seconds
[2022-12-16T16:44:31.810+0000] {processor.py:154} INFO - Started process (PID=2143) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:31.835+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:44:31.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:31.838+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:31.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:32.290+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:32.289+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:44:32.530+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:32.529+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:44:32.831+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-16T16:44:43.190+0000] {processor.py:154} INFO - Started process (PID=2153) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:43.212+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:44:43.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:43.215+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:43.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:43.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:43.631+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:44:43.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:43.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:44:43.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.708 seconds
[2022-12-16T16:44:54.208+0000] {processor.py:154} INFO - Started process (PID=2163) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:54.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:44:54.240+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:54.239+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:54.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:44:54.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:54.687+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:44:54.802+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:44:54.801+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:44:54.944+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.751 seconds
[2022-12-16T16:45:05.239+0000] {processor.py:154} INFO - Started process (PID=2173) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:05.283+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:45:05.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:05.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:05.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:07.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:07.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:45:07.277+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:07.276+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:45:07.406+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.182 seconds
[2022-12-16T16:45:17.819+0000] {processor.py:154} INFO - Started process (PID=2192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:17.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:45:17.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:17.853+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:17.946+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:18.274+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:18.272+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:45:18.407+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:18.406+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:45:18.540+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.735 seconds
[2022-12-16T16:45:28.818+0000] {processor.py:154} INFO - Started process (PID=2202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:28.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:45:28.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:28.825+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:28.919+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:29.935+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:45:40.523+0000] {processor.py:154} INFO - Started process (PID=2212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:40.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:45:40.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:40.555+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:40.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:40.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:40.895+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:45:41.050+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:41.049+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:45:41.202+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.758 seconds
[2022-12-16T16:45:51.637+0000] {processor.py:154} INFO - Started process (PID=2230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:51.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:45:51.645+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:51.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:51.767+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:45:53.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:53.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:45:53.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:45:53.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:45:54.043+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.423 seconds
[2022-12-16T16:46:04.552+0000] {processor.py:154} INFO - Started process (PID=2240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:04.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:46:04.579+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:04.578+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:04.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:04.831+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:04.830+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:46:04.953+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:04.952+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:46:05.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.540 seconds
[2022-12-16T16:46:15.447+0000] {processor.py:154} INFO - Started process (PID=2250) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:15.478+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:46:15.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:15.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:15.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:17.032+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:17.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:46:17.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:17.219+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:46:17.400+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.985 seconds
[2022-12-16T16:46:27.990+0000] {processor.py:154} INFO - Started process (PID=2260) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:28.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:46:28.045+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:28.044+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:28.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:29.278+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:46:39.873+0000] {processor.py:154} INFO - Started process (PID=2279) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:39.876+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:46:39.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:39.879+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:39.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:40.634+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:40.633+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:46:40.770+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:40.769+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:46:40.884+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.025 seconds
[2022-12-16T16:46:51.130+0000] {processor.py:154} INFO - Started process (PID=2287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:51.154+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:46:51.158+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:51.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:51.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:46:51.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:51.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:46:51.677+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:46:51.676+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:46:51.808+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-16T16:47:02.126+0000] {processor.py:154} INFO - Started process (PID=2297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:02.179+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:47:02.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:02.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:02.325+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:03.764+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:47:14.237+0000] {processor.py:154} INFO - Started process (PID=2315) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:14.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:47:14.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:14.256+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:14.582+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:15.107+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:15.106+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:47:15.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:15.441+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:47:15.720+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.519 seconds
[2022-12-16T16:47:25.932+0000] {processor.py:154} INFO - Started process (PID=2327) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:25.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:47:25.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:25.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:26.036+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:26.542+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:26.537+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:47:26.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:26.879+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:47:27.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.212 seconds
[2022-12-16T16:47:37.504+0000] {processor.py:154} INFO - Started process (PID=2337) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:37.515+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:47:37.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:37.521+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:37.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:38.006+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:38.004+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:47:38.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:38.276+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:47:38.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-16T16:47:48.979+0000] {processor.py:154} INFO - Started process (PID=2347) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:49.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:47:49.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:49.059+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:49.292+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:47:49.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:49.984+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:47:50.142+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:47:50.141+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:47:50.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.428 seconds
[2022-12-16T16:48:00.545+0000] {processor.py:154} INFO - Started process (PID=2365) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:00.566+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:00.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:00.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:00.841+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:01.768+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:01.767+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:02.045+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:02.044+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:02.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.803 seconds
[2022-12-16T16:48:13.265+0000] {processor.py:154} INFO - Started process (PID=2375) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:13.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:13.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:13.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:13.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:14.275+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:14.274+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:14.466+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:14.465+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:14.630+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.404 seconds
[2022-12-16T16:48:24.977+0000] {processor.py:154} INFO - Started process (PID=2385) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:25.031+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:25.035+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:25.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:25.138+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:25.355+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:25.354+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:25.555+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:25.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:25.664+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.709 seconds
[2022-12-16T16:48:36.300+0000] {processor.py:154} INFO - Started process (PID=2401) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:36.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:36.353+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:36.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:36.845+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:37.181+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:37.180+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:37.553+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:37.552+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:37.915+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.675 seconds
[2022-12-16T16:48:48.184+0000] {processor.py:154} INFO - Started process (PID=2414) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:48.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:48.224+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:48.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:48.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:48.718+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:48.717+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:48.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:48.867+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:49.019+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.860 seconds
[2022-12-16T16:48:59.400+0000] {processor.py:154} INFO - Started process (PID=2422) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:59.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:48:59.430+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:59.429+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:59.537+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:48:59.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:59.691+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:48:59.838+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:48:59.837+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:48:59.956+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.573 seconds
[2022-12-16T16:49:10.468+0000] {processor.py:154} INFO - Started process (PID=2432) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:10.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:49:10.506+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:10.505+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:11.161+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:11.940+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:49:22.206+0000] {processor.py:154} INFO - Started process (PID=2449) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:22.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:49:22.281+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:22.273+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:22.671+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:23.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:23.259+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:49:23.562+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:23.561+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:49:23.909+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.719 seconds
[2022-12-16T16:49:34.388+0000] {processor.py:154} INFO - Started process (PID=2459) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:34.417+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:49:34.427+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:34.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:34.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:34.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:34.952+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:49:35.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:35.087+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:49:35.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.873 seconds
[2022-12-16T16:49:45.522+0000] {processor.py:154} INFO - Started process (PID=2469) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:45.546+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:49:45.551+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:45.550+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:45.663+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:46.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:46.459+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:49:46.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:46.984+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:49:47.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.701 seconds
[2022-12-16T16:49:57.559+0000] {processor.py:154} INFO - Started process (PID=2481) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:57.591+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:49:57.595+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:57.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:57.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:49:57.889+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:57.888+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:49:58.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:49:58.026+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:49:58.199+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.672 seconds
[2022-12-16T16:50:08.941+0000] {processor.py:154} INFO - Started process (PID=2498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:09.002+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:50:09.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:09.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:09.316+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:09.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:09.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:50:09.806+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:09.804+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:50:10.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.194 seconds
[2022-12-16T16:50:20.473+0000] {processor.py:154} INFO - Started process (PID=2508) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:20.494+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:50:20.498+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:20.496+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:20.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:20.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:20.759+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:50:20.890+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:20.889+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:50:21.058+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.600 seconds
[2022-12-16T16:50:31.709+0000] {processor.py:154} INFO - Started process (PID=2518) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:31.713+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:50:31.718+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:31.717+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:31.819+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:32.489+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:50:42.999+0000] {processor.py:154} INFO - Started process (PID=2536) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:43.030+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:50:43.034+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:43.033+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:43.180+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:43.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:43.407+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:50:43.611+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:43.610+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:50:43.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.837 seconds
[2022-12-16T16:50:54.458+0000] {processor.py:154} INFO - Started process (PID=2547) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:54.473+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:50:54.478+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:50:54.477+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:54.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:50:55.974+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:51:06.373+0000] {processor.py:154} INFO - Started process (PID=2557) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:06.419+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:51:06.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:06.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:06.545+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:07.322+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:07.321+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:51:07.437+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:07.436+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:51:07.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.200 seconds
[2022-12-16T16:51:17.839+0000] {processor.py:154} INFO - Started process (PID=2567) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:17.867+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:51:17.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:17.871+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:17.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:18.152+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:18.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:51:18.287+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:18.286+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:51:18.431+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.607 seconds
[2022-12-16T16:51:28.908+0000] {processor.py:154} INFO - Started process (PID=2585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:28.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:51:28.917+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:28.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:29.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:29.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:29.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:51:29.731+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:29.730+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:51:29.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.978 seconds
[2022-12-16T16:51:40.471+0000] {processor.py:154} INFO - Started process (PID=2595) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:40.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:51:40.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:40.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:40.623+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:42.034+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:51:52.587+0000] {processor.py:154} INFO - Started process (PID=2605) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:52.602+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:51:52.608+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:51:52.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:52.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:51:54.103+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:52:04.524+0000] {processor.py:154} INFO - Started process (PID=2615) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:04.576+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:52:04.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:04.579+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:04.674+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:05.224+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:05.223+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:52:05.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:05.759+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:52:05.944+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.434 seconds
[2022-12-16T16:52:16.621+0000] {processor.py:154} INFO - Started process (PID=2632) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:16.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:52:16.658+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:16.657+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:16.807+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:17.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:17.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:52:17.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:17.664+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:52:18.108+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.504 seconds
[2022-12-16T16:52:28.944+0000] {processor.py:154} INFO - Started process (PID=2642) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:28.959+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:52:28.970+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:28.964+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:29.083+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:29.267+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:29.266+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:52:29.402+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:29.400+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:52:29.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.664 seconds
[2022-12-16T16:52:40.471+0000] {processor.py:154} INFO - Started process (PID=2652) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:40.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:52:40.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:40.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:40.672+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:40.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:40.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:52:41.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:41.076+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:52:41.221+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.776 seconds
[2022-12-16T16:52:51.898+0000] {processor.py:154} INFO - Started process (PID=2670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:51.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:52:51.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:51.955+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:52.090+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:52:52.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:52.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:52:52.561+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:52:52.560+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:52:53.100+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.243 seconds
[2022-12-16T16:53:04.392+0000] {processor.py:154} INFO - Started process (PID=2680) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:04.446+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:53:04.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:04.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:04.669+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:04.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:04.924+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:53:05.145+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:05.144+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:53:05.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.133 seconds
[2022-12-16T16:53:15.750+0000] {processor.py:154} INFO - Started process (PID=2690) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:16.005+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:53:16.009+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:16.008+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:16.100+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:17.592+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:53:28.274+0000] {processor.py:154} INFO - Started process (PID=2700) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:28.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:53:28.308+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:28.307+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:28.398+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:28.561+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:28.560+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:53:28.698+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:28.697+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:53:28.823+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-16T16:53:39.356+0000] {processor.py:154} INFO - Started process (PID=2718) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:39.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:53:39.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:39.392+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:39.601+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:39.909+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:39.907+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:53:40.337+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:40.336+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:53:40.579+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.250 seconds
[2022-12-16T16:53:51.255+0000] {processor.py:154} INFO - Started process (PID=2728) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:51.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:53:51.264+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:51.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:51.419+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:53:51.647+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:51.646+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:53:51.799+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:53:51.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:53:51.960+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.743 seconds
[2022-12-16T16:54:02.253+0000] {processor.py:154} INFO - Started process (PID=2738) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:02.261+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:54:02.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:02.264+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:02.390+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:02.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:02.575+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:54:02.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:02.785+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:54:03.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.808 seconds
[2022-12-16T16:54:13.576+0000] {processor.py:154} INFO - Started process (PID=2755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:13.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:54:13.609+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:13.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:13.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:14.217+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:14.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:54:14.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:14.720+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:54:15.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.722 seconds
[2022-12-16T16:54:25.724+0000] {processor.py:154} INFO - Started process (PID=2766) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:25.735+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:54:25.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:25.754+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:26.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:26.710+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:26.709+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:54:27.062+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:27.057+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:54:27.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.750 seconds
[2022-12-16T16:54:37.819+0000] {processor.py:154} INFO - Started process (PID=2776) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:37.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:54:37.875+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:37.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:37.962+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:39.351+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:54:49.897+0000] {processor.py:154} INFO - Started process (PID=2786) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:49.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:54:49.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:49.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:50.120+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:54:50.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:50.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:54:50.877+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:54:50.876+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:54:51.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.193 seconds
[2022-12-16T16:55:01.728+0000] {processor.py:154} INFO - Started process (PID=2804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:01.746+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:55:01.758+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:01.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:02.096+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:03.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:03.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:55:03.587+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:03.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:55:03.787+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.135 seconds
[2022-12-16T16:55:14.452+0000] {processor.py:154} INFO - Started process (PID=2815) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:14.455+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:55:14.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:14.459+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:14.553+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:14.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:14.734+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:55:15.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:15.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:55:15.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.838 seconds
[2022-12-16T16:55:25.715+0000] {processor.py:154} INFO - Started process (PID=2825) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:25.763+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:55:25.768+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:25.767+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:25.950+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:26.644+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:55:36.967+0000] {processor.py:154} INFO - Started process (PID=2835) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:37.044+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:55:37.052+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:37.051+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:37.170+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:37.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:37.321+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:55:37.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:37.453+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:55:37.601+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-16T16:55:48.080+0000] {processor.py:154} INFO - Started process (PID=2849) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:48.391+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:55:48.395+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:48.394+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:48.535+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:48.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:48.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:55:49.044+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:55:49.043+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:55:49.223+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.185 seconds
[2022-12-16T16:55:59.929+0000] {processor.py:154} INFO - Started process (PID=2857) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:55:59.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:00.057+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:00.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:00.619+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:01.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:01.520+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:56:01.680+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:01.679+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:56:01.937+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.078 seconds
[2022-12-16T16:56:12.385+0000] {processor.py:154} INFO - Started process (PID=2870) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:12.436+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:12.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:12.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:12.544+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:12.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:12.970+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:56:13.250+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:13.249+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:56:13.406+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.035 seconds
[2022-12-16T16:56:24.009+0000] {processor.py:154} INFO - Started process (PID=2877) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:24.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:24.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:24.103+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:24.438+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:24.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:24.605+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:56:24.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:24.756+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:56:24.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.073 seconds
[2022-12-16T16:56:35.433+0000] {processor.py:154} INFO - Started process (PID=2896) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:35.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:35.498+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:35.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:35.723+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:36.651+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:36.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:56:36.827+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:36.826+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:56:36.954+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.537 seconds
[2022-12-16T16:56:47.310+0000] {processor.py:154} INFO - Started process (PID=2906) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:47.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:47.317+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:47.316+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:47.428+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:48.373+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:48.372+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:56:48.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:48.605+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:56:48.763+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.469 seconds
[2022-12-16T16:56:59.345+0000] {processor.py:154} INFO - Started process (PID=2916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:59.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:56:59.359+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:56:59.358+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:56:59.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:00.089+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:00.080+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:57:00.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:00.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:57:00.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.681 seconds
[2022-12-16T16:57:11.969+0000] {processor.py:154} INFO - Started process (PID=2933) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:11.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:57:12.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:12.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:12.495+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:13.848+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:57:24.586+0000] {processor.py:154} INFO - Started process (PID=2944) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:24.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:57:24.644+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:24.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:24.992+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:26.319+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:26.318+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:57:26.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:26.488+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:57:26.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.489 seconds
[2022-12-16T16:57:37.267+0000] {processor.py:154} INFO - Started process (PID=2959) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:37.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:57:37.296+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:37.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:37.408+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:38.108+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:38.107+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:57:38.331+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:38.331+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:57:38.659+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.410 seconds
[2022-12-16T16:57:49.339+0000] {processor.py:154} INFO - Started process (PID=2967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:49.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:57:49.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:49.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:49.640+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:57:49.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:49.931+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:57:50.241+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:57:50.240+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:57:50.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.129 seconds
[2022-12-16T16:58:00.988+0000] {processor.py:154} INFO - Started process (PID=2985) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:01.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:58:01.034+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:01.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:01.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:02.938+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:02.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:58:03.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:03.219+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:58:03.531+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.606 seconds
[2022-12-16T16:58:14.300+0000] {processor.py:154} INFO - Started process (PID=2997) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:14.326+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:58:14.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:14.329+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:14.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:14.643+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:14.642+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:58:14.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:14.788+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:58:15.046+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-16T16:58:25.404+0000] {processor.py:154} INFO - Started process (PID=3007) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:25.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:58:25.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:25.459+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:25.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:26.287+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:58:36.766+0000] {processor.py:154} INFO - Started process (PID=3017) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:36.788+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:58:36.792+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:36.791+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:36.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:37.063+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:37.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:58:37.192+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:37.191+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:58:37.330+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.594 seconds
[2022-12-16T16:58:48.039+0000] {processor.py:154} INFO - Started process (PID=3035) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:48.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:58:48.110+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:58:48.105+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:48.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:58:50.116+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:59:00.463+0000] {processor.py:154} INFO - Started process (PID=3045) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:00.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:00.471+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:00.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:00.558+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:00.703+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:00.702+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:59:00.830+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:00.829+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:59:00.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-16T16:59:11.435+0000] {processor.py:154} INFO - Started process (PID=3055) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:11.469+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:11.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:11.472+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:11.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:12.414+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:12.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:59:12.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:12.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:59:12.672+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.285 seconds
[2022-12-16T16:59:23.176+0000] {processor.py:154} INFO - Started process (PID=3069) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:23.191+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:23.240+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:23.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:23.454+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:23.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:23.696+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:59:23.839+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:23.839+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:59:24.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.076 seconds
[2022-12-16T16:59:34.674+0000] {processor.py:154} INFO - Started process (PID=3082) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:34.683+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:34.691+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:34.690+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:34.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:35.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:35.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:59:35.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:35.197+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:59:35.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.880 seconds
[2022-12-16T16:59:45.943+0000] {processor.py:154} INFO - Started process (PID=3092) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:45.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:45.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:45.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:46.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:47.622+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T16:59:58.102+0000] {processor.py:154} INFO - Started process (PID=3102) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:58.124+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T16:59:58.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:58.136+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:58.400+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T16:59:58.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:58.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T16:59:58.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T16:59:58.768+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T16:59:58.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.936 seconds
[2022-12-16T17:00:09.360+0000] {processor.py:154} INFO - Started process (PID=3121) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:09.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:00:09.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:09.392+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:09.599+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:10.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:10.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:00:11.221+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:11.220+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:00:11.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.204 seconds
[2022-12-16T17:00:22.105+0000] {processor.py:154} INFO - Started process (PID=3131) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:22.123+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:00:22.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:22.134+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:22.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:22.648+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:22.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:00:22.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:22.789+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:00:22.895+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.839 seconds
[2022-12-16T17:00:33.025+0000] {processor.py:154} INFO - Started process (PID=3141) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:33.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:00:33.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:33.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:33.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:33.826+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:33.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:00:34.180+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:34.179+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:00:34.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.320 seconds
[2022-12-16T17:00:44.528+0000] {processor.py:154} INFO - Started process (PID=3151) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:44.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:00:44.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:44.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:44.636+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:45.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:45.356+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:00:45.661+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:45.660+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:00:45.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.359 seconds
[2022-12-16T17:00:56.347+0000] {processor.py:154} INFO - Started process (PID=3169) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:56.378+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:00:56.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:56.380+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:56.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:00:57.713+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:57.712+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:00:57.869+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:00:57.868+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:00:58.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.741 seconds
[2022-12-16T17:01:08.261+0000] {processor.py:154} INFO - Started process (PID=3179) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:08.311+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:01:08.316+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:08.315+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:08.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:09.207+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:09.206+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:01:09.365+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:09.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:01:09.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.226 seconds
[2022-12-16T17:01:19.739+0000] {processor.py:154} INFO - Started process (PID=3189) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:19.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:01:19.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:19.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:19.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:20.178+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:20.177+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:01:20.586+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:20.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:01:20.762+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.038 seconds
[2022-12-16T17:01:31.044+0000] {processor.py:154} INFO - Started process (PID=3207) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:31.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:01:31.075+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:31.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:31.386+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:31.661+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:31.660+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:01:31.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:31.835+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:01:32.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.103 seconds
[2022-12-16T17:01:42.536+0000] {processor.py:154} INFO - Started process (PID=3217) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:42.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:01:42.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:42.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:42.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:42.980+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:42.979+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:01:43.203+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:43.202+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:01:43.332+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.810 seconds
[2022-12-16T17:01:53.605+0000] {processor.py:154} INFO - Started process (PID=3227) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:53.621+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:01:53.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:53.624+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:53.718+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:01:53.901+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:53.900+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:01:54.025+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:01:54.024+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:01:54.213+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.625 seconds
[2022-12-16T17:02:04.526+0000] {processor.py:154} INFO - Started process (PID=3237) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:04.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:02:04.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:04.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:04.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:04.902+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:04.896+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:02:05.165+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:05.164+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:02:05.320+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.808 seconds
[2022-12-16T17:02:16.100+0000] {processor.py:154} INFO - Started process (PID=3255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:16.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:02:16.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:16.131+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:16.651+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:17.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:17.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:02:17.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:17.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:02:17.535+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.450 seconds
[2022-12-16T17:02:27.856+0000] {processor.py:154} INFO - Started process (PID=3265) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:27.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:02:27.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:27.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:28.050+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:28.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:28.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:02:28.356+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:28.355+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:02:28.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.670 seconds
[2022-12-16T17:02:38.715+0000] {processor.py:154} INFO - Started process (PID=3273) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:38.743+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:02:38.747+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:38.746+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:38.864+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:39.035+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:39.034+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:02:39.158+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:39.157+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:02:39.300+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.606 seconds
[2022-12-16T17:02:49.632+0000] {processor.py:154} INFO - Started process (PID=3290) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:49.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:02:49.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:49.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:49.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:02:49.974+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:49.973+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:02:50.105+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:02:50.104+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:02:50.294+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.712 seconds
[2022-12-16T17:03:01.440+0000] {processor.py:154} INFO - Started process (PID=3298) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:01.446+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:01.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:01.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:01.614+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:02.722+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:02.722+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:03:02.858+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:02.857+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:03:02.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.541 seconds
[2022-12-16T17:03:13.663+0000] {processor.py:154} INFO - Started process (PID=3313) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:13.685+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:13.689+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:13.688+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:13.780+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:13.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:13.924+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:03:14.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:14.058+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:03:14.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.552 seconds
[2022-12-16T17:03:24.508+0000] {processor.py:154} INFO - Started process (PID=3323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:24.534+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:24.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:24.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:24.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:24.798+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:24.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:03:24.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:24.930+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:03:25.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-16T17:03:35.385+0000] {processor.py:154} INFO - Started process (PID=3342) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:35.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:35.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:35.392+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:35.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:36.883+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:03:47.337+0000] {processor.py:154} INFO - Started process (PID=3352) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:47.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:47.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:47.345+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:47.548+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:47.700+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:47.699+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:03:47.822+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:47.821+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:03:47.987+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.671 seconds
[2022-12-16T17:03:58.390+0000] {processor.py:154} INFO - Started process (PID=3362) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:58.419+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:03:58.423+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:58.422+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:58.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:03:58.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:58.754+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:03:58.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:03:58.919+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:03:59.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.721 seconds
[2022-12-16T17:04:09.573+0000] {processor.py:154} INFO - Started process (PID=3376) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:09.583+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:04:09.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:09.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:09.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:10.741+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:10.740+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:04:10.933+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:10.932+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:04:11.217+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.670 seconds
[2022-12-16T17:04:21.666+0000] {processor.py:154} INFO - Started process (PID=3389) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:21.711+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:04:21.719+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:21.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:21.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:21.968+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:21.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:04:22.134+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:22.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:04:22.319+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.672 seconds
[2022-12-16T17:04:32.985+0000] {processor.py:154} INFO - Started process (PID=3399) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:33.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:04:33.042+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:33.041+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:33.131+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:33.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:33.726+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:04:34.009+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:34.008+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:04:34.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.289 seconds
[2022-12-16T17:04:44.452+0000] {processor.py:154} INFO - Started process (PID=3409) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:44.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:04:44.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:44.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:44.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:44.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:44.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:04:45.124+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:45.123+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:04:45.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.909 seconds
[2022-12-16T17:04:55.903+0000] {processor.py:154} INFO - Started process (PID=3426) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:55.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:04:55.934+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:55.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:56.166+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:04:56.467+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:56.466+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:04:56.682+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:04:56.681+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:04:56.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.030 seconds
[2022-12-16T17:05:07.248+0000] {processor.py:154} INFO - Started process (PID=3436) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:07.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:05:07.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:07.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:07.372+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:07.550+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:07.549+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:05:07.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:07.700+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:05:08.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.999 seconds
[2022-12-16T17:05:18.532+0000] {processor.py:154} INFO - Started process (PID=3446) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:18.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:05:18.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:18.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:18.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:19.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:19.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:05:19.238+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:19.237+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:05:19.382+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.865 seconds
[2022-12-16T17:05:29.660+0000] {processor.py:154} INFO - Started process (PID=3463) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:29.695+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:05:29.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:29.710+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:29.968+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:30.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:30.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:05:30.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:30.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:05:31.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.399 seconds
[2022-12-16T17:05:42.061+0000] {processor.py:154} INFO - Started process (PID=3474) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:42.093+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:05:42.097+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:42.096+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:42.183+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:42.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:42.348+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:05:42.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:42.467+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:05:42.611+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.562 seconds
[2022-12-16T17:05:52.821+0000] {processor.py:154} INFO - Started process (PID=3484) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:52.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:05:52.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:52.867+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:52.957+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:05:53.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:53.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:05:53.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:05:53.269+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:05:53.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.645 seconds
[2022-12-16T17:06:03.845+0000] {processor.py:154} INFO - Started process (PID=3494) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:03.868+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:06:03.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:03.871+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:04.049+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:04.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:04.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:06:04.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:04.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:06:04.452+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.656 seconds
[2022-12-16T17:06:15.625+0000] {processor.py:154} INFO - Started process (PID=3512) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:15.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:06:15.639+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:15.638+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:15.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:16.185+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:16.184+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:06:16.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:16.502+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:06:16.699+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.143 seconds
[2022-12-16T17:06:27.044+0000] {processor.py:154} INFO - Started process (PID=3522) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:27.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:06:27.088+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:27.087+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:27.272+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:27.958+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:27.957+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:06:28.095+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:28.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:06:28.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-16T17:06:38.755+0000] {processor.py:154} INFO - Started process (PID=3532) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:38.796+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:06:38.801+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:38.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:38.917+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:39.063+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:39.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:06:39.263+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:39.262+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:06:39.499+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.842 seconds
[2022-12-16T17:06:50.146+0000] {processor.py:154} INFO - Started process (PID=3548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:50.155+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:06:50.166+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:50.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:50.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:06:51.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:51.079+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:06:51.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:06:51.248+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:06:51.792+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.678 seconds
[2022-12-16T17:07:02.239+0000] {processor.py:154} INFO - Started process (PID=3559) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:02.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:07:02.251+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:02.250+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:02.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:02.785+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:02.784+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:07:02.973+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:02.972+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:07:03.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.910 seconds
[2022-12-16T17:07:13.404+0000] {processor.py:154} INFO - Started process (PID=3569) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:13.408+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:07:13.413+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:13.412+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:13.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:13.636+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:13.635+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:07:13.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:13.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:07:14.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.785 seconds
[2022-12-16T17:07:24.678+0000] {processor.py:154} INFO - Started process (PID=3579) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:24.725+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:07:24.730+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:24.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:24.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:25.382+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:25.380+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:07:25.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:25.532+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:07:25.641+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.977 seconds
[2022-12-16T17:07:36.308+0000] {processor.py:154} INFO - Started process (PID=3598) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:36.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:07:36.366+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:36.363+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:36.539+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:36.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:36.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:07:37.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:37.186+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:07:37.483+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.256 seconds
[2022-12-16T17:07:47.997+0000] {processor.py:154} INFO - Started process (PID=3608) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:48.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:07:48.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:07:48.026+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:48.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:07:49.668+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:08:00.445+0000] {processor.py:154} INFO - Started process (PID=3618) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:00.498+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:00.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:00.501+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:00.729+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:01.155+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:01.154+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:01.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:01.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:01.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.083 seconds
[2022-12-16T17:08:11.803+0000] {processor.py:154} INFO - Started process (PID=3636) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:11.857+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:11.865+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:11.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:11.985+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:12.639+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:12.637+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:12.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:12.895+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:13.039+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.279 seconds
[2022-12-16T17:08:23.464+0000] {processor.py:154} INFO - Started process (PID=3647) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:23.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:23.522+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:23.521+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:23.603+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:23.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:23.734+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:23.852+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:23.851+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:23.980+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.534 seconds
[2022-12-16T17:08:34.237+0000] {processor.py:154} INFO - Started process (PID=3657) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:34.285+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:34.290+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:34.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:34.403+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:35.055+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:35.054+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:35.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:35.186+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:35.317+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.095 seconds
[2022-12-16T17:08:45.609+0000] {processor.py:154} INFO - Started process (PID=3667) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:45.632+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:45.636+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:45.635+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:45.721+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:45.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:45.856+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:45.968+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:45.967+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:46.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.483 seconds
[2022-12-16T17:08:56.445+0000] {processor.py:154} INFO - Started process (PID=3685) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:56.454+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:08:56.462+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:56.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:56.571+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:08:56.839+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:56.838+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:08:56.987+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:08:56.986+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:08:57.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.742 seconds
[2022-12-16T17:09:07.606+0000] {processor.py:154} INFO - Started process (PID=3695) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:07.609+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:09:07.613+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:07.612+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:07.699+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:08.299+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:08.298+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:09:08.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:08.432+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:09:08.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.977 seconds
[2022-12-16T17:09:18.843+0000] {processor.py:154} INFO - Started process (PID=3705) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:18.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:09:18.851+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:18.850+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:18.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:19.073+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:19.072+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:09:19.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:19.184+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:09:19.332+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-16T17:09:29.603+0000] {processor.py:154} INFO - Started process (PID=3715) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:29.607+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:09:29.611+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:29.610+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:29.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:30.444+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:09:40.980+0000] {processor.py:154} INFO - Started process (PID=3733) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:41.005+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:09:41.025+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:41.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:41.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:41.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:41.548+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:09:41.751+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:41.750+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:09:41.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.056 seconds
[2022-12-16T17:09:52.382+0000] {processor.py:154} INFO - Started process (PID=3743) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:52.407+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:09:52.419+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:52.418+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:52.586+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:09:52.767+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:52.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:09:52.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:09:52.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:09:53.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-16T17:10:03.910+0000] {processor.py:154} INFO - Started process (PID=3753) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:03.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:10:03.918+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:03.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:04.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:04.274+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:04.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:10:04.429+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:04.428+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:10:04.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.673 seconds
[2022-12-16T17:10:15.062+0000] {processor.py:154} INFO - Started process (PID=3770) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:15.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:10:15.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:15.095+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:15.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:15.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:15.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:10:15.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:15.781+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:10:16.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.273 seconds
[2022-12-16T17:10:27.013+0000] {processor.py:154} INFO - Started process (PID=3781) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:27.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:10:27.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:27.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:27.327+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:28.556+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:28.555+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:10:28.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:28.670+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:10:28.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.877 seconds
[2022-12-16T17:10:39.079+0000] {processor.py:154} INFO - Started process (PID=3791) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:39.083+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:10:39.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:39.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:39.168+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:39.733+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:10:50.379+0000] {processor.py:154} INFO - Started process (PID=3801) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:50.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:10:50.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:10:50.407+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:50.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:10:51.078+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:11:02.170+0000] {processor.py:154} INFO - Started process (PID=3819) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:02.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:02.195+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:02.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:02.563+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:03.014+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:03.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:11:03.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:03.442+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:11:03.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.619 seconds
[2022-12-16T17:11:14.718+0000] {processor.py:154} INFO - Started process (PID=3829) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:14.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:14.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:14.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:14.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:15.174+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:15.173+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:11:15.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:15.432+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:11:15.731+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.058 seconds
[2022-12-16T17:11:26.010+0000] {processor.py:154} INFO - Started process (PID=3839) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:26.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:26.018+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:26.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:26.111+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:26.289+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:26.288+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:11:26.569+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:26.568+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:11:26.811+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T17:11:37.100+0000] {processor.py:154} INFO - Started process (PID=3849) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:37.104+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:37.109+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:37.108+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:37.191+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:37.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:37.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:11:37.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:37.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:11:37.614+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.527 seconds
[2022-12-16T17:11:47.911+0000] {processor.py:154} INFO - Started process (PID=3867) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:47.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:47.927+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:47.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:48.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:48.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:48.734+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:11:48.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:48.927+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:11:49.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.208 seconds
[2022-12-16T17:11:59.462+0000] {processor.py:154} INFO - Started process (PID=3877) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:59.515+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:11:59.519+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:11:59.518+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:11:59.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:00.164+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:12:10.507+0000] {processor.py:154} INFO - Started process (PID=3887) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:10.543+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:12:10.547+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:10.546+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:10.640+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:11.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:11.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:12:11.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:11.390+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:12:11.497+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.005 seconds
[2022-12-16T17:12:21.850+0000] {processor.py:154} INFO - Started process (PID=3897) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:21.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:12:21.858+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:21.857+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:21.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:22.141+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:22.140+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:12:22.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:22.254+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:12:22.397+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.573 seconds
[2022-12-16T17:12:32.906+0000] {processor.py:154} INFO - Started process (PID=3915) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:32.955+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:12:32.958+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:32.958+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:33.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:33.477+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:33.476+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:12:33.675+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:33.674+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:12:33.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.044 seconds
[2022-12-16T17:12:44.247+0000] {processor.py:154} INFO - Started process (PID=3925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:44.251+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:12:44.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:44.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:44.343+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:45.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:45.835+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:12:45.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:45.976+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:12:46.113+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.880 seconds
[2022-12-16T17:12:56.422+0000] {processor.py:154} INFO - Started process (PID=3935) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:56.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:12:56.440+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:56.439+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:56.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:12:56.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:56.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:12:57.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:12:57.035+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:12:57.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.766 seconds
[2022-12-16T17:13:07.474+0000] {processor.py:154} INFO - Started process (PID=3952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:07.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:13:07.535+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:07.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:07.703+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:07.882+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:07.881+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:13:08.028+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:08.027+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:13:08.444+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-16T17:13:18.724+0000] {processor.py:154} INFO - Started process (PID=3962) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:18.775+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:13:18.779+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:18.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:18.874+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:19.045+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:19.044+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:13:19.186+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:19.186+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:13:19.381+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.697 seconds
[2022-12-16T17:13:29.788+0000] {processor.py:154} INFO - Started process (PID=3972) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:29.807+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:13:29.816+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:29.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:29.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:30.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:30.091+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:13:30.217+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:30.216+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:13:30.348+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.575 seconds
[2022-12-16T17:13:40.650+0000] {processor.py:154} INFO - Started process (PID=3982) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:40.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:13:40.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:40.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:40.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:40.941+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:40.940+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:13:41.129+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:41.128+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:13:41.237+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.604 seconds
[2022-12-16T17:13:51.526+0000] {processor.py:154} INFO - Started process (PID=4000) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:51.554+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:13:51.558+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:51.557+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:51.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:13:53.144+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:53.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:13:53.321+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:13:53.320+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:13:53.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.011 seconds
[2022-12-16T17:14:03.919+0000] {processor.py:154} INFO - Started process (PID=4010) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:03.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:14:03.927+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:03.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:04.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:04.172+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:04.171+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:14:04.375+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:04.374+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:14:04.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.581 seconds
[2022-12-16T17:14:14.735+0000] {processor.py:154} INFO - Started process (PID=4020) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:14.738+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:14:14.742+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:14.741+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:14.840+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:15.015+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:15.014+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:14:15.141+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:15.140+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:14:15.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.552 seconds
[2022-12-16T17:14:25.630+0000] {processor.py:154} INFO - Started process (PID=4030) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:25.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:14:25.679+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:25.678+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:25.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:27.394+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:14:37.777+0000] {processor.py:154} INFO - Started process (PID=4047) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:37.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:14:37.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:37.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:37.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:38.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:38.224+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:14:38.345+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:38.344+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:14:38.477+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.714 seconds
[2022-12-16T17:14:49.122+0000] {processor.py:154} INFO - Started process (PID=4057) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:49.131+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:14:49.143+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:49.142+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:49.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:14:49.533+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:49.532+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:14:49.663+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:14:49.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:14:49.767+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.700 seconds
[2022-12-16T17:15:00.137+0000] {processor.py:154} INFO - Started process (PID=4067) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:00.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:00.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:00.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:00.366+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:00.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:00.928+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:15:01.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:01.076+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:15:01.188+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.084 seconds
[2022-12-16T17:15:11.730+0000] {processor.py:154} INFO - Started process (PID=4086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:11.743+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:11.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:11.750+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:12.192+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:13.301+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:15:24.047+0000] {processor.py:154} INFO - Started process (PID=4096) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:24.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:24.076+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:24.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:24.158+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:24.636+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:24.635+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:15:24.861+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:24.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:15:25.007+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.974 seconds
[2022-12-16T17:15:35.548+0000] {processor.py:154} INFO - Started process (PID=4106) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:35.563+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:35.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:35.578+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:35.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:36.059+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:36.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:15:36.172+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:36.172+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:15:36.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.865 seconds
[2022-12-16T17:15:46.650+0000] {processor.py:154} INFO - Started process (PID=4116) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:46.659+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:46.663+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:46.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:46.832+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:47.693+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:47.692+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:15:47.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:47.956+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:15:48.101+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.467 seconds
[2022-12-16T17:15:58.328+0000] {processor.py:154} INFO - Started process (PID=4134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:58.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:15:58.340+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:58.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:58.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:15:59.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:59.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:15:59.622+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:15:59.620+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:15:59.740+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.427 seconds
[2022-12-16T17:16:10.315+0000] {processor.py:154} INFO - Started process (PID=4144) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:10.362+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:16:10.367+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:10.366+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:10.531+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:11.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:11.441+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:16:11.817+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:11.816+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:16:11.992+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.719 seconds
[2022-12-16T17:16:22.593+0000] {processor.py:154} INFO - Started process (PID=4154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:22.603+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:16:22.611+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:22.610+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:22.851+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:23.939+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:16:34.317+0000] {processor.py:154} INFO - Started process (PID=4172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:34.369+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:16:34.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:34.383+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:34.679+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:35.472+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:35.471+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:16:35.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:35.936+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:16:36.199+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.898 seconds
[2022-12-16T17:16:46.693+0000] {processor.py:154} INFO - Started process (PID=4182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:46.699+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:16:46.703+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:46.702+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:47.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:47.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:47.566+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:16:47.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:47.710+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:16:47.830+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.153 seconds
[2022-12-16T17:16:58.100+0000] {processor.py:154} INFO - Started process (PID=4192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:58.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:16:58.113+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:58.112+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:58.244+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:16:58.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:58.905+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:16:59.092+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:16:59.091+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:16:59.335+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.259 seconds
[2022-12-16T17:17:09.904+0000] {processor.py:154} INFO - Started process (PID=4208) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:09.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:17:09.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:09.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:10.167+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:11.067+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:11.066+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:17:11.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:11.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:17:12.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.318 seconds
[2022-12-16T17:17:23.346+0000] {processor.py:154} INFO - Started process (PID=4219) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:23.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:17:23.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:23.357+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:23.498+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:23.745+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:23.743+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:17:23.898+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:23.897+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:17:24.001+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-16T17:17:34.749+0000] {processor.py:154} INFO - Started process (PID=4229) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:34.758+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:17:34.766+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:34.765+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:34.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:35.252+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:35.251+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:17:35.367+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:35.366+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:17:35.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.794 seconds
[2022-12-16T17:17:45.944+0000] {processor.py:154} INFO - Started process (PID=4239) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:45.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:17:46.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:46.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:46.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:46.978+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:46.977+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:17:47.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:47.093+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:17:47.218+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.290 seconds
[2022-12-16T17:17:57.707+0000] {processor.py:154} INFO - Started process (PID=4259) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:57.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:17:57.736+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:57.735+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:57.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:17:58.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:58.325+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:17:58.789+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:17:58.788+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:17:59.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.708 seconds
[2022-12-16T17:18:09.919+0000] {processor.py:154} INFO - Started process (PID=4269) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:09.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:18:09.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:09.975+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:10.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:10.271+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:10.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:18:10.427+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:10.426+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:18:10.792+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.890 seconds
[2022-12-16T17:18:21.397+0000] {processor.py:154} INFO - Started process (PID=4279) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:21.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:18:21.408+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:21.407+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:21.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:21.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:21.863+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:18:22.057+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:22.056+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:18:22.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.816 seconds
[2022-12-16T17:18:32.459+0000] {processor.py:154} INFO - Started process (PID=4289) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:32.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:18:32.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:32.488+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:32.712+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:33.316+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:18:43.651+0000] {processor.py:154} INFO - Started process (PID=4306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:43.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:18:43.722+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:43.689+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:43.993+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:45.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:45.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:18:45.835+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:45.834+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:18:46.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.513 seconds
[2022-12-16T17:18:57.282+0000] {processor.py:154} INFO - Started process (PID=4316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:57.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:18:57.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:57.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:57.422+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:18:57.552+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:57.551+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:18:57.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:18:57.663+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:18:57.856+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-16T17:19:08.675+0000] {processor.py:154} INFO - Started process (PID=4326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:08.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:19:08.727+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:08.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:08.833+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:09.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:09.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:19:09.444+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:09.443+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:19:09.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.280 seconds
[2022-12-16T17:19:20.213+0000] {processor.py:154} INFO - Started process (PID=4343) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:20.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:19:20.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:20.221+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:20.335+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:21.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:21.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:19:21.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:21.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:19:21.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.359 seconds
[2022-12-16T17:19:32.577+0000] {processor.py:154} INFO - Started process (PID=4354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:32.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:19:32.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:32.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:32.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:33.390+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:33.389+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:19:33.578+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:33.577+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:19:33.747+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.186 seconds
[2022-12-16T17:19:44.219+0000] {processor.py:154} INFO - Started process (PID=4364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:44.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:19:44.268+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:44.267+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:44.374+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:45.310+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:45.309+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:19:45.479+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:45.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:19:45.898+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.697 seconds
[2022-12-16T17:19:56.241+0000] {processor.py:154} INFO - Started process (PID=4374) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:56.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:19:56.267+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:56.266+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:56.353+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:19:56.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:56.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:19:56.630+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:19:56.629+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:19:56.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.522 seconds
[2022-12-16T17:20:07.249+0000] {processor.py:154} INFO - Started process (PID=4391) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:07.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:20:07.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:07.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:07.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:07.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:07.675+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:20:07.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:07.835+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:20:08.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-16T17:20:18.466+0000] {processor.py:154} INFO - Started process (PID=4401) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:18.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:20:18.491+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:18.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:18.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:19.794+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:20:30.322+0000] {processor.py:154} INFO - Started process (PID=4411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:30.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:20:30.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:30.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:30.441+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:30.640+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:30.639+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:20:30.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:30.852+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:20:31.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T17:20:41.574+0000] {processor.py:154} INFO - Started process (PID=4421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:41.592+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:20:41.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:41.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:41.832+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:41.988+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:41.987+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:20:42.097+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:42.096+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:20:42.238+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-16T17:20:52.908+0000] {processor.py:154} INFO - Started process (PID=4438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:52.918+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:20:52.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:52.923+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:53.141+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:20:53.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:53.523+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:20:53.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:20:53.859+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:20:54.139+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.270 seconds
[2022-12-16T17:21:04.585+0000] {processor.py:154} INFO - Started process (PID=4448) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:04.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:21:04.598+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:04.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:04.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:05.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:05.323+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:21:05.604+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:05.603+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:21:05.728+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.173 seconds
[2022-12-16T17:21:16.033+0000] {processor.py:154} INFO - Started process (PID=4458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:16.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:21:16.041+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:16.040+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:16.145+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:16.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:16.379+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:21:16.561+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:16.560+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:21:16.716+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.697 seconds
[2022-12-16T17:21:27.023+0000] {processor.py:154} INFO - Started process (PID=4468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:27.051+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:21:27.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:27.067+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:27.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:28.388+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:21:39.044+0000] {processor.py:154} INFO - Started process (PID=4486) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:39.089+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:21:39.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:39.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:39.664+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:40.140+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:40.139+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:21:40.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:40.291+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:21:40.423+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.411 seconds
[2022-12-16T17:21:50.711+0000] {processor.py:154} INFO - Started process (PID=4496) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:50.739+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:21:50.743+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:50.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:50.849+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:21:51.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:51.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:21:51.230+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:21:51.229+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:21:51.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.647 seconds
[2022-12-16T17:22:01.700+0000] {processor.py:154} INFO - Started process (PID=4506) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:01.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:22:01.724+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:01.711+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:01.839+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:02.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:02.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:22:02.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:02.252+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:22:02.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.844 seconds
[2022-12-16T17:22:12.950+0000] {processor.py:154} INFO - Started process (PID=4524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:12.977+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:22:12.981+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:12.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:13.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:13.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:13.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:22:13.993+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:13.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:22:14.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.429 seconds
[2022-12-16T17:22:24.872+0000] {processor.py:154} INFO - Started process (PID=4535) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:24.898+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:22:24.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:24.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:25.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:26.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:26.118+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:22:26.491+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:26.488+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:22:26.673+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.817 seconds
[2022-12-16T17:22:37.030+0000] {processor.py:154} INFO - Started process (PID=4545) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:37.074+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:22:37.084+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:37.083+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:37.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:37.841+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:37.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:22:37.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:37.962+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:22:38.106+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.090 seconds
[2022-12-16T17:22:48.480+0000] {processor.py:154} INFO - Started process (PID=4555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:48.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:22:48.569+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:22:48.568+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:48.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:22:49.977+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:23:00.280+0000] {processor.py:154} INFO - Started process (PID=4574) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:00.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:00.312+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:00.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:00.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:00.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:00.715+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:23:00.851+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:00.850+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:23:01.108+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.865 seconds
[2022-12-16T17:23:11.485+0000] {processor.py:154} INFO - Started process (PID=4584) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:11.532+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:11.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:11.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:11.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:11.781+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:11.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:23:11.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:11.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:23:12.158+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.687 seconds
[2022-12-16T17:23:23.239+0000] {processor.py:154} INFO - Started process (PID=4594) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:23.255+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:23.263+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:23.262+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:23.410+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:23.610+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:23.608+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:23:23.775+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:23.773+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:23:23.966+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.783 seconds
[2022-12-16T17:23:34.515+0000] {processor.py:154} INFO - Started process (PID=4604) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:34.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:34.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:34.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:34.637+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:35.460+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:23:46.330+0000] {processor.py:154} INFO - Started process (PID=4622) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:46.366+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:46.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:46.376+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:46.562+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:46.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:46.927+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:23:47.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:47.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:23:47.221+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.962 seconds
[2022-12-16T17:23:57.645+0000] {processor.py:154} INFO - Started process (PID=4632) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:57.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:23:57.667+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:57.666+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:57.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:23:58.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:58.512+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:23:58.691+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:23:58.690+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:23:58.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.171 seconds
[2022-12-16T17:24:09.270+0000] {processor.py:154} INFO - Started process (PID=4642) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:09.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:24:09.307+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:09.306+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:09.696+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:10.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:10.670+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:24:10.800+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:10.799+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:24:10.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.755 seconds
[2022-12-16T17:24:21.317+0000] {processor.py:154} INFO - Started process (PID=4658) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:21.322+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:24:21.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:21.325+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:21.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:21.590+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:21.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:24:21.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:21.795+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:24:21.927+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.626 seconds
[2022-12-16T17:24:32.495+0000] {processor.py:154} INFO - Started process (PID=4669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:32.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:24:32.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:32.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:32.606+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:32.760+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:32.759+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:24:32.899+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:32.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:24:33.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-16T17:24:43.708+0000] {processor.py:154} INFO - Started process (PID=4679) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:43.740+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:24:43.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:43.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:43.845+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:44.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:44.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:24:45.106+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:45.105+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:24:45.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.582 seconds
[2022-12-16T17:24:55.589+0000] {processor.py:154} INFO - Started process (PID=4689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:55.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:24:55.640+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:55.639+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:55.724+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:24:56.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:56.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:24:56.463+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:24:56.462+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:24:56.601+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.031 seconds
[2022-12-16T17:25:07.078+0000] {processor.py:154} INFO - Started process (PID=4706) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:07.125+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:25:07.137+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:07.136+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:07.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:07.929+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:07.928+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:25:08.326+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:08.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:25:08.560+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-16T17:25:19.387+0000] {processor.py:154} INFO - Started process (PID=4716) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:19.434+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:25:19.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:19.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:19.666+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:20.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:20.079+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:25:20.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:20.382+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:25:20.643+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.287 seconds
[2022-12-16T17:25:31.052+0000] {processor.py:154} INFO - Started process (PID=4726) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:31.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:25:31.106+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:31.105+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:31.195+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:31.802+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:31.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:25:31.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:31.944+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:25:32.119+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.086 seconds
[2022-12-16T17:25:42.551+0000] {processor.py:154} INFO - Started process (PID=4743) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:42.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:25:42.574+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:42.573+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:42.879+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:43.704+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:25:54.517+0000] {processor.py:154} INFO - Started process (PID=4754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:54.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:25:54.572+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:54.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:54.671+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:25:54.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:54.814+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:25:54.940+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:25:54.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:25:55.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-16T17:26:05.441+0000] {processor.py:154} INFO - Started process (PID=4764) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:05.511+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:26:05.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:05.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:05.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:06.137+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:06.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:26:06.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:06.299+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:26:06.488+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.082 seconds
[2022-12-16T17:26:16.999+0000] {processor.py:154} INFO - Started process (PID=4774) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:17.050+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:26:17.058+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:17.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:17.274+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:17.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:17.517+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:26:17.752+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:17.751+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:26:17.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.010 seconds
[2022-12-16T17:26:28.414+0000] {processor.py:154} INFO - Started process (PID=4792) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:28.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:26:28.432+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:28.431+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:28.749+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:29.132+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:29.131+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:26:29.525+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:29.524+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:26:30.100+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.754 seconds
[2022-12-16T17:26:40.920+0000] {processor.py:154} INFO - Started process (PID=4802) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:40.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:26:40.926+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:40.925+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:41.023+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:41.191+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:41.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:26:41.323+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:41.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:26:41.427+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.524 seconds
[2022-12-16T17:26:51.810+0000] {processor.py:154} INFO - Started process (PID=4812) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:51.885+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:26:51.892+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:51.891+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:52.071+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:26:52.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:52.739+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:26:52.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:26:52.879+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:26:53.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.306 seconds
[2022-12-16T17:27:03.979+0000] {processor.py:154} INFO - Started process (PID=4822) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:04.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:27:04.022+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:04.020+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:04.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:04.303+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:04.302+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:27:04.418+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:04.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:27:04.573+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.610 seconds
[2022-12-16T17:27:15.084+0000] {processor.py:154} INFO - Started process (PID=4840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:15.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:27:15.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:15.113+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:15.371+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:15.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:15.773+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:27:16.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:16.059+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:27:16.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.304 seconds
[2022-12-16T17:27:26.608+0000] {processor.py:154} INFO - Started process (PID=4850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:26.627+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:27:26.638+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:26.637+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:26.749+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:27.831+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:27:38.248+0000] {processor.py:154} INFO - Started process (PID=4860) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:38.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:27:38.298+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:38.296+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:38.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:39.314+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:27:49.767+0000] {processor.py:154} INFO - Started process (PID=4870) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:49.821+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:27:49.824+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:49.823+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:49.978+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:27:50.426+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:50.424+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:27:50.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:27:50.542+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:27:50.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.225 seconds
[2022-12-16T17:28:01.398+0000] {processor.py:154} INFO - Started process (PID=4888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:01.414+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:01.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:01.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:01.599+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:01.818+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:01.817+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:02.086+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:02.072+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:02.399+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.034 seconds
[2022-12-16T17:28:12.892+0000] {processor.py:154} INFO - Started process (PID=4898) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:12.915+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:12.928+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:12.927+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:13.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:13.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:13.227+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:13.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:13.341+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:13.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.612 seconds
[2022-12-16T17:28:23.784+0000] {processor.py:154} INFO - Started process (PID=4908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:23.829+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:23.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:23.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:23.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:24.113+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:24.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:24.308+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:24.307+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:24.434+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-16T17:28:35.006+0000] {processor.py:154} INFO - Started process (PID=4925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:35.031+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:35.035+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:35.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:35.196+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:35.603+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:35.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:35.831+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:35.830+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:36.112+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.171 seconds
[2022-12-16T17:28:46.492+0000] {processor.py:154} INFO - Started process (PID=4936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:46.542+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:46.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:46.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:46.684+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:47.019+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:47.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:47.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:47.148+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:47.335+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.880 seconds
[2022-12-16T17:28:57.689+0000] {processor.py:154} INFO - Started process (PID=4946) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:57.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:28:57.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:57.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:57.799+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:28:57.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:57.938+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:28:58.082+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:28:58.081+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:28:58.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.732 seconds
[2022-12-16T17:29:08.578+0000] {processor.py:154} INFO - Started process (PID=4956) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:08.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:29:08.608+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:08.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:08.724+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:08.972+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:08.972+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:29:09.342+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:09.341+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:29:09.487+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.923 seconds
[2022-12-16T17:29:20.229+0000] {processor.py:154} INFO - Started process (PID=4973) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:20.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:29:20.310+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:20.306+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:20.532+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:20.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:20.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:29:21.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:21.086+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:29:21.341+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.264 seconds
[2022-12-16T17:29:31.976+0000] {processor.py:154} INFO - Started process (PID=4983) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:31.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:29:32.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:32.006+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:32.245+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:32.445+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:32.444+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:29:32.567+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:32.566+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:29:32.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.747 seconds
[2022-12-16T17:29:43.019+0000] {processor.py:154} INFO - Started process (PID=4993) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:43.035+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:29:43.039+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:43.038+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:43.234+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:43.575+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:43.567+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:29:43.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:43.843+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:29:44.227+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.240 seconds
[2022-12-16T17:29:54.724+0000] {processor.py:154} INFO - Started process (PID=5003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:54.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:29:54.784+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:54.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:54.989+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:29:55.658+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:55.652+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:29:56.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:29:56.000+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:29:56.367+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.671 seconds
[2022-12-16T17:30:07.330+0000] {processor.py:154} INFO - Started process (PID=5020) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:07.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:30:07.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:07.379+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:07.683+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:08.189+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:30:19.106+0000] {processor.py:154} INFO - Started process (PID=5030) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:19.126+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:30:19.130+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:19.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:19.221+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:19.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:19.415+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:30:19.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:19.558+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:30:19.713+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-16T17:30:30.645+0000] {processor.py:154} INFO - Started process (PID=5040) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:30.671+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:30:30.675+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:30.674+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:30.917+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:32.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:32.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:30:32.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:32.781+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:30:32.974+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.355 seconds
[2022-12-16T17:30:43.536+0000] {processor.py:154} INFO - Started process (PID=5057) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:43.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:30:43.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:43.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:44.116+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:45.071+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:45.070+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:30:45.240+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:45.239+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:30:45.515+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.024 seconds
[2022-12-16T17:30:56.154+0000] {processor.py:154} INFO - Started process (PID=5068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:56.232+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:30:56.244+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:56.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:56.501+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:30:57.657+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:57.656+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:30:57.778+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:30:57.778+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:30:57.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.909 seconds
[2022-12-16T17:31:08.512+0000] {processor.py:154} INFO - Started process (PID=5078) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:08.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:31:08.531+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:08.530+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:08.695+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:08.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:08.914+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:31:09.082+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:09.081+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:31:09.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.815 seconds
[2022-12-16T17:31:19.622+0000] {processor.py:154} INFO - Started process (PID=5088) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:19.633+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:31:19.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:19.636+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:19.805+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:20.681+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:20.679+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:31:20.901+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:20.900+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:31:21.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.476 seconds
[2022-12-16T17:31:31.816+0000] {processor.py:154} INFO - Started process (PID=5106) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:31.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:31:31.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:31.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:32.020+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:32.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:32.715+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:31:33.108+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:33.107+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:31:33.568+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.800 seconds
[2022-12-16T17:31:44.451+0000] {processor.py:154} INFO - Started process (PID=5116) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:44.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:31:44.477+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:44.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:44.635+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:44.900+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:44.899+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:31:45.222+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:45.217+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:31:45.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.041 seconds
[2022-12-16T17:31:56.066+0000] {processor.py:154} INFO - Started process (PID=5126) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:56.084+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:31:56.097+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:56.096+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:56.201+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:31:56.370+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:56.370+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:31:56.555+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:31:56.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:31:56.824+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.805 seconds
[2022-12-16T17:32:07.356+0000] {processor.py:154} INFO - Started process (PID=5136) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:07.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:32:07.389+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:07.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:07.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:07.624+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:07.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:32:07.741+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:07.740+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:32:07.906+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-16T17:32:18.562+0000] {processor.py:154} INFO - Started process (PID=5154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:18.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:32:18.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:18.580+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:18.864+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:20.913+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:20.900+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:32:21.510+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:21.509+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:32:21.763+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.263 seconds
[2022-12-16T17:32:32.194+0000] {processor.py:154} INFO - Started process (PID=5164) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:32.232+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:32:32.240+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:32.239+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:32.452+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:32.946+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:32.945+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:32:33.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:33.334+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:32:33.666+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.486 seconds
[2022-12-16T17:32:44.248+0000] {processor.py:154} INFO - Started process (PID=5174) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:44.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:32:44.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:44.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:44.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:45.827+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:32:56.359+0000] {processor.py:154} INFO - Started process (PID=5191) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:56.400+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:32:56.415+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:56.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:56.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:32:57.110+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:57.100+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:32:57.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:32:57.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:32:57.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.117 seconds
[2022-12-16T17:33:07.998+0000] {processor.py:154} INFO - Started process (PID=5202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:08.024+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:33:08.035+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:08.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:08.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:08.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:08.558+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:33:08.722+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:08.721+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:33:08.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.882 seconds
[2022-12-16T17:33:19.830+0000] {processor.py:154} INFO - Started process (PID=5212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:19.856+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:33:19.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:19.859+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:20.045+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:20.234+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:20.232+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:33:20.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:20.356+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:33:20.514+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.737 seconds
[2022-12-16T17:33:31.031+0000] {processor.py:154} INFO - Started process (PID=5222) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:31.049+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:33:31.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:31.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:31.210+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:31.472+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:31.471+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:33:31.670+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:31.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:33:31.808+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.793 seconds
[2022-12-16T17:33:42.274+0000] {processor.py:154} INFO - Started process (PID=5239) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:42.328+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:33:42.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:42.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:42.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:42.798+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:42.796+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:33:43.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:43.031+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:33:43.244+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.988 seconds
[2022-12-16T17:33:53.535+0000] {processor.py:154} INFO - Started process (PID=5249) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:53.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:33:53.565+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:53.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:53.696+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:33:53.861+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:53.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:33:53.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:33:53.984+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:33:54.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.614 seconds
[2022-12-16T17:34:04.403+0000] {processor.py:154} INFO - Started process (PID=5259) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:04.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:34:04.458+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:04.456+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:04.551+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:05.637+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:05.636+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:34:05.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:05.747+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:34:05.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.494 seconds
[2022-12-16T17:34:16.199+0000] {processor.py:154} INFO - Started process (PID=5269) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:16.255+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:34:16.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:16.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:16.504+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:17.406+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:34:28.065+0000] {processor.py:154} INFO - Started process (PID=5287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:28.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:34:28.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:28.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:28.184+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:29.143+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:34:39.513+0000] {processor.py:154} INFO - Started process (PID=5297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:39.559+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:34:39.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:39.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:39.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:40.336+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:40.335+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:34:40.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:40.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:34:40.766+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.268 seconds
[2022-12-16T17:34:51.162+0000] {processor.py:154} INFO - Started process (PID=5307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:51.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:34:51.192+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:51.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:51.369+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:34:51.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:51.579+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:34:51.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:34:51.735+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:34:51.839+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-16T17:35:02.775+0000] {processor.py:154} INFO - Started process (PID=5324) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:02.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:02.813+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:02.808+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:02.927+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:03.482+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:35:13.889+0000] {processor.py:154} INFO - Started process (PID=5334) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:13.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:13.942+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:13.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:14.023+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:14.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:14.183+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:35:14.323+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:14.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:35:14.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-16T17:35:24.647+0000] {processor.py:154} INFO - Started process (PID=5344) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:24.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:24.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:24.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:24.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:25.211+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:35:35.619+0000] {processor.py:154} INFO - Started process (PID=5354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:35.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:35.673+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:35.672+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:35.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:36.361+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:36.360+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:35:36.506+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:36.505+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:35:36.619+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.024 seconds
[2022-12-16T17:35:46.954+0000] {processor.py:154} INFO - Started process (PID=5372) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:46.982+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:46.990+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:46.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:47.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:48.378+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:35:58.573+0000] {processor.py:154} INFO - Started process (PID=5382) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:58.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:35:58.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:58.600+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:58.698+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:35:58.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:58.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:35:58.946+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:35:58.945+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:35:59.075+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.517 seconds
[2022-12-16T17:36:09.359+0000] {processor.py:154} INFO - Started process (PID=5392) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:09.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:36:09.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:09.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:09.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:09.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:09.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:36:09.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:09.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:36:09.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.531 seconds
[2022-12-16T17:36:20.335+0000] {processor.py:154} INFO - Started process (PID=5402) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:20.369+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:36:20.373+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:20.372+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:20.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:21.240+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:21.239+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:36:21.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:21.379+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:36:21.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.273 seconds
[2022-12-16T17:36:32.152+0000] {processor.py:154} INFO - Started process (PID=5421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:32.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:36:32.196+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:32.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:32.389+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:32.704+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:32.703+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:36:32.937+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:32.936+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:36:33.258+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.132 seconds
[2022-12-16T17:36:43.558+0000] {processor.py:154} INFO - Started process (PID=5431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:43.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:36:43.636+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:43.635+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:43.785+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:43.956+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:43.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:36:44.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:44.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:36:44.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.662 seconds
[2022-12-16T17:36:54.847+0000] {processor.py:154} INFO - Started process (PID=5441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:54.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:36:54.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:54.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:55.006+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:36:55.306+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:55.305+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:36:55.461+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:36:55.460+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:36:55.600+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.768 seconds
[2022-12-16T17:37:06.082+0000] {processor.py:154} INFO - Started process (PID=5458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:06.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:37:06.136+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:06.135+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:06.411+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:07.322+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:37:17.784+0000] {processor.py:154} INFO - Started process (PID=5468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:17.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:37:17.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:17.802+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:17.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:18.579+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:37:29.041+0000] {processor.py:154} INFO - Started process (PID=5478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:29.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:37:29.068+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:29.067+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:29.248+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:29.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:29.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:37:29.656+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:29.655+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:37:29.812+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.799 seconds
[2022-12-16T17:37:40.167+0000] {processor.py:154} INFO - Started process (PID=5488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:40.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:37:40.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:40.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:40.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:40.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:40.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:37:40.634+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:40.633+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:37:40.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.696 seconds
[2022-12-16T17:37:51.343+0000] {processor.py:154} INFO - Started process (PID=5506) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:51.406+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:37:51.410+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:37:51.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:51.606+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:37:52.143+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:38:02.627+0000] {processor.py:154} INFO - Started process (PID=5516) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:02.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:38:02.660+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:02.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:02.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:02.946+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:02.945+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:38:03.085+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:03.084+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:38:03.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.665 seconds
[2022-12-16T17:38:13.595+0000] {processor.py:154} INFO - Started process (PID=5526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:13.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:38:13.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:13.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:13.787+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:14.293+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:14.292+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:38:14.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:14.537+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:38:14.775+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.195 seconds
[2022-12-16T17:38:25.456+0000] {processor.py:154} INFO - Started process (PID=5544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:25.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:38:25.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:25.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:25.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:26.523+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:38:37.213+0000] {processor.py:154} INFO - Started process (PID=5555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:37.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:38:37.264+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:37.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:37.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:37.625+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:37.624+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:38:37.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:37.748+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:38:37.925+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.729 seconds
[2022-12-16T17:38:48.373+0000] {processor.py:154} INFO - Started process (PID=5565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:48.407+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:38:48.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:38:48.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:48.663+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:38:50.191+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:39:00.466+0000] {processor.py:154} INFO - Started process (PID=5575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:00.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:00.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:00.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:00.651+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:00.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:00.802+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:39:00.951+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:00.950+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:39:01.142+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-16T17:39:11.657+0000] {processor.py:154} INFO - Started process (PID=5594) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:11.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:11.699+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:11.698+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:12.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:12.607+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:12.605+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:39:12.977+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:12.976+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:39:13.223+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.626 seconds
[2022-12-16T17:39:23.668+0000] {processor.py:154} INFO - Started process (PID=5604) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:23.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:23.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:23.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:23.805+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:24.159+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:24.159+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:39:24.278+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:24.277+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:39:24.381+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.727 seconds
[2022-12-16T17:39:34.794+0000] {processor.py:154} INFO - Started process (PID=5614) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:34.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:34.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:34.825+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:35.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:35.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:35.345+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:39:35.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:35.544+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:39:35.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.014 seconds
[2022-12-16T17:39:46.102+0000] {processor.py:154} INFO - Started process (PID=5624) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:46.128+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:46.132+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:46.131+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:46.279+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:47.765+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:47.763+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:39:48.077+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:48.076+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:39:48.367+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.289 seconds
[2022-12-16T17:39:59.313+0000] {processor.py:154} INFO - Started process (PID=5643) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:59.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:39:59.329+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:39:59.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:39:59.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:00.618+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:00.617+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:40:00.958+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:00.945+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:40:01.404+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.165 seconds
[2022-12-16T17:40:12.173+0000] {processor.py:154} INFO - Started process (PID=5653) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:12.196+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:40:12.200+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:12.199+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:12.372+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:12.754+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:12.752+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:40:12.888+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:12.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:40:13.035+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.918 seconds
[2022-12-16T17:40:23.516+0000] {processor.py:154} INFO - Started process (PID=5663) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:23.554+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:40:23.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:23.558+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:23.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:23.839+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:23.838+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:40:23.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:23.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:40:24.112+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.615 seconds
[2022-12-16T17:40:34.788+0000] {processor.py:154} INFO - Started process (PID=5680) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:34.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:40:34.887+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:34.886+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:35.327+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:35.566+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:35.565+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:40:35.716+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:35.715+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:40:35.865+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.171 seconds
[2022-12-16T17:40:46.426+0000] {processor.py:154} INFO - Started process (PID=5691) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:46.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:40:46.479+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:46.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:46.601+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:48.183+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:40:59.144+0000] {processor.py:154} INFO - Started process (PID=5701) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:59.175+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:40:59.179+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:40:59.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:40:59.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:00.133+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:41:10.573+0000] {processor.py:154} INFO - Started process (PID=5711) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:10.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:41:10.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:10.592+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:10.676+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:10.808+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:10.807+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:41:10.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:10.919+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:41:11.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.489 seconds
[2022-12-16T17:41:21.232+0000] {processor.py:154} INFO - Started process (PID=5729) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:21.248+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:41:21.252+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:21.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:21.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:21.715+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:21.714+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:41:22.206+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:22.189+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:41:22.446+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.241 seconds
[2022-12-16T17:41:32.916+0000] {processor.py:154} INFO - Started process (PID=5739) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:32.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:41:32.942+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:32.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:33.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:33.156+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:33.155+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:41:33.272+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:33.271+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:41:33.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.486 seconds
[2022-12-16T17:41:43.685+0000] {processor.py:154} INFO - Started process (PID=5749) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:43.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:41:43.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:43.738+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:43.845+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:43.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:43.985+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:41:44.097+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:44.096+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:41:44.210+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.539 seconds
[2022-12-16T17:41:54.569+0000] {processor.py:154} INFO - Started process (PID=5759) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:54.590+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:41:54.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:54.592+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:54.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:41:54.836+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:54.835+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:41:54.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:41:54.956+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:41:55.106+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-16T17:42:05.658+0000] {processor.py:154} INFO - Started process (PID=5777) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:05.682+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:42:05.695+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:05.694+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:05.805+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:05.979+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:05.978+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:42:06.149+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:06.148+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:42:06.315+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.675 seconds
[2022-12-16T17:42:16.616+0000] {processor.py:154} INFO - Started process (PID=5787) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:16.674+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:42:16.686+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:16.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:16.769+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:17.920+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:17.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:42:18.037+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:18.036+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:42:18.174+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.574 seconds
[2022-12-16T17:42:28.456+0000] {processor.py:154} INFO - Started process (PID=5797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:28.485+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:42:28.490+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:28.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:28.571+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:29.188+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:29.187+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:42:29.307+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:29.307+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:42:29.428+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.986 seconds
[2022-12-16T17:42:39.733+0000] {processor.py:154} INFO - Started process (PID=5815) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:39.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:42:39.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:39.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:39.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:40.376+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:40.375+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:42:40.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:40.517+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:42:40.646+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.943 seconds
[2022-12-16T17:42:51.335+0000] {processor.py:154} INFO - Started process (PID=5825) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:51.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:42:51.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:42:51.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:51.502+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:42:52.016+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:43:02.334+0000] {processor.py:154} INFO - Started process (PID=5835) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:02.351+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:43:02.355+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:02.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:02.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:03.012+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:03.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:43:03.292+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:03.291+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:43:03.426+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.120 seconds
[2022-12-16T17:43:12.268+0000] {processor.py:154} INFO - Started process (PID=5850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:12.358+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:43:12.363+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:12.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:12.497+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:12.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:12.975+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:43:13.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:13.847+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:43:14.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.976 seconds
[2022-12-16T17:43:24.745+0000] {processor.py:154} INFO - Started process (PID=5868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:24.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:43:24.811+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:24.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:25.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:25.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:25.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:43:25.902+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:25.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:43:26.086+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.427 seconds
[2022-12-16T17:43:36.495+0000] {processor.py:154} INFO - Started process (PID=5878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:36.523+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:43:36.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:36.528+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:36.709+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:37.672+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:37.671+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:43:37.999+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:37.998+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:43:38.251+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.777 seconds
[2022-12-16T17:43:48.633+0000] {processor.py:154} INFO - Started process (PID=5888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:48.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:43:48.680+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:48.679+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:48.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:43:49.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:49.755+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:43:49.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:43:49.953+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:43:50.144+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.646 seconds
[2022-12-16T17:44:00.844+0000] {processor.py:154} INFO - Started process (PID=5908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:00.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:00.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:00.938+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:01.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:01.879+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:01.878+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:44:02.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:02.256+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:44:02.699+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.960 seconds
[2022-12-16T17:44:13.516+0000] {processor.py:154} INFO - Started process (PID=5916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:13.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:13.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:13.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:13.868+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:14.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:14.691+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:44:14.986+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:14.973+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:44:15.160+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.751 seconds
[2022-12-16T17:44:25.626+0000] {processor.py:154} INFO - Started process (PID=5929) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:25.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:25.686+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:25.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:25.982+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:26.294+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:26.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:44:26.474+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:26.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:44:26.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.089 seconds
[2022-12-16T17:44:36.971+0000] {processor.py:154} INFO - Started process (PID=5939) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:36.975+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:36.980+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:36.978+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:37.071+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:37.211+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:37.210+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:44:37.331+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:37.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:44:37.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.552 seconds
[2022-12-16T17:44:48.107+0000] {processor.py:154} INFO - Started process (PID=5953) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:48.177+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:48.196+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:48.194+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:48.301+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:48.505+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:48.504+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:44:48.763+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:48.762+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:44:49.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.170 seconds
[2022-12-16T17:44:59.841+0000] {processor.py:154} INFO - Started process (PID=5963) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:44:59.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:44:59.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:44:59.858+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:00.384+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:00.999+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:00.998+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:45:01.144+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:01.143+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:45:01.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.478 seconds
[2022-12-16T17:45:11.650+0000] {processor.py:154} INFO - Started process (PID=5973) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:11.666+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:45:11.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:11.669+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:11.896+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:12.262+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:12.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:45:12.428+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:12.427+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:45:12.547+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.923 seconds
[2022-12-16T17:45:23.119+0000] {processor.py:154} INFO - Started process (PID=5983) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:23.147+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:45:23.152+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:23.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:23.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:23.380+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:23.379+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:45:23.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:23.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:45:24.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.919 seconds
[2022-12-16T17:45:34.706+0000] {processor.py:154} INFO - Started process (PID=6001) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:34.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:45:34.742+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:34.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:35.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:36.216+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:36.215+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:45:37.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:37.424+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:45:37.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.203 seconds
[2022-12-16T17:45:48.373+0000] {processor.py:154} INFO - Started process (PID=6011) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:48.379+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:45:48.383+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:48.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:48.492+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:48.629+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:48.628+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:45:48.747+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:48.746+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:45:49.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.706 seconds
[2022-12-16T17:45:59.511+0000] {processor.py:154} INFO - Started process (PID=6021) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:59.532+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:45:59.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:59.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:59.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:45:59.980+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:45:59.979+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:00.185+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:00.184+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:00.393+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-16T17:46:11.039+0000] {processor.py:154} INFO - Started process (PID=6031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:11.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:46:11.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:11.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:11.168+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:11.830+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:11.828+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:11.976+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:11.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:12.136+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.115 seconds
[2022-12-16T17:46:22.805+0000] {processor.py:154} INFO - Started process (PID=6048) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:22.876+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:46:22.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:22.879+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:23.052+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:23.599+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:23.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:23.878+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:23.877+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:24.207+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.440 seconds
[2022-12-16T17:46:35.320+0000] {processor.py:154} INFO - Started process (PID=6058) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:35.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:46:35.334+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:35.333+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:35.462+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:35.600+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:35.599+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:35.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:35.710+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:35.858+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.571 seconds
[2022-12-16T17:46:46.036+0000] {processor.py:154} INFO - Started process (PID=6068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:46.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:46:46.061+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:46.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:46.144+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:46.711+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:46.710+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:46.832+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:46.832+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:47.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.999 seconds
[2022-12-16T17:46:57.362+0000] {processor.py:154} INFO - Started process (PID=6078) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:57.380+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:46:57.384+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:57.383+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:57.526+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:46:58.968+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:58.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:46:59.147+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:46:59.146+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:46:59.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.995 seconds
[2022-12-16T17:47:09.700+0000] {processor.py:154} INFO - Started process (PID=6095) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:09.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:47:09.742+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:09.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:09.969+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:10.915+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:10.914+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:47:11.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:11.119+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:47:11.371+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.714 seconds
[2022-12-16T17:47:22.014+0000] {processor.py:154} INFO - Started process (PID=6105) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:22.018+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:47:22.030+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:22.026+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:22.230+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:23.181+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:47:33.627+0000] {processor.py:154} INFO - Started process (PID=6115) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:33.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:47:33.685+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:33.684+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:33.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:33.987+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:33.985+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:47:34.150+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:34.149+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:47:34.311+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.702 seconds
[2022-12-16T17:47:44.803+0000] {processor.py:154} INFO - Started process (PID=6125) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:44.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:47:44.864+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:44.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:45.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:45.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:45.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:47:45.666+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:45.665+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:47:45.866+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.087 seconds
[2022-12-16T17:47:56.124+0000] {processor.py:154} INFO - Started process (PID=6144) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:56.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:47:56.173+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:47:56.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:56.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:47:57.087+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:48:07.403+0000] {processor.py:154} INFO - Started process (PID=6154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:07.454+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:48:07.458+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:07.457+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:07.559+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:08.589+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:48:18.879+0000] {processor.py:154} INFO - Started process (PID=6164) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:18.932+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:48:18.936+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:18.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:19.031+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:19.372+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:19.371+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:48:19.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:19.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:48:19.794+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.935 seconds
[2022-12-16T17:48:30.451+0000] {processor.py:154} INFO - Started process (PID=6181) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:30.478+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:48:30.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:30.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:30.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:30.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:30.871+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:48:31.039+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:31.037+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:48:31.298+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.905 seconds
[2022-12-16T17:48:41.886+0000] {processor.py:154} INFO - Started process (PID=6192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:41.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:48:41.923+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:41.921+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:42.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:42.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:42.535+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:48:42.992+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:42.991+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:48:43.249+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.416 seconds
[2022-12-16T17:48:53.707+0000] {processor.py:154} INFO - Started process (PID=6202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:53.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:48:53.717+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:53.716+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:53.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:48:54.047+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:54.046+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:48:54.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:48:54.196+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:48:54.593+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.903 seconds
[2022-12-16T17:49:05.194+0000] {processor.py:154} INFO - Started process (PID=6212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:05.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:49:05.230+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:05.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:05.366+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:05.569+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:05.565+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:49:05.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:05.707+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:49:05.860+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.715 seconds
[2022-12-16T17:49:16.451+0000] {processor.py:154} INFO - Started process (PID=6230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:16.471+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:49:16.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:16.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:16.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:17.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:17.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:49:17.823+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:17.822+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:49:18.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.735 seconds
[2022-12-16T17:49:28.703+0000] {processor.py:154} INFO - Started process (PID=6240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:28.726+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:49:28.730+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:28.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:28.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:29.048+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:29.047+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:49:29.189+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:29.188+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:49:29.323+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.634 seconds
[2022-12-16T17:49:39.721+0000] {processor.py:154} INFO - Started process (PID=6250) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:39.740+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:49:39.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:39.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:39.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:40.487+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:40.486+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:49:40.659+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:40.658+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:49:40.839+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.160 seconds
[2022-12-16T17:49:51.264+0000] {processor.py:154} INFO - Started process (PID=6260) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:51.286+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:49:51.291+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:51.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:51.444+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:49:52.020+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:52.019+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:49:52.432+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:49:52.431+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:49:52.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.365 seconds
[2022-12-16T17:50:03.179+0000] {processor.py:154} INFO - Started process (PID=6277) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:03.187+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:50:03.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:03.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:03.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:03.653+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:03.651+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:50:04.072+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:04.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:50:04.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.224 seconds
[2022-12-16T17:50:14.968+0000] {processor.py:154} INFO - Started process (PID=6287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:15.019+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:50:15.023+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:15.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:15.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:15.350+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:15.349+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:50:15.474+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:15.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:50:15.633+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-16T17:50:25.869+0000] {processor.py:154} INFO - Started process (PID=6297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:25.989+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:50:25.993+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:25.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:26.085+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:26.371+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:26.370+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:50:26.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:26.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:50:26.620+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-16T17:50:37.310+0000] {processor.py:154} INFO - Started process (PID=6307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:37.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:50:37.316+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:37.315+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:37.438+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:38.160+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:38.159+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:50:38.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:38.356+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:50:38.545+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.259 seconds
[2022-12-16T17:50:49.145+0000] {processor.py:154} INFO - Started process (PID=6325) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:49.168+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:50:49.172+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:49.171+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:49.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:50:49.628+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:49.627+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:50:49.917+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:50:49.916+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:50:50.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.073 seconds
[2022-12-16T17:51:00.708+0000] {processor.py:154} INFO - Started process (PID=6335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:00.736+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:00.748+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:00.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:00.899+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:01.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:01.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:51:01.339+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:01.338+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:51:01.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.828 seconds
[2022-12-16T17:51:11.971+0000] {processor.py:154} INFO - Started process (PID=6345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:11.975+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:11.987+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:11.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:12.145+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:12.358+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:12.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:51:12.654+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:12.653+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:51:12.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.963 seconds
[2022-12-16T17:51:23.307+0000] {processor.py:154} INFO - Started process (PID=6355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:23.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:23.340+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:23.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:23.431+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:23.668+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:23.667+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:51:23.843+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:23.842+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:51:24.028+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.736 seconds
[2022-12-16T17:51:34.500+0000] {processor.py:154} INFO - Started process (PID=6373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:34.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:34.550+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:34.549+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:34.780+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:36.364+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:51:47.000+0000] {processor.py:154} INFO - Started process (PID=6383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:47.051+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:47.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:47.059+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:47.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:47.577+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:47.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:51:47.882+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:47.877+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:51:48.228+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.260 seconds
[2022-12-16T17:51:58.879+0000] {processor.py:154} INFO - Started process (PID=6393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:58.907+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:51:58.911+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:58.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:59.047+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:51:59.299+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:59.298+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:51:59.478+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:51:59.477+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:51:59.602+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.807 seconds
[2022-12-16T17:52:10.761+0000] {processor.py:154} INFO - Started process (PID=6410) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:10.798+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:52:10.803+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:10.802+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:11.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:11.633+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:11.632+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:52:12.071+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:12.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:52:12.279+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.569 seconds
[2022-12-16T17:52:22.883+0000] {processor.py:154} INFO - Started process (PID=6421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:22.891+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:52:22.907+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:22.906+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:23.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:24.323+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:24.322+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:52:24.438+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:24.437+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:52:24.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.809 seconds
[2022-12-16T17:52:35.006+0000] {processor.py:154} INFO - Started process (PID=6431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:35.035+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:52:35.043+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:35.043+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:35.200+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:35.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:35.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:52:35.645+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:35.644+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:52:35.750+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.763 seconds
[2022-12-16T17:52:46.066+0000] {processor.py:154} INFO - Started process (PID=6441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:46.123+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:52:46.127+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:46.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:46.281+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:47.377+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:47.376+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:52:47.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:47.582+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:52:47.732+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.683 seconds
[2022-12-16T17:52:58.296+0000] {processor.py:154} INFO - Started process (PID=6458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:58.306+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:52:58.315+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:58.314+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:58.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:52:59.715+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:52:59.713+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:00.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:00.218+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:00.556+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.299 seconds
[2022-12-16T17:53:11.228+0000] {processor.py:154} INFO - Started process (PID=6468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:11.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:53:11.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:11.282+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:11.500+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:11.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:11.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:12.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:12.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:12.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.109 seconds
[2022-12-16T17:53:22.808+0000] {processor.py:154} INFO - Started process (PID=6478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:22.815+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:53:22.819+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:22.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:22.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:23.311+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:23.309+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:23.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:23.687+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:24.039+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.257 seconds
[2022-12-16T17:53:34.503+0000] {processor.py:154} INFO - Started process (PID=6488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:34.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:53:34.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:34.567+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:34.787+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:34.979+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:34.978+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:35.139+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:35.138+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:35.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.929 seconds
[2022-12-16T17:53:45.843+0000] {processor.py:154} INFO - Started process (PID=6505) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:45.856+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:53:45.862+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:45.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:46.103+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:46.785+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:46.784+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:47.051+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:47.050+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:47.215+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.408 seconds
[2022-12-16T17:53:57.730+0000] {processor.py:154} INFO - Started process (PID=6515) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:57.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:53:57.775+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:57.774+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:57.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:53:58.203+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:58.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:53:58.394+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:53:58.393+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:53:58.580+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.890 seconds
[2022-12-16T17:54:09.080+0000] {processor.py:154} INFO - Started process (PID=6525) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:09.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:54:09.131+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:09.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:09.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:09.575+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:09.574+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:54:09.723+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:09.721+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:54:09.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.914 seconds
[2022-12-16T17:54:20.409+0000] {processor.py:154} INFO - Started process (PID=6535) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:20.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:54:20.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:20.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:20.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:20.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:20.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:54:20.854+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:20.853+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:54:21.019+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-16T17:54:31.547+0000] {processor.py:154} INFO - Started process (PID=6552) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:31.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:54:31.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:31.600+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:31.771+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:32.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:32.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:54:32.747+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:32.746+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:54:32.951+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.418 seconds
[2022-12-16T17:54:43.392+0000] {processor.py:154} INFO - Started process (PID=6562) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:43.410+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:54:43.415+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:43.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:43.564+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:43.720+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:43.719+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:54:43.852+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:43.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:54:43.978+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.605 seconds
[2022-12-16T17:54:54.249+0000] {processor.py:154} INFO - Started process (PID=6572) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:54.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:54:54.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:54:54.256+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:54.343+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:54:55.007+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:55:05.440+0000] {processor.py:154} INFO - Started process (PID=6582) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:05.466+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:55:05.473+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:05.469+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:05.649+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:06.444+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:06.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:55:06.688+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:06.687+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:55:06.990+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.574 seconds
[2022-12-16T17:55:17.334+0000] {processor.py:154} INFO - Started process (PID=6600) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:17.355+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:55:17.360+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:17.359+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:17.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:19.114+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:19.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:55:19.245+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:19.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:55:19.393+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.085 seconds
[2022-12-16T17:55:29.955+0000] {processor.py:154} INFO - Started process (PID=6610) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:30.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:55:30.139+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:30.138+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:30.333+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:30.543+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:30.542+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:55:30.714+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:30.713+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:55:30.946+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.095 seconds
[2022-12-16T17:55:41.536+0000] {processor.py:154} INFO - Started process (PID=6620) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:41.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:55:41.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:41.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:41.851+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:42.619+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:42.618+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:55:43.264+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:43.263+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:55:43.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.346 seconds
[2022-12-16T17:55:54.410+0000] {processor.py:154} INFO - Started process (PID=6637) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:54.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:55:54.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:54.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:55.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:55:57.000+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:56.999+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:55:58.095+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:55:58.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:55:58.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 4.322 seconds
[2022-12-16T17:56:10.258+0000] {processor.py:154} INFO - Started process (PID=6648) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:10.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:56:10.344+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:10.343+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:11.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:11.684+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:11.683+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:56:12.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:12.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:56:12.711+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.659 seconds
[2022-12-16T17:56:23.395+0000] {processor.py:154} INFO - Started process (PID=6658) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:23.552+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:56:23.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:23.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:23.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:24.056+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:24.055+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:56:24.282+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:24.275+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:56:24.431+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.127 seconds
[2022-12-16T17:56:34.985+0000] {processor.py:154} INFO - Started process (PID=6668) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:35.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:56:35.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:35.094+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:35.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:35.953+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:35.952+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:56:36.209+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:36.209+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:56:36.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.439 seconds
[2022-12-16T17:56:46.836+0000] {processor.py:154} INFO - Started process (PID=6678) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:46.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:56:46.862+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:46.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:46.967+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:47.168+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:47.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:56:47.499+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:47.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:56:47.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.893 seconds
[2022-12-16T17:56:58.233+0000] {processor.py:154} INFO - Started process (PID=6696) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:58.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:56:58.287+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:56:58.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:58.407+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:56:59.900+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:57:10.917+0000] {processor.py:154} INFO - Started process (PID=6706) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:10.954+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:57:10.960+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:10.959+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:11.096+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:11.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:11.252+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:57:11.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:11.361+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:57:11.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-16T17:57:21.738+0000] {processor.py:154} INFO - Started process (PID=6716) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:21.769+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:57:21.776+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:21.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:21.856+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:21.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:21.995+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:57:22.119+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:22.118+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:57:22.521+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-16T17:57:32.944+0000] {processor.py:154} INFO - Started process (PID=6734) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:33.004+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:57:33.011+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:33.010+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:33.168+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:33.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:33.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:57:33.997+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:33.996+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:57:34.191+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.276 seconds
[2022-12-16T17:57:45.336+0000] {processor.py:154} INFO - Started process (PID=6744) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:45.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:57:45.361+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:45.360+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:45.443+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:45.571+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:45.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:57:45.683+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:45.682+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:57:45.882+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.562 seconds
[2022-12-16T17:57:56.162+0000] {processor.py:154} INFO - Started process (PID=6754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:56.171+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:57:56.176+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:56.175+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:56.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:57:56.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:56.420+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:57:56.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:57:56.596+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:57:56.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-16T17:58:07.108+0000] {processor.py:154} INFO - Started process (PID=6764) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:07.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:58:07.156+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:07.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:07.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:08.494+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:58:19.062+0000] {processor.py:154} INFO - Started process (PID=6781) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:19.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:58:19.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:19.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:19.183+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:19.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:19.334+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:58:19.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:19.558+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:58:19.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.635 seconds
[2022-12-16T17:58:30.362+0000] {processor.py:154} INFO - Started process (PID=6791) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:30.411+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:58:30.417+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:30.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:30.503+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:30.642+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:30.641+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:58:30.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:30.755+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:58:30.884+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.536 seconds
[2022-12-16T17:58:41.780+0000] {processor.py:154} INFO - Started process (PID=6801) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:41.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:58:41.828+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:41.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:41.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:42.573+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:42.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:58:42.686+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:42.685+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:58:42.805+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.039 seconds
[2022-12-16T17:58:53.088+0000] {processor.py:154} INFO - Started process (PID=6818) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:53.103+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:58:53.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:53.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:53.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:58:53.385+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:53.384+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:58:53.529+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:58:53.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:58:53.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.610 seconds
[2022-12-16T17:59:04.392+0000] {processor.py:154} INFO - Started process (PID=6828) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:04.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:04.442+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:04.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:04.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:04.654+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:04.653+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:59:04.762+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:04.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:59:04.890+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.511 seconds
[2022-12-16T17:59:15.155+0000] {processor.py:154} INFO - Started process (PID=6838) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:15.175+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:15.179+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:15.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:15.275+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:15.443+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:15.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:59:15.648+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:15.645+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:59:15.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.613 seconds
[2022-12-16T17:59:26.080+0000] {processor.py:154} INFO - Started process (PID=6848) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:26.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:26.105+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:26.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:26.198+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:26.360+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:26.358+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:59:26.541+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:26.540+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:59:26.674+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.610 seconds
[2022-12-16T17:59:37.123+0000] {processor.py:154} INFO - Started process (PID=6866) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:37.159+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:37.170+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:37.169+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:37.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:37.856+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T17:59:48.440+0000] {processor.py:154} INFO - Started process (PID=6876) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:48.472+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:48.476+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:48.475+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:48.567+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:48.712+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:48.711+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T17:59:48.844+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:48.843+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T17:59:48.966+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.542 seconds
[2022-12-16T17:59:59.431+0000] {processor.py:154} INFO - Started process (PID=6886) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:59.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T17:59:59.492+0000] {logging_mixin.py:137} INFO - [2022-12-16T17:59:59.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T17:59:59.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:00.343+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:00.342+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:00.458+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:00.457+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:00.801+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.426 seconds
[2022-12-16T18:00:11.251+0000] {processor.py:154} INFO - Started process (PID=6903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:11.303+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:00:11.308+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:11.307+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:11.417+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:11.922+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:11.921+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:12.100+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:12.099+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:12.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.024 seconds
[2022-12-16T18:00:22.920+0000] {processor.py:154} INFO - Started process (PID=6914) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:22.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:00:22.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:22.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:23.160+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:23.883+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:23.882+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:24.021+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:24.020+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:24.181+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.280 seconds
[2022-12-16T18:00:34.515+0000] {processor.py:154} INFO - Started process (PID=6924) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:34.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:00:34.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:34.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:34.674+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:35.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:35.707+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:35.837+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:35.836+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:35.970+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.474 seconds
[2022-12-16T18:00:46.225+0000] {processor.py:154} INFO - Started process (PID=6934) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:46.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:00:46.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:46.257+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:46.341+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:46.473+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:46.472+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:46.584+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:46.584+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:46.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T18:00:57.692+0000] {processor.py:154} INFO - Started process (PID=6952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:57.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:00:57.744+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:57.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:58.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:00:58.208+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:58.207+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:00:58.386+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:00:58.386+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:00:58.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.897 seconds
[2022-12-16T18:01:09.163+0000] {processor.py:154} INFO - Started process (PID=6962) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:09.198+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:01:09.204+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:09.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:09.418+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:09.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:09.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:01:09.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:09.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:01:09.810+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.715 seconds
[2022-12-16T18:01:20.092+0000] {processor.py:154} INFO - Started process (PID=6972) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:20.141+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:01:20.146+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:20.144+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:20.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:20.428+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:20.416+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:01:20.815+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:20.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:01:20.939+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.862 seconds
[2022-12-16T18:01:31.640+0000] {processor.py:154} INFO - Started process (PID=6988) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:31.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:01:31.666+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:31.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:31.771+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:32.104+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:32.103+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:01:32.629+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:32.628+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:01:33.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.407 seconds
[2022-12-16T18:01:43.279+0000] {processor.py:154} INFO - Started process (PID=6999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:43.299+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:01:43.304+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:43.303+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:43.405+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:43.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:43.558+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:01:43.683+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:43.682+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:01:43.906+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.641 seconds
[2022-12-16T18:01:54.214+0000] {processor.py:154} INFO - Started process (PID=7009) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:54.258+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:01:54.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:54.265+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:54.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:01:54.809+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:54.808+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:01:54.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:01:54.920+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:01:55.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.831 seconds
[2022-12-16T18:02:05.478+0000] {processor.py:154} INFO - Started process (PID=7019) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:05.506+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:02:05.511+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:05.509+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:05.593+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:05.786+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:05.786+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:02:05.915+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:05.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:02:06.057+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.593 seconds
[2022-12-16T18:02:16.513+0000] {processor.py:154} INFO - Started process (PID=7036) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:16.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:02:16.538+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:16.533+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:16.713+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:16.868+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:16.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:02:16.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:16.983+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:02:17.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.721 seconds
[2022-12-16T18:02:27.484+0000] {processor.py:154} INFO - Started process (PID=7046) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:27.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:02:27.536+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:27.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:27.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:28.682+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:02:38.977+0000] {processor.py:154} INFO - Started process (PID=7056) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:39.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:02:39.028+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:39.027+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:39.112+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:39.800+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:02:50.141+0000] {processor.py:154} INFO - Started process (PID=7066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:50.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:02:50.198+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:50.197+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:50.290+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:02:50.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:50.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:02:50.537+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:02:50.536+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:02:50.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.562 seconds
[2022-12-16T18:03:01.081+0000] {processor.py:154} INFO - Started process (PID=7084) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:01.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:01.138+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:01.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:01.324+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:01.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:01.674+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:03:02.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:02.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:03:02.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.343 seconds
[2022-12-16T18:03:12.795+0000] {processor.py:154} INFO - Started process (PID=7094) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:12.830+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:12.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:12.837+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:13.068+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:13.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:13.227+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:03:13.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:13.392+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:03:13.560+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.803 seconds
[2022-12-16T18:03:23.970+0000] {processor.py:154} INFO - Started process (PID=7104) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:23.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:24.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:24.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:24.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:24.932+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:24.931+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:03:25.049+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:25.048+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:03:25.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.210 seconds
[2022-12-16T18:03:35.633+0000] {processor.py:154} INFO - Started process (PID=7121) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:35.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:35.724+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:35.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:35.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:36.822+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:03:47.512+0000] {processor.py:154} INFO - Started process (PID=7132) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:47.555+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:47.562+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:47.561+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:47.769+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:48.427+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:48.426+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:03:48.610+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:48.609+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:03:48.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-16T18:03:59.144+0000] {processor.py:154} INFO - Started process (PID=7142) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:59.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:03:59.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:03:59.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:03:59.329+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:00.814+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:00.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:04:00.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:00.970+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:04:01.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.116 seconds
[2022-12-16T18:04:11.827+0000] {processor.py:154} INFO - Started process (PID=7152) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:11.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:04:11.942+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:11.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:12.134+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:12.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:12.739+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:04:13.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:13.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:04:13.193+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.385 seconds
[2022-12-16T18:04:23.774+0000] {processor.py:154} INFO - Started process (PID=7170) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:23.819+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:04:23.849+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:23.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:24.231+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:25.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:25.026+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:04:25.328+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:25.327+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:04:25.567+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.964 seconds
[2022-12-16T18:04:36.152+0000] {processor.py:154} INFO - Started process (PID=7180) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:36.239+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:04:36.244+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:36.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:36.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:37.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:37.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:04:37.638+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:37.637+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:04:37.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.641 seconds
[2022-12-16T18:04:48.092+0000] {processor.py:154} INFO - Started process (PID=7190) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:48.139+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:04:48.145+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:48.144+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:48.233+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:48.373+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:48.372+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:04:48.486+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:48.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:04:48.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.598 seconds
[2022-12-16T18:04:58.957+0000] {processor.py:154} INFO - Started process (PID=7200) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:58.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:04:58.991+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:04:58.990+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:04:59.080+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:00.223+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:00.222+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:05:00.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:00.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:05:00.447+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-16T18:05:10.762+0000] {processor.py:154} INFO - Started process (PID=7219) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:10.771+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:05:10.784+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:10.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:11.045+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:11.936+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:11.932+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:05:12.254+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:12.253+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:05:12.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.909 seconds
[2022-12-16T18:05:22.970+0000] {processor.py:154} INFO - Started process (PID=7229) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:22.977+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:05:22.983+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:22.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:23.112+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:23.283+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:23.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:05:23.434+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:23.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:05:23.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.636 seconds
[2022-12-16T18:05:33.913+0000] {processor.py:154} INFO - Started process (PID=7239) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:33.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:05:33.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:33.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:34.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:34.500+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:34.499+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:05:34.773+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:34.772+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:05:35.184+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.291 seconds
[2022-12-16T18:05:46.311+0000] {processor.py:154} INFO - Started process (PID=7249) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:46.338+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:05:46.345+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:46.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:46.665+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:47.910+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:47.908+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:05:48.184+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:48.183+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:05:48.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.071 seconds
[2022-12-16T18:05:59.122+0000] {processor.py:154} INFO - Started process (PID=7268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:59.124+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:05:59.133+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:05:59.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:05:59.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:00.312+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:00.311+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:06:00.649+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:00.648+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:06:01.046+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.014 seconds
[2022-12-16T18:06:11.379+0000] {processor.py:154} INFO - Started process (PID=7278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:11.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:06:11.418+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:11.413+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:11.661+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:12.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:12.002+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:06:12.359+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:12.358+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:06:12.751+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.413 seconds
[2022-12-16T18:06:23.253+0000] {processor.py:154} INFO - Started process (PID=7288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:23.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:06:23.276+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:23.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:23.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:24.589+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:06:35.223+0000] {processor.py:154} INFO - Started process (PID=7306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:35.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:06:35.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:35.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:35.511+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:35.708+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:35.707+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:06:36.193+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:36.192+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:06:36.751+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.558 seconds
[2022-12-16T18:06:47.734+0000] {processor.py:154} INFO - Started process (PID=7316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:47.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:06:47.793+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:47.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:48.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:06:50.040+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:50.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:06:50.291+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:06:50.289+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:06:50.567+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.886 seconds
[2022-12-16T18:07:01.291+0000] {processor.py:154} INFO - Started process (PID=7326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:01.317+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:07:01.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:01.323+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:01.537+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:01.961+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:01.960+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:07:02.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:02.287+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:07:02.522+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.276 seconds
[2022-12-16T18:07:12.805+0000] {processor.py:154} INFO - Started process (PID=7336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:12.830+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:07:12.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:12.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:12.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:13.169+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:13.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:07:13.463+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:13.459+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:07:13.732+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-16T18:07:24.348+0000] {processor.py:154} INFO - Started process (PID=7353) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:24.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:07:24.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:24.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:25.325+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:26.325+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:26.324+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:07:26.861+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:26.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:07:27.299+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.998 seconds
[2022-12-16T18:07:37.826+0000] {processor.py:154} INFO - Started process (PID=7363) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:37.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:07:37.857+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:37.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:38.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:38.296+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:38.295+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:07:38.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:38.582+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:07:38.923+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.129 seconds
[2022-12-16T18:07:49.371+0000] {processor.py:154} INFO - Started process (PID=7373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:49.403+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:07:49.407+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:49.406+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:49.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:07:50.512+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:50.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:07:50.874+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:07:50.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:07:51.247+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.897 seconds
[2022-12-16T18:08:01.887+0000] {processor.py:154} INFO - Started process (PID=7383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:01.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:08:01.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:01.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:02.267+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:03.700+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:03.680+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:08:04.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:04.115+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:08:04.551+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.742 seconds
[2022-12-16T18:08:15.688+0000] {processor.py:154} INFO - Started process (PID=7401) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:15.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:08:15.776+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:15.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:16.140+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:17.164+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:17.163+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:08:17.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:17.675+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:08:18.075+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.415 seconds
[2022-12-16T18:08:28.381+0000] {processor.py:154} INFO - Started process (PID=7411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:28.436+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:08:28.441+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:28.439+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:28.560+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:29.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:29.575+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:08:29.697+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:29.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:08:29.826+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.466 seconds
[2022-12-16T18:08:40.112+0000] {processor.py:154} INFO - Started process (PID=7424) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:40.117+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:08:40.121+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:40.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:40.228+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:40.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:40.839+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:08:40.954+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:40.953+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:08:41.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.990 seconds
[2022-12-16T18:08:51.335+0000] {processor.py:154} INFO - Started process (PID=7431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:51.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:08:51.363+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:51.362+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:51.556+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:08:51.871+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:51.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:08:52.069+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:08:52.068+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:08:52.249+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.932 seconds
[2022-12-16T18:09:02.880+0000] {processor.py:154} INFO - Started process (PID=7449) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:02.883+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:09:02.894+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:02.887+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:03.197+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:04.086+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:09:14.652+0000] {processor.py:154} INFO - Started process (PID=7459) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:14.672+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:09:14.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:14.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:14.788+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:15.330+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:15.328+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:09:15.513+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:15.512+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:09:15.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.141 seconds
[2022-12-16T18:09:26.153+0000] {processor.py:154} INFO - Started process (PID=7469) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:26.163+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:09:26.167+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:26.166+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:26.288+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:26.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:26.484+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:09:26.594+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:26.593+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:09:26.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.578 seconds
[2022-12-16T18:09:37.167+0000] {processor.py:154} INFO - Started process (PID=7486) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:37.243+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:09:37.256+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:37.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:37.480+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:37.729+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:37.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:09:37.927+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:37.926+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:09:38.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.111 seconds
[2022-12-16T18:09:48.879+0000] {processor.py:154} INFO - Started process (PID=7497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:48.889+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:09:48.908+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:48.907+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:49.151+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:09:49.578+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:49.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:09:50.073+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:09:50.072+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:09:50.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.765 seconds
[2022-12-16T18:10:01.505+0000] {processor.py:154} INFO - Started process (PID=7507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:01.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:10:01.559+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:01.558+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:01.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:01.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:01.997+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:10:02.205+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:02.204+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:10:02.419+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.932 seconds
[2022-12-16T18:10:12.793+0000] {processor.py:154} INFO - Started process (PID=7517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:12.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:10:12.825+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:12.823+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:12.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:13.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:13.587+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:10:13.726+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:13.725+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:10:13.855+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.077 seconds
[2022-12-16T18:10:24.210+0000] {processor.py:154} INFO - Started process (PID=7535) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:24.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:10:24.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:24.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:24.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:26.147+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:10:37.073+0000] {processor.py:154} INFO - Started process (PID=7545) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:37.077+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:10:37.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:37.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:37.175+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:37.859+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:37.858+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:10:37.989+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:37.988+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:10:38.176+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.122 seconds
[2022-12-16T18:10:48.514+0000] {processor.py:154} INFO - Started process (PID=7555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:48.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:10:48.549+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:48.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:48.642+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:10:49.333+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:49.332+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:10:49.539+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:10:49.538+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:10:49.814+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.314 seconds
[2022-12-16T18:11:00.155+0000] {processor.py:154} INFO - Started process (PID=7565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:00.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:00.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:00.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:00.280+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:00.880+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:00.879+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:11:01.001+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:01.000+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:11:01.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.071 seconds
[2022-12-16T18:11:11.796+0000] {processor.py:154} INFO - Started process (PID=7583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:11.838+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:11.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:11.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:12.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:12.300+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:12.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:11:12.493+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:12.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:11:12.752+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.977 seconds
[2022-12-16T18:11:23.192+0000] {processor.py:154} INFO - Started process (PID=7593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:23.251+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:23.256+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:23.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:23.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:23.506+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:23.505+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:11:23.642+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:23.641+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:11:23.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.605 seconds
[2022-12-16T18:11:34.081+0000] {processor.py:154} INFO - Started process (PID=7603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:34.114+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:34.122+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:34.117+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:34.214+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:35.507+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:35.506+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:11:35.662+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:35.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:11:35.803+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.737 seconds
[2022-12-16T18:11:46.102+0000] {processor.py:154} INFO - Started process (PID=7613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:46.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:46.327+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:46.326+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:46.502+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:47.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:47.319+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:11:47.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:47.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:11:48.010+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.976 seconds
[2022-12-16T18:11:59.243+0000] {processor.py:154} INFO - Started process (PID=7634) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:59.270+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:11:59.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:59.279+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:59.612+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:11:59.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:11:59.908+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:00.183+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:00.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:00.443+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.470 seconds
[2022-12-16T18:12:11.032+0000] {processor.py:154} INFO - Started process (PID=7644) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:11.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:12:11.069+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:11.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:11.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:12.454+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:12.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:12.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:12.587+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:12.773+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.777 seconds
[2022-12-16T18:12:23.159+0000] {processor.py:154} INFO - Started process (PID=7654) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:23.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:12:23.196+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:23.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:23.474+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:24.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:24.069+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:24.186+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:24.185+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:24.331+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.188 seconds
[2022-12-16T18:12:34.790+0000] {processor.py:154} INFO - Started process (PID=7674) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:34.843+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:12:34.869+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:34.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:35.170+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:35.407+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:35.402+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:35.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:35.605+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:35.830+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.077 seconds
[2022-12-16T18:12:46.327+0000] {processor.py:154} INFO - Started process (PID=7684) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:46.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:12:46.337+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:46.336+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:46.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:47.125+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:47.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:47.395+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:47.394+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:47.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.287 seconds
[2022-12-16T18:12:58.105+0000] {processor.py:154} INFO - Started process (PID=7694) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:58.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:12:58.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:58.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:58.275+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:12:59.397+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:59.396+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:12:59.524+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:12:59.523+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:12:59.990+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.915 seconds
[2022-12-16T18:13:10.392+0000] {processor.py:154} INFO - Started process (PID=7704) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:10.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:13:10.419+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:10.418+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:10.511+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:11.179+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:11.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:13:11.324+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:11.323+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:13:11.494+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.117 seconds
[2022-12-16T18:13:14.511+0000] {processor.py:154} INFO - Started process (PID=7721) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:14.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:13:14.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:14.527+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:14.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:15.195+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:15.186+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:13:15.534+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:15.533+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:13:15.815+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.362 seconds
[2022-12-16T18:13:26.188+0000] {processor.py:154} INFO - Started process (PID=7732) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:26.231+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:13:26.235+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:26.234+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:26.322+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:26.991+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:26.990+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:13:27.200+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:27.199+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:13:27.323+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.162 seconds
[2022-12-16T18:13:37.594+0000] {processor.py:154} INFO - Started process (PID=7742) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:37.619+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:13:37.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:37.631+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:37.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:38.687+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:13:48.969+0000] {processor.py:154} INFO - Started process (PID=7752) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:49.024+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:13:49.032+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:49.031+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:49.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:13:50.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:50.573+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:13:50.788+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:13:50.787+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:13:50.995+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.065 seconds
[2022-12-16T18:14:01.717+0000] {processor.py:154} INFO - Started process (PID=7773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:01.747+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:14:01.754+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:01.753+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:02.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:03.734+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:14:14.648+0000] {processor.py:154} INFO - Started process (PID=7783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:14.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:14:14.661+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:14.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:14.916+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:15.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:15.515+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:14:15.764+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:15.763+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:14:15.941+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.310 seconds
[2022-12-16T18:14:26.244+0000] {processor.py:154} INFO - Started process (PID=7793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:26.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:14:26.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:26.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:26.504+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:26.692+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:26.691+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:14:26.842+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:26.839+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:14:27.049+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.842 seconds
[2022-12-16T18:14:37.451+0000] {processor.py:154} INFO - Started process (PID=7803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:37.483+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:14:37.488+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:37.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:37.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:37.863+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:37.862+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:14:37.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:37.998+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:14:38.115+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.702 seconds
[2022-12-16T18:14:48.957+0000] {processor.py:154} INFO - Started process (PID=7820) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:48.990+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:14:49.026+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:48.993+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:49.334+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:14:49.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:49.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:14:49.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:14:49.956+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:14:50.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.624 seconds
[2022-12-16T18:15:01.281+0000] {processor.py:154} INFO - Started process (PID=7827) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:01.342+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:01.355+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:01.349+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:01.531+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:01.966+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:01.965+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:15:02.117+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:02.116+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:15:02.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.049 seconds
[2022-12-16T18:15:12.571+0000] {processor.py:154} INFO - Started process (PID=7840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:12.596+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:12.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:12.600+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:12.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:12.886+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:12.885+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:15:13.021+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:13.020+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:15:13.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.705 seconds
[2022-12-16T18:15:23.804+0000] {processor.py:154} INFO - Started process (PID=7850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:23.815+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:23.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:23.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:24.171+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:25.545+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:25.544+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:15:25.666+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:25.666+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:15:25.823+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.071 seconds
[2022-12-16T18:15:36.673+0000] {processor.py:154} INFO - Started process (PID=7869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:36.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:36.713+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:36.712+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:36.964+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:37.594+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:37.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:15:37.873+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:37.872+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:15:38.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.532 seconds
[2022-12-16T18:15:48.507+0000] {processor.py:154} INFO - Started process (PID=7879) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:48.539+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:48.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:48.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:48.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:48.874+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:48.873+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:15:49.058+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:49.057+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:15:49.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.755 seconds
[2022-12-16T18:15:59.658+0000] {processor.py:154} INFO - Started process (PID=7889) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:59.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:15:59.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:15:59.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:15:59.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:00.093+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:00.083+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:16:00.347+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:00.347+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:16:00.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.820 seconds
[2022-12-16T18:16:10.926+0000] {processor.py:154} INFO - Started process (PID=7899) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:10.946+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:16:10.955+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:10.952+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:11.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:12.566+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:12.551+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:16:13.253+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:13.251+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:16:13.591+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.706 seconds
[2022-12-16T18:16:23.879+0000] {processor.py:154} INFO - Started process (PID=7917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:23.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:16:23.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:23.920+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:24.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:24.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:24.389+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:16:24.534+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:24.533+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:16:24.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.882 seconds
[2022-12-16T18:16:35.243+0000] {processor.py:154} INFO - Started process (PID=7927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:35.275+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:16:35.281+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:35.280+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:35.546+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:35.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:35.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:16:35.951+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:35.950+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:16:36.086+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.873 seconds
[2022-12-16T18:16:46.644+0000] {processor.py:154} INFO - Started process (PID=7937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:46.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:16:46.709+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:46.708+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:47.301+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:48.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:48.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:16:48.730+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:48.729+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:16:48.932+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.363 seconds
[2022-12-16T18:16:59.545+0000] {processor.py:154} INFO - Started process (PID=7956) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:16:59.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:16:59.568+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:16:59.567+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:00.195+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:01.816+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:01.808+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:17:02.181+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:02.180+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:17:02.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.972 seconds
[2022-12-16T18:17:13.232+0000] {processor.py:154} INFO - Started process (PID=7966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:13.236+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:17:13.249+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:13.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:13.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:15.020+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:17:25.300+0000] {processor.py:154} INFO - Started process (PID=7976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:25.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:17:25.357+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:25.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:25.450+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:25.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:25.675+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:17:25.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:25.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:17:25.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-16T18:17:36.409+0000] {processor.py:154} INFO - Started process (PID=7986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:36.433+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:17:36.437+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:36.436+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:36.586+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:37.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:37.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:17:37.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:37.429+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:17:37.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.266 seconds
[2022-12-16T18:17:48.366+0000] {processor.py:154} INFO - Started process (PID=8003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:48.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:17:48.426+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:48.425+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:48.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:17:49.541+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:49.540+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:17:50.002+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:17:49.996+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:17:50.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.169 seconds
[2022-12-16T18:18:01.332+0000] {processor.py:154} INFO - Started process (PID=8014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:01.340+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:18:01.350+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:01.349+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:01.622+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:03.078+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:03.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:18:03.308+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:03.307+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:18:03.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.338 seconds
[2022-12-16T18:18:14.638+0000] {processor.py:154} INFO - Started process (PID=8024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:14.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:18:14.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:14.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:14.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:14.939+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:14.938+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:18:15.116+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:15.115+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:18:15.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.745 seconds
[2022-12-16T18:18:26.162+0000] {processor.py:154} INFO - Started process (PID=8034) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:26.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:18:26.218+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:26.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:26.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:26.450+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:26.449+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:18:26.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:26.579+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:18:26.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.574 seconds
[2022-12-16T18:18:37.692+0000] {processor.py:154} INFO - Started process (PID=8051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:37.747+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:18:37.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:37.755+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:37.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:38.612+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:38.611+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:18:38.975+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:38.972+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:18:39.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.601 seconds
[2022-12-16T18:18:49.765+0000] {processor.py:154} INFO - Started process (PID=8061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:49.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:18:49.799+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:18:49.798+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:49.917+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:18:50.889+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:19:01.349+0000] {processor.py:154} INFO - Started process (PID=8071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:01.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:19:01.359+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:01.358+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:01.462+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:01.672+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:01.671+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:19:01.847+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:01.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:19:02.105+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.773 seconds
[2022-12-16T18:19:12.364+0000] {processor.py:154} INFO - Started process (PID=8081) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:12.367+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:19:12.371+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:12.370+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:12.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:13.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:13.053+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:19:13.310+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:13.309+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:19:13.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.139 seconds
[2022-12-16T18:19:24.023+0000] {processor.py:154} INFO - Started process (PID=8099) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:24.051+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:19:24.055+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:24.054+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:24.280+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:26.369+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:19:37.380+0000] {processor.py:154} INFO - Started process (PID=8109) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:37.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:19:37.406+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:37.404+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:37.709+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:38.869+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:19:49.214+0000] {processor.py:154} INFO - Started process (PID=8119) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:49.234+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:19:49.247+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:49.246+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:49.439+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:19:49.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:49.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:19:49.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:19:49.930+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:19:50.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.885 seconds
[2022-12-16T18:20:00.289+0000] {processor.py:154} INFO - Started process (PID=8129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:00.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:00.345+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:00.341+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:00.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:01.027+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:01.026+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:01.296+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:01.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:20:01.647+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.374 seconds
[2022-12-16T18:20:12.548+0000] {processor.py:154} INFO - Started process (PID=8147) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:12.582+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:12.606+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:12.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:13.048+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:13.605+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:13.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:14.528+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:14.527+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:20:14.927+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.456 seconds
[2022-12-16T18:20:25.243+0000] {processor.py:154} INFO - Started process (PID=8157) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:25.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:25.252+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:25.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:25.340+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:25.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:25.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:25.610+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:25.609+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:20:25.775+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.545 seconds
[2022-12-16T18:20:36.037+0000] {processor.py:154} INFO - Started process (PID=8167) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:36.090+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:36.094+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:36.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:36.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:36.349+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:36.348+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:36.491+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:36.490+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:20:36.615+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-16T18:20:46.917+0000] {processor.py:154} INFO - Started process (PID=8177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:46.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:46.964+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:46.963+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:47.103+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:47.738+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:47.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:47.905+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:47.904+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:20:48.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.124 seconds
[2022-12-16T18:20:58.629+0000] {processor.py:154} INFO - Started process (PID=8196) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:58.662+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:20:58.671+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:58.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:58.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:20:59.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:59.579+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:20:59.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:20:59.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:00.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.709 seconds
[2022-12-16T18:21:10.928+0000] {processor.py:154} INFO - Started process (PID=8206) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:10.952+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:21:10.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:10.956+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:11.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:12.047+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:12.046+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:21:12.291+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:12.290+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:12.467+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.585 seconds
[2022-12-16T18:21:22.815+0000] {processor.py:154} INFO - Started process (PID=8216) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:22.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:21:22.833+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:22.832+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:23.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:23.257+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:23.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:21:23.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:23.423+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:23.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.829 seconds
[2022-12-16T18:21:34.620+0000] {processor.py:154} INFO - Started process (PID=8226) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:34.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:21:34.653+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:34.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:34.749+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:35.069+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:35.068+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:21:35.186+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:35.185+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:35.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.686 seconds
[2022-12-16T18:21:45.668+0000] {processor.py:154} INFO - Started process (PID=8244) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:45.672+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:21:45.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:45.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:45.790+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:46.400+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:46.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:21:46.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:46.754+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:46.977+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.341 seconds
[2022-12-16T18:21:57.556+0000] {processor.py:154} INFO - Started process (PID=8254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:57.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:21:57.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:57.587+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:57.681+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:21:58.031+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:58.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:21:58.151+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:21:58.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:21:58.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.808 seconds
[2022-12-16T18:22:08.645+0000] {processor.py:154} INFO - Started process (PID=8264) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:08.699+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:22:08.703+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:08.702+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:08.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:09.075+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:09.074+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:22:09.251+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:09.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:22:09.594+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.966 seconds
[2022-12-16T18:22:20.164+0000] {processor.py:154} INFO - Started process (PID=8272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:20.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:22:20.204+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:20.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:20.572+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:21.378+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:21.369+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:22:21.669+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:21.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:22:21.970+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.847 seconds
[2022-12-16T18:22:33.027+0000] {processor.py:154} INFO - Started process (PID=8290) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:33.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:22:33.127+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:33.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:33.478+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:34.054+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:34.051+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:22:34.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:34.254+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:22:34.570+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.806 seconds
[2022-12-16T18:22:45.048+0000] {processor.py:154} INFO - Started process (PID=8302) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:45.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:22:45.061+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:45.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:45.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:45.995+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:45.994+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:22:46.220+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:46.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:22:46.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.679 seconds
[2022-12-16T18:22:57.346+0000] {processor.py:154} INFO - Started process (PID=8312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:57.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:22:57.364+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:22:57.363+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:57.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:22:58.408+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:23:08.796+0000] {processor.py:154} INFO - Started process (PID=8322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:08.836+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:23:08.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:08.839+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:08.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:09.804+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:09.803+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:23:10.103+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:10.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:23:10.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.573 seconds
[2022-12-16T18:23:20.951+0000] {processor.py:154} INFO - Started process (PID=8340) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:20.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:23:20.987+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:20.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:21.089+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:21.302+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:21.300+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:23:21.433+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:21.432+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:23:21.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-16T18:23:32.337+0000] {processor.py:154} INFO - Started process (PID=8348) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:32.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:23:32.420+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:32.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:32.838+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:33.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:33.515+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:23:33.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:33.852+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:23:34.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.002 seconds
[2022-12-16T18:23:44.707+0000] {processor.py:154} INFO - Started process (PID=8360) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:44.711+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:23:44.715+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:44.714+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:44.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:44.972+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:44.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:23:45.108+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:45.107+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:23:45.386+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.707 seconds
[2022-12-16T18:23:56.476+0000] {processor.py:154} INFO - Started process (PID=8375) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:56.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:23:56.632+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:56.631+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:56.974+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:23:58.008+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:58.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:23:58.790+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:23:58.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:23:58.991+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.681 seconds
[2022-12-16T18:24:09.584+0000] {processor.py:154} INFO - Started process (PID=8387) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:09.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:24:09.621+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:09.620+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:09.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:11.139+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:11.138+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:24:11.273+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:11.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:24:11.413+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.854 seconds
[2022-12-16T18:24:21.661+0000] {processor.py:154} INFO - Started process (PID=8397) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:21.716+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:24:21.721+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:21.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:21.823+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:21.985+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:21.984+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:24:22.192+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:22.185+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:24:22.458+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.835 seconds
[2022-12-16T18:24:32.844+0000] {processor.py:154} INFO - Started process (PID=8407) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:32.898+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:24:32.902+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:32.901+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:33.003+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:33.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:33.170+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:24:33.341+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:33.340+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:24:33.507+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-16T18:24:44.139+0000] {processor.py:154} INFO - Started process (PID=8426) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:44.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:24:44.171+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:44.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:44.331+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:44.580+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:44.579+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:24:44.845+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:44.844+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:24:45.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.972 seconds
[2022-12-16T18:24:55.564+0000] {processor.py:154} INFO - Started process (PID=8436) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:55.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:24:55.579+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:55.578+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:55.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:24:55.944+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:55.943+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:24:56.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:24:56.069+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:24:56.180+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.652 seconds
[2022-12-16T18:25:06.470+0000] {processor.py:154} INFO - Started process (PID=8444) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:06.524+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:25:06.532+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:06.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:06.782+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:07.453+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:25:17.771+0000] {processor.py:154} INFO - Started process (PID=8451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:17.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:25:17.834+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:17.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:18.060+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:20.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:20.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:25:20.948+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:20.947+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:25:21.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.474 seconds
[2022-12-16T18:25:31.925+0000] {processor.py:154} INFO - Started process (PID=8472) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:31.929+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:25:31.958+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:31.944+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:32.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:33.577+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:25:44.025+0000] {processor.py:154} INFO - Started process (PID=8479) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:44.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:25:44.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:44.035+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:44.121+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:44.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:44.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:25:44.368+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:44.367+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:25:44.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.511 seconds
[2022-12-16T18:25:54.694+0000] {processor.py:154} INFO - Started process (PID=8489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:54.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:25:54.701+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:54.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:54.792+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:25:55.020+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:55.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:25:55.205+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:25:55.204+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:25:55.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.751 seconds
[2022-12-16T18:26:05.593+0000] {processor.py:154} INFO - Started process (PID=8499) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:05.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:26:05.602+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:05.600+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:05.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:06.120+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:06.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:26:06.540+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:06.539+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:26:07.302+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.723 seconds
[2022-12-16T18:26:17.977+0000] {processor.py:154} INFO - Started process (PID=8517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:17.998+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:26:18.003+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:18.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:18.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:19.278+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:26:29.562+0000] {processor.py:154} INFO - Started process (PID=8527) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:29.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:26:29.589+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:29.588+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:29.696+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:29.879+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:29.878+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:26:30.018+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:30.018+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:26:30.141+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-16T18:26:41.061+0000] {processor.py:154} INFO - Started process (PID=8537) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:41.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:26:41.080+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:41.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:41.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:41.484+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:41.483+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:26:41.734+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:41.733+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:26:42.001+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.979 seconds
[2022-12-16T18:26:52.746+0000] {processor.py:154} INFO - Started process (PID=8555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:52.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:26:52.772+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:52.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:53.056+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:26:53.521+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:53.520+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:26:53.687+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:26:53.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:26:53.911+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.202 seconds
[2022-12-16T18:27:04.660+0000] {processor.py:154} INFO - Started process (PID=8565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:04.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:27:04.674+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:04.673+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:04.825+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:05.118+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:05.116+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:27:05.318+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:05.317+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:27:05.580+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.937 seconds
[2022-12-16T18:27:16.038+0000] {processor.py:154} INFO - Started process (PID=8575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:16.042+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:27:16.046+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:16.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:16.131+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:16.270+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:16.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:27:16.393+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:16.392+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:27:16.573+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-16T18:27:26.960+0000] {processor.py:154} INFO - Started process (PID=8585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:26.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:27:26.995+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:26.994+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:27.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:27.255+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:27.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:27:27.369+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:27.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:27:27.526+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.591 seconds
[2022-12-16T18:27:38.067+0000] {processor.py:154} INFO - Started process (PID=8603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:38.115+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:27:38.175+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:38.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:38.575+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:39.015+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:39.014+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:27:39.515+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:39.513+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:27:39.709+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.678 seconds
[2022-12-16T18:27:50.039+0000] {processor.py:154} INFO - Started process (PID=8613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:50.050+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:27:50.058+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:50.057+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:50.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:27:50.783+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:50.782+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:27:51.211+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:27:51.209+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:27:51.684+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.687 seconds
[2022-12-16T18:28:01.963+0000] {processor.py:154} INFO - Started process (PID=8623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:01.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:28:01.971+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:01.970+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:02.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:03.120+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:28:13.839+0000] {processor.py:154} INFO - Started process (PID=8633) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:13.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:28:13.853+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:13.850+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:14.021+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:15.132+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:28:25.735+0000] {processor.py:154} INFO - Started process (PID=8651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:25.742+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:28:25.756+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:25.755+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:26.010+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:27.459+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:28:38.102+0000] {processor.py:154} INFO - Started process (PID=8661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:38.142+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:28:38.148+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:38.146+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:38.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:38.516+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:38.514+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:28:38.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:38.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:28:39.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.952 seconds
[2022-12-16T18:28:49.478+0000] {processor.py:154} INFO - Started process (PID=8671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:49.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:28:49.491+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:28:49.490+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:49.593+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:28:50.704+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:29:01.170+0000] {processor.py:154} INFO - Started process (PID=8681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:01.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:01.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:01.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:01.268+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:01.468+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:01.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:29:01.633+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:01.632+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:29:01.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-16T18:29:12.008+0000] {processor.py:154} INFO - Started process (PID=8699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:12.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:12.065+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:12.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:12.293+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:13.135+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:13.134+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:29:13.385+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:13.384+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:29:13.586+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.592 seconds
[2022-12-16T18:29:23.968+0000] {processor.py:154} INFO - Started process (PID=8709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:23.993+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:23.997+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:23.996+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:24.155+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:25.280+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:25.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:29:25.593+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:25.592+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:29:25.765+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.811 seconds
[2022-12-16T18:29:36.169+0000] {processor.py:154} INFO - Started process (PID=8719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:36.172+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:36.177+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:36.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:36.270+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:36.680+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:29:46.888+0000] {processor.py:154} INFO - Started process (PID=8736) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:46.893+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:46.898+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:46.897+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:47.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:47.656+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:47.655+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:29:48.029+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:48.027+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:29:48.448+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.581 seconds
[2022-12-16T18:29:59.401+0000] {processor.py:154} INFO - Started process (PID=8747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:59.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:29:59.427+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:29:59.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:29:59.658+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:00.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:00.546+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:00.746+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:00.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:00.954+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.577 seconds
[2022-12-16T18:30:11.967+0000] {processor.py:154} INFO - Started process (PID=8757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:11.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:30:11.998+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:11.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:12.116+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:12.871+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:12.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:13.018+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:13.017+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:13.182+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.240 seconds
[2022-12-16T18:30:23.648+0000] {processor.py:154} INFO - Started process (PID=8767) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:23.715+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:30:23.719+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:23.719+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:23.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:24.070+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:24.069+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:24.209+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:24.207+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:24.374+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.768 seconds
[2022-12-16T18:30:34.907+0000] {processor.py:154} INFO - Started process (PID=8785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:34.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:30:34.931+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:34.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:35.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:36.096+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:36.095+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:36.366+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:36.361+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:36.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.840 seconds
[2022-12-16T18:30:47.630+0000] {processor.py:154} INFO - Started process (PID=8795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:47.633+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:30:47.636+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:47.636+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:47.793+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:48.004+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:48.002+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:48.161+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:48.160+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:48.368+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.817 seconds
[2022-12-16T18:30:58.590+0000] {processor.py:154} INFO - Started process (PID=8805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:58.612+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:30:58.619+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:58.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:58.744+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:30:59.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:59.419+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:30:59.546+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:30:59.545+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:30:59.655+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.103 seconds
[2022-12-16T18:31:09.854+0000] {processor.py:154} INFO - Started process (PID=8813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:09.894+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:31:09.935+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:09.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:10.075+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:10.529+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:31:20.949+0000] {processor.py:154} INFO - Started process (PID=8828) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:21.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:31:21.072+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:21.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:21.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:21.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:21.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:31:21.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:21.958+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:31:22.190+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.264 seconds
[2022-12-16T18:31:32.664+0000] {processor.py:154} INFO - Started process (PID=8838) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:32.721+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:31:32.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:32.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:33.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:33.963+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:33.962+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:31:34.103+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:34.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:31:34.251+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.632 seconds
[2022-12-16T18:31:44.731+0000] {processor.py:154} INFO - Started process (PID=8851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:44.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:31:44.779+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:44.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:45.157+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:45.444+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:45.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:31:45.581+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:45.580+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:31:45.843+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.209 seconds
[2022-12-16T18:31:56.183+0000] {processor.py:154} INFO - Started process (PID=8861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:56.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:31:56.229+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:56.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:56.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:31:57.215+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:57.212+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:31:57.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:31:57.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:31:57.948+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.786 seconds
[2022-12-16T18:32:08.415+0000] {processor.py:154} INFO - Started process (PID=8880) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:08.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:32:08.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:08.459+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:08.598+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:09.062+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:32:19.584+0000] {processor.py:154} INFO - Started process (PID=8890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:19.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:32:19.596+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:19.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:19.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:20.124+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:20.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:32:20.258+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:20.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:32:20.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.834 seconds
[2022-12-16T18:32:30.803+0000] {processor.py:154} INFO - Started process (PID=8897) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:30.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:32:30.817+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:30.816+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:31.022+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:31.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:31.757+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:32:32.263+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:32.262+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:32:32.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.728 seconds
[2022-12-16T18:32:43.231+0000] {processor.py:154} INFO - Started process (PID=8917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:43.254+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:32:43.271+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:43.257+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:43.684+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:44.597+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:44.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:32:45.629+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:45.628+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:32:45.995+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.872 seconds
[2022-12-16T18:32:56.426+0000] {processor.py:154} INFO - Started process (PID=8925) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:56.450+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:32:56.460+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:32:56.458+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:56.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:32:57.888+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:33:08.330+0000] {processor.py:154} INFO - Started process (PID=8938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:08.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:33:08.358+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:08.357+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:08.780+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:09.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:09.585+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:33:09.848+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:09.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:33:10.017+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.702 seconds
[2022-12-16T18:33:20.840+0000] {processor.py:154} INFO - Started process (PID=8948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:20.879+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:33:20.889+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:20.888+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:21.112+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:21.387+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:21.379+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:33:21.628+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:21.628+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:33:21.879+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.163 seconds
[2022-12-16T18:33:32.641+0000] {processor.py:154} INFO - Started process (PID=8966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:32.687+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:33:32.691+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:32.690+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:32.948+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:33.560+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:33.559+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:33:34.075+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:34.068+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:33:34.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.746 seconds
[2022-12-16T18:33:44.777+0000] {processor.py:154} INFO - Started process (PID=8978) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:44.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:33:44.827+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:44.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:44.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:45.288+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:45.287+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:33:45.617+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:45.616+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:33:45.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.114 seconds
[2022-12-16T18:33:56.244+0000] {processor.py:154} INFO - Started process (PID=8988) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:56.296+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:33:56.304+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:33:56.303+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:56.509+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:33:57.813+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:34:08.577+0000] {processor.py:154} INFO - Started process (PID=9005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:08.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:34:08.676+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:08.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:09.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:10.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:10.059+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:34:10.502+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:10.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:34:10.798+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.310 seconds
[2022-12-16T18:34:21.339+0000] {processor.py:154} INFO - Started process (PID=9016) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:21.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:34:21.388+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:21.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:21.830+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:22.295+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:22.285+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:34:22.518+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:22.517+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:34:22.763+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.542 seconds
[2022-12-16T18:34:33.972+0000] {processor.py:154} INFO - Started process (PID=9026) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:34.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:34:34.086+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:34.085+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:34.271+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:34.621+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:34.620+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:34:34.768+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:34.767+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:34:35.004+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.052 seconds
[2022-12-16T18:34:45.449+0000] {processor.py:154} INFO - Started process (PID=9036) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:45.476+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:34:45.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:45.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:45.908+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:46.172+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:46.171+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:34:46.295+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:46.294+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:34:46.422+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-16T18:34:57.082+0000] {processor.py:154} INFO - Started process (PID=9054) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:57.124+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:34:57.132+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:57.131+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:57.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:34:58.475+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:58.473+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:34:59.081+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:34:59.080+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:34:59.401+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.405 seconds
[2022-12-16T18:35:10.528+0000] {processor.py:154} INFO - Started process (PID=9064) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:10.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:35:10.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:10.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:10.990+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:11.489+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:11.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:35:11.872+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:11.871+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:35:12.183+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.766 seconds
[2022-12-16T18:35:22.772+0000] {processor.py:154} INFO - Started process (PID=9074) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:22.848+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:35:22.852+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:22.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:23.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:23.867+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:23.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:35:24.015+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:24.014+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:35:24.202+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.478 seconds
[2022-12-16T18:35:34.519+0000] {processor.py:154} INFO - Started process (PID=9084) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:34.552+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:35:34.562+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:34.555+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:34.843+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:36.007+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:36.006+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:35:36.269+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:36.268+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:35:36.448+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.956 seconds
[2022-12-16T18:35:47.080+0000] {processor.py:154} INFO - Started process (PID=9102) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:47.118+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:35:47.138+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:47.121+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:47.470+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:48.352+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:35:59.541+0000] {processor.py:154} INFO - Started process (PID=9112) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:59.572+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:35:59.583+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:35:59.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:35:59.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:00.407+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:00.406+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:00.599+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:00.597+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:00.799+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.289 seconds
[2022-12-16T18:36:11.196+0000] {processor.py:154} INFO - Started process (PID=9122) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:11.220+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:36:11.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:11.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:11.351+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:11.596+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:11.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:11.759+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:11.758+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:11.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.827 seconds
[2022-12-16T18:36:22.698+0000] {processor.py:154} INFO - Started process (PID=9132) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:22.714+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:36:22.738+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:22.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:22.992+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:23.295+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:23.294+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:23.421+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:23.420+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:23.554+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.994 seconds
[2022-12-16T18:36:34.045+0000] {processor.py:154} INFO - Started process (PID=9150) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:34.095+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:36:34.099+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:34.098+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:34.295+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:34.530+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:34.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:35.225+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:35.224+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:35.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.681 seconds
[2022-12-16T18:36:46.614+0000] {processor.py:154} INFO - Started process (PID=9160) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:46.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:36:46.626+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:46.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:46.820+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:47.480+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:47.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:47.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:47.781+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:47.942+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.348 seconds
[2022-12-16T18:36:58.231+0000] {processor.py:154} INFO - Started process (PID=9170) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:58.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:36:58.260+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:58.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:58.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:36:58.588+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:58.587+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:36:59.050+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:36:59.049+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:36:59.307+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.091 seconds
[2022-12-16T18:37:09.801+0000] {processor.py:154} INFO - Started process (PID=9180) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:09.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:37:09.820+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:09.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:09.958+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:10.199+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:10.198+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:37:10.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:10.415+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:37:10.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.081 seconds
[2022-12-16T18:37:21.301+0000] {processor.py:154} INFO - Started process (PID=9198) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:21.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:37:21.392+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:21.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:21.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:23.306+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:37:33.870+0000] {processor.py:154} INFO - Started process (PID=9208) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:33.873+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:37:33.884+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:33.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:34.175+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:35.501+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:35.500+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:37:35.996+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:35.996+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:37:36.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.705 seconds
[2022-12-16T18:37:47.052+0000] {processor.py:154} INFO - Started process (PID=9218) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:47.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:37:47.088+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:47.087+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:47.275+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:47.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:47.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:37:48.265+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:48.264+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:37:48.512+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.474 seconds
[2022-12-16T18:37:58.801+0000] {processor.py:154} INFO - Started process (PID=9228) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:58.889+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:37:58.893+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:58.892+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:59.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:37:59.823+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:59.822+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:37:59.979+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:37:59.979+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:00.131+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.345 seconds
[2022-12-16T18:38:10.832+0000] {processor.py:154} INFO - Started process (PID=9245) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:10.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:38:10.905+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:10.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:11.242+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:11.439+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:11.438+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:38:11.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:11.562+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:11.821+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.015 seconds
[2022-12-16T18:38:22.361+0000] {processor.py:154} INFO - Started process (PID=9255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:22.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:38:22.391+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:22.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:22.485+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:22.670+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:22.669+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:38:22.814+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:22.813+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:22.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.625 seconds
[2022-12-16T18:38:33.270+0000] {processor.py:154} INFO - Started process (PID=9265) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:33.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:38:33.319+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:33.318+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:33.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:33.631+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:33.630+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:38:33.769+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:33.768+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:33.951+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.695 seconds
[2022-12-16T18:38:44.305+0000] {processor.py:154} INFO - Started process (PID=9275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:44.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:38:44.335+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:44.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:44.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:45.036+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:45.035+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:38:45.211+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:45.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:45.507+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.222 seconds
[2022-12-16T18:38:56.143+0000] {processor.py:154} INFO - Started process (PID=9292) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:56.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:38:56.181+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:56.164+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:56.331+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:38:57.503+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:57.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:38:57.755+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:38:57.754+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:38:58.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.015 seconds
[2022-12-16T18:39:08.591+0000] {processor.py:154} INFO - Started process (PID=9302) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:08.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:39:08.601+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:08.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:08.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:09.651+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:39:20.180+0000] {processor.py:154} INFO - Started process (PID=9312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:20.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:39:20.187+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:20.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:20.297+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:20.592+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:20.591+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:39:20.709+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:20.708+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:39:20.879+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.713 seconds
[2022-12-16T18:39:31.324+0000] {processor.py:154} INFO - Started process (PID=9322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:31.358+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:39:31.362+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:31.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:31.449+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:32.496+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:39:42.800+0000] {processor.py:154} INFO - Started process (PID=9341) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:42.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:39:42.831+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:42.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:42.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:43.887+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:39:54.672+0000] {processor.py:154} INFO - Started process (PID=9351) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:54.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:39:54.704+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:54.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:54.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:39:55.527+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:55.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:39:55.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:39:55.663+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:39:55.788+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.157 seconds
[2022-12-16T18:40:06.332+0000] {processor.py:154} INFO - Started process (PID=9361) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:06.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:40:06.416+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:06.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:06.553+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:06.740+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:06.738+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:40:07.013+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:07.012+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:40:07.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.016 seconds
[2022-12-16T18:40:17.733+0000] {processor.py:154} INFO - Started process (PID=9378) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:17.787+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:40:17.796+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:17.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:18.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:18.984+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:18.983+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:40:19.517+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:19.508+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:40:19.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.293 seconds
[2022-12-16T18:40:30.925+0000] {processor.py:154} INFO - Started process (PID=9390) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:30.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:40:30.983+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:30.982+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:31.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:32.353+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:32.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:40:32.791+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:32.789+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:40:33.075+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.262 seconds
[2022-12-16T18:40:43.514+0000] {processor.py:154} INFO - Started process (PID=9400) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:43.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:40:43.548+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:43.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:43.637+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:44.200+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:44.199+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:40:44.320+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:44.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:40:44.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-16T18:40:54.918+0000] {processor.py:154} INFO - Started process (PID=9410) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:54.921+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:40:54.925+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:54.924+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:55.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:40:55.215+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:55.214+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:40:55.338+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:40:55.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:40:55.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.622 seconds
[2022-12-16T18:41:05.973+0000] {processor.py:154} INFO - Started process (PID=9420) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:06.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:41:06.038+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:06.037+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:06.560+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:07.836+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:41:18.706+0000] {processor.py:154} INFO - Started process (PID=9438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:18.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:41:18.733+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:18.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:19.267+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:19.576+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:19.575+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:41:19.706+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:19.705+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:41:20.226+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.607 seconds
[2022-12-16T18:41:30.582+0000] {processor.py:154} INFO - Started process (PID=9448) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:30.602+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:41:30.615+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:30.614+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:30.710+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:30.860+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:30.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:41:30.978+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:30.978+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:41:31.186+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.626 seconds
[2022-12-16T18:41:41.818+0000] {processor.py:154} INFO - Started process (PID=9458) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:41.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:41:41.866+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:41.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:42.357+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:42.896+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:42.895+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:41:43.060+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:43.059+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:41:43.204+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.484 seconds
[2022-12-16T18:41:53.511+0000] {processor.py:154} INFO - Started process (PID=9468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:53.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:41:53.544+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:53.542+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:53.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:41:54.664+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:54.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:41:54.806+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:41:54.805+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:41:54.955+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.462 seconds
[2022-12-16T18:42:05.374+0000] {processor.py:154} INFO - Started process (PID=9486) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:05.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:42:05.425+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:05.424+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:05.561+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:05.820+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:05.819+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:42:06.087+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:06.086+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:42:06.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.098 seconds
[2022-12-16T18:42:16.810+0000] {processor.py:154} INFO - Started process (PID=9496) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:16.836+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:42:16.840+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:16.839+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:16.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:17.100+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:17.099+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:42:17.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:17.218+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:42:17.390+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.595 seconds
[2022-12-16T18:42:28.147+0000] {processor.py:154} INFO - Started process (PID=9506) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:28.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:42:28.197+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:28.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:28.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:28.440+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:28.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:42:28.564+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:28.563+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:42:28.742+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-16T18:42:39.372+0000] {processor.py:154} INFO - Started process (PID=9524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:39.416+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:42:39.424+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:39.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:39.681+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:39.930+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:39.928+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:42:40.284+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:40.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:42:40.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.206 seconds
[2022-12-16T18:42:51.204+0000] {processor.py:154} INFO - Started process (PID=9534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:51.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:42:51.239+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:51.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:51.340+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:42:51.782+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:51.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:42:51.921+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:42:51.920+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:42:52.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.884 seconds
[2022-12-16T18:43:02.435+0000] {processor.py:154} INFO - Started process (PID=9544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:02.478+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:02.482+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:02.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:02.571+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:02.810+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:02.809+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:43:03.015+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:03.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:43:03.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.810 seconds
[2022-12-16T18:43:13.716+0000] {processor.py:154} INFO - Started process (PID=9554) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:13.735+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:13.739+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:13.738+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:13.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:14.041+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:14.040+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:43:14.214+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:14.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:43:14.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.697 seconds
[2022-12-16T18:43:24.807+0000] {processor.py:154} INFO - Started process (PID=9572) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:24.947+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:24.957+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:24.956+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:25.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:25.777+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:25.776+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:43:25.950+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:25.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:43:26.146+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.355 seconds
[2022-12-16T18:43:36.745+0000] {processor.py:154} INFO - Started process (PID=9582) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:36.771+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:36.780+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:36.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:36.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:37.295+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-16T18:43:48.148+0000] {processor.py:154} INFO - Started process (PID=9592) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:48.198+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:48.202+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:48.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:48.314+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:48.767+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:48.766+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:43:48.918+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:48.917+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:43:49.051+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.919 seconds
[2022-12-16T18:43:59.592+0000] {processor.py:154} INFO - Started process (PID=9609) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:59.687+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:43:59.696+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:59.695+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:59.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:43:59.982+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:43:59.981+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:44:00.228+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:00.224+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:44:00.573+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.007 seconds
[2022-12-16T18:44:11.180+0000] {processor.py:154} INFO - Started process (PID=9620) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:11.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:44:11.219+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:11.218+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:11.527+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:11.735+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:11.734+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:44:11.916+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:11.915+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:44:12.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.149 seconds
[2022-12-16T18:44:22.734+0000] {processor.py:154} INFO - Started process (PID=9630) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:22.747+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-16T18:44:22.752+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:22.750+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:22.892+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-16T18:44:23.611+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:23.609+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-16T18:44:23.941+0000] {logging_mixin.py:137} INFO - [2022-12-16T18:44:23.940+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-16T18:44:24.220+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.520 seconds
