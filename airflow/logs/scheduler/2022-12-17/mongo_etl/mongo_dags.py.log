[2022-12-17T03:25:50.569+0000] {processor.py:154} INFO - Started process (PID=203) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:25:50.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:25:50.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:25:50.623+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:25:51.599+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:25:53.640+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:26:04.964+0000] {processor.py:154} INFO - Started process (PID=213) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:05.018+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:26:05.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:05.050+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:05.962+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:07.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:07.693+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:26:08.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:08.573+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:26:09.758+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 4.886 seconds
[2022-12-17T03:26:20.935+0000] {processor.py:154} INFO - Started process (PID=223) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:20.991+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:26:21.039+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:21.035+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:21.464+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:22.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:22.013+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:26:22.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:22.503+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:26:22.688+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.893 seconds
[2022-12-17T03:26:33.679+0000] {processor.py:154} INFO - Started process (PID=241) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:33.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:26:33.745+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:33.744+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:34.258+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:35.604+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:26:46.230+0000] {processor.py:154} INFO - Started process (PID=251) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:46.238+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:26:46.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:46.250+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:46.417+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:46.653+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:46.652+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:26:46.897+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:46.896+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:26:47.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.050 seconds
[2022-12-17T03:26:57.576+0000] {processor.py:154} INFO - Started process (PID=261) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:57.580+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:26:57.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:57.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:57.868+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:26:58.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:58.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:26:58.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:26:58.438+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:26:58.709+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.154 seconds
[2022-12-17T03:27:09.174+0000] {processor.py:154} INFO - Started process (PID=271) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:09.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:27:09.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:09.207+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:09.646+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:10.578+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:10.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:27:10.777+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:10.776+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:27:11.097+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.956 seconds
[2022-12-17T03:27:21.542+0000] {processor.py:154} INFO - Started process (PID=288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:21.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:27:21.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:21.578+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:21.882+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:23.453+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:27:34.489+0000] {processor.py:154} INFO - Started process (PID=298) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:34.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:27:34.504+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:34.503+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:34.740+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:35.725+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:27:46.311+0000] {processor.py:154} INFO - Started process (PID=308) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:46.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:27:46.333+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:46.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:46.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:47.865+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:47.864+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:27:48.020+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:48.019+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:27:48.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.896 seconds
[2022-12-17T03:27:58.825+0000] {processor.py:154} INFO - Started process (PID=318) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:58.877+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:27:58.894+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:58.893+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:59.155+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:27:59.342+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:59.341+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:27:59.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:27:59.504+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:27:59.686+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.876 seconds
[2022-12-17T03:28:10.088+0000] {processor.py:154} INFO - Started process (PID=336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:10.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:28:10.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:10.101+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:10.274+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:10.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:10.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:28:11.264+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:11.256+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:28:11.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.634 seconds
[2022-12-17T03:28:22.008+0000] {processor.py:154} INFO - Started process (PID=346) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:22.011+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:28:22.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:22.014+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:22.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:22.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:22.317+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:28:22.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:22.491+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:28:22.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.652 seconds
[2022-12-17T03:28:32.919+0000] {processor.py:154} INFO - Started process (PID=356) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:32.935+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:28:32.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:32.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:33.026+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:34.086+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:34.085+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:28:34.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:34.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:28:34.345+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.441 seconds
[2022-12-17T03:28:44.670+0000] {processor.py:154} INFO - Started process (PID=366) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:44.674+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:28:44.678+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:44.677+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:44.775+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:44.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:44.932+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:28:45.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:45.063+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:28:45.349+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-17T03:28:55.811+0000] {processor.py:154} INFO - Started process (PID=383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:55.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:28:55.820+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:55.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:55.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:28:57.674+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:57.673+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:28:57.875+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:28:57.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:28:58.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.303 seconds
[2022-12-17T03:29:08.492+0000] {processor.py:154} INFO - Started process (PID=398) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:08.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:29:08.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:08.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:08.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:08.785+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:08.784+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:29:08.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:08.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:29:09.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.587 seconds
[2022-12-17T03:29:19.332+0000] {processor.py:154} INFO - Started process (PID=406) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:19.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:29:19.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:19.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:19.514+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:19.731+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:19.730+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:29:19.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:19.869+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:29:20.218+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.905 seconds
[2022-12-17T03:29:30.523+0000] {processor.py:154} INFO - Started process (PID=413) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:30.559+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:29:30.571+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:30.562+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:30.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:31.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:31.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:29:31.730+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:31.729+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:29:31.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.369 seconds
[2022-12-17T03:29:42.135+0000] {processor.py:154} INFO - Started process (PID=431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:42.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:29:42.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:42.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:42.311+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:43.315+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:43.314+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:29:43.447+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:43.446+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:29:43.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.506 seconds
[2022-12-17T03:29:53.736+0000] {processor.py:154} INFO - Started process (PID=441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:53.794+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:29:53.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:29:53.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:53.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:29:54.906+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:30:05.179+0000] {processor.py:154} INFO - Started process (PID=451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:05.209+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:30:05.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:05.237+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:05.466+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:05.676+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:05.674+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:30:05.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:05.799+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:30:06.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.991 seconds
[2022-12-17T03:30:16.861+0000] {processor.py:154} INFO - Started process (PID=468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:16.879+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:30:16.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:16.902+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:17.270+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:18.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:18.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:30:18.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:18.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:30:18.610+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.912 seconds
[2022-12-17T03:30:29.729+0000] {processor.py:154} INFO - Started process (PID=478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:29.751+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:30:29.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:29.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:29.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:30.551+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:30.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:30:30.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:30.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:30:31.167+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.480 seconds
[2022-12-17T03:30:41.567+0000] {processor.py:154} INFO - Started process (PID=488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:41.589+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:30:41.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:41.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:41.690+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:42.904+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:30:53.125+0000] {processor.py:154} INFO - Started process (PID=498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:53.157+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:30:53.164+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:30:53.164+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:53.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:30:54.057+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:31:04.817+0000] {processor.py:154} INFO - Started process (PID=517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:04.875+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:31:04.879+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:04.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:05.132+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:05.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:05.981+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:31:06.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:06.312+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:31:06.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.763 seconds
[2022-12-17T03:31:16.878+0000] {processor.py:154} INFO - Started process (PID=527) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:16.882+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:31:16.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:16.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:16.964+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:17.578+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:17.577+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:31:17.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:17.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:31:17.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.110 seconds
[2022-12-17T03:31:28.163+0000] {processor.py:154} INFO - Started process (PID=537) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:28.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:31:28.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:28.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:28.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:29.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:29.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:31:29.240+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:29.240+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:31:29.362+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.211 seconds
[2022-12-17T03:31:39.617+0000] {processor.py:154} INFO - Started process (PID=547) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:39.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:31:39.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:39.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:39.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:39.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:39.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:31:39.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:39.981+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:31:40.116+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.513 seconds
[2022-12-17T03:31:50.843+0000] {processor.py:154} INFO - Started process (PID=565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:50.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:31:50.879+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:50.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:51.064+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:31:51.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:51.225+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:31:51.390+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:31:51.390+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:31:51.557+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.728 seconds
[2022-12-17T03:32:01.879+0000] {processor.py:154} INFO - Started process (PID=575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:01.900+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:01.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:01.903+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:02.057+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:02.215+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:02.214+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:02.343+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:02.342+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:02.463+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-17T03:32:12.701+0000] {processor.py:154} INFO - Started process (PID=585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:12.705+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:12.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:12.708+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:12.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:12.920+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:12.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:13.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:13.040+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:13.448+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.761 seconds
[2022-12-17T03:32:23.674+0000] {processor.py:154} INFO - Started process (PID=595) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:23.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:23.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:23.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:23.817+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:23.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:23.942+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:24.052+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:24.051+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:24.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-17T03:32:34.332+0000] {processor.py:154} INFO - Started process (PID=613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:34.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:34.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:34.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:34.577+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:34.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:34.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:34.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:34.904+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:35.079+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.762 seconds
[2022-12-17T03:32:45.370+0000] {processor.py:154} INFO - Started process (PID=623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:45.400+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:45.404+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:45.403+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:45.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:46.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:46.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:46.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:46.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:46.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.899 seconds
[2022-12-17T03:32:56.720+0000] {processor.py:154} INFO - Started process (PID=633) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:56.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:32:56.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:56.753+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:56.851+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:32:57.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:57.013+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:32:57.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:32:57.156+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:32:57.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.589 seconds
[2022-12-17T03:33:07.514+0000] {processor.py:154} INFO - Started process (PID=650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:07.529+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:33:07.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:07.544+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:07.783+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:09.254+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:09.253+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:33:09.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:09.538+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:33:09.740+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.257 seconds
[2022-12-17T03:33:20.450+0000] {processor.py:154} INFO - Started process (PID=661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:20.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:33:20.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:20.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:20.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:21.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:21.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:33:21.332+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:21.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:33:21.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.318 seconds
[2022-12-17T03:33:32.496+0000] {processor.py:154} INFO - Started process (PID=671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:32.505+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:33:32.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:32.508+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:32.728+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:34.037+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:33:44.632+0000] {processor.py:154} INFO - Started process (PID=681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:44.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:33:44.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:44.663+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:44.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:44.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:44.915+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:33:45.072+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:45.071+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:33:45.220+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.603 seconds
[2022-12-17T03:33:56.105+0000] {processor.py:154} INFO - Started process (PID=698) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:56.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:33:56.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:56.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:56.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:33:57.090+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:57.089+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:33:57.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:33:57.529+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:33:57.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.041 seconds
[2022-12-17T03:34:08.764+0000] {processor.py:154} INFO - Started process (PID=709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:08.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:34:08.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:08.798+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:09.073+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:09.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:09.334+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:34:09.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:09.782+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:34:10.146+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.423 seconds
[2022-12-17T03:34:20.579+0000] {processor.py:154} INFO - Started process (PID=719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:20.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:34:20.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:20.603+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:20.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:21.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:21.277+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:34:21.466+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:21.465+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:34:21.593+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.037 seconds
[2022-12-17T03:34:31.932+0000] {processor.py:154} INFO - Started process (PID=729) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:31.958+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:34:31.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:31.961+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:32.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:34.077+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:34.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:34:34.198+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:34.197+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:34:34.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.429 seconds
[2022-12-17T03:34:44.702+0000] {processor.py:154} INFO - Started process (PID=739) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:44.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:34:44.737+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:44.736+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:44.829+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:44.964+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:44.964+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:34:45.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:45.077+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:34:45.208+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.525 seconds
[2022-12-17T03:34:55.679+0000] {processor.py:154} INFO - Started process (PID=757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:55.726+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:34:55.730+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:55.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:55.835+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:34:56.154+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:56.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:34:56.286+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:34:56.285+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:34:56.455+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-17T03:35:06.690+0000] {processor.py:154} INFO - Started process (PID=767) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:06.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:35:06.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:06.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:06.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:07.198+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:07.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:35:07.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:07.430+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:35:07.629+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.953 seconds
[2022-12-17T03:35:18.228+0000] {processor.py:154} INFO - Started process (PID=777) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:18.275+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:35:18.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:18.279+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:18.360+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:19.395+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:19.394+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:35:19.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:19.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:35:19.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.437 seconds
[2022-12-17T03:35:30.228+0000] {processor.py:154} INFO - Started process (PID=794) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:30.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:35:30.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:30.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:30.666+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:31.007+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:31.006+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:35:31.220+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:31.219+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:35:31.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.359 seconds
[2022-12-17T03:35:41.902+0000] {processor.py:154} INFO - Started process (PID=804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:41.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:35:41.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:41.946+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:42.041+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:42.173+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:42.172+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:35:42.285+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:42.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:35:42.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.533 seconds
[2022-12-17T03:35:52.679+0000] {processor.py:154} INFO - Started process (PID=814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:52.702+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:35:52.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:52.706+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:52.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:35:52.926+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:52.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:35:53.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:35:53.179+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:35:53.567+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.901 seconds
[2022-12-17T03:36:03.898+0000] {processor.py:154} INFO - Started process (PID=824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:03.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:03.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:03.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:04.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:04.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:04.154+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:36:04.265+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:04.264+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:36:04.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.515 seconds
[2022-12-17T03:36:14.916+0000] {processor.py:154} INFO - Started process (PID=842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:14.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:14.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:14.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:15.198+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:15.622+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:15.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:36:15.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:15.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:36:15.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.105 seconds
[2022-12-17T03:36:26.282+0000] {processor.py:154} INFO - Started process (PID=852) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:26.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:26.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:26.346+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:26.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:26.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:26.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:36:26.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:26.708+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:36:26.890+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.623 seconds
[2022-12-17T03:36:37.142+0000] {processor.py:154} INFO - Started process (PID=862) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:37.170+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:37.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:37.173+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:37.257+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:37.391+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:37.390+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:36:37.503+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:37.502+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:36:37.618+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.490 seconds
[2022-12-17T03:36:48.366+0000] {processor.py:154} INFO - Started process (PID=878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:48.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:48.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:48.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:48.501+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:48.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:48.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:36:48.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:48.793+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:36:48.937+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.586 seconds
[2022-12-17T03:36:59.407+0000] {processor.py:154} INFO - Started process (PID=889) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:59.453+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:36:59.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:36:59.457+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:36:59.544+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:00.727+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:00.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:37:00.965+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:00.964+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:37:01.154+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.760 seconds
[2022-12-17T03:37:11.733+0000] {processor.py:154} INFO - Started process (PID=899) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:11.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:37:11.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:11.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:11.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:13.099+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:37:23.878+0000] {processor.py:154} INFO - Started process (PID=909) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:23.929+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:37:23.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:23.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:24.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:24.784+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:37:35.466+0000] {processor.py:154} INFO - Started process (PID=927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:35.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:37:35.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:35.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:35.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:36.141+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:37:46.768+0000] {processor.py:154} INFO - Started process (PID=937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:46.814+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:37:46.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:46.821+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:46.904+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:48.095+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:37:58.437+0000] {processor.py:154} INFO - Started process (PID=947) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:58.441+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:37:58.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:58.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:58.527+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:37:58.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:58.664+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:37:58.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:37:58.775+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:37:58.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.493 seconds
[2022-12-17T03:38:09.204+0000] {processor.py:154} INFO - Started process (PID=957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:09.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:38:09.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:09.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:09.405+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:09.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:09.778+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:38:09.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:09.911+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:38:10.147+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.958 seconds
[2022-12-17T03:38:20.698+0000] {processor.py:154} INFO - Started process (PID=974) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:20.807+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:38:20.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:20.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:20.908+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:21.055+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:21.054+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:38:21.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:21.169+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:38:21.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-17T03:38:31.621+0000] {processor.py:154} INFO - Started process (PID=984) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:31.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:38:31.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:31.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:31.731+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:31.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:31.877+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:38:31.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:31.990+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:38:32.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.522 seconds
[2022-12-17T03:38:42.378+0000] {processor.py:154} INFO - Started process (PID=994) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:42.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:38:42.386+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:42.385+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:42.470+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:43.300+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:38:53.707+0000] {processor.py:154} INFO - Started process (PID=1013) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:53.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:38:53.741+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:38:53.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:53.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:38:55.296+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:39:05.461+0000] {processor.py:154} INFO - Started process (PID=1023) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:05.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:39:05.525+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:05.524+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:05.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:06.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:06.029+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:39:06.153+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:06.152+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:39:06.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.831 seconds
[2022-12-17T03:39:16.547+0000] {processor.py:154} INFO - Started process (PID=1033) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:16.593+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:39:16.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:16.600+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:16.689+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:16.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:16.876+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:39:16.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:16.990+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:39:17.105+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.574 seconds
[2022-12-17T03:39:27.378+0000] {processor.py:154} INFO - Started process (PID=1043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:27.405+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:39:27.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:27.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:27.492+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:27.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:27.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:39:27.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:27.737+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:39:27.870+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.507 seconds
[2022-12-17T03:39:38.252+0000] {processor.py:154} INFO - Started process (PID=1061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:38.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:39:38.269+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:38.262+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:38.362+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:38.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:38.628+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:39:39.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:39.072+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:39:39.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.144 seconds
[2022-12-17T03:39:49.565+0000] {processor.py:154} INFO - Started process (PID=1071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:49.574+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:39:49.578+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:49.577+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:49.666+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:39:50.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:50.323+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:39:50.611+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:39:50.610+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:39:50.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.294 seconds
[2022-12-17T03:40:01.163+0000] {processor.py:154} INFO - Started process (PID=1081) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:01.186+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:01.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:01.189+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:01.281+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:01.443+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:01.442+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:40:01.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:01.601+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:40:02.050+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.902 seconds
[2022-12-17T03:40:12.476+0000] {processor.py:154} INFO - Started process (PID=1100) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:12.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:12.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:12.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:12.746+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:13.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:13.468+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:40:13.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:13.797+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:40:14.122+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.662 seconds
[2022-12-17T03:40:24.589+0000] {processor.py:154} INFO - Started process (PID=1110) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:24.632+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:24.637+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:24.635+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:24.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:24.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:24.989+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:40:25.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:25.113+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:40:25.397+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.827 seconds
[2022-12-17T03:40:35.656+0000] {processor.py:154} INFO - Started process (PID=1120) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:35.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:35.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:35.663+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:35.752+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:35.913+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:35.912+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:40:36.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:36.045+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:40:36.341+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.700 seconds
[2022-12-17T03:40:46.996+0000] {processor.py:154} INFO - Started process (PID=1130) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:47.027+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:47.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:47.031+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:47.119+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:48.299+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:40:58.585+0000] {processor.py:154} INFO - Started process (PID=1148) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:58.644+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:40:58.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:58.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:58.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:40:59.096+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:59.094+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:40:59.228+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:40:59.227+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:40:59.396+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.827 seconds
[2022-12-17T03:41:09.635+0000] {processor.py:154} INFO - Started process (PID=1158) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:09.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:41:09.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:09.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:09.724+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:09.863+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:09.862+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:41:09.999+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:09.994+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:41:10.172+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-17T03:41:20.418+0000] {processor.py:154} INFO - Started process (PID=1168) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:20.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:41:20.427+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:20.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:20.515+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:20.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:20.760+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:41:20.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:20.885+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:41:21.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.618 seconds
[2022-12-17T03:41:31.284+0000] {processor.py:154} INFO - Started process (PID=1178) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:31.339+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:41:31.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:31.342+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:31.431+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:31.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:31.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:41:31.775+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:31.774+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:41:31.889+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.621 seconds
[2022-12-17T03:41:42.929+0000] {processor.py:154} INFO - Started process (PID=1196) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:42.951+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:41:42.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:42.954+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:43.044+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:43.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:43.279+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:41:43.412+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:43.411+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:41:43.608+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.698 seconds
[2022-12-17T03:41:53.804+0000] {processor.py:154} INFO - Started process (PID=1206) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:53.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:41:53.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:41:53.811+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:53.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:41:54.402+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:42:04.707+0000] {processor.py:154} INFO - Started process (PID=1216) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:04.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:42:04.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:04.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:04.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:06.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:06.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:42:06.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:06.222+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:42:06.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.663 seconds
[2022-12-17T03:42:16.698+0000] {processor.py:154} INFO - Started process (PID=1235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:16.702+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:42:16.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:16.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:16.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:17.134+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:17.133+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:42:17.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:17.343+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:42:17.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.896 seconds
[2022-12-17T03:42:27.866+0000] {processor.py:154} INFO - Started process (PID=1245) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:27.905+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:42:27.917+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:27.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:28.049+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:29.294+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:29.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:42:29.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:29.404+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:42:29.568+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.727 seconds
[2022-12-17T03:42:39.846+0000] {processor.py:154} INFO - Started process (PID=1255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:39.872+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:42:39.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:39.875+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:40.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:40.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:40.457+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:42:40.570+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:40.569+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:42:40.703+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.874 seconds
[2022-12-17T03:42:50.951+0000] {processor.py:154} INFO - Started process (PID=1265) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:50.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:42:50.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:50.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:51.074+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:42:51.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:51.737+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:42:51.966+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:42:51.965+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:42:52.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.239 seconds
[2022-12-17T03:43:02.858+0000] {processor.py:154} INFO - Started process (PID=1284) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:02.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:02.919+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:02.918+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:03.090+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:03.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:03.276+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:43:03.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:03.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:43:03.580+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.788 seconds
[2022-12-17T03:43:14.221+0000] {processor.py:154} INFO - Started process (PID=1294) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:14.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:14.229+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:14.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:14.314+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:15.444+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:43:25.777+0000] {processor.py:154} INFO - Started process (PID=1304) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:25.781+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:25.785+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:25.784+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:25.881+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:26.019+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:26.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:43:26.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:26.144+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:43:26.257+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.497 seconds
[2022-12-17T03:43:36.521+0000] {processor.py:154} INFO - Started process (PID=1322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:36.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:36.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:36.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:36.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:37.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:37.629+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:43:37.908+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:37.907+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:43:38.040+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.566 seconds
[2022-12-17T03:43:48.399+0000] {processor.py:154} INFO - Started process (PID=1332) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:48.403+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:48.407+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:48.406+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:48.490+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:48.625+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:48.624+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:43:48.745+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:48.744+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:43:48.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.465 seconds
[2022-12-17T03:43:59.098+0000] {processor.py:154} INFO - Started process (PID=1342) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:59.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:43:59.106+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:59.105+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:59.188+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:43:59.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:59.323+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:43:59.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:43:59.441+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:43:59.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-17T03:44:09.978+0000] {processor.py:154} INFO - Started process (PID=1352) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:10.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:44:10.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:10.020+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:10.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:10.429+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:10.428+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:44:10.567+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:10.566+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:44:10.677+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.749 seconds
[2022-12-17T03:44:21.083+0000] {processor.py:154} INFO - Started process (PID=1369) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:21.088+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:44:21.096+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:21.091+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:21.198+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:21.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:21.979+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:44:22.249+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:22.248+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:44:22.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.323 seconds
[2022-12-17T03:44:32.673+0000] {processor.py:154} INFO - Started process (PID=1379) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:32.717+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:44:32.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:32.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:32.824+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:34.131+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:44:44.439+0000] {processor.py:154} INFO - Started process (PID=1389) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:44.494+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:44:44.506+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:44.501+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:44.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:44.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:44.793+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:44:44.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:44.908+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:44:45.140+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-17T03:44:55.419+0000] {processor.py:154} INFO - Started process (PID=1407) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:55.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:44:55.430+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:44:55.429+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:55.544+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:44:56.298+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:45:06.859+0000] {processor.py:154} INFO - Started process (PID=1418) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:06.863+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:45:06.867+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:06.866+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:06.971+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:07.159+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:07.158+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:45:07.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:07.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:45:07.376+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.533 seconds
[2022-12-17T03:45:17.645+0000] {processor.py:154} INFO - Started process (PID=1428) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:17.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:45:17.653+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:17.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:17.736+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:18.490+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:45:28.873+0000] {processor.py:154} INFO - Started process (PID=1438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:28.877+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:45:28.882+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:28.881+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:28.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:30.921+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:30.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:45:31.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:31.073+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:45:31.189+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.331 seconds
[2022-12-17T03:45:41.539+0000] {processor.py:154} INFO - Started process (PID=1455) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:41.543+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:45:41.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:41.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:41.641+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:41.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:41.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:45:42.003+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:42.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:45:42.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.952 seconds
[2022-12-17T03:45:53.297+0000] {processor.py:154} INFO - Started process (PID=1465) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:53.342+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:45:53.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:53.345+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:53.454+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:45:53.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:53.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:45:53.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:45:53.877+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:45:54.062+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.780 seconds
[2022-12-17T03:46:04.744+0000] {processor.py:154} INFO - Started process (PID=1475) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:04.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:46:04.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:04.752+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:04.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:05.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:05.222+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:46:05.353+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:05.351+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:46:05.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.790 seconds
[2022-12-17T03:46:15.790+0000] {processor.py:154} INFO - Started process (PID=1485) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:15.794+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:46:15.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:15.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:15.882+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:17.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:17.418+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:46:17.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:17.547+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:46:17.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.933 seconds
[2022-12-17T03:46:28.487+0000] {processor.py:154} INFO - Started process (PID=1503) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:28.511+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:46:28.516+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:28.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:28.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:29.695+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:46:40.078+0000] {processor.py:154} INFO - Started process (PID=1513) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:40.103+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:46:40.108+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:40.107+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:40.195+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:40.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:40.924+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:46:41.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:41.156+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:46:41.342+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.279 seconds
[2022-12-17T03:46:51.599+0000] {processor.py:154} INFO - Started process (PID=1523) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:51.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:46:51.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:51.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:51.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:46:51.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:51.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:46:52.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:46:52.033+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:46:52.210+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-17T03:47:02.602+0000] {processor.py:154} INFO - Started process (PID=1541) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:02.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:47:02.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:02.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:02.744+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:03.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:03.237+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:47:03.386+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:03.386+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:47:03.622+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.082 seconds
[2022-12-17T03:47:13.896+0000] {processor.py:154} INFO - Started process (PID=1551) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:13.922+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:47:13.926+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:13.925+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:14.056+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:15.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:15.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:47:15.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:15.345+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:47:15.510+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.652 seconds
[2022-12-17T03:47:26.136+0000] {processor.py:154} INFO - Started process (PID=1566) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:26.165+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:47:26.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:26.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:26.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:26.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:26.418+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:47:26.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:26.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:47:26.845+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.725 seconds
[2022-12-17T03:47:37.511+0000] {processor.py:154} INFO - Started process (PID=1580) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:37.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:47:37.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:37.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:37.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:39.222+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:47:49.507+0000] {processor.py:154} INFO - Started process (PID=1593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:49.521+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:47:49.525+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:49.524+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:49.675+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:47:49.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:49.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:47:49.965+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:47:49.964+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:47:50.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-17T03:48:00.375+0000] {processor.py:154} INFO - Started process (PID=1601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:00.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:00.392+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:00.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:00.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:01.872+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:48:12.252+0000] {processor.py:154} INFO - Started process (PID=1611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:12.299+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:12.326+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:12.314+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:12.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:12.757+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:12.756+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:48:12.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:12.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:48:13.026+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-17T03:48:23.338+0000] {processor.py:154} INFO - Started process (PID=1629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:23.379+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:23.387+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:23.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:23.548+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:24.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:24.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:48:24.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:24.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:48:24.581+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.260 seconds
[2022-12-17T03:48:34.942+0000] {processor.py:154} INFO - Started process (PID=1639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:34.970+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:34.980+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:34.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:35.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:35.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:35.486+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:48:35.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:35.702+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:48:35.811+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.888 seconds
[2022-12-17T03:48:46.126+0000] {processor.py:154} INFO - Started process (PID=1649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:46.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:46.172+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:46.171+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:46.264+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:46.717+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:48:57.089+0000] {processor.py:154} INFO - Started process (PID=1667) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:57.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:48:57.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:57.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:57.318+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:48:57.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:57.608+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:48:57.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:48:57.770+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:48:58.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.003 seconds
[2022-12-17T03:49:08.649+0000] {processor.py:154} INFO - Started process (PID=1678) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:08.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:49:08.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:08.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:08.884+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:09.533+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:09.532+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:49:09.661+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:09.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:49:09.764+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.210 seconds
[2022-12-17T03:49:20.270+0000] {processor.py:154} INFO - Started process (PID=1690) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:20.305+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:49:20.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:20.329+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:20.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:20.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:20.693+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:49:20.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:20.813+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:49:20.921+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.700 seconds
[2022-12-17T03:49:31.654+0000] {processor.py:154} INFO - Started process (PID=1700) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:31.692+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:49:31.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:31.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:31.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:32.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:32.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:49:32.243+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:32.234+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:49:32.436+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.811 seconds
[2022-12-17T03:49:43.185+0000] {processor.py:154} INFO - Started process (PID=1718) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:43.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:49:43.237+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:43.219+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:43.528+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:43.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:43.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:49:43.947+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:43.946+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:49:44.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.377 seconds
[2022-12-17T03:49:55.033+0000] {processor.py:154} INFO - Started process (PID=1728) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:55.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:49:55.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:55.063+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:55.296+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:49:55.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:55.478+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:49:55.636+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:49:55.627+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:49:55.857+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.903 seconds
[2022-12-17T03:50:06.395+0000] {processor.py:154} INFO - Started process (PID=1738) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:06.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:50:06.466+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:06.465+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:06.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:07.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:07.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:50:07.430+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:07.429+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:50:07.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.304 seconds
[2022-12-17T03:50:18.565+0000] {processor.py:154} INFO - Started process (PID=1755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:18.608+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:50:18.645+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:18.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:19.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:20.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:20.361+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:50:20.737+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:20.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:50:20.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.579 seconds
[2022-12-17T03:50:32.059+0000] {processor.py:154} INFO - Started process (PID=1766) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:32.120+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:50:32.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:32.123+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:32.286+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:32.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:32.553+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:50:32.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:32.929+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:50:33.341+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.381 seconds
[2022-12-17T03:50:44.009+0000] {processor.py:154} INFO - Started process (PID=1776) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:44.156+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:50:44.160+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:44.158+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:44.395+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:44.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:44.980+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:50:45.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:45.418+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:50:45.760+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.828 seconds
[2022-12-17T03:50:56.255+0000] {processor.py:154} INFO - Started process (PID=1786) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:56.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:50:56.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:56.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:56.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:50:57.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:57.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:50:58.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:50:58.178+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:50:58.363+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.129 seconds
[2022-12-17T03:51:09.019+0000] {processor.py:154} INFO - Started process (PID=1803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:09.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:51:09.049+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:09.048+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:09.597+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:10.286+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:10.285+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:51:10.562+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:10.561+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:51:10.810+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.908 seconds
[2022-12-17T03:51:21.619+0000] {processor.py:154} INFO - Started process (PID=1814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:21.677+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:51:21.691+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:21.690+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:22.066+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:22.850+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:22.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:51:23.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:23.714+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:51:24.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.720 seconds
[2022-12-17T03:51:34.492+0000] {processor.py:154} INFO - Started process (PID=1824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:34.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:51:34.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:34.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:34.681+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:35.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:35.142+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:51:35.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:35.559+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:51:35.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.255 seconds
[2022-12-17T03:51:45.948+0000] {processor.py:154} INFO - Started process (PID=1834) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:45.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:51:45.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:45.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:46.173+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:47.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:47.343+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:51:47.478+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:47.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:51:47.591+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.685 seconds
[2022-12-17T03:51:58.567+0000] {processor.py:154} INFO - Started process (PID=1851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:58.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:51:58.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:51:58.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:51:58.900+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:00.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:00.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:52:01.116+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:01.115+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:52:01.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.992 seconds
[2022-12-17T03:52:12.151+0000] {processor.py:154} INFO - Started process (PID=1862) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:12.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:52:12.201+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:12.200+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:12.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:13.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:13.437+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:52:14.364+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:14.347+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:52:14.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.691 seconds
[2022-12-17T03:52:25.139+0000] {processor.py:154} INFO - Started process (PID=1872) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:25.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:52:25.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:25.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:25.261+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:26.348+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:52:36.697+0000] {processor.py:154} INFO - Started process (PID=1882) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:36.775+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:52:36.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:36.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:36.918+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:37.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:37.222+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:52:37.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:37.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:52:37.549+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.879 seconds
[2022-12-17T03:52:48.199+0000] {processor.py:154} INFO - Started process (PID=1899) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:48.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:52:48.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:48.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:48.413+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:52:49.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:49.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:52:49.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:52:49.434+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:52:49.575+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.403 seconds
[2022-12-17T03:53:00.089+0000] {processor.py:154} INFO - Started process (PID=1910) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:00.125+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:00.133+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:00.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:00.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:00.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:00.374+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:00.659+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:00.654+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:00.812+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.750 seconds
[2022-12-17T03:53:11.535+0000] {processor.py:154} INFO - Started process (PID=1920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:11.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:11.561+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:11.560+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:11.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:12.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:12.229+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:12.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:12.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:12.482+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.962 seconds
[2022-12-17T03:53:22.797+0000] {processor.py:154} INFO - Started process (PID=1930) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:22.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:22.827+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:22.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:22.916+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:23.172+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:23.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:23.401+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:23.400+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:23.542+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.764 seconds
[2022-12-17T03:53:33.825+0000] {processor.py:154} INFO - Started process (PID=1948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:33.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:33.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:33.884+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:34.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:34.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:34.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:34.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:34.372+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:34.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.711 seconds
[2022-12-17T03:53:44.892+0000] {processor.py:154} INFO - Started process (PID=1958) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:44.917+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:44.921+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:44.920+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:45.017+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:45.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:45.157+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:45.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:45.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:45.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-17T03:53:55.671+0000] {processor.py:154} INFO - Started process (PID=1968) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:55.675+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:53:55.680+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:55.679+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:55.764+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:53:56.198+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:56.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:53:56.313+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:53:56.313+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:53:56.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.764 seconds
[2022-12-17T03:54:06.691+0000] {processor.py:154} INFO - Started process (PID=1978) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:06.714+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:54:06.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:06.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:06.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:07.557+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:07.556+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:54:07.678+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:07.677+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:54:07.836+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.160 seconds
[2022-12-17T03:54:18.184+0000] {processor.py:154} INFO - Started process (PID=1996) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:18.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:54:18.254+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:18.253+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:18.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:18.723+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:18.722+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:54:18.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:18.942+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:54:19.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.966 seconds
[2022-12-17T03:54:29.412+0000] {processor.py:154} INFO - Started process (PID=2006) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:29.416+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:54:29.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:29.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:29.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:29.649+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:29.648+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:54:29.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:29.788+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:54:29.926+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-17T03:54:40.635+0000] {processor.py:154} INFO - Started process (PID=2016) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:40.666+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:54:40.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:40.669+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:40.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:42.022+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:54:52.525+0000] {processor.py:154} INFO - Started process (PID=2033) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:52.736+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:54:52.745+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:52.744+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:52.882+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:54:53.129+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:53.128+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:54:53.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:54:53.454+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:54:53.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-17T03:55:04.280+0000] {processor.py:154} INFO - Started process (PID=2044) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:04.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:55:04.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:04.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:04.466+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:04.672+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:04.671+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:55:04.862+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:04.861+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:55:05.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.885 seconds
[2022-12-17T03:55:15.475+0000] {processor.py:154} INFO - Started process (PID=2054) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:15.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:55:15.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:15.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:15.567+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:15.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:15.941+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:55:16.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:16.260+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:55:16.466+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.005 seconds
[2022-12-17T03:55:26.677+0000] {processor.py:154} INFO - Started process (PID=2064) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:26.681+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:55:26.689+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:26.688+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:26.841+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:27.056+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:27.055+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:55:27.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:27.214+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:55:27.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.761 seconds
[2022-12-17T03:55:37.866+0000] {processor.py:154} INFO - Started process (PID=2082) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:37.869+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:55:37.879+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:37.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:38.242+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:55:40.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:40.594+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:55:41.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:55:41.030+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:55:41.229+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.399 seconds
[2022-12-17T03:56:42.188+0000] {processor.py:154} INFO - Started process (PID=171) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:42.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:56:42.218+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:42.217+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:42.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:42.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:42.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:56:43.070+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:43.069+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:56:43.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.157 seconds
[2022-12-17T03:56:53.873+0000] {processor.py:154} INFO - Started process (PID=182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:53.974+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:56:53.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:53.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:54.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:56:54.559+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:54.557+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:56:54.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:56:54.719+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:56:54.852+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.015 seconds
[2022-12-17T03:57:05.138+0000] {processor.py:154} INFO - Started process (PID=192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:05.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:57:05.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:05.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:05.288+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:05.551+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:05.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:57:05.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:05.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:57:05.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.780 seconds
[2022-12-17T03:57:16.400+0000] {processor.py:154} INFO - Started process (PID=210) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:16.417+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:57:16.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:16.427+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:16.700+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:17.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:17.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:57:17.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:17.538+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:57:17.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.332 seconds
[2022-12-17T03:57:28.057+0000] {processor.py:154} INFO - Started process (PID=220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:28.085+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:57:28.089+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:28.088+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:28.178+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:28.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:28.377+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:57:28.514+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:28.513+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:57:28.673+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-17T03:57:38.919+0000] {processor.py:154} INFO - Started process (PID=230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:38.989+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:57:38.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:38.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:39.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:39.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:39.719+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:57:39.937+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:39.937+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:57:40.113+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.207 seconds
[2022-12-17T03:57:50.529+0000] {processor.py:154} INFO - Started process (PID=240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:50.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:57:50.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:50.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:50.668+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:57:50.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:50.950+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:57:51.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:57:51.103+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:57:51.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.804 seconds
[2022-12-17T03:58:02.203+0000] {processor.py:154} INFO - Started process (PID=258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:02.207+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:58:02.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:02.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:02.707+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:03.613+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:03.611+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:58:04.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:04.277+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:58:04.748+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.605 seconds
[2022-12-17T03:58:15.546+0000] {processor.py:154} INFO - Started process (PID=268) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:15.549+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:58:15.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:15.558+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:15.753+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:17.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:17.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:58:17.307+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:17.306+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:58:17.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.089 seconds
[2022-12-17T03:58:28.033+0000] {processor.py:154} INFO - Started process (PID=278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:28.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:58:28.068+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:28.062+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:28.287+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:28.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:28.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:58:29.103+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:29.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:58:29.514+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-17T03:58:39.965+0000] {processor.py:154} INFO - Started process (PID=288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:39.970+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:58:39.977+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:39.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:40.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:41.346+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T03:58:52.210+0000] {processor.py:154} INFO - Started process (PID=306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:52.233+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:58:52.243+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:52.242+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:52.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:58:53.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:53.365+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:58:54.247+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:58:54.246+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:58:54.680+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.531 seconds
[2022-12-17T03:59:05.306+0000] {processor.py:154} INFO - Started process (PID=316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:05.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:59:05.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:05.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:05.473+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:05.903+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:05.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:59:06.088+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:06.087+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:59:06.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.086 seconds
[2022-12-17T03:59:16.841+0000] {processor.py:154} INFO - Started process (PID=326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:16.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:59:16.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:16.853+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:17.031+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:17.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:17.564+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:59:17.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:17.810+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:59:18.126+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.311 seconds
[2022-12-17T03:59:28.477+0000] {processor.py:154} INFO - Started process (PID=336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:28.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:59:28.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:28.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:28.620+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:29.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:29.027+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:59:29.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:29.361+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:59:29.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.108 seconds
[2022-12-17T03:59:40.269+0000] {processor.py:154} INFO - Started process (PID=354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:40.277+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:59:40.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:40.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:40.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:41.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:41.501+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:59:41.847+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:41.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:59:42.160+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.932 seconds
[2022-12-17T03:59:52.938+0000] {processor.py:154} INFO - Started process (PID=364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:52.954+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T03:59:52.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:52.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:53.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T03:59:54.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:54.400+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T03:59:54.672+0000] {logging_mixin.py:137} INFO - [2022-12-17T03:59:54.671+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T03:59:54.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.057 seconds
[2022-12-17T04:00:05.591+0000] {processor.py:154} INFO - Started process (PID=374) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:05.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:00:05.639+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:05.634+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:05.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:06.221+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:06.220+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:00:06.411+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:06.410+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:00:06.561+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.015 seconds
[2022-12-17T04:00:16.793+0000] {processor.py:154} INFO - Started process (PID=384) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:16.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:00:16.852+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:16.850+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:16.942+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:17.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:17.144+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:00:17.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:17.274+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:00:17.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.636 seconds
[2022-12-17T04:00:27.672+0000] {processor.py:154} INFO - Started process (PID=402) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:27.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:00:27.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:27.741+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:27.913+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:28.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:28.528+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:00:28.727+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:28.726+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:00:28.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.279 seconds
[2022-12-17T04:00:39.858+0000] {processor.py:154} INFO - Started process (PID=412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:39.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:00:39.897+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:39.896+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:39.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:40.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:40.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:00:40.313+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:40.312+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:00:40.632+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.787 seconds
[2022-12-17T04:00:51.162+0000] {processor.py:154} INFO - Started process (PID=422) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:51.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:00:51.186+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:51.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:51.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:00:51.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:51.706+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:00:51.914+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:00:51.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:00:52.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.962 seconds
[2022-12-17T04:01:02.665+0000] {processor.py:154} INFO - Started process (PID=439) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:02.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:02.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:02.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:02.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:03.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:03.077+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:01:03.235+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:03.234+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:01:03.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.754 seconds
[2022-12-17T04:01:14.143+0000] {processor.py:154} INFO - Started process (PID=449) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:14.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:14.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:14.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:14.272+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:14.621+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:14.620+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:01:14.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:14.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:01:14.868+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-17T04:01:25.212+0000] {processor.py:154} INFO - Started process (PID=459) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:25.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:25.269+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:25.268+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:25.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:25.562+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:25.561+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:01:25.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:25.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:01:25.807+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.610 seconds
[2022-12-17T04:01:36.066+0000] {processor.py:154} INFO - Started process (PID=469) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:36.138+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:36.144+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:36.143+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:36.229+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:36.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:36.431+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:01:36.573+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:36.572+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:01:36.709+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-17T04:01:47.208+0000] {processor.py:154} INFO - Started process (PID=487) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:47.251+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:47.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:47.270+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:47.445+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:48.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:48.081+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:01:48.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:48.366+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:01:48.655+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.482 seconds
[2022-12-17T04:01:58.974+0000] {processor.py:154} INFO - Started process (PID=497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:59.019+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:01:59.024+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:01:59.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:01:59.107+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:00.079+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:02:10.431+0000] {processor.py:154} INFO - Started process (PID=507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:10.480+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:02:10.485+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:10.484+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:10.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:10.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:10.794+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:02:10.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:10.929+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:02:11.039+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.621 seconds
[2022-12-17T04:02:21.489+0000] {processor.py:154} INFO - Started process (PID=524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:21.546+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:02:21.568+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:21.557+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:21.800+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:22.490+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:22.489+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:02:22.829+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:22.828+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:02:23.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.556 seconds
[2022-12-17T04:02:33.415+0000] {processor.py:154} INFO - Started process (PID=535) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:33.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:02:33.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:33.439+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:33.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:34.280+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:02:44.631+0000] {processor.py:154} INFO - Started process (PID=545) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:44.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:02:44.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:44.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:44.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:45.129+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:45.128+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:02:45.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:45.261+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:02:45.368+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.751 seconds
[2022-12-17T04:02:56.225+0000] {processor.py:154} INFO - Started process (PID=555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:56.283+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:02:56.287+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:02:56.286+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:56.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:02:58.116+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:03:08.463+0000] {processor.py:154} INFO - Started process (PID=573) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:08.494+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:03:08.506+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:08.505+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:08.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:09.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:09.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:03:10.161+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:10.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:03:10.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.157 seconds
[2022-12-17T04:03:21.220+0000] {processor.py:154} INFO - Started process (PID=583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:21.230+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:03:21.234+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:21.233+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:21.400+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:22.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:22.063+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:03:22.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:22.335+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:03:22.557+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.359 seconds
[2022-12-17T04:03:32.976+0000] {processor.py:154} INFO - Started process (PID=593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:32.979+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:03:32.983+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:32.982+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:33.079+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:33.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:33.329+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:03:33.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:33.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:03:33.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.716 seconds
[2022-12-17T04:03:44.075+0000] {processor.py:154} INFO - Started process (PID=603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:44.103+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:03:44.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:44.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:44.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:45.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:45.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:03:45.966+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:45.965+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:03:46.188+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.144 seconds
[2022-12-17T04:03:56.682+0000] {processor.py:154} INFO - Started process (PID=621) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:56.708+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:03:56.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:56.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:57.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:03:57.736+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:57.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:03:58.182+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:03:58.181+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:03:58.482+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.843 seconds
[2022-12-17T04:04:09.318+0000] {processor.py:154} INFO - Started process (PID=631) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:09.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:04:09.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:09.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:09.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:10.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:10.277+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:04:10.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:10.545+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:04:10.880+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.591 seconds
[2022-12-17T04:04:21.290+0000] {processor.py:154} INFO - Started process (PID=641) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:21.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:04:21.336+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:21.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:21.474+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:22.737+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:04:33.572+0000] {processor.py:154} INFO - Started process (PID=651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:33.577+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:04:33.584+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:33.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:33.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:35.245+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:04:46.164+0000] {processor.py:154} INFO - Started process (PID=669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:46.167+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:04:46.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:46.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:46.481+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:47.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:47.489+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:04:47.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:47.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:04:48.197+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.083 seconds
[2022-12-17T04:04:58.949+0000] {processor.py:154} INFO - Started process (PID=679) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:58.981+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:04:58.985+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:58.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:59.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:04:59.600+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:59.594+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:04:59.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:04:59.797+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:04:59.959+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-17T04:05:10.322+0000] {processor.py:154} INFO - Started process (PID=689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:10.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:05:10.341+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:10.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:10.635+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:11.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:11.066+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:05:11.398+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:11.397+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:05:11.588+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.287 seconds
[2022-12-17T04:05:22.084+0000] {processor.py:154} INFO - Started process (PID=699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:22.088+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:05:22.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:22.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:22.233+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:22.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:22.581+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:05:22.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:22.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:05:22.921+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-17T04:05:33.986+0000] {processor.py:154} INFO - Started process (PID=717) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:34.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:05:34.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:34.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:34.862+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:35.650+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:35.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:05:36.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:36.265+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:05:36.643+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.782 seconds
[2022-12-17T04:05:47.507+0000] {processor.py:154} INFO - Started process (PID=727) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:47.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:05:47.528+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:47.527+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:47.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:05:48.817+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:48.816+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:05:49.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:05:49.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:05:49.700+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.227 seconds
[2022-12-17T04:06:00.246+0000] {processor.py:154} INFO - Started process (PID=737) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:00.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:06:00.291+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:00.290+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:00.626+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:02.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:02.031+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:06:02.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:02.690+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:06:03.209+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.987 seconds
[2022-12-17T04:06:14.308+0000] {processor.py:154} INFO - Started process (PID=747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:14.344+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:06:14.360+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:14.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:14.686+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:15.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:15.275+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:06:15.795+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:15.794+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:06:16.140+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.970 seconds
[2022-12-17T04:06:27.033+0000] {processor.py:154} INFO - Started process (PID=763) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:27.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:06:27.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:27.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:28.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:29.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:29.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:06:30.258+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:30.257+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:06:31.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 4.352 seconds
[2022-12-17T04:06:42.886+0000] {processor.py:154} INFO - Started process (PID=773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:42.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:06:43.000+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:43.000+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:44.285+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:06:47.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:47.072+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:06:48.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:06:48.202+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:06:49.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 6.654 seconds
[2022-12-17T04:07:00.732+0000] {processor.py:154} INFO - Started process (PID=783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:00.774+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:07:00.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:00.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:01.870+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:04.072+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:04.071+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:07:05.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:05.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:07:07.283+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 6.689 seconds
[2022-12-17T04:07:18.166+0000] {processor.py:154} INFO - Started process (PID=795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:18.175+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:07:18.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:18.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:18.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:19.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:19.073+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:07:19.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:19.354+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:07:19.566+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.440 seconds
[2022-12-17T04:07:30.377+0000] {processor.py:154} INFO - Started process (PID=811) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:30.416+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:07:30.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:30.434+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:30.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:32.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:32.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:07:32.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:32.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:07:33.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.073 seconds
[2022-12-17T04:07:43.950+0000] {processor.py:154} INFO - Started process (PID=821) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:43.977+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:07:43.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:43.981+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:44.188+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:44.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:44.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:07:44.768+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:44.766+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:07:45.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.313 seconds
[2022-12-17T04:07:55.630+0000] {processor.py:154} INFO - Started process (PID=831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:55.646+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:07:55.666+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:55.665+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:55.936+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:07:56.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:56.577+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:07:57.246+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:07:57.245+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:07:57.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.202 seconds
[2022-12-17T04:08:08.257+0000] {processor.py:154} INFO - Started process (PID=838) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:08.287+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:08:08.291+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:08.290+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:08.415+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:09.790+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:08:20.387+0000] {processor.py:154} INFO - Started process (PID=856) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:20.442+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:08:20.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:20.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:20.880+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:22.130+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:22.129+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:08:22.897+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:22.858+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:08:23.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.088 seconds
[2022-12-17T04:08:34.097+0000] {processor.py:154} INFO - Started process (PID=866) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:34.146+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:08:34.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:34.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:34.349+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:35.216+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:35.215+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:08:35.403+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:35.401+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:08:35.641+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.593 seconds
[2022-12-17T04:08:46.144+0000] {processor.py:154} INFO - Started process (PID=876) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:46.190+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:08:46.198+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:46.197+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:46.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:46.963+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:46.962+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:08:47.189+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:47.188+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:08:47.332+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.254 seconds
[2022-12-17T04:08:57.698+0000] {processor.py:154} INFO - Started process (PID=886) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:57.715+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:08:57.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:57.719+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:57.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:08:58.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:58.072+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:08:58.457+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:08:58.456+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:08:58.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.024 seconds
[2022-12-17T04:09:09.397+0000] {processor.py:154} INFO - Started process (PID=903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:09.409+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:09:09.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:09.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:09.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:09.890+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:09.889+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:09:10.116+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:10.115+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:09:10.364+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.993 seconds
[2022-12-17T04:09:20.807+0000] {processor.py:154} INFO - Started process (PID=913) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:20.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:09:20.852+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:20.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:20.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:21.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:21.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:09:21.862+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:21.861+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:09:22.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.219 seconds
[2022-12-17T04:09:32.301+0000] {processor.py:154} INFO - Started process (PID=923) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:32.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:09:32.331+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:32.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:32.440+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:33.087+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:33.086+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:09:33.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:33.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:09:33.366+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.078 seconds
[2022-12-17T04:09:43.723+0000] {processor.py:154} INFO - Started process (PID=933) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:43.777+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:09:43.782+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:43.781+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:43.885+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:44.598+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:44.597+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:09:44.919+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:44.918+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:09:45.248+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.544 seconds
[2022-12-17T04:09:55.776+0000] {processor.py:154} INFO - Started process (PID=951) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:55.848+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:09:55.852+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:55.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:55.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:09:57.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:57.602+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:09:57.732+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:09:57.731+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:09:57.862+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.099 seconds
[2022-12-17T04:10:08.124+0000] {processor.py:154} INFO - Started process (PID=961) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:08.142+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:10:08.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:08.145+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:08.225+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:08.436+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:08.435+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:10:08.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:08.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:10:08.741+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.630 seconds
[2022-12-17T04:10:19.060+0000] {processor.py:154} INFO - Started process (PID=971) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:19.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:10:19.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:19.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:19.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:19.447+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:19.446+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:10:19.661+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:19.660+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:10:19.774+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.727 seconds
[2022-12-17T04:10:30.143+0000] {processor.py:154} INFO - Started process (PID=989) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:30.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:10:30.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:30.183+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:30.294+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:30.551+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:30.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:10:30.737+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:30.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:10:30.937+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.825 seconds
[2022-12-17T04:10:41.450+0000] {processor.py:154} INFO - Started process (PID=999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:41.461+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:10:41.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:41.468+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:41.686+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:41.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:41.940+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:10:42.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:42.075+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:10:42.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.778 seconds
[2022-12-17T04:10:52.486+0000] {processor.py:154} INFO - Started process (PID=1009) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:52.516+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:10:52.524+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:52.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:52.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:10:54.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:54.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:10:54.465+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:10:54.464+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:10:54.606+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.138 seconds
[2022-12-17T04:11:04.897+0000] {processor.py:154} INFO - Started process (PID=1019) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:04.910+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:11:04.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:04.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:04.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:05.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:05.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:11:05.367+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:05.366+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:11:05.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.603 seconds
[2022-12-17T04:11:16.002+0000] {processor.py:154} INFO - Started process (PID=1038) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:16.016+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:11:16.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:16.033+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:16.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:17.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:17.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:11:17.233+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:17.232+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:11:17.376+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.425 seconds
[2022-12-17T04:11:27.700+0000] {processor.py:154} INFO - Started process (PID=1048) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:27.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:11:27.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:27.712+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:27.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:28.530+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:11:38.899+0000] {processor.py:154} INFO - Started process (PID=1058) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:38.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:11:38.952+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:38.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:39.216+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:40.382+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:11:51.001+0000] {processor.py:154} INFO - Started process (PID=1076) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:51.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:11:51.072+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:51.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:51.211+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:11:51.496+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:51.494+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:11:51.676+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:11:51.675+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:11:51.796+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.838 seconds
[2022-12-17T04:12:02.386+0000] {processor.py:154} INFO - Started process (PID=1086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:02.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:12:02.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:02.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:02.534+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:02.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:02.821+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:12:02.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:02.977+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:12:03.090+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.756 seconds
[2022-12-17T04:12:13.990+0000] {processor.py:154} INFO - Started process (PID=1096) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:14.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:12:14.024+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:14.020+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:14.132+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:15.002+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:12:25.304+0000] {processor.py:154} INFO - Started process (PID=1106) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:25.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:12:25.315+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:25.314+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:25.546+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:26.395+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:12:36.673+0000] {processor.py:154} INFO - Started process (PID=1124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:36.778+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:12:36.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:36.784+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:37.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:38.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:38.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:12:38.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:38.274+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:12:38.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.771 seconds
[2022-12-17T04:12:49.089+0000] {processor.py:154} INFO - Started process (PID=1134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:49.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:12:49.167+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:49.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:49.249+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:12:50.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:50.551+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:12:50.687+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:12:50.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:12:50.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.750 seconds
[2022-12-17T04:13:01.646+0000] {processor.py:154} INFO - Started process (PID=1144) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:01.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:01.653+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:01.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:01.736+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:02.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:02.204+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:13:02.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:02.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:13:02.459+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.828 seconds
[2022-12-17T04:13:12.721+0000] {processor.py:154} INFO - Started process (PID=1162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:12.725+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:12.733+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:12.731+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:12.830+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:14.305+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:13:24.748+0000] {processor.py:154} INFO - Started process (PID=1172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:24.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:24.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:24.780+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:24.895+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:25.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:25.347+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:13:25.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:25.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:13:25.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.049 seconds
[2022-12-17T04:13:36.105+0000] {processor.py:154} INFO - Started process (PID=1182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:36.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:36.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:36.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:36.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:36.501+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:36.500+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:13:36.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:36.640+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:13:36.760+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.671 seconds
[2022-12-17T04:13:47.017+0000] {processor.py:154} INFO - Started process (PID=1192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:47.020+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:47.024+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:47.023+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:47.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:47.340+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:47.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:13:47.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:47.469+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:13:47.590+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.587 seconds
[2022-12-17T04:13:58.106+0000] {processor.py:154} INFO - Started process (PID=1210) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:58.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:13:58.164+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:58.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:58.323+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:13:58.593+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:58.592+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:13:58.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:13:58.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:13:59.033+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.985 seconds
[2022-12-17T04:14:09.404+0000] {processor.py:154} INFO - Started process (PID=1220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:09.436+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:14:09.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:09.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:09.551+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:10.770+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:14:21.685+0000] {processor.py:154} INFO - Started process (PID=1230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:21.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:14:21.693+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:21.692+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:21.780+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:21.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:21.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:14:22.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:22.121+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:14:22.252+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.579 seconds
[2022-12-17T04:14:32.581+0000] {processor.py:154} INFO - Started process (PID=1248) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:32.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:14:32.594+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:32.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:32.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:33.704+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:33.702+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:14:33.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:33.903+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:14:34.054+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.508 seconds
[2022-12-17T04:14:44.442+0000] {processor.py:154} INFO - Started process (PID=1259) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:44.446+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:14:44.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:44.449+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:44.532+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:44.739+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:44.738+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:14:44.888+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:44.887+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:14:45.043+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.615 seconds
[2022-12-17T04:14:55.299+0000] {processor.py:154} INFO - Started process (PID=1269) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:55.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:14:55.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:55.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:55.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:14:55.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:55.694+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:14:55.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:14:55.853+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:14:55.960+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.675 seconds
[2022-12-17T04:15:06.386+0000] {processor.py:154} INFO - Started process (PID=1279) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:06.445+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:15:06.450+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:06.449+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:06.557+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:06.826+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:06.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:15:06.974+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:06.973+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:15:07.094+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.768 seconds
[2022-12-17T04:15:17.468+0000] {processor.py:154} INFO - Started process (PID=1297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:17.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:15:17.501+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:17.500+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:17.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:18.043+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:18.042+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:15:18.317+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:18.316+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:15:18.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.191 seconds
[2022-12-17T04:15:29.020+0000] {processor.py:154} INFO - Started process (PID=1307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:29.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:15:29.065+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:29.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:29.150+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:29.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:29.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:15:30.249+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:30.248+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:15:30.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.351 seconds
[2022-12-17T04:15:40.638+0000] {processor.py:154} INFO - Started process (PID=1317) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:40.743+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:15:40.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:40.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:41.001+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:41.363+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:41.362+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:15:41.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:41.629+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:15:41.783+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.159 seconds
[2022-12-17T04:15:52.142+0000] {processor.py:154} INFO - Started process (PID=1327) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:52.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:15:52.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:15:52.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:52.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:15:53.854+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:16:04.129+0000] {processor.py:154} INFO - Started process (PID=1345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:04.158+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:16:04.162+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:04.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:04.294+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:04.756+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:04.754+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:16:04.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:04.937+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:16:05.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.968 seconds
[2022-12-17T04:16:15.315+0000] {processor.py:154} INFO - Started process (PID=1355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:15.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:16:15.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:15.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:15.410+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:16.896+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:16:27.228+0000] {processor.py:154} INFO - Started process (PID=1365) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:27.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:16:27.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:27.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:27.646+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:28.461+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:28.460+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:16:28.636+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:28.635+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:16:28.764+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.555 seconds
[2022-12-17T04:16:39.332+0000] {processor.py:154} INFO - Started process (PID=1383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:39.361+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:16:39.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:39.364+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:39.651+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:40.239+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:40.238+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:16:40.404+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:40.403+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:16:40.665+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.378 seconds
[2022-12-17T04:16:51.041+0000] {processor.py:154} INFO - Started process (PID=1393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:51.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:16:51.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:51.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:51.170+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:16:51.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:51.929+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:16:52.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:16:52.057+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:16:52.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.167 seconds
[2022-12-17T04:17:02.505+0000] {processor.py:154} INFO - Started process (PID=1403) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:02.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:17:02.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:02.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:02.639+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:02.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:02.877+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:17:03.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:03.020+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:17:03.142+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T04:17:13.670+0000] {processor.py:154} INFO - Started process (PID=1419) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:13.687+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:17:13.691+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:13.690+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:13.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:14.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:14.799+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:17:14.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:14.977+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:17:15.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.577 seconds
[2022-12-17T04:17:25.873+0000] {processor.py:154} INFO - Started process (PID=1431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:25.889+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:17:25.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:25.895+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:26.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:27.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:27.313+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:17:27.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:27.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:17:27.627+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.868 seconds
[2022-12-17T04:17:38.154+0000] {processor.py:154} INFO - Started process (PID=1441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:38.158+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:17:38.162+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:38.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:38.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:38.445+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:38.444+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:17:38.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:38.978+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:17:39.196+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.058 seconds
[2022-12-17T04:17:49.525+0000] {processor.py:154} INFO - Started process (PID=1451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:49.553+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:17:49.561+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:49.560+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:49.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:17:49.874+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:49.872+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:17:50.013+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:17:50.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:17:50.124+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.627 seconds
[2022-12-17T04:18:00.658+0000] {processor.py:154} INFO - Started process (PID=1468) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:00.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:00.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:00.699+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:01.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:01.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:01.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:18:01.959+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:01.958+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:18:02.648+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.049 seconds
[2022-12-17T04:18:13.040+0000] {processor.py:154} INFO - Started process (PID=1478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:13.066+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:13.070+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:13.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:13.153+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:14.654+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:18:24.956+0000] {processor.py:154} INFO - Started process (PID=1488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:24.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:25.004+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:25.003+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:25.109+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:25.816+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:18:36.249+0000] {processor.py:154} INFO - Started process (PID=1505) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:36.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:36.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:36.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:36.422+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:36.787+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:36.786+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:18:36.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:36.959+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:18:37.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.902 seconds
[2022-12-17T04:18:47.872+0000] {processor.py:154} INFO - Started process (PID=1516) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:47.876+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:47.880+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:47.879+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:47.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:48.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:48.183+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:18:48.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:48.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:18:48.439+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.582 seconds
[2022-12-17T04:18:58.804+0000] {processor.py:154} INFO - Started process (PID=1526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:58.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:18:58.817+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:18:58.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:58.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:18:59.857+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:19:10.212+0000] {processor.py:154} INFO - Started process (PID=1536) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:10.255+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:19:10.260+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:10.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:10.353+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:10.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:10.798+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:19:10.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:10.933+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:19:11.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.880 seconds
[2022-12-17T04:19:21.404+0000] {processor.py:154} INFO - Started process (PID=1554) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:21.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:19:21.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:21.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:21.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:22.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:22.693+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:19:22.917+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:22.916+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:19:23.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.812 seconds
[2022-12-17T04:19:33.581+0000] {processor.py:154} INFO - Started process (PID=1564) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:33.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:19:33.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:33.627+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:33.711+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:33.966+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:33.965+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:19:34.127+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:34.126+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:19:34.257+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.704 seconds
[2022-12-17T04:19:45.028+0000] {processor.py:154} INFO - Started process (PID=1574) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:45.080+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:19:45.085+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:45.084+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:45.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:45.944+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:19:56.296+0000] {processor.py:154} INFO - Started process (PID=1590) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:56.311+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:19:56.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:19:56.318+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:56.422+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:19:58.038+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:20:08.691+0000] {processor.py:154} INFO - Started process (PID=1604) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:08.700+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:20:08.710+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:08.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:08.824+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:09.129+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:09.128+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:20:09.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:09.289+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:20:09.411+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.740 seconds
[2022-12-17T04:20:19.632+0000] {processor.py:154} INFO - Started process (PID=1611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:19.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:20:19.645+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:19.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:19.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:20.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:20.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:20:20.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:20.507+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:20:20.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.035 seconds
[2022-12-17T04:20:31.102+0000] {processor.py:154} INFO - Started process (PID=1621) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:31.128+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:20:31.141+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:31.141+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:31.317+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:31.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:31.754+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:20:32.068+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:32.067+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:20:32.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.368 seconds
[2022-12-17T04:20:42.819+0000] {processor.py:154} INFO - Started process (PID=1639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:42.830+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:20:42.840+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:42.838+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:43.137+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:45.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:45.239+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:20:45.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:45.508+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:20:45.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.998 seconds
[2022-12-17T04:20:56.089+0000] {processor.py:154} INFO - Started process (PID=1649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:56.138+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:20:56.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:56.149+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:56.248+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:20:56.503+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:56.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:20:56.677+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:20:56.677+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:20:56.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.719 seconds
[2022-12-17T04:21:07.105+0000] {processor.py:154} INFO - Started process (PID=1659) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:07.131+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:21:07.136+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:07.135+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:07.219+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:08.081+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:08.080+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:21:08.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:08.297+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:21:08.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.332 seconds
[2022-12-17T04:21:18.845+0000] {processor.py:154} INFO - Started process (PID=1669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:18.916+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:21:18.920+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:18.919+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:19.083+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:20.499+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:20.498+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:21:21.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:21.032+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:21:21.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.650 seconds
[2022-12-17T04:21:31.936+0000] {processor.py:154} INFO - Started process (PID=1692) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:31.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:21:31.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:31.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:32.029+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:32.385+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:21:43.158+0000] {processor.py:154} INFO - Started process (PID=1702) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:43.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:21:43.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:43.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:43.250+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:43.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:43.471+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:21:43.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:43.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:21:44.111+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.969 seconds
[2022-12-17T04:21:54.641+0000] {processor.py:154} INFO - Started process (PID=1712) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:54.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:21:54.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:54.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:54.853+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:21:55.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:55.622+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:21:55.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:21:55.768+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:21:55.941+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.345 seconds
[2022-12-17T04:22:06.526+0000] {processor.py:154} INFO - Started process (PID=1730) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:06.554+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:22:06.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:06.557+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:06.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:07.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:07.289+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:22:07.841+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:07.840+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:22:08.287+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.776 seconds
[2022-12-17T04:22:18.698+0000] {processor.py:154} INFO - Started process (PID=1740) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:18.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:22:18.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:18.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:18.820+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:20.100+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:22:31.085+0000] {processor.py:154} INFO - Started process (PID=1750) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:31.089+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:22:31.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:31.092+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:31.194+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:31.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:31.434+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:22:31.581+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:31.580+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:22:31.721+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.652 seconds
[2022-12-17T04:22:42.260+0000] {processor.py:154} INFO - Started process (PID=1766) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:42.263+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:22:42.267+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:42.266+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:42.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:43.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:43.037+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:22:43.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:43.262+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:22:43.521+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.333 seconds
[2022-12-17T04:22:54.020+0000] {processor.py:154} INFO - Started process (PID=1777) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:54.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:22:54.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:54.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:54.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:22:54.577+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:54.575+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:22:54.809+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:22:54.808+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:22:54.924+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.928 seconds
[2022-12-17T04:23:05.256+0000] {processor.py:154} INFO - Started process (PID=1787) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:05.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:23:05.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:05.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:05.359+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:06.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:06.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:23:07.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:07.151+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:23:07.290+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.049 seconds
[2022-12-17T04:23:17.574+0000] {processor.py:154} INFO - Started process (PID=1797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:17.601+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:23:17.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:17.606+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:17.700+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:18.111+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:18.110+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:23:18.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:18.261+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:23:18.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.851 seconds
[2022-12-17T04:23:28.947+0000] {processor.py:154} INFO - Started process (PID=1814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:28.969+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:23:28.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:28.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:29.184+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:30.080+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:23:40.683+0000] {processor.py:154} INFO - Started process (PID=1824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:40.701+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:23:40.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:40.706+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:40.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:41.260+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:41.258+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:23:41.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:41.414+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:23:41.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.873 seconds
[2022-12-17T04:23:51.980+0000] {processor.py:154} INFO - Started process (PID=1834) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:52.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:23:52.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:52.033+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:52.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:23:52.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:52.327+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:23:52.456+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:23:52.455+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:23:52.614+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.677 seconds
[2022-12-17T04:24:03.139+0000] {processor.py:154} INFO - Started process (PID=1851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:03.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:24:03.181+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:03.180+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:03.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:04.903+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:04.902+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:24:05.211+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:05.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:24:05.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.311 seconds
[2022-12-17T04:24:15.863+0000] {processor.py:154} INFO - Started process (PID=1862) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:15.962+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:24:15.967+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:15.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:16.051+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:16.820+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:16.819+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:24:16.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:16.996+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:24:17.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.334 seconds
[2022-12-17T04:24:27.397+0000] {processor.py:154} INFO - Started process (PID=1872) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:27.419+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:24:27.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:27.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:27.504+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:27.965+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:27.964+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:24:28.099+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:28.098+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:24:28.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.848 seconds
[2022-12-17T04:24:38.531+0000] {processor.py:154} INFO - Started process (PID=1882) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:38.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:24:38.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:38.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:38.635+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:38.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:38.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:24:39.106+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:39.106+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:24:39.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-17T04:24:49.500+0000] {processor.py:154} INFO - Started process (PID=1900) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:49.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:24:49.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:49.519+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:49.859+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:24:50.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:50.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:24:50.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:24:50.450+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:24:50.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.218 seconds
[2022-12-17T04:25:01.015+0000] {processor.py:154} INFO - Started process (PID=1910) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:01.073+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:01.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:01.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:01.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:02.459+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:25:12.914+0000] {processor.py:154} INFO - Started process (PID=1920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:13.020+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:13.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:13.026+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:13.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:13.795+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:25:24.253+0000] {processor.py:154} INFO - Started process (PID=1930) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:24.261+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:24.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:24.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:24.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:25.226+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:25:35.576+0000] {processor.py:154} INFO - Started process (PID=1948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:35.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:35.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:35.634+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:35.853+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:37.115+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:37.114+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:25:37.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:37.246+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:25:37.433+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.889 seconds
[2022-12-17T04:25:47.787+0000] {processor.py:154} INFO - Started process (PID=1958) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:47.818+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:47.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:47.822+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:47.935+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:48.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:48.782+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:25:48.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:48.969+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:25:49.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.334 seconds
[2022-12-17T04:25:59.334+0000] {processor.py:154} INFO - Started process (PID=1968) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:59.489+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:25:59.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:25:59.496+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:25:59.631+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:00.619+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:00.618+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:26:00.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:00.747+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:26:00.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.588 seconds
[2022-12-17T04:26:11.505+0000] {processor.py:154} INFO - Started process (PID=1986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:11.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:26:11.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:11.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:11.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:12.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:12.629+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:26:12.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:12.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:26:12.918+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.475 seconds
[2022-12-17T04:26:23.204+0000] {processor.py:154} INFO - Started process (PID=1996) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:23.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:26:23.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:23.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:23.350+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:23.651+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:23.650+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:26:23.797+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:23.796+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:26:23.912+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.729 seconds
[2022-12-17T04:26:34.208+0000] {processor.py:154} INFO - Started process (PID=2006) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:34.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:26:34.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:34.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:34.412+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:26:34.739+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:34.738+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:26:34.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:26:34.908+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:26:35.025+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.831 seconds
[2022-12-17T04:27:23.017+0000] {processor.py:154} INFO - Started process (PID=167) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:23.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:27:23.054+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:23.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:23.345+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:25.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:25.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:27:25.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:25.506+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:27:25.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.009 seconds
[2022-12-17T04:27:36.375+0000] {processor.py:154} INFO - Started process (PID=184) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:36.379+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:27:36.383+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:36.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:36.472+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:38.009+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:38.008+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:27:38.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:38.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:27:38.672+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.310 seconds
[2022-12-17T04:27:48.952+0000] {processor.py:154} INFO - Started process (PID=194) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:48.981+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:27:48.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:48.988+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:49.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:27:49.964+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:49.963+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:27:50.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:27:50.177+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:27:50.389+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.455 seconds
[2022-12-17T04:28:00.694+0000] {processor.py:154} INFO - Started process (PID=204) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:00.716+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:00.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:00.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:00.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:01.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:01.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:28:01.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:01.192+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:28:01.473+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.792 seconds
[2022-12-17T04:28:11.907+0000] {processor.py:154} INFO - Started process (PID=222) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:11.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:11.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:11.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:12.054+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:12.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:12.581+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:28:12.887+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:12.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:28:13.349+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.456 seconds
[2022-12-17T04:28:23.789+0000] {processor.py:154} INFO - Started process (PID=232) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:23.805+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:23.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:23.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:23.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:24.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:24.365+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:28:24.619+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:24.618+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:28:24.831+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.054 seconds
[2022-12-17T04:28:35.112+0000] {processor.py:154} INFO - Started process (PID=242) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:35.154+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:35.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:35.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:35.257+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:35.688+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:35.687+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:28:35.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:35.923+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:28:36.269+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.170 seconds
[2022-12-17T04:28:46.646+0000] {processor.py:154} INFO - Started process (PID=261) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:46.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:46.666+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:46.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:46.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:48.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:48.130+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:28:48.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:48.369+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:28:48.510+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.899 seconds
[2022-12-17T04:28:59.214+0000] {processor.py:154} INFO - Started process (PID=271) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:59.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:28:59.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:28:59.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:28:59.726+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:00.417+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:00.416+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:29:00.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:00.578+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:29:00.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.550 seconds
[2022-12-17T04:29:11.109+0000] {processor.py:154} INFO - Started process (PID=281) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:11.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:29:11.141+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:11.140+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:11.292+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:11.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:11.795+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:29:11.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:11.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:29:12.066+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.016 seconds
[2022-12-17T04:29:22.392+0000] {processor.py:154} INFO - Started process (PID=291) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:22.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:29:22.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:22.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:22.558+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:22.809+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:22.808+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:29:22.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:22.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:29:23.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.695 seconds
[2022-12-17T04:29:33.752+0000] {processor.py:154} INFO - Started process (PID=309) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:33.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:29:33.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:33.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:34.403+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:34.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:34.888+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:29:35.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:35.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:29:35.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.666 seconds
[2022-12-17T04:29:45.865+0000] {processor.py:154} INFO - Started process (PID=319) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:45.882+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:29:45.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:45.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:46.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:46.388+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:46.387+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:29:46.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:46.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:29:46.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.903 seconds
[2022-12-17T04:29:56.968+0000] {processor.py:154} INFO - Started process (PID=329) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:56.977+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:29:56.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:29:56.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:57.165+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:29:58.171+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:30:08.600+0000] {processor.py:154} INFO - Started process (PID=347) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:08.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:30:08.657+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:08.656+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:08.786+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:09.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:09.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:30:09.892+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:09.891+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:30:10.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.449 seconds
[2022-12-17T04:30:20.145+0000] {processor.py:154} INFO - Started process (PID=357) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:20.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:30:20.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:20.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:20.242+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:21.154+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:21.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:30:21.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:21.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:30:21.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.475 seconds
[2022-12-17T04:30:32.451+0000] {processor.py:154} INFO - Started process (PID=367) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:32.472+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:30:32.489+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:32.486+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:32.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:33.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:33.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:30:33.620+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:33.619+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:30:33.738+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.316 seconds
[2022-12-17T04:30:44.092+0000] {processor.py:154} INFO - Started process (PID=377) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:44.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:30:44.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:44.108+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:44.280+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:45.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:45.903+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:30:46.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:46.096+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:30:46.230+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.174 seconds
[2022-12-17T04:30:56.779+0000] {processor.py:154} INFO - Started process (PID=395) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:56.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:30:56.845+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:56.844+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:57.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:30:57.678+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:57.677+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:30:57.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:30:57.977+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:30:58.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.544 seconds
[2022-12-17T04:31:08.622+0000] {processor.py:154} INFO - Started process (PID=405) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:08.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:31:08.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:08.669+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:08.755+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:10.027+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:31:20.861+0000] {processor.py:154} INFO - Started process (PID=415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:20.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:31:20.891+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:20.890+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:20.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:22.045+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:31:32.654+0000] {processor.py:154} INFO - Started process (PID=432) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:32.671+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:31:32.675+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:32.674+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:32.788+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:33.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:33.033+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:31:33.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:33.179+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:31:33.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.730 seconds
[2022-12-17T04:31:43.666+0000] {processor.py:154} INFO - Started process (PID=442) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:43.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:31:43.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:43.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:43.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:44.016+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:44.015+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:31:44.144+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:44.143+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:31:44.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.638 seconds
[2022-12-17T04:31:54.633+0000] {processor.py:154} INFO - Started process (PID=452) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:54.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:31:54.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:54.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:54.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:31:54.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:54.988+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:31:55.136+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:31:55.136+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:31:55.270+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T04:32:05.579+0000] {processor.py:154} INFO - Started process (PID=462) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:05.593+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:32:05.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:05.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:05.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:06.428+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:06.419+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:32:06.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:06.669+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:32:06.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.226 seconds
[2022-12-17T04:32:17.211+0000] {processor.py:154} INFO - Started process (PID=480) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:17.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:32:17.264+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:17.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:17.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:18.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:18.174+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:32:18.450+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:18.449+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:32:18.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.512 seconds
[2022-12-17T04:32:29.268+0000] {processor.py:154} INFO - Started process (PID=490) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:29.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:32:29.406+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:29.405+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:29.600+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:30.483+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:30.482+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:32:30.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:30.665+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:32:30.812+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.560 seconds
[2022-12-17T04:32:41.644+0000] {processor.py:154} INFO - Started process (PID=500) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:41.691+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:32:41.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:41.695+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:41.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:42.007+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:42.006+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:32:42.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:42.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:32:42.458+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.829 seconds
[2022-12-17T04:32:53.047+0000] {processor.py:154} INFO - Started process (PID=519) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:53.074+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:32:53.081+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:53.081+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:53.190+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:32:53.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:53.431+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:32:53.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:32:53.590+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:32:53.766+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.764 seconds
[2022-12-17T04:33:04.833+0000] {processor.py:154} INFO - Started process (PID=529) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:04.836+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:33:04.840+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:04.839+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:04.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:05.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:05.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:33:05.263+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:05.262+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:33:05.385+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-17T04:33:15.680+0000] {processor.py:154} INFO - Started process (PID=539) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:15.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:33:15.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:15.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:15.797+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:16.555+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:16.554+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:33:16.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:16.701+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:33:16.832+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.165 seconds
[2022-12-17T04:33:27.124+0000] {processor.py:154} INFO - Started process (PID=549) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:27.178+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:33:27.182+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:27.181+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:27.269+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:27.600+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:27.599+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:33:27.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:27.742+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:33:28.177+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.067 seconds
[2022-12-17T04:33:38.530+0000] {processor.py:154} INFO - Started process (PID=566) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:38.613+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:33:38.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:38.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:38.845+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:39.617+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:33:50.176+0000] {processor.py:154} INFO - Started process (PID=576) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:50.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:33:50.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:50.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:50.322+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:33:50.551+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:50.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:33:50.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:33:50.718+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:33:50.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.743 seconds
[2022-12-17T04:34:01.117+0000] {processor.py:154} INFO - Started process (PID=586) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:01.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:01.134+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:01.133+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:01.219+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:01.617+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:01.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:34:01.747+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:01.746+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:34:01.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-17T04:34:12.906+0000] {processor.py:154} INFO - Started process (PID=603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:12.941+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:12.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:12.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:13.118+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:13.607+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:34:24.322+0000] {processor.py:154} INFO - Started process (PID=614) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:24.343+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:24.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:24.346+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:24.498+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:24.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:24.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:34:24.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:24.971+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:34:25.110+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.811 seconds
[2022-12-17T04:34:35.363+0000] {processor.py:154} INFO - Started process (PID=624) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:35.413+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:35.417+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:35.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:35.510+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:36.204+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:36.203+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:34:36.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:36.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:34:36.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.216 seconds
[2022-12-17T04:34:46.804+0000] {processor.py:154} INFO - Started process (PID=634) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:46.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:46.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:46.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:47.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:48.118+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:48.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:34:48.259+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:48.258+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:34:48.412+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.621 seconds
[2022-12-17T04:34:58.929+0000] {processor.py:154} INFO - Started process (PID=651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:58.934+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:34:58.946+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:58.945+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:59.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:34:59.894+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:34:59.893+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:00.215+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:00.214+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:00.429+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.514 seconds
[2022-12-17T04:35:11.490+0000] {processor.py:154} INFO - Started process (PID=661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:11.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:35:11.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:11.496+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:11.589+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:12.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:12.313+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:12.456+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:12.455+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:12.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.109 seconds
[2022-12-17T04:35:22.845+0000] {processor.py:154} INFO - Started process (PID=671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:22.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:35:22.862+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:22.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:22.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:23.147+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:23.146+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:23.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:23.287+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:23.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.589 seconds
[2022-12-17T04:35:33.678+0000] {processor.py:154} INFO - Started process (PID=688) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:33.785+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:35:33.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:33.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:33.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:34.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:34.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:34.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:34.531+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:34.754+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.093 seconds
[2022-12-17T04:35:44.937+0000] {processor.py:154} INFO - Started process (PID=699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:44.941+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:35:44.945+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:44.944+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:45.034+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:45.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:45.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:45.407+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:45.406+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:45.544+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.621 seconds
[2022-12-17T04:35:55.802+0000] {processor.py:154} INFO - Started process (PID=709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:55.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:35:55.831+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:55.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:56.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:35:56.679+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:56.678+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:35:56.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:35:56.812+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:35:56.936+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.148 seconds
[2022-12-17T04:36:07.201+0000] {processor.py:154} INFO - Started process (PID=719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:07.232+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:36:07.240+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:07.235+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:07.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:08.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:08.026+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:36:08.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:08.156+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:36:08.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.116 seconds
[2022-12-17T04:36:18.755+0000] {processor.py:154} INFO - Started process (PID=736) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:18.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:36:18.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:18.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:18.962+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:19.682+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:19.681+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:36:19.828+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:19.828+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:36:20.020+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.296 seconds
[2022-12-17T04:36:30.348+0000] {processor.py:154} INFO - Started process (PID=746) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:30.396+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:36:30.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:30.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:30.507+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:30.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:30.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:36:30.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:30.924+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:36:31.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.706 seconds
[2022-12-17T04:36:41.251+0000] {processor.py:154} INFO - Started process (PID=756) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:41.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:36:41.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:41.300+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:41.397+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:42.055+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:42.054+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:36:42.182+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:42.181+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:36:42.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.070 seconds
[2022-12-17T04:36:52.635+0000] {processor.py:154} INFO - Started process (PID=766) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:52.857+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:36:52.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:36:52.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:52.967+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:36:54.092+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:37:04.736+0000] {processor.py:154} INFO - Started process (PID=783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:04.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:37:04.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:04.765+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:04.969+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:05.554+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:05.553+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:37:05.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:05.702+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:37:05.858+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.167 seconds
[2022-12-17T04:37:16.136+0000] {processor.py:154} INFO - Started process (PID=793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:16.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:37:16.176+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:16.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:16.287+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:16.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:16.510+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:37:16.673+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:16.672+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:37:16.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-17T04:37:27.232+0000] {processor.py:154} INFO - Started process (PID=803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:27.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:37:27.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:27.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:27.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:28.509+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:37:39.015+0000] {processor.py:154} INFO - Started process (PID=821) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:39.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:37:39.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:39.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:39.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:39.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:39.989+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:37:40.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:40.144+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:37:40.255+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.293 seconds
[2022-12-17T04:37:50.680+0000] {processor.py:154} INFO - Started process (PID=831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:50.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:37:50.752+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:50.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:50.891+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:37:51.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:51.166+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:37:51.307+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:37:51.306+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:37:51.469+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.840 seconds
[2022-12-17T04:38:01.721+0000] {processor.py:154} INFO - Started process (PID=841) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:01.724+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:38:01.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:01.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:01.811+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:02.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:02.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:38:02.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:02.414+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:38:02.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.974 seconds
[2022-12-17T04:38:13.035+0000] {processor.py:154} INFO - Started process (PID=851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:13.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:38:13.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:13.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:13.215+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:13.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:13.758+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:38:14.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:14.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:38:14.496+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.477 seconds
[2022-12-17T04:38:25.180+0000] {processor.py:154} INFO - Started process (PID=869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:25.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:38:25.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:25.211+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:25.425+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:26.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:26.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:38:26.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:26.875+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:38:27.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.153 seconds
[2022-12-17T04:38:37.649+0000] {processor.py:154} INFO - Started process (PID=879) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:37.706+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:38:37.710+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:37.709+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:37.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:38.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:38.026+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:38:38.170+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:38.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:38:38.415+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.793 seconds
[2022-12-17T04:38:48.670+0000] {processor.py:154} INFO - Started process (PID=889) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:48.710+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:38:48.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:48.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:48.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:38:49.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:49.073+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:38:49.227+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:38:49.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:38:49.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.692 seconds
[2022-12-17T04:39:00.127+0000] {processor.py:154} INFO - Started process (PID=906) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:00.181+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:00.189+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:00.188+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:00.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:01.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:01.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:39:02.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:02.194+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:39:02.433+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.336 seconds
[2022-12-17T04:39:13.063+0000] {processor.py:154} INFO - Started process (PID=917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:13.074+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:13.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:13.077+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:13.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:13.576+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:13.575+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:39:13.845+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:13.844+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:39:14.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.040 seconds
[2022-12-17T04:39:24.576+0000] {processor.py:154} INFO - Started process (PID=927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:24.598+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:24.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:24.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:24.725+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:25.085+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:25.084+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:39:25.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:25.302+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:39:25.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.907 seconds
[2022-12-17T04:39:35.767+0000] {processor.py:154} INFO - Started process (PID=937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:35.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:35.816+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:35.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:35.950+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:36.232+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:36.231+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:39:36.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:36.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:39:36.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.765 seconds
[2022-12-17T04:39:47.381+0000] {processor.py:154} INFO - Started process (PID=955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:47.401+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:47.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:47.412+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:47.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:47.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:47.953+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:39:48.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:48.229+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:39:48.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.364 seconds
[2022-12-17T04:39:59.170+0000] {processor.py:154} INFO - Started process (PID=965) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:59.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:39:59.215+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:39:59.214+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:39:59.298+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:00.498+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:40:10.846+0000] {processor.py:154} INFO - Started process (PID=975) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:10.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:40:10.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:10.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:11.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:11.770+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:11.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:40:11.944+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:11.943+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:40:12.061+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.233 seconds
[2022-12-17T04:40:22.343+0000] {processor.py:154} INFO - Started process (PID=985) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:22.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:40:22.399+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:22.397+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:22.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:23.797+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:23.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:40:24.077+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:24.076+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:40:24.632+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.303 seconds
[2022-12-17T04:40:35.277+0000] {processor.py:154} INFO - Started process (PID=1003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:35.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:40:35.312+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:35.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:35.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:35.666+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:35.665+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:40:35.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:35.799+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:40:35.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.646 seconds
[2022-12-17T04:40:46.174+0000] {processor.py:154} INFO - Started process (PID=1013) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:46.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:40:46.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:46.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:46.313+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:47.020+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:47.019+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:40:47.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:47.148+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:40:47.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.131 seconds
[2022-12-17T04:40:57.600+0000] {processor.py:154} INFO - Started process (PID=1023) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:57.614+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:40:57.619+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:57.617+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:57.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:40:57.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:57.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:40:58.090+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:40:58.089+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:40:58.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.608 seconds
[2022-12-17T04:41:08.615+0000] {processor.py:154} INFO - Started process (PID=1041) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:08.648+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:41:08.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:08.656+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:08.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:09.788+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:41:19.967+0000] {processor.py:154} INFO - Started process (PID=1051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:20.018+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:41:20.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:20.021+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:20.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:21.336+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:21.335+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:41:21.501+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:21.500+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:41:21.620+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.666 seconds
[2022-12-17T04:41:31.976+0000] {processor.py:154} INFO - Started process (PID=1061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:32.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:41:32.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:32.031+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:32.119+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:32.697+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:32.696+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:41:32.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:32.884+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:41:33.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.061 seconds
[2022-12-17T04:41:43.429+0000] {processor.py:154} INFO - Started process (PID=1071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:43.474+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:41:43.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:43.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:43.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:43.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:43.770+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:41:43.920+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:43.919+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:41:44.057+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.644 seconds
[2022-12-17T04:41:54.858+0000] {processor.py:154} INFO - Started process (PID=1089) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:54.873+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:41:54.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:54.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:54.994+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:41:55.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:55.586+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:41:55.908+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:41:55.907+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:41:56.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.276 seconds
[2022-12-17T04:42:06.531+0000] {processor.py:154} INFO - Started process (PID=1099) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:06.558+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:42:06.568+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:06.562+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:06.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:07.767+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:07.766+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:42:07.944+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:07.943+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:42:08.119+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.605 seconds
[2022-12-17T04:42:18.493+0000] {processor.py:154} INFO - Started process (PID=1109) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:18.511+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:42:18.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:18.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:18.615+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:19.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:19.211+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:42:19.349+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:19.348+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:42:19.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.075 seconds
[2022-12-17T04:42:30.014+0000] {processor.py:154} INFO - Started process (PID=1126) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:30.034+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:42:30.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:30.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:30.158+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:30.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:30.499+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:42:30.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:30.736+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:42:31.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.202 seconds
[2022-12-17T04:42:41.430+0000] {processor.py:154} INFO - Started process (PID=1136) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:41.447+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:42:41.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:41.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:41.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:41.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:41.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:42:41.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:41.908+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:42:42.043+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-17T04:42:52.294+0000] {processor.py:154} INFO - Started process (PID=1146) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:52.346+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:42:52.351+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:52.350+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:52.431+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:42:53.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:53.108+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:42:53.235+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:42:53.234+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:42:53.401+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.121 seconds
[2022-12-17T04:43:03.545+0000] {processor.py:154} INFO - Started process (PID=1156) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:03.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:03.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:03.565+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:03.654+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:04.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:04.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:43:04.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:04.187+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:43:04.325+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.794 seconds
[2022-12-17T04:43:14.732+0000] {processor.py:154} INFO - Started process (PID=1174) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:14.755+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:14.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:14.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:14.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:15.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:15.246+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:43:15.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:15.410+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:43:15.600+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.882 seconds
[2022-12-17T04:43:26.026+0000] {processor.py:154} INFO - Started process (PID=1184) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:26.054+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:26.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:26.057+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:26.140+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:27.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:27.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:43:27.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:27.155+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:43:27.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.283 seconds
[2022-12-17T04:43:37.545+0000] {processor.py:154} INFO - Started process (PID=1194) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:37.589+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:37.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:37.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:37.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:37.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:37.985+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:43:38.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:38.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:43:38.290+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.758 seconds
[2022-12-17T04:43:48.445+0000] {processor.py:154} INFO - Started process (PID=1204) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:48.449+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:48.453+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:48.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:48.533+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:48.787+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:48.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:43:49.115+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:49.114+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:43:49.293+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.862 seconds
[2022-12-17T04:43:59.726+0000] {processor.py:154} INFO - Started process (PID=1223) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:59.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:43:59.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:43:59.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:43:59.821+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:00.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:00.041+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:44:00.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:00.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:44:00.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.584 seconds
[2022-12-17T04:44:10.547+0000] {processor.py:154} INFO - Started process (PID=1233) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:10.550+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:44:10.565+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:10.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:10.657+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:10.900+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:10.899+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:44:11.044+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:11.043+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:44:11.174+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.641 seconds
[2022-12-17T04:44:21.429+0000] {processor.py:154} INFO - Started process (PID=1243) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:21.432+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:44:21.437+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:21.436+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:21.522+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:22.740+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:44:33.277+0000] {processor.py:154} INFO - Started process (PID=1262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:33.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:44:33.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:33.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:33.453+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:34.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:34.009+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:44:34.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:34.196+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:44:34.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.141 seconds
[2022-12-17T04:44:44.507+0000] {processor.py:154} INFO - Started process (PID=1272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:44.570+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:44:44.575+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:44.573+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:44.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:45.199+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:45.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:44:45.380+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:45.379+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:44:45.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.003 seconds
[2022-12-17T04:44:55.782+0000] {processor.py:154} INFO - Started process (PID=1282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:55.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:44:55.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:55.812+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:55.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:44:56.270+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:56.266+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:44:56.524+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:44:56.523+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:44:56.704+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.936 seconds
[2022-12-17T04:45:07.187+0000] {processor.py:154} INFO - Started process (PID=1292) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:07.232+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:45:07.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:07.237+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:07.326+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:07.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:07.804+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:45:08.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:08.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:45:08.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.443 seconds
[2022-12-17T04:45:19.011+0000] {processor.py:154} INFO - Started process (PID=1310) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:19.030+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:45:19.035+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:19.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:19.237+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:19.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:19.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:45:20.559+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:20.558+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:45:20.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.975 seconds
[2022-12-17T04:45:31.164+0000] {processor.py:154} INFO - Started process (PID=1320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:31.167+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:45:31.171+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:31.170+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:31.256+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:31.478+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:31.477+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:45:31.645+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:31.644+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:45:31.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.835 seconds
[2022-12-17T04:45:42.443+0000] {processor.py:154} INFO - Started process (PID=1330) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:42.460+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:45:42.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:42.463+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:42.554+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:43.528+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:43.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:45:43.725+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:43.724+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:45:43.945+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.527 seconds
[2022-12-17T04:45:54.388+0000] {processor.py:154} INFO - Started process (PID=1347) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:54.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:45:54.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:54.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:54.704+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:45:55.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:55.431+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:45:55.663+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:45:55.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:45:55.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.531 seconds
[2022-12-17T04:46:06.536+0000] {processor.py:154} INFO - Started process (PID=1357) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:06.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:46:06.565+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:06.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:06.652+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:07.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:07.212+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:46:07.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:07.373+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:46:07.515+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.998 seconds
[2022-12-17T04:46:17.865+0000] {processor.py:154} INFO - Started process (PID=1367) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:17.895+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:46:17.900+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:17.899+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:17.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:18.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:18.192+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:46:18.317+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:18.316+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:46:18.492+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.646 seconds
[2022-12-17T04:46:28.857+0000] {processor.py:154} INFO - Started process (PID=1377) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:28.873+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:46:28.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:28.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:28.993+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:29.377+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:29.376+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:46:29.524+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:29.523+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:46:29.638+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.805 seconds
[2022-12-17T04:46:39.869+0000] {processor.py:154} INFO - Started process (PID=1394) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:39.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:46:39.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:39.884+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:40.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:40.396+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:40.395+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:46:40.657+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:40.656+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:46:40.926+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.104 seconds
[2022-12-17T04:46:51.326+0000] {processor.py:154} INFO - Started process (PID=1404) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:51.330+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:46:51.333+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:51.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:51.424+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:46:51.660+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:51.659+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:46:51.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:46:51.797+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:46:51.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-17T04:47:02.212+0000] {processor.py:154} INFO - Started process (PID=1414) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:02.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:47:02.224+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:02.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:02.367+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:03.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:03.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:47:03.585+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:03.584+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:47:03.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.595 seconds
[2022-12-17T04:47:14.742+0000] {processor.py:154} INFO - Started process (PID=1431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:14.794+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:47:14.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:14.821+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:15.012+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:15.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:15.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:47:16.059+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:16.058+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:47:16.240+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.520 seconds
[2022-12-17T04:47:27.344+0000] {processor.py:154} INFO - Started process (PID=1442) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:27.369+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:47:27.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:27.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:27.456+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:27.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:27.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:47:27.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:27.792+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:47:27.932+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.603 seconds
[2022-12-17T04:47:38.239+0000] {processor.py:154} INFO - Started process (PID=1452) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:38.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:47:38.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:38.265+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:38.356+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:38.686+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:38.685+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:47:38.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:38.829+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:47:38.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.733 seconds
[2022-12-17T04:47:49.225+0000] {processor.py:154} INFO - Started process (PID=1462) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:49.276+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:47:49.281+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:49.280+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:49.374+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:47:49.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:49.694+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:47:49.848+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:47:49.847+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:47:50.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-17T04:48:00.524+0000] {processor.py:154} INFO - Started process (PID=1479) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:00.579+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:00.588+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:00.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:00.794+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:01.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:01.641+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:01.859+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:01.858+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:02.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.603 seconds
[2022-12-17T04:48:12.423+0000] {processor.py:154} INFO - Started process (PID=1489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:12.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:12.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:12.472+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:12.570+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:12.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:12.876+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:13.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:13.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:13.208+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.799 seconds
[2022-12-17T04:48:23.508+0000] {processor.py:154} INFO - Started process (PID=1499) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:23.510+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:23.514+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:23.513+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:23.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:24.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:24.715+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:24.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:24.870+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:24.999+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.505 seconds
[2022-12-17T04:48:35.263+0000] {processor.py:154} INFO - Started process (PID=1509) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:35.294+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:35.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:35.299+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:35.430+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:35.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:35.981+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:36.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:36.145+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:36.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.025 seconds
[2022-12-17T04:48:46.589+0000] {processor.py:154} INFO - Started process (PID=1528) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:46.619+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:46.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:46.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:46.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:47.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:47.810+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:47.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:47.960+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:48.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.497 seconds
[2022-12-17T04:48:58.350+0000] {processor.py:154} INFO - Started process (PID=1538) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:58.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:48:58.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:58.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:58.484+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:48:59.165+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:59.165+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:48:59.291+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:48:59.290+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:48:59.427+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.090 seconds
[2022-12-17T04:49:09.761+0000] {processor.py:154} INFO - Started process (PID=1548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:09.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:49:09.775+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:09.774+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:09.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:10.467+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:10.466+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:49:10.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:10.608+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:49:10.721+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.987 seconds
[2022-12-17T04:49:21.102+0000] {processor.py:154} INFO - Started process (PID=1565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:21.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:49:21.115+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:21.114+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:21.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:21.618+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:21.617+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:49:21.795+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:21.794+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:49:22.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.987 seconds
[2022-12-17T04:49:32.312+0000] {processor.py:154} INFO - Started process (PID=1575) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:32.360+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:49:32.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:32.364+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:32.448+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:32.906+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:49:43.187+0000] {processor.py:154} INFO - Started process (PID=1585) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:43.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:49:43.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:43.212+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:43.332+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:43.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:43.665+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:49:43.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:43.986+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:49:44.212+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.039 seconds
[2022-12-17T04:49:54.627+0000] {processor.py:154} INFO - Started process (PID=1595) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:54.655+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:49:54.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:54.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:54.786+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:49:56.117+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:56.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:49:56.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:49:56.253+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:49:56.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.827 seconds
[2022-12-17T04:50:06.726+0000] {processor.py:154} INFO - Started process (PID=1613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:06.777+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:50:06.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:06.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:07.009+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:07.994+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:50:18.286+0000] {processor.py:154} INFO - Started process (PID=1623) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:18.333+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:50:18.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:18.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:18.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:18.649+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:18.648+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:50:18.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:18.779+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:50:18.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.619 seconds
[2022-12-17T04:50:29.468+0000] {processor.py:154} INFO - Started process (PID=1633) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:29.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:50:29.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:29.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:29.618+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:30.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:30.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:50:30.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:30.297+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:50:30.411+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-17T04:50:40.855+0000] {processor.py:154} INFO - Started process (PID=1650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:40.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:50:40.910+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:40.909+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:41.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:41.617+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:41.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:50:41.820+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:41.819+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:50:42.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.300 seconds
[2022-12-17T04:50:52.352+0000] {processor.py:154} INFO - Started process (PID=1661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:52.373+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:50:52.377+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:52.376+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:52.487+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:50:52.945+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:52.944+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:50:53.095+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:50:53.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:50:53.249+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.911 seconds
[2022-12-17T04:51:03.460+0000] {processor.py:154} INFO - Started process (PID=1671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:03.491+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:03.495+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:03.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:03.623+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:03.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:03.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:51:03.996+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:03.995+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:51:04.119+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.694 seconds
[2022-12-17T04:51:14.376+0000] {processor.py:154} INFO - Started process (PID=1681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:14.384+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:14.388+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:14.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:14.527+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:15.289+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:15.288+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:51:15.429+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:15.428+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:51:15.541+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.193 seconds
[2022-12-17T04:51:26.053+0000] {processor.py:154} INFO - Started process (PID=1699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:26.081+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:26.085+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:26.084+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:26.290+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:27.042+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:27.041+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:51:27.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:27.393+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:51:27.652+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.618 seconds
[2022-12-17T04:51:38.082+0000] {processor.py:154} INFO - Started process (PID=1709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:38.103+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:38.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:38.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:38.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:38.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:38.409+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:51:38.564+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:38.562+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:51:38.794+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.727 seconds
[2022-12-17T04:51:48.961+0000] {processor.py:154} INFO - Started process (PID=1719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:49.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:49.011+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:49.010+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:49.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:49.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:49.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:51:49.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:49.514+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:51:49.672+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.725 seconds
[2022-12-17T04:51:59.839+0000] {processor.py:154} INFO - Started process (PID=1729) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:59.866+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:51:59.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:51:59.869+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:51:59.961+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:00.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:00.194+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:52:00.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:00.354+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:52:00.496+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.672 seconds
[2022-12-17T04:52:10.787+0000] {processor.py:154} INFO - Started process (PID=1747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:10.794+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:52:10.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:10.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:11.029+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:11.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:11.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:52:12.006+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:12.005+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:52:12.349+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.581 seconds
[2022-12-17T04:52:22.457+0000] {processor.py:154} INFO - Started process (PID=1757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:22.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:52:22.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:22.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:22.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:23.343+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:23.342+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:52:23.481+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:23.480+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:52:23.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.164 seconds
[2022-12-17T04:52:33.957+0000] {processor.py:154} INFO - Started process (PID=1767) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:33.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:52:33.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:33.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:34.079+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:34.789+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:52:45.341+0000] {processor.py:154} INFO - Started process (PID=1784) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:45.364+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:52:45.376+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:45.375+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:45.543+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:46.079+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:46.078+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:52:46.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:46.301+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:52:46.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.213 seconds
[2022-12-17T04:52:56.994+0000] {processor.py:154} INFO - Started process (PID=1795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:56.997+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:52:57.001+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:57.000+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:57.087+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:52:57.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:57.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:52:57.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:52:57.479+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:52:57.626+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.647 seconds
[2022-12-17T04:53:07.923+0000] {processor.py:154} INFO - Started process (PID=1805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:07.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:53:07.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:07.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:08.014+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:08.650+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:08.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:53:08.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:08.820+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:53:08.946+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-17T04:53:19.137+0000] {processor.py:154} INFO - Started process (PID=1815) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:19.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:53:19.153+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:19.152+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:19.246+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:19.858+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:53:30.549+0000] {processor.py:154} INFO - Started process (PID=1832) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:30.553+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:53:30.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:30.566+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:30.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:32.045+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:32.044+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:53:32.338+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:32.337+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:53:32.523+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.008 seconds
[2022-12-17T04:53:43.007+0000] {processor.py:154} INFO - Started process (PID=1842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:43.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:53:43.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:43.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:43.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:44.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:44.177+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:53:44.309+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:44.308+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:53:44.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.436 seconds
[2022-12-17T04:53:54.739+0000] {processor.py:154} INFO - Started process (PID=1852) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:54.817+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:53:54.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:54.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:54.951+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:53:55.222+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:55.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:53:55.380+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:53:55.379+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:53:55.502+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.780 seconds
[2022-12-17T04:54:05.916+0000] {processor.py:154} INFO - Started process (PID=1869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:05.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:54:05.979+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:05.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:06.128+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:07.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:07.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:54:07.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:07.345+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:54:07.591+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.698 seconds
[2022-12-17T04:54:17.793+0000] {processor.py:154} INFO - Started process (PID=1880) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:17.819+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:54:17.823+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:17.822+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:18.011+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:18.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:18.252+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:54:18.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:18.389+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:54:18.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-17T04:54:28.856+0000] {processor.py:154} INFO - Started process (PID=1890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:28.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:54:28.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:28.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:29.004+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:29.236+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:29.235+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:54:29.376+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:29.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:54:29.513+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.683 seconds
[2022-12-17T04:54:39.874+0000] {processor.py:154} INFO - Started process (PID=1900) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:39.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:54:39.929+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:39.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:40.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:40.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:40.727+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:54:40.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:40.961+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:54:41.218+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.367 seconds
[2022-12-17T04:54:51.924+0000] {processor.py:154} INFO - Started process (PID=1917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:52.165+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:54:52.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:52.173+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:52.318+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:54:53.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:53.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:54:53.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:54:53.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:54:54.166+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.321 seconds
[2022-12-17T04:55:05.270+0000] {processor.py:154} INFO - Started process (PID=1928) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:05.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:55:05.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:05.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:05.363+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:05.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:05.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:55:05.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:05.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:55:05.923+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.664 seconds
[2022-12-17T04:55:16.248+0000] {processor.py:154} INFO - Started process (PID=1938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:16.299+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:55:16.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:16.303+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:16.423+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:16.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:16.758+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:55:16.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:16.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:55:17.115+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.884 seconds
[2022-12-17T04:55:27.650+0000] {processor.py:154} INFO - Started process (PID=1955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:27.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:55:27.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:27.657+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:27.773+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:28.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:28.186+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:55:28.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:28.418+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:55:28.568+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.935 seconds
[2022-12-17T04:55:38.803+0000] {processor.py:154} INFO - Started process (PID=1966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:38.814+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:55:38.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:38.824+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:38.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:39.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:39.187+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:55:39.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:39.323+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:55:39.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.685 seconds
[2022-12-17T04:55:50.331+0000] {processor.py:154} INFO - Started process (PID=1976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:50.334+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:55:50.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:50.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:50.446+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:55:51.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:51.021+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:55:51.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:55:51.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:55:51.333+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-17T04:56:01.639+0000] {processor.py:154} INFO - Started process (PID=1986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:01.652+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:01.656+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:01.655+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:01.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:01.977+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:01.976+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:02.118+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:02.117+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:02.252+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.628 seconds
[2022-12-17T04:56:12.716+0000] {processor.py:154} INFO - Started process (PID=2004) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:12.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:12.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:12.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:12.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:13.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:13.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:13.519+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:13.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:13.751+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.061 seconds
[2022-12-17T04:56:24.055+0000] {processor.py:154} INFO - Started process (PID=2014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:24.058+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:24.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:24.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:24.148+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:24.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:24.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:24.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:24.543+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:24.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.698 seconds
[2022-12-17T04:56:34.949+0000] {processor.py:154} INFO - Started process (PID=2022) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:34.954+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:34.958+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:34.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:35.057+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:35.496+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:35.495+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:35.704+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:35.703+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:35.820+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.895 seconds
[2022-12-17T04:56:46.210+0000] {processor.py:154} INFO - Started process (PID=2032) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:46.215+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:46.219+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:46.218+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:46.310+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:46.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:46.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:47.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:47.093+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:47.385+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.196 seconds
[2022-12-17T04:56:57.806+0000] {processor.py:154} INFO - Started process (PID=2047) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:57.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:56:57.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:57.824+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:57.918+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:56:58.153+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:58.152+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:56:58.294+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:56:58.293+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:56:58.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.644 seconds
[2022-12-17T04:57:08.758+0000] {processor.py:154} INFO - Started process (PID=2057) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:08.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:57:08.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:57:08.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:08.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:09.316+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:57:19.854+0000] {processor.py:154} INFO - Started process (PID=2067) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:19.872+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:57:19.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:57:19.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:20.048+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:57:21.574+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T04:58:06.793+0000] {processor.py:154} INFO - Started process (PID=167) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:06.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:58:06.863+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:06.862+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:06.992+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:07.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:07.551+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:58:07.729+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:07.728+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:58:07.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.113 seconds
[2022-12-17T04:58:18.244+0000] {processor.py:154} INFO - Started process (PID=179) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:18.248+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:58:18.255+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:18.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:18.380+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:19.140+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:19.139+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:58:19.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:19.290+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:58:19.427+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.199 seconds
[2022-12-17T04:58:29.755+0000] {processor.py:154} INFO - Started process (PID=189) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:29.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:58:29.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:29.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:29.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:30.408+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:30.407+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:58:30.617+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:30.616+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:58:30.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.055 seconds
[2022-12-17T04:58:41.131+0000] {processor.py:154} INFO - Started process (PID=199) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:41.169+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:58:41.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:41.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:41.351+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:41.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:41.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:58:41.816+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:41.815+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:58:42.339+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.225 seconds
[2022-12-17T04:58:53.504+0000] {processor.py:154} INFO - Started process (PID=217) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:53.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:58:53.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:53.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:53.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:58:54.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:54.155+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:58:54.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:58:54.344+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:58:54.526+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.086 seconds
[2022-12-17T04:59:04.828+0000] {processor.py:154} INFO - Started process (PID=227) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:04.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:59:04.836+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:04.834+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:04.936+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:05.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:05.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:59:05.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:05.717+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:59:05.850+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-17T04:59:16.271+0000] {processor.py:154} INFO - Started process (PID=237) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:16.316+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:59:16.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:16.320+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:16.413+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:16.620+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:16.619+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:59:16.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:16.746+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:59:16.896+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.638 seconds
[2022-12-17T04:59:27.095+0000] {processor.py:154} INFO - Started process (PID=254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:27.120+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:59:27.127+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:27.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:27.245+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:28.758+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:28.757+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:59:28.995+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:28.994+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:59:29.217+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.137 seconds
[2022-12-17T04:59:39.656+0000] {processor.py:154} INFO - Started process (PID=265) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:39.675+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:59:39.680+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:39.678+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:39.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:39.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:39.996+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T04:59:40.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:40.475+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T04:59:40.785+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.143 seconds
[2022-12-17T04:59:51.264+0000] {processor.py:154} INFO - Started process (PID=275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:51.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T04:59:51.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T04:59:51.302+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:51.552+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T04:59:53.024+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:00:03.394+0000] {processor.py:154} INFO - Started process (PID=285) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:03.399+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:00:03.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:03.403+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:03.514+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:03.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:03.821+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:00:04.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:04.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:00:04.136+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.759 seconds
[2022-12-17T05:00:14.634+0000] {processor.py:154} INFO - Started process (PID=303) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:14.677+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:00:14.697+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:14.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:14.933+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:15.364+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:15.363+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:00:15.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:15.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:00:16.025+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.435 seconds
[2022-12-17T05:00:26.320+0000] {processor.py:154} INFO - Started process (PID=313) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:26.346+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:00:26.350+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:26.349+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:26.433+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:27.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:27.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:00:27.485+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:27.484+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:00:27.622+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.316 seconds
[2022-12-17T05:00:37.917+0000] {processor.py:154} INFO - Started process (PID=323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:37.951+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:00:37.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:37.954+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:38.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:38.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:38.357+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:00:38.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:38.499+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:00:38.617+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-17T05:00:48.935+0000] {processor.py:154} INFO - Started process (PID=339) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:48.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:00:48.999+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:48.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:49.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:00:49.400+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:49.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:00:49.691+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:00:49.690+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:00:49.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.997 seconds
[2022-12-17T05:01:00.338+0000] {processor.py:154} INFO - Started process (PID=350) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:00.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:01:00.345+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:00.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:00.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:01.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:01.355+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:01:01.483+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:01.482+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:01:01.605+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.281 seconds
[2022-12-17T05:01:11.904+0000] {processor.py:154} INFO - Started process (PID=360) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:11.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:01:11.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:11.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:12.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:13.645+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:01:24.097+0000] {processor.py:154} INFO - Started process (PID=370) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:24.120+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:01:24.124+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:24.123+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:24.207+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:25.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:25.875+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:01:26.020+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:26.019+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:01:26.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.273 seconds
[2022-12-17T05:01:36.922+0000] {processor.py:154} INFO - Started process (PID=390) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:36.972+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:01:36.977+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:36.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:37.223+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:38.684+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:38.683+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:01:38.875+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:38.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:01:39.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.142 seconds
[2022-12-17T05:01:49.365+0000] {processor.py:154} INFO - Started process (PID=402) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:49.471+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:01:49.475+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:49.474+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:49.759+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:01:50.161+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:50.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:01:50.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:01:50.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:01:50.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.153 seconds
[2022-12-17T05:02:00.801+0000] {processor.py:154} INFO - Started process (PID=412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:00.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:00.831+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:00.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:00.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:01.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:01.883+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:02:02.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:02.022+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:02:02.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.437 seconds
[2022-12-17T05:02:12.744+0000] {processor.py:154} INFO - Started process (PID=430) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:12.782+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:12.790+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:12.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:13.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:13.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:13.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:02:14.039+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:14.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:02:14.309+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.635 seconds
[2022-12-17T05:02:24.586+0000] {processor.py:154} INFO - Started process (PID=440) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:24.590+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:24.595+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:24.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:24.725+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:25.529+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:25.529+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:02:25.678+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:25.677+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:02:26.023+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.469 seconds
[2022-12-17T05:02:36.296+0000] {processor.py:154} INFO - Started process (PID=450) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:36.362+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:36.367+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:36.366+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:36.457+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:37.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:37.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:02:37.252+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:37.251+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:02:37.385+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.102 seconds
[2022-12-17T05:02:47.744+0000] {processor.py:154} INFO - Started process (PID=460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:47.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:47.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:47.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:47.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:48.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:48.192+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:02:48.341+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:48.340+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:02:48.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.830 seconds
[2022-12-17T05:02:58.950+0000] {processor.py:154} INFO - Started process (PID=477) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:58.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:02:58.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:02:58.988+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:02:59.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:00.042+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:00.041+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:03:00.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:00.201+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:03:00.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.416 seconds
[2022-12-17T05:03:10.924+0000] {processor.py:154} INFO - Started process (PID=487) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:10.955+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:03:10.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:10.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:11.197+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:11.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:11.699+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:03:11.867+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:11.866+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:03:12.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.201 seconds
[2022-12-17T05:03:22.423+0000] {processor.py:154} INFO - Started process (PID=497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:22.446+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:03:22.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:22.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:22.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:23.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:23.468+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:03:23.763+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:23.762+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:03:24.216+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.815 seconds
[2022-12-17T05:03:34.966+0000] {processor.py:154} INFO - Started process (PID=514) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:35.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:03:35.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:35.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:35.287+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:35.650+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:35.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:03:35.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:35.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:03:36.110+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.264 seconds
[2022-12-17T05:03:46.531+0000] {processor.py:154} INFO - Started process (PID=524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:46.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:03:46.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:46.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:46.638+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:47.429+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:03:57.757+0000] {processor.py:154} INFO - Started process (PID=534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:57.792+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:03:57.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:57.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:57.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:03:58.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:58.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:03:58.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:03:58.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:03:58.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.646 seconds
[2022-12-17T05:04:08.685+0000] {processor.py:154} INFO - Started process (PID=544) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:08.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:04:08.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:08.716+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:08.806+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:09.160+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:09.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:04:09.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:09.539+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:04:09.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.278 seconds
[2022-12-17T05:04:20.320+0000] {processor.py:154} INFO - Started process (PID=562) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:20.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:04:20.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:20.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:20.513+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:21.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:21.270+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:04:21.428+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:21.427+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:04:21.608+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.339 seconds
[2022-12-17T05:04:31.919+0000] {processor.py:154} INFO - Started process (PID=572) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:31.923+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:04:31.927+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:31.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:32.010+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:32.808+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:32.807+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:04:32.956+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:32.956+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:04:33.084+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.178 seconds
[2022-12-17T05:04:44.209+0000] {processor.py:154} INFO - Started process (PID=582) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:44.229+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:04:44.239+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:44.233+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:44.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:45.257+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:04:55.466+0000] {processor.py:154} INFO - Started process (PID=600) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:55.510+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:04:55.518+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:55.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:55.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:04:55.938+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:55.937+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:04:56.103+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:04:56.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:04:56.307+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.857 seconds
[2022-12-17T05:05:06.984+0000] {processor.py:154} INFO - Started process (PID=610) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:07.012+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:05:07.018+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:07.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:07.108+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:07.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:07.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:05:07.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:07.472+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:05:07.592+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.622 seconds
[2022-12-17T05:05:18.518+0000] {processor.py:154} INFO - Started process (PID=620) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:18.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:05:18.541+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:18.540+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:18.635+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:18.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:18.922+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:05:19.068+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:19.067+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:05:19.197+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.692 seconds
[2022-12-17T05:05:29.605+0000] {processor.py:154} INFO - Started process (PID=630) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:29.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:05:29.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:29.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:29.946+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:30.244+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:30.240+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:05:30.399+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:30.399+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:05:30.572+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.038 seconds
[2022-12-17T05:05:41.034+0000] {processor.py:154} INFO - Started process (PID=648) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:41.062+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:05:41.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:41.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:41.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:41.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:41.744+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:05:41.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:41.932+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:05:42.128+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.110 seconds
[2022-12-17T05:05:52.397+0000] {processor.py:154} INFO - Started process (PID=658) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:52.420+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:05:52.425+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:52.424+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:52.509+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:05:53.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:53.720+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:05:53.952+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:05:53.951+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:05:54.099+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.717 seconds
[2022-12-17T05:06:04.418+0000] {processor.py:154} INFO - Started process (PID=668) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:04.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:06:04.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:04.425+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:04.510+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:04.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:04.719+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:06:04.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:04.906+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:06:05.081+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.677 seconds
[2022-12-17T05:06:15.482+0000] {processor.py:154} INFO - Started process (PID=687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:15.523+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:06:15.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:15.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:15.646+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:16.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:16.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:06:16.431+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:16.430+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:06:16.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.171 seconds
[2022-12-17T05:06:27.202+0000] {processor.py:154} INFO - Started process (PID=697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:27.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:06:27.228+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:27.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:27.322+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:27.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:27.538+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:06:27.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:27.701+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:06:27.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-17T05:06:38.164+0000] {processor.py:154} INFO - Started process (PID=707) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:38.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:06:38.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:38.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:38.277+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:39.359+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:39.358+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:06:39.503+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:39.502+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:06:39.716+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.575 seconds
[2022-12-17T05:06:50.457+0000] {processor.py:154} INFO - Started process (PID=717) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:50.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:06:50.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:06:50.507+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:50.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:06:51.727+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:07:02.482+0000] {processor.py:154} INFO - Started process (PID=735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:02.516+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:07:02.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:02.519+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:02.613+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:02.845+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:02.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:07:03.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:03.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:07:03.185+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.719 seconds
[2022-12-17T05:07:13.442+0000] {processor.py:154} INFO - Started process (PID=745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:13.485+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:07:13.489+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:13.488+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:13.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:14.336+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:14.335+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:07:14.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:14.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:07:14.611+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.184 seconds
[2022-12-17T05:07:24.927+0000] {processor.py:154} INFO - Started process (PID=755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:24.945+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:07:24.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:24.948+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:25.060+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:25.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:25.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:07:25.453+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:25.452+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:07:25.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-17T05:07:35.902+0000] {processor.py:154} INFO - Started process (PID=773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:35.956+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:07:35.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:35.959+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:36.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:37.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:37.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:07:38.139+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:38.138+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:07:38.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.080 seconds
[2022-12-17T05:07:49.414+0000] {processor.py:154} INFO - Started process (PID=783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:49.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:07:49.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:49.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:49.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:07:51.218+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:51.217+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:07:51.618+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:07:51.617+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:07:51.773+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.373 seconds
[2022-12-17T05:08:02.160+0000] {processor.py:154} INFO - Started process (PID=793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:02.182+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:08:02.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:02.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:02.337+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:03.807+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:03.806+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:08:03.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:03.946+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:08:04.082+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.942 seconds
[2022-12-17T05:08:14.442+0000] {processor.py:154} INFO - Started process (PID=811) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:14.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:08:14.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:14.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:14.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:14.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:14.960+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:08:15.162+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:15.161+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:08:15.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.248 seconds
[2022-12-17T05:08:26.099+0000] {processor.py:154} INFO - Started process (PID=822) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:26.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:08:26.106+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:26.105+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:26.244+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:27.494+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:08:37.969+0000] {processor.py:154} INFO - Started process (PID=832) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:37.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:08:37.998+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:37.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:38.103+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:38.351+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:38.350+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:08:38.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:38.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:08:38.623+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.679 seconds
[2022-12-17T05:08:48.938+0000] {processor.py:154} INFO - Started process (PID=842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:48.968+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:08:48.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:48.971+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:49.092+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:08:49.499+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:49.498+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:08:49.647+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:08:49.646+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:08:49.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.887 seconds
[2022-12-17T05:09:00.354+0000] {processor.py:154} INFO - Started process (PID=861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:00.377+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:00.403+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:00.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:00.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:01.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:01.022+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:01.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:01.281+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:01.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.239 seconds
[2022-12-17T05:09:11.977+0000] {processor.py:154} INFO - Started process (PID=871) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:11.984+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:11.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:11.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:12.165+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:12.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:12.647+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:12.785+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:12.784+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:12.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.963 seconds
[2022-12-17T05:09:23.262+0000] {processor.py:154} INFO - Started process (PID=881) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:23.396+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:23.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:23.495+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:23.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:23.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:23.824+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:23.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:23.977+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:24.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.029 seconds
[2022-12-17T05:09:34.734+0000] {processor.py:154} INFO - Started process (PID=897) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:34.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:34.760+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:34.759+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:34.962+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:35.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:35.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:35.484+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:35.483+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:35.639+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.945 seconds
[2022-12-17T05:09:46.366+0000] {processor.py:154} INFO - Started process (PID=909) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:46.408+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:46.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:46.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:46.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:46.928+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:46.927+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:47.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:47.066+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:47.199+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.909 seconds
[2022-12-17T05:09:57.555+0000] {processor.py:154} INFO - Started process (PID=919) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:57.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:09:57.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:57.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:57.859+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:09:58.244+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:58.242+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:09:58.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:09:58.410+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:09:58.532+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.027 seconds
[2022-12-17T05:10:08.834+0000] {processor.py:154} INFO - Started process (PID=929) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:08.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:10:08.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:08.853+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:09.058+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:10.276+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:10:21.160+0000] {processor.py:154} INFO - Started process (PID=947) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:21.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:10:21.237+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:21.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:21.638+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:22.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:22.357+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:10:22.593+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:22.590+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:10:22.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.726 seconds
[2022-12-17T05:10:33.390+0000] {processor.py:154} INFO - Started process (PID=957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:33.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:10:33.428+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:33.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:33.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:33.784+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:33.783+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:10:33.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:33.915+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:10:34.047+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.687 seconds
[2022-12-17T05:10:44.702+0000] {processor.py:154} INFO - Started process (PID=967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:44.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:10:44.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:44.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:44.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:45.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:45.286+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:10:45.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:45.413+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:10:45.549+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.896 seconds
[2022-12-17T05:10:55.840+0000] {processor.py:154} INFO - Started process (PID=977) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:55.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:10:55.849+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:55.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:55.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:10:57.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:57.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:10:57.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:10:57.273+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:10:57.409+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.585 seconds
[2022-12-17T05:11:07.856+0000] {processor.py:154} INFO - Started process (PID=995) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:07.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:11:07.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:07.894+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:08.013+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:09.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:09.641+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:11:09.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:09.804+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:11:10.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.188 seconds
[2022-12-17T05:11:20.474+0000] {processor.py:154} INFO - Started process (PID=1005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:20.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:11:20.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:20.521+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:20.701+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:21.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:21.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:11:21.359+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:21.358+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:11:21.490+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.054 seconds
[2022-12-17T05:11:31.943+0000] {processor.py:154} INFO - Started process (PID=1015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:31.972+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:11:31.979+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:31.978+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:32.092+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:33.699+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:11:44.160+0000] {processor.py:154} INFO - Started process (PID=1033) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:44.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:11:44.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:44.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:44.285+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:45.082+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:11:55.412+0000] {processor.py:154} INFO - Started process (PID=1043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:55.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:11:55.439+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:55.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:55.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:11:56.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:56.530+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:11:56.831+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:11:56.830+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:11:57.059+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.665 seconds
[2022-12-17T05:12:07.460+0000] {processor.py:154} INFO - Started process (PID=1053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:07.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:12:07.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:07.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:07.694+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:07.920+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:07.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:12:08.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:08.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:12:08.184+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.762 seconds
[2022-12-17T05:12:18.542+0000] {processor.py:154} INFO - Started process (PID=1069) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:18.565+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:12:18.569+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:18.568+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:18.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:19.005+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:19.004+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:12:19.173+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:19.172+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:12:19.337+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.810 seconds
[2022-12-17T05:12:29.778+0000] {processor.py:154} INFO - Started process (PID=1080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:29.781+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:12:29.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:29.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:29.880+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:30.092+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:30.091+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:12:30.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:30.229+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:12:30.378+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.613 seconds
[2022-12-17T05:12:41.171+0000] {processor.py:154} INFO - Started process (PID=1090) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:41.220+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:12:41.225+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:41.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:41.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:41.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:41.708+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:12:41.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:41.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:12:42.016+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.858 seconds
[2022-12-17T05:12:52.319+0000] {processor.py:154} INFO - Started process (PID=1100) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:52.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:12:52.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:52.326+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:52.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:12:52.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:52.764+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:12:52.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:12:52.923+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:12:53.044+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-17T05:13:03.230+0000] {processor.py:154} INFO - Started process (PID=1118) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:03.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:13:03.269+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:03.268+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:03.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:04.135+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:04.134+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:13:04.297+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:04.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:13:04.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.225 seconds
[2022-12-17T05:13:14.918+0000] {processor.py:154} INFO - Started process (PID=1128) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:14.933+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:13:14.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:14.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:15.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:15.353+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:15.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:13:15.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:15.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:13:15.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.778 seconds
[2022-12-17T05:13:25.993+0000] {processor.py:154} INFO - Started process (PID=1138) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:26.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:13:26.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:26.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:26.232+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:27.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:27.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:13:27.210+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:27.209+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:13:27.375+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.414 seconds
[2022-12-17T05:13:37.721+0000] {processor.py:154} INFO - Started process (PID=1148) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:37.743+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:13:37.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:37.746+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:38.033+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:38.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:38.508+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:13:38.673+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:38.671+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:13:38.860+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.155 seconds
[2022-12-17T05:13:49.463+0000] {processor.py:154} INFO - Started process (PID=1166) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:49.470+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:13:49.475+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:49.474+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:49.735+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:13:50.571+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:50.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:13:50.708+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:13:50.707+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:13:51.103+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.662 seconds
[2022-12-17T05:14:01.415+0000] {processor.py:154} INFO - Started process (PID=1176) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:01.444+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:01.448+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:01.447+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:01.532+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:01.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:01.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:14:01.891+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:01.890+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:14:02.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.628 seconds
[2022-12-17T05:14:12.295+0000] {processor.py:154} INFO - Started process (PID=1186) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:12.299+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:12.303+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:12.302+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:12.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:13.738+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:14:24.284+0000] {processor.py:154} INFO - Started process (PID=1205) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:24.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:24.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:24.313+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:24.653+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:25.186+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:25.185+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:14:25.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:25.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:14:25.685+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.495 seconds
[2022-12-17T05:14:36.133+0000] {processor.py:154} INFO - Started process (PID=1215) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:36.159+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:36.167+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:36.166+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:36.283+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:36.501+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:36.500+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:14:36.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:36.865+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:14:37.136+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.029 seconds
[2022-12-17T05:14:47.659+0000] {processor.py:154} INFO - Started process (PID=1225) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:47.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:47.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:47.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:47.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:48.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:48.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:14:48.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:48.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:14:48.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.849 seconds
[2022-12-17T05:14:59.415+0000] {processor.py:154} INFO - Started process (PID=1235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:59.433+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:14:59.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:14:59.437+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:14:59.543+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:00.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:00.317+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:00.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:00.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:00.695+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.325 seconds
[2022-12-17T05:15:11.143+0000] {processor.py:154} INFO - Started process (PID=1252) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:11.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:15:11.233+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:11.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:11.319+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:11.523+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:11.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:11.661+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:11.660+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:11.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.698 seconds
[2022-12-17T05:15:22.147+0000] {processor.py:154} INFO - Started process (PID=1262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:22.165+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:15:22.170+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:22.169+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:22.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:22.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:22.476+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:22.613+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:22.612+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:22.728+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.594 seconds
[2022-12-17T05:15:32.921+0000] {processor.py:154} INFO - Started process (PID=1272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:32.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:15:32.936+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:32.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:33.122+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:33.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:33.715+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:33.842+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:33.841+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:34.009+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.102 seconds
[2022-12-17T05:15:44.396+0000] {processor.py:154} INFO - Started process (PID=1290) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:44.438+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:15:44.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:44.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:44.782+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:45.654+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:45.653+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:45.843+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:45.842+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:46.000+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.620 seconds
[2022-12-17T05:15:56.380+0000] {processor.py:154} INFO - Started process (PID=1300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:56.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:15:56.431+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:56.430+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:56.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:15:58.199+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:58.198+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:15:58.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:15:58.346+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:15:58.512+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.146 seconds
[2022-12-17T05:16:08.827+0000] {processor.py:154} INFO - Started process (PID=1310) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:08.847+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:16:08.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:08.853+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:08.942+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:09.147+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:09.146+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:16:09.281+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:09.280+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:16:09.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-17T05:16:19.721+0000] {processor.py:154} INFO - Started process (PID=1320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:19.740+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:16:19.745+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:19.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:19.826+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:21.223+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:16:31.694+0000] {processor.py:154} INFO - Started process (PID=1338) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:31.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:16:31.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:31.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:31.783+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:32.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:32.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:16:32.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:32.508+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:16:32.619+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-17T05:16:42.921+0000] {processor.py:154} INFO - Started process (PID=1348) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:42.954+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:16:42.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:42.981+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:43.072+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:43.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:43.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:16:43.412+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:43.411+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:16:43.549+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.648 seconds
[2022-12-17T05:16:53.940+0000] {processor.py:154} INFO - Started process (PID=1358) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:54.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:16:54.204+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:54.204+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:54.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:16:54.531+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:54.530+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:16:54.704+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:16:54.704+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:16:55.105+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.187 seconds
[2022-12-17T05:17:05.905+0000] {processor.py:154} INFO - Started process (PID=1376) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:05.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:17:05.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:05.948+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:06.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:06.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:06.534+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:17:06.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:06.690+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:17:06.832+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-17T05:17:17.229+0000] {processor.py:154} INFO - Started process (PID=1386) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:17.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:17:17.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:17.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:17.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:17.988+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:17.987+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:17:18.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:18.114+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:17:18.222+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-17T05:17:28.530+0000] {processor.py:154} INFO - Started process (PID=1396) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:28.551+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:17:28.556+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:28.554+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:28.654+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:29.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:29.534+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:17:29.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:29.694+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:17:29.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.284 seconds
[2022-12-17T05:17:40.768+0000] {processor.py:154} INFO - Started process (PID=1406) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:40.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:17:40.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:40.801+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:40.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:42.360+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:17:53.197+0000] {processor.py:154} INFO - Started process (PID=1424) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:53.201+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:17:53.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:53.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:53.301+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:17:53.580+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:53.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:17:53.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:17:53.872+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:17:53.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.824 seconds
[2022-12-17T05:18:04.279+0000] {processor.py:154} INFO - Started process (PID=1434) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:04.318+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:18:04.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:04.333+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:04.445+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:04.784+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:04.783+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:18:04.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:04.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:18:05.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.816 seconds
[2022-12-17T05:18:15.401+0000] {processor.py:154} INFO - Started process (PID=1444) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:15.436+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:18:15.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:15.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:15.552+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:16.340+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:16.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:18:16.565+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:16.564+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:18:16.715+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.331 seconds
[2022-12-17T05:18:27.117+0000] {processor.py:154} INFO - Started process (PID=1462) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:27.143+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:18:27.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:27.167+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:27.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:28.383+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:28.382+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:18:28.862+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:28.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:18:29.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.263 seconds
[2022-12-17T05:18:39.497+0000] {processor.py:154} INFO - Started process (PID=1472) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:39.500+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:18:39.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:39.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:39.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:39.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:39.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:18:40.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:40.027+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:18:40.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.683 seconds
[2022-12-17T05:18:50.420+0000] {processor.py:154} INFO - Started process (PID=1482) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:50.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:18:50.467+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:50.466+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:50.592+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:18:51.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:51.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:18:51.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:18:51.261+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:18:51.412+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.006 seconds
[2022-12-17T05:19:01.787+0000] {processor.py:154} INFO - Started process (PID=1492) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:01.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:01.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:01.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:01.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:02.144+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:02.144+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:02.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:02.279+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:02.390+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.617 seconds
[2022-12-17T05:19:12.859+0000] {processor.py:154} INFO - Started process (PID=1511) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:12.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:12.897+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:12.896+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:13.038+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:13.353+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:13.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:13.531+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:13.530+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:13.659+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.818 seconds
[2022-12-17T05:19:23.961+0000] {processor.py:154} INFO - Started process (PID=1521) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:23.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:23.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:23.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:24.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:24.264+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:24.262+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:24.396+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:24.395+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:24.678+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.730 seconds
[2022-12-17T05:19:35.382+0000] {processor.py:154} INFO - Started process (PID=1531) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:35.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:35.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:35.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:35.659+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:36.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:36.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:36.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:36.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:36.263+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.984 seconds
[2022-12-17T05:19:46.599+0000] {processor.py:154} INFO - Started process (PID=1548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:46.636+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:46.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:46.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:46.742+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:47.100+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:47.098+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:47.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:47.448+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:47.708+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.165 seconds
[2022-12-17T05:19:58.188+0000] {processor.py:154} INFO - Started process (PID=1558) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:58.203+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:19:58.214+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:58.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:58.356+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:19:58.711+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:58.705+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:19:58.944+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:19:58.943+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:19:59.219+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.046 seconds
[2022-12-17T05:20:09.487+0000] {processor.py:154} INFO - Started process (PID=1568) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:09.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:20:09.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:09.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:09.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:09.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:09.865+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:20:09.998+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:09.997+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:20:10.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.647 seconds
[2022-12-17T05:20:20.229+0000] {processor.py:154} INFO - Started process (PID=1578) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:20.273+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:20:20.277+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:20.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:20.393+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:20.614+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:20.613+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:20:20.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:20.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:20:20.882+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-17T05:20:31.979+0000] {processor.py:154} INFO - Started process (PID=1596) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:32.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:20:32.052+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:32.046+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:32.160+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:32.809+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:32.808+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:20:32.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:32.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:20:33.119+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.157 seconds
[2022-12-17T05:20:43.422+0000] {processor.py:154} INFO - Started process (PID=1606) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:43.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:20:43.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:43.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:43.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:44.401+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:20:54.794+0000] {processor.py:154} INFO - Started process (PID=1616) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:54.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:20:54.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:54.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:54.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:20:56.364+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:56.363+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:20:56.567+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:20:56.554+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:20:56.821+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.040 seconds
[2022-12-17T05:21:07.061+0000] {processor.py:154} INFO - Started process (PID=1634) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:07.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:21:07.070+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:07.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:07.196+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:07.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:07.448+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:21:07.672+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:07.672+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:21:07.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.872 seconds
[2022-12-17T05:21:18.093+0000] {processor.py:154} INFO - Started process (PID=1644) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:18.097+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:21:18.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:18.100+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:18.185+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:19.736+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:19.734+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:21:19.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:19.911+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:21:20.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.083 seconds
[2022-12-17T05:21:30.365+0000] {processor.py:154} INFO - Started process (PID=1654) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:30.389+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:21:30.393+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:30.392+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:30.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:31.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:31.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:21:31.679+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:31.678+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:21:31.797+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.446 seconds
[2022-12-17T05:21:42.148+0000] {processor.py:154} INFO - Started process (PID=1664) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:42.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:21:42.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:42.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:42.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:43.031+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:21:53.464+0000] {processor.py:154} INFO - Started process (PID=1681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:53.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:21:53.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:21:53.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:53.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:21:54.685+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:22:05.134+0000] {processor.py:154} INFO - Started process (PID=1691) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:05.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:22:05.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:05.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:05.487+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:06.130+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:06.129+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:22:06.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:06.479+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:22:06.705+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.607 seconds
[2022-12-17T05:22:17.577+0000] {processor.py:154} INFO - Started process (PID=1701) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:17.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:22:17.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:17.634+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:17.835+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:18.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:18.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:22:18.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:18.448+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:22:18.604+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.050 seconds
[2022-12-17T05:22:28.982+0000] {processor.py:154} INFO - Started process (PID=1719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:29.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:22:29.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:29.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:29.268+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:30.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:30.137+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:22:30.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:30.519+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:22:30.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.814 seconds
[2022-12-17T05:22:41.265+0000] {processor.py:154} INFO - Started process (PID=1729) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:41.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:22:41.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:41.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:41.444+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:41.675+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:41.674+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:22:41.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:41.868+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:22:42.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.819 seconds
[2022-12-17T05:22:52.364+0000] {processor.py:154} INFO - Started process (PID=1739) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:52.417+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:22:52.421+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:52.420+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:52.578+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:22:53.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:53.077+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:22:53.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:22:53.294+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:22:53.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.107 seconds
[2022-12-17T05:23:03.754+0000] {processor.py:154} INFO - Started process (PID=1749) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:03.842+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:23:03.852+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:03.845+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:03.955+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:04.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:04.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:23:04.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:04.715+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:23:04.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.081 seconds
[2022-12-17T05:23:15.382+0000] {processor.py:154} INFO - Started process (PID=1767) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:15.431+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:23:15.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:15.434+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:15.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:17.052+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:17.050+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:23:17.417+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:17.416+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:23:17.748+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.412 seconds
[2022-12-17T05:23:28.123+0000] {processor.py:154} INFO - Started process (PID=1777) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:28.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:23:28.170+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:28.169+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:28.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:28.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:28.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:23:28.874+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:28.873+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:23:28.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.903 seconds
[2022-12-17T05:23:39.328+0000] {processor.py:154} INFO - Started process (PID=1787) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:39.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:23:39.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:39.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:39.424+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:39.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:39.760+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:23:39.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:39.915+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:23:40.405+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.091 seconds
[2022-12-17T05:23:51.069+0000] {processor.py:154} INFO - Started process (PID=1804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:51.078+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:23:51.112+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:51.111+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:51.331+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:23:51.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:51.689+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:23:52.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:23:52.014+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:23:52.251+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.256 seconds
[2022-12-17T05:24:03.337+0000] {processor.py:154} INFO - Started process (PID=1814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:03.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:24:03.392+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:03.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:03.487+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:03.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:03.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:24:03.932+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:03.931+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:24:04.100+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.800 seconds
[2022-12-17T05:24:14.374+0000] {processor.py:154} INFO - Started process (PID=1824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:14.383+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:24:14.388+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:14.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:14.472+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:14.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:14.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:24:14.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:14.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:24:15.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T05:24:25.314+0000] {processor.py:154} INFO - Started process (PID=1834) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:25.328+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:24:25.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:25.333+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:25.439+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:26.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:26.603+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:24:26.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:26.771+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:24:26.892+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.593 seconds
[2022-12-17T05:24:37.869+0000] {processor.py:154} INFO - Started process (PID=1852) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:37.893+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:24:37.897+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:37.896+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:38.089+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:38.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:38.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:24:38.908+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:38.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:24:39.202+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.384 seconds
[2022-12-17T05:24:49.547+0000] {processor.py:154} INFO - Started process (PID=1862) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:49.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:24:49.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:49.576+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:49.764+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:24:50.047+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:50.046+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:24:50.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:24:50.210+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:24:50.376+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.866 seconds
[2022-12-17T05:25:00.737+0000] {processor.py:154} INFO - Started process (PID=1872) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:00.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:25:00.751+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:00.750+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:00.880+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:02.005+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:02.004+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:25:02.172+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:02.171+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:25:02.333+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.627 seconds
[2022-12-17T05:25:13.152+0000] {processor.py:154} INFO - Started process (PID=1890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:13.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:25:13.233+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:13.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:13.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:15.326+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:15.325+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:25:15.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:15.718+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:25:16.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.932 seconds
[2022-12-17T05:25:26.773+0000] {processor.py:154} INFO - Started process (PID=1905) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:26.779+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:25:26.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:26.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:26.911+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:28.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:28.346+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:25:28.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:28.810+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:25:28.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.249 seconds
[2022-12-17T05:25:39.286+0000] {processor.py:154} INFO - Started process (PID=1915) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:39.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:25:39.381+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:39.379+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:39.507+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:41.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:41.074+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:25:41.214+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:41.213+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:25:41.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.071 seconds
[2022-12-17T05:25:51.831+0000] {processor.py:154} INFO - Started process (PID=1931) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:51.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:25:51.859+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:25:51.857+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:52.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:25:53.728+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:26:04.234+0000] {processor.py:154} INFO - Started process (PID=1942) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:04.261+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:26:04.265+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:04.264+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:04.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:04.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:04.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:26:04.752+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:04.751+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:26:04.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-17T05:26:15.271+0000] {processor.py:154} INFO - Started process (PID=1952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:15.496+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:26:15.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:15.504+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:15.613+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:16.001+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:16.000+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:26:16.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:16.157+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:26:16.745+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.508 seconds
[2022-12-17T05:26:27.013+0000] {processor.py:154} INFO - Started process (PID=1962) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:27.058+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:26:27.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:27.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:27.161+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:27.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:27.481+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:26:27.627+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:27.626+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:26:27.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.745 seconds
[2022-12-17T05:26:38.193+0000] {processor.py:154} INFO - Started process (PID=1980) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:38.238+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:26:38.250+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:38.241+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:38.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:39.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:39.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:26:39.513+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:39.512+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:26:39.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.491 seconds
[2022-12-17T05:26:50.040+0000] {processor.py:154} INFO - Started process (PID=1990) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:50.094+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:26:50.098+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:50.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:50.189+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:26:50.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:50.622+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:26:50.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:26:50.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:26:51.088+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.062 seconds
[2022-12-17T05:27:01.275+0000] {processor.py:154} INFO - Started process (PID=2000) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:01.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:27:01.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:01.329+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:01.485+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:01.807+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:01.806+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:27:02.336+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:02.308+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:27:02.773+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.518 seconds
[2022-12-17T05:27:13.432+0000] {processor.py:154} INFO - Started process (PID=2018) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:13.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:27:13.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:13.503+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:13.935+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:14.491+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:14.490+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:27:14.660+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:14.658+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:27:14.867+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.537 seconds
[2022-12-17T05:27:25.316+0000] {processor.py:154} INFO - Started process (PID=2029) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:25.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:27:25.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:25.355+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:25.465+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:26.018+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:26.017+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:27:26.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:26.327+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:27:26.473+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.175 seconds
[2022-12-17T05:27:36.757+0000] {processor.py:154} INFO - Started process (PID=2039) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:36.829+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:27:36.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:36.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:36.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:37.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:37.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:27:37.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:37.541+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:27:37.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.135 seconds
[2022-12-17T05:27:48.282+0000] {processor.py:154} INFO - Started process (PID=2049) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:48.297+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:27:48.303+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:48.302+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:48.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:27:49.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:49.946+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:27:50.080+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:27:50.080+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:27:50.214+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.964 seconds
[2022-12-17T05:28:00.668+0000] {processor.py:154} INFO - Started process (PID=2066) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:00.690+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:00.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:00.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:00.861+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:01.622+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:28:12.244+0000] {processor.py:154} INFO - Started process (PID=2076) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:12.255+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:12.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:12.258+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:12.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:12.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:12.897+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:28:13.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:13.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:28:13.290+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.084 seconds
[2022-12-17T05:28:23.566+0000] {processor.py:154} INFO - Started process (PID=2086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:23.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:23.607+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:23.605+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:23.828+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:24.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:24.173+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:28:24.322+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:24.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:28:24.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.944 seconds
[2022-12-17T05:28:34.977+0000] {processor.py:154} INFO - Started process (PID=2103) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:35.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:35.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:35.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:35.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:36.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:36.437+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:28:36.715+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:36.714+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:28:37.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.065 seconds
[2022-12-17T05:28:47.580+0000] {processor.py:154} INFO - Started process (PID=2114) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:47.612+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:47.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:47.615+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:47.706+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:48.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:48.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:28:48.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:48.559+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:28:48.986+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.420 seconds
[2022-12-17T05:28:59.334+0000] {processor.py:154} INFO - Started process (PID=2124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:59.379+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:28:59.383+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:28:59.382+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:28:59.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:00.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:00.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:29:00.252+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:00.251+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:29:00.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.073 seconds
[2022-12-17T05:29:10.776+0000] {processor.py:154} INFO - Started process (PID=2134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:10.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:29:10.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:10.812+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:10.940+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:11.392+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:11.391+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:29:11.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:11.543+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:29:11.688+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.938 seconds
[2022-12-17T05:29:22.192+0000] {processor.py:154} INFO - Started process (PID=2152) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:22.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:29:22.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:22.241+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:22.422+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:22.880+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:22.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:29:23.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:23.103+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:29:23.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.190 seconds
[2022-12-17T05:29:33.733+0000] {processor.py:154} INFO - Started process (PID=2162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:33.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:29:33.741+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:33.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:33.829+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:34.971+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:34.970+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:29:35.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:35.154+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:29:35.427+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.709 seconds
[2022-12-17T05:29:45.707+0000] {processor.py:154} INFO - Started process (PID=2172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:45.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:29:45.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:45.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:45.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:47.322+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:29:57.822+0000] {processor.py:154} INFO - Started process (PID=2189) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:57.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:29:57.846+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:57.845+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:57.996+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:29:59.621+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:59.620+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:29:59.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:29:59.806+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:29:59.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.182 seconds
[2022-12-17T05:30:10.126+0000] {processor.py:154} INFO - Started process (PID=2200) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:10.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:30:10.134+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:10.133+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:10.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:10.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:10.468+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:30:10.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:10.604+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:30:10.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.600 seconds
[2022-12-17T05:30:20.938+0000] {processor.py:154} INFO - Started process (PID=2210) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:20.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:30:20.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:20.970+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:21.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:21.969+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:21.968+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:30:22.112+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:22.111+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:30:22.247+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.322 seconds
[2022-12-17T05:30:32.635+0000] {processor.py:154} INFO - Started process (PID=2220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:32.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:30:32.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:32.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:32.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:33.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:33.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:30:33.221+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:33.220+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:30:33.331+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.710 seconds
[2022-12-17T05:30:43.701+0000] {processor.py:154} INFO - Started process (PID=2238) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:43.705+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:30:43.713+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:43.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:43.823+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:44.204+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:44.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:30:44.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:44.441+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:30:44.632+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-17T05:30:55.074+0000] {processor.py:154} INFO - Started process (PID=2248) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:55.112+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:30:55.116+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:55.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:55.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:30:55.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:55.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:30:55.589+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:30:55.588+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:30:55.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.688 seconds
[2022-12-17T05:31:06.226+0000] {processor.py:154} INFO - Started process (PID=2258) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:06.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:31:06.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:06.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:06.517+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:06.892+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:06.891+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:31:07.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:07.092+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:31:07.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.111 seconds
[2022-12-17T05:31:17.700+0000] {processor.py:154} INFO - Started process (PID=2276) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:17.760+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:31:17.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:17.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:18.590+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:19.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:19.667+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:31:19.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:19.825+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:31:20.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.592 seconds
[2022-12-17T05:31:30.941+0000] {processor.py:154} INFO - Started process (PID=2287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:30.966+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:31:30.969+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:30.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:31.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:31.465+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:31.464+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:31:31.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:31.601+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:31:31.741+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.825 seconds
[2022-12-17T05:31:42.067+0000] {processor.py:154} INFO - Started process (PID=2297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:42.114+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:31:42.119+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:42.118+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:42.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:43.683+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:31:53.894+0000] {processor.py:154} INFO - Started process (PID=2307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:53.947+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:31:53.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:53.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:54.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:31:54.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:54.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:31:54.725+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:31:54.724+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:31:54.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.996 seconds
[2022-12-17T05:32:05.431+0000] {processor.py:154} INFO - Started process (PID=2325) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:05.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:32:05.495+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:05.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:05.691+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:06.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:06.021+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:32:06.227+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:06.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:32:06.399+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-17T05:32:16.806+0000] {processor.py:154} INFO - Started process (PID=2335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:16.854+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:32:16.859+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:16.858+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:16.951+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:17.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:17.174+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:32:17.326+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:17.325+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:32:17.433+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.641 seconds
[2022-12-17T05:32:28.164+0000] {processor.py:154} INFO - Started process (PID=2345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:28.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:32:28.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:28.193+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:28.276+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:29.712+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:32:40.590+0000] {processor.py:154} INFO - Started process (PID=2361) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:40.642+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:32:40.654+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:40.653+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:40.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:41.191+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:41.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:32:41.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:41.360+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:32:41.505+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.942 seconds
[2022-12-17T05:32:51.950+0000] {processor.py:154} INFO - Started process (PID=2372) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:51.991+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:32:51.998+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:51.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:52.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:32:52.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:52.821+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:32:52.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:32:52.959+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:32:53.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.140 seconds
[2022-12-17T05:33:03.339+0000] {processor.py:154} INFO - Started process (PID=2382) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:03.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:03.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:03.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:03.457+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:03.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:03.693+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:33:03.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:03.851+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:33:03.961+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.636 seconds
[2022-12-17T05:33:14.274+0000] {processor.py:154} INFO - Started process (PID=2392) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:14.296+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:14.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:14.300+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:14.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:14.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:14.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:33:15.209+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:15.208+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:33:15.399+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.139 seconds
[2022-12-17T05:33:25.679+0000] {processor.py:154} INFO - Started process (PID=2409) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:25.710+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:25.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:25.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:26.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:26.504+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:26.503+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:33:26.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:26.700+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:33:26.934+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.273 seconds
[2022-12-17T05:33:37.094+0000] {processor.py:154} INFO - Started process (PID=2419) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:37.097+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:37.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:37.101+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:37.191+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:37.880+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:33:48.482+0000] {processor.py:154} INFO - Started process (PID=2429) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:48.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:48.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:48.507+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:48.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:48.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:48.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:33:49.108+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:49.107+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:33:49.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.777 seconds
[2022-12-17T05:33:59.423+0000] {processor.py:154} INFO - Started process (PID=2439) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:59.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:33:59.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:59.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:59.546+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:33:59.782+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:59.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:33:59.927+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:33:59.926+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:34:00.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.663 seconds
[2022-12-17T05:34:10.881+0000] {processor.py:154} INFO - Started process (PID=2457) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:10.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:34:10.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:10.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:11.229+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:11.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:11.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:34:12.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:12.040+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:34:12.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.347 seconds
[2022-12-17T05:34:22.482+0000] {processor.py:154} INFO - Started process (PID=2467) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:22.509+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:34:22.514+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:22.513+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:22.649+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:23.414+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:34:33.900+0000] {processor.py:154} INFO - Started process (PID=2477) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:33.944+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:34:33.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:33.947+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:34.045+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:34.803+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:34.802+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:34:34.973+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:34.972+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:34:35.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.212 seconds
[2022-12-17T05:34:45.512+0000] {processor.py:154} INFO - Started process (PID=2495) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:45.548+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:34:45.555+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:45.553+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:45.759+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:46.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:46.701+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:34:46.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:46.932+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:34:47.169+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.693 seconds
[2022-12-17T05:34:57.625+0000] {processor.py:154} INFO - Started process (PID=2505) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:57.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:34:57.639+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:57.638+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:57.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:34:58.133+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:58.132+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:34:58.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:34:58.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:34:58.627+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.025 seconds
[2022-12-17T05:35:08.936+0000] {processor.py:154} INFO - Started process (PID=2515) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:08.969+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:35:08.973+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:08.973+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:09.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:09.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:09.322+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:35:09.525+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:09.525+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:35:09.693+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.773 seconds
[2022-12-17T05:35:20.003+0000] {processor.py:154} INFO - Started process (PID=2525) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:20.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:35:20.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:20.033+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:20.138+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:20.401+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:20.400+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:35:20.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:20.534+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:35:20.649+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.732 seconds
[2022-12-17T05:35:31.491+0000] {processor.py:154} INFO - Started process (PID=2543) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:31.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:35:31.557+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:31.556+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:31.891+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:32.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:32.514+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:35:32.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:32.750+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:35:32.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.478 seconds
[2022-12-17T05:35:43.298+0000] {processor.py:154} INFO - Started process (PID=2553) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:43.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:35:43.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:43.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:43.472+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:43.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:43.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:35:43.840+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:43.839+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:35:43.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-17T05:35:54.226+0000] {processor.py:154} INFO - Started process (PID=2563) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:54.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:35:54.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:54.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:54.455+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:35:54.979+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:54.973+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:35:55.461+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:35:55.460+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:35:55.628+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.416 seconds
[2022-12-17T05:36:06.130+0000] {processor.py:154} INFO - Started process (PID=2580) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:06.170+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:36:06.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:06.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:06.405+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:07.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:07.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:36:07.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:07.354+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:36:07.492+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.430 seconds
[2022-12-17T05:36:17.903+0000] {processor.py:154} INFO - Started process (PID=2591) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:17.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:36:17.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:17.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:18.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:18.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:18.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:36:18.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:18.355+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:36:18.542+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.653 seconds
[2022-12-17T05:36:29.057+0000] {processor.py:154} INFO - Started process (PID=2601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:29.084+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:36:29.089+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:29.088+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:29.180+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:29.385+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:29.385+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:36:29.512+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:29.511+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:36:29.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-17T05:36:39.925+0000] {processor.py:154} INFO - Started process (PID=2611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:39.978+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:36:39.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:39.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:40.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:40.313+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:40.312+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:36:40.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:40.450+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:36:40.615+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.703 seconds
[2022-12-17T05:36:51.031+0000] {processor.py:154} INFO - Started process (PID=2629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:51.058+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:36:51.070+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:51.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:51.250+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:36:51.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:51.989+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:36:52.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:36:52.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:36:52.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.277 seconds
[2022-12-17T05:37:02.569+0000] {processor.py:154} INFO - Started process (PID=2639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:02.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:37:02.599+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:02.598+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:02.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:03.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:03.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:37:03.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:03.737+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:37:03.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.304 seconds
[2022-12-17T05:37:14.829+0000] {processor.py:154} INFO - Started process (PID=2649) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:14.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:37:14.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:14.884+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:14.994+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:15.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:15.267+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:37:15.413+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:15.413+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:37:15.792+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.977 seconds
[2022-12-17T05:37:26.032+0000] {processor.py:154} INFO - Started process (PID=2659) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:26.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:37:26.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:26.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:26.174+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:26.829+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:26.828+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:37:27.070+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:27.069+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:37:27.332+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.318 seconds
[2022-12-17T05:37:37.875+0000] {processor.py:154} INFO - Started process (PID=2677) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:37.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:37:37.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:37.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:37.999+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:38.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:38.300+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:37:38.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:38.441+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:37:38.559+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.698 seconds
[2022-12-17T05:37:48.819+0000] {processor.py:154} INFO - Started process (PID=2687) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:48.865+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:37:48.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:48.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:49.010+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:37:49.287+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:49.286+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:37:49.430+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:37:49.430+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:37:49.595+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.792 seconds
[2022-12-17T05:38:00.170+0000] {processor.py:154} INFO - Started process (PID=2697) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:00.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:00.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:00.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:00.267+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:00.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:00.496+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:38:00.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:00.661+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:38:00.838+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-17T05:38:11.617+0000] {processor.py:154} INFO - Started process (PID=2715) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:11.629+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:11.646+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:11.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:11.758+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:12.599+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:12.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:38:13.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:13.015+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:38:13.451+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.911 seconds
[2022-12-17T05:38:23.978+0000] {processor.py:154} INFO - Started process (PID=2725) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:24.016+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:24.025+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:24.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:24.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:24.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:24.437+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:38:24.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:24.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:38:24.773+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.823 seconds
[2022-12-17T05:38:35.111+0000] {processor.py:154} INFO - Started process (PID=2735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:35.142+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:35.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:35.145+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:35.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:35.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:35.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:38:35.770+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:35.770+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:38:35.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.845 seconds
[2022-12-17T05:38:46.510+0000] {processor.py:154} INFO - Started process (PID=2745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:46.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:46.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:46.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:46.617+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:46.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:46.884+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:38:47.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:47.031+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:38:47.146+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-17T05:38:57.609+0000] {processor.py:154} INFO - Started process (PID=2763) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:57.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:38:57.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:38:57.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:57.877+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:38:58.410+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:39:08.740+0000] {processor.py:154} INFO - Started process (PID=2773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:08.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:39:08.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:08.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:08.861+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:09.084+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:09.083+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:39:09.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:09.229+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:39:09.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.689 seconds
[2022-12-17T05:39:19.741+0000] {processor.py:154} INFO - Started process (PID=2783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:19.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:39:19.790+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:19.789+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:19.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:20.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:20.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:39:20.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:20.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:39:20.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.148 seconds
[2022-12-17T05:39:31.084+0000] {processor.py:154} INFO - Started process (PID=2800) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:31.100+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:39:31.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:31.103+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:31.263+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:33.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:33.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:39:33.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:33.301+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:39:33.550+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.487 seconds
[2022-12-17T05:39:44.105+0000] {processor.py:154} INFO - Started process (PID=2811) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:44.206+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:39:44.211+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:44.210+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:44.350+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:44.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:44.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:39:44.739+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:44.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:39:44.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-17T05:39:55.142+0000] {processor.py:154} INFO - Started process (PID=2821) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:55.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:39:55.191+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:55.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:55.283+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:39:55.513+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:55.512+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:39:55.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:39:55.664+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:39:55.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.674 seconds
[2022-12-17T05:40:06.102+0000] {processor.py:154} INFO - Started process (PID=2831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:06.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:40:06.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:06.112+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:06.212+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:06.453+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:06.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:40:06.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:06.607+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:40:06.765+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.677 seconds
[2022-12-17T05:40:17.201+0000] {processor.py:154} INFO - Started process (PID=2849) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:17.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:40:17.241+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:17.240+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:17.474+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:18.092+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:18.091+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:40:18.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:18.439+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:40:18.666+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.510 seconds
[2022-12-17T05:40:28.853+0000] {processor.py:154} INFO - Started process (PID=2859) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:28.856+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:40:28.863+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:28.862+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:28.971+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:29.209+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:29.208+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:40:29.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:29.346+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:40:29.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.665 seconds
[2022-12-17T05:40:39.889+0000] {processor.py:154} INFO - Started process (PID=2869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:39.932+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:40:39.936+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:39.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:40.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:40.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:40.260+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:40:40.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:40.443+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:40:40.561+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-17T05:40:51.012+0000] {processor.py:154} INFO - Started process (PID=2879) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:51.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:40:51.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:51.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:51.137+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:40:51.666+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:51.665+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:40:51.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:40:51.806+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:40:52.373+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.444 seconds
[2022-12-17T05:41:03.080+0000] {processor.py:154} INFO - Started process (PID=2897) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:03.084+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:41:03.098+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:03.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:03.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:03.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:03.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:41:03.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:03.872+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:41:04.171+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.110 seconds
[2022-12-17T05:41:15.239+0000] {processor.py:154} INFO - Started process (PID=2907) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:15.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:41:15.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:15.261+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:15.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:15.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:15.785+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:41:15.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:15.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:41:16.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.933 seconds
[2022-12-17T05:41:26.364+0000] {processor.py:154} INFO - Started process (PID=2917) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:26.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:41:26.385+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:26.385+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:26.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:27.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:27.174+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:41:27.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:27.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:41:27.505+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.166 seconds
[2022-12-17T05:41:37.969+0000] {processor.py:154} INFO - Started process (PID=2935) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:37.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:41:37.988+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:37.981+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:38.131+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:38.621+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:41:49.483+0000] {processor.py:154} INFO - Started process (PID=2945) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:49.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:41:49.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:49.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:49.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:41:49.816+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:49.815+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:41:49.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:41:49.978+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:41:50.099+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.634 seconds
[2022-12-17T05:42:00.361+0000] {processor.py:154} INFO - Started process (PID=2955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:00.445+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:00.450+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:00.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:00.536+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:00.803+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:00.802+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:42:00.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:00.953+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:42:01.145+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-17T05:42:11.636+0000] {processor.py:154} INFO - Started process (PID=2965) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:11.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:11.704+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:11.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:11.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:12.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:12.727+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:42:13.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:13.060+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:42:13.244+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.639 seconds
[2022-12-17T05:42:23.820+0000] {processor.py:154} INFO - Started process (PID=2983) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:23.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:23.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:23.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:23.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:24.475+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:42:34.830+0000] {processor.py:154} INFO - Started process (PID=2993) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:34.882+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:34.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:34.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:34.974+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:35.398+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:35.397+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:42:35.723+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:35.722+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:42:35.924+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.107 seconds
[2022-12-17T05:42:46.232+0000] {processor.py:154} INFO - Started process (PID=3003) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:46.285+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:46.289+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:46.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:46.380+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:46.862+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:46.861+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:42:47.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:47.144+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:42:47.353+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.136 seconds
[2022-12-17T05:42:57.902+0000] {processor.py:154} INFO - Started process (PID=3021) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:57.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:42:57.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:57.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:58.140+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:42:58.485+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:58.484+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:42:59.035+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:42:59.034+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:42:59.380+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.526 seconds
[2022-12-17T05:43:10.032+0000] {processor.py:154} INFO - Started process (PID=3031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:10.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:43:10.045+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:10.044+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:10.138+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:10.481+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:10.480+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:43:10.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:10.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:43:11.153+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.138 seconds
[2022-12-17T05:43:21.363+0000] {processor.py:154} INFO - Started process (PID=3041) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:21.366+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:43:21.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:21.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:21.453+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:22.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:22.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:43:22.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:22.252+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:43:22.374+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.023 seconds
[2022-12-17T05:43:32.673+0000] {processor.py:154} INFO - Started process (PID=3051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:32.700+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:43:32.705+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:32.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:32.793+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:33.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:33.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:43:33.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:33.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:43:33.389+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.730 seconds
[2022-12-17T05:43:43.929+0000] {processor.py:154} INFO - Started process (PID=3069) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:44.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:43:44.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:44.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:44.172+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:44.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:44.458+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:43:44.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:44.608+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:43:44.753+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.839 seconds
[2022-12-17T05:43:55.613+0000] {processor.py:154} INFO - Started process (PID=3079) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:55.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:43:55.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:55.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:55.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:43:56.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:56.980+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:43:57.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:43:57.108+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:43:57.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.640 seconds
[2022-12-17T05:44:07.513+0000] {processor.py:154} INFO - Started process (PID=3089) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:07.517+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:44:07.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:07.520+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:07.620+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:07.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:07.872+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:44:08.016+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:08.015+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:44:08.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.733 seconds
[2022-12-17T05:44:18.831+0000] {processor.py:154} INFO - Started process (PID=3106) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:18.884+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:44:18.892+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:18.886+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:19.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:19.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:19.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:44:19.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:19.741+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:44:19.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.183 seconds
[2022-12-17T05:44:30.200+0000] {processor.py:154} INFO - Started process (PID=3116) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:30.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:44:30.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:30.207+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:30.294+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:30.523+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:30.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:44:30.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:30.670+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:44:30.837+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.654 seconds
[2022-12-17T05:44:41.170+0000] {processor.py:154} INFO - Started process (PID=3126) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:41.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:44:41.177+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:41.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:41.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:41.757+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:41.757+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:44:41.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:41.967+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:44:42.109+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.953 seconds
[2022-12-17T05:44:52.408+0000] {processor.py:154} INFO - Started process (PID=3136) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:52.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:44:52.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:52.418+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:52.587+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:44:52.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:52.817+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:44:52.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:44:52.969+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:44:53.090+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.696 seconds
[2022-12-17T05:45:03.487+0000] {processor.py:154} INFO - Started process (PID=3154) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:03.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:45:03.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:03.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:03.622+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:04.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:04.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:45:04.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:04.950+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:45:05.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.831 seconds
[2022-12-17T05:45:15.689+0000] {processor.py:154} INFO - Started process (PID=3164) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:15.742+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:45:15.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:15.745+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:15.834+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:16.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:16.155+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:45:16.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:16.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:45:16.443+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.768 seconds
[2022-12-17T05:45:26.751+0000] {processor.py:154} INFO - Started process (PID=3174) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:26.754+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:45:26.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:26.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:26.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:27.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:27.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:45:27.639+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:27.638+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:45:28.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.296 seconds
[2022-12-17T05:45:38.459+0000] {processor.py:154} INFO - Started process (PID=3192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:38.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:45:38.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:38.466+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:38.590+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:39.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:39.469+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:45:39.713+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:39.712+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:45:39.969+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.540 seconds
[2022-12-17T05:45:50.467+0000] {processor.py:154} INFO - Started process (PID=3202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:50.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:45:50.518+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:45:50.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:50.636+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:45:52.212+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:46:03.007+0000] {processor.py:154} INFO - Started process (PID=3212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:03.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:46:03.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:03.037+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:03.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:03.354+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:03.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:46:03.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:03.497+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:46:04.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-17T05:46:14.201+0000] {processor.py:154} INFO - Started process (PID=3222) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:14.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:46:14.232+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:14.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:14.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:14.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:14.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:46:14.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:14.793+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:46:14.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.743 seconds
[2022-12-17T05:46:25.672+0000] {processor.py:154} INFO - Started process (PID=3240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:25.715+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:46:25.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:25.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:25.919+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:26.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:26.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:46:26.399+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:26.398+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:46:26.522+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.868 seconds
[2022-12-17T05:46:37.042+0000] {processor.py:154} INFO - Started process (PID=3250) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:37.046+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:46:37.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:37.049+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:37.138+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:37.890+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:37.889+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:46:38.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:38.032+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:46:38.168+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.143 seconds
[2022-12-17T05:46:48.372+0000] {processor.py:154} INFO - Started process (PID=3260) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:48.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:46:48.395+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:48.394+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:48.492+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:46:49.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:49.853+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:46:50.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:46:50.120+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:46:50.373+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.029 seconds
[2022-12-17T05:47:00.895+0000] {processor.py:154} INFO - Started process (PID=3277) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:00.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:00.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:00.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:01.227+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:02.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:02.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:02.673+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:02.673+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:02.888+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.048 seconds
[2022-12-17T05:47:13.110+0000] {processor.py:154} INFO - Started process (PID=3287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:13.161+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:13.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:13.164+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:13.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:13.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:13.457+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:13.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:13.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:13.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.696 seconds
[2022-12-17T05:47:24.234+0000] {processor.py:154} INFO - Started process (PID=3297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:24.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:24.258+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:24.256+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:24.340+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:24.888+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:24.887+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:25.013+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:25.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:25.157+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.937 seconds
[2022-12-17T05:47:35.638+0000] {processor.py:154} INFO - Started process (PID=3307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:35.666+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:35.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:35.669+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:35.755+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:36.164+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:36.163+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:36.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:36.291+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:36.446+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.823 seconds
[2022-12-17T05:47:46.950+0000] {processor.py:154} INFO - Started process (PID=3325) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:47.035+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:47.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:47.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:47.256+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:47.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:47.708+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:47.894+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:47.894+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:48.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.116 seconds
[2022-12-17T05:47:58.329+0000] {processor.py:154} INFO - Started process (PID=3335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:58.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:47:58.352+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:58.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:58.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:47:58.650+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:58.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:47:58.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:47:58.923+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:47:59.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.845 seconds
[2022-12-17T05:48:09.722+0000] {processor.py:154} INFO - Started process (PID=3345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:09.749+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:48:09.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:09.753+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:09.856+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:10.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:10.119+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:48:10.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:10.278+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:48:10.386+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.685 seconds
[2022-12-17T05:48:20.922+0000] {processor.py:154} INFO - Started process (PID=3363) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:20.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:48:20.980+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:20.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:21.091+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:21.423+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:21.422+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:48:21.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:21.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:48:21.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.080 seconds
[2022-12-17T05:48:32.322+0000] {processor.py:154} INFO - Started process (PID=3373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:32.343+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:48:32.352+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:32.350+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:32.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:32.674+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:32.673+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:48:32.833+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:32.832+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:48:32.956+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.649 seconds
[2022-12-17T05:48:43.232+0000] {processor.py:154} INFO - Started process (PID=3383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:43.258+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:48:43.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:43.261+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:43.360+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:43.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:43.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:48:43.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:43.804+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:48:43.989+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-17T05:48:54.261+0000] {processor.py:154} INFO - Started process (PID=3393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:54.284+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:48:54.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:48:54.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:54.376+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:48:55.455+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:49:05.943+0000] {processor.py:154} INFO - Started process (PID=3411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:05.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:49:05.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:05.969+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:06.131+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:06.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:06.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:49:06.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:06.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:49:07.107+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.181 seconds
[2022-12-17T05:49:17.404+0000] {processor.py:154} INFO - Started process (PID=3421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:17.431+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:49:17.436+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:17.434+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:17.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:18.540+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:49:28.889+0000] {processor.py:154} INFO - Started process (PID=3431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:28.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:49:28.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:28.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:29.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:29.263+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:29.262+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:49:29.412+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:29.411+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:49:29.547+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.676 seconds
[2022-12-17T05:49:39.957+0000] {processor.py:154} INFO - Started process (PID=3448) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:39.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:49:39.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:39.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:40.235+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:40.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:40.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:49:40.835+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:40.830+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:49:41.080+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.181 seconds
[2022-12-17T05:49:51.708+0000] {processor.py:154} INFO - Started process (PID=3460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:51.759+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:49:51.763+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:51.762+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:51.862+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:49:53.233+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:53.232+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:49:53.379+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:49:53.378+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:49:53.491+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.797 seconds
[2022-12-17T05:50:03.769+0000] {processor.py:154} INFO - Started process (PID=3470) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:03.792+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:50:03.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:03.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:03.893+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:04.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:04.130+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:50:04.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:04.323+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:50:04.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.684 seconds
[2022-12-17T05:50:14.753+0000] {processor.py:154} INFO - Started process (PID=3480) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:14.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:50:14.788+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:14.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:14.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:15.773+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:15.772+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:50:16.051+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:16.050+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:50:16.200+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.463 seconds
[2022-12-17T05:50:26.388+0000] {processor.py:154} INFO - Started process (PID=3497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:26.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:50:26.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:26.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:26.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:26.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:26.939+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:50:27.232+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:27.231+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:50:27.474+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.113 seconds
[2022-12-17T05:50:38.012+0000] {processor.py:154} INFO - Started process (PID=3507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:38.042+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:50:38.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:38.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:38.139+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:38.510+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:38.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:50:38.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:38.827+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:50:39.026+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.029 seconds
[2022-12-17T05:50:49.410+0000] {processor.py:154} INFO - Started process (PID=3517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:49.455+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:50:49.464+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:49.458+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:49.600+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:50:49.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:49.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:50:49.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:50:49.997+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:50:50.144+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.754 seconds
[2022-12-17T05:51:00.402+0000] {processor.py:154} INFO - Started process (PID=3527) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:00.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:00.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:00.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:00.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:02.170+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:02.169+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:02.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:02.354+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:02.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.143 seconds
[2022-12-17T05:51:12.969+0000] {processor.py:154} INFO - Started process (PID=3546) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:13.001+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:13.005+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:13.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:13.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:13.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:13.329+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:13.496+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:13.495+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:13.633+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-17T05:51:23.849+0000] {processor.py:154} INFO - Started process (PID=3556) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:23.894+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:23.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:23.897+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:24.008+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:24.225+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:24.224+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:24.471+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:24.470+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:24.617+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.801 seconds
[2022-12-17T05:51:34.794+0000] {processor.py:154} INFO - Started process (PID=3566) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:34.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:34.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:34.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:34.949+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:35.219+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:35.218+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:35.368+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:35.367+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:35.521+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.744 seconds
[2022-12-17T05:51:45.925+0000] {processor.py:154} INFO - Started process (PID=3583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:45.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:45.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:45.940+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:46.119+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:46.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:46.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:46.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:46.725+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:46.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.078 seconds
[2022-12-17T05:51:57.429+0000] {processor.py:154} INFO - Started process (PID=3593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:57.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:51:57.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:57.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:57.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:51:57.850+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:57.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:51:58.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:51:58.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:51:58.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.734 seconds
[2022-12-17T05:52:08.515+0000] {processor.py:154} INFO - Started process (PID=3603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:08.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:52:08.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:08.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:08.688+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:09.409+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:09.408+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:52:09.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:09.578+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:52:09.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.234 seconds
[2022-12-17T05:52:20.132+0000] {processor.py:154} INFO - Started process (PID=3613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:20.206+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:52:20.216+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:20.215+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:20.329+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:20.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:20.717+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:52:20.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:20.941+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:52:21.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.958 seconds
[2022-12-17T05:52:31.523+0000] {processor.py:154} INFO - Started process (PID=3631) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:31.608+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:52:31.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:31.610+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:31.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:32.851+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:32.850+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:52:33.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:33.156+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:52:33.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.853 seconds
[2022-12-17T05:52:43.812+0000] {processor.py:154} INFO - Started process (PID=3641) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:43.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:52:43.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:43.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:43.971+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:44.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:44.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:52:44.322+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:44.321+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:52:44.480+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.687 seconds
[2022-12-17T05:52:54.771+0000] {processor.py:154} INFO - Started process (PID=3651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:54.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:52:54.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:52:54.803+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:54.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:52:56.374+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:53:07.029+0000] {processor.py:154} INFO - Started process (PID=3669) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:07.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:53:07.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:07.112+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:07.313+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:08.364+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:53:19.064+0000] {processor.py:154} INFO - Started process (PID=3679) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:19.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:53:19.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:19.090+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:19.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:19.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:19.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:53:19.763+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:19.762+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:53:19.899+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.867 seconds
[2022-12-17T05:53:30.340+0000] {processor.py:154} INFO - Started process (PID=3689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:30.367+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:53:30.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:30.372+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:30.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:30.971+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:30.970+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:53:31.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:31.103+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:53:31.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.933 seconds
[2022-12-17T05:53:41.513+0000] {processor.py:154} INFO - Started process (PID=3699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:41.562+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:53:41.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:41.573+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:41.658+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:42.798+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:53:53.400+0000] {processor.py:154} INFO - Started process (PID=3717) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:53.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:53:53.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:53:53.451+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:53.663+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:53:54.752+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:54:05.273+0000] {processor.py:154} INFO - Started process (PID=3727) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:05.315+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:54:05.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:05.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:05.404+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:05.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:05.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:54:06.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:06.104+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:54:06.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.016 seconds
[2022-12-17T05:54:16.616+0000] {processor.py:154} INFO - Started process (PID=3737) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:16.629+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:54:16.633+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:16.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:16.728+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:16.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:16.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:54:17.103+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:17.102+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:54:17.281+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.679 seconds
[2022-12-17T05:54:27.780+0000] {processor.py:154} INFO - Started process (PID=3754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:27.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:54:27.841+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:27.840+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:28.029+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:28.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:28.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:54:28.639+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:28.638+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:54:28.809+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.055 seconds
[2022-12-17T05:54:38.996+0000] {processor.py:154} INFO - Started process (PID=3765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:39.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:54:39.049+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:39.048+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:39.237+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:39.679+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:39.678+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:54:39.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:39.818+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:54:39.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.004 seconds
[2022-12-17T05:54:50.276+0000] {processor.py:154} INFO - Started process (PID=3775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:50.325+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:54:50.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:50.328+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:50.415+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:54:51.029+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:51.028+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:54:51.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:54:51.187+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:54:51.376+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.112 seconds
[2022-12-17T05:55:01.697+0000] {processor.py:154} INFO - Started process (PID=3785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:01.717+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:01.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:01.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:01.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:02.048+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:02.047+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:55:02.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:02.183+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:55:02.320+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.645 seconds
[2022-12-17T05:55:13.013+0000] {processor.py:154} INFO - Started process (PID=3803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:13.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:13.025+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:13.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:13.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:13.934+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:55:24.581+0000] {processor.py:154} INFO - Started process (PID=3813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:24.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:24.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:24.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:24.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:25.599+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:25.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:55:25.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:25.933+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:55:26.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.601 seconds
[2022-12-17T05:55:36.554+0000] {processor.py:154} INFO - Started process (PID=3823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:36.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:36.583+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:36.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:36.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:37.153+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:37.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:55:37.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:37.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:55:37.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.959 seconds
[2022-12-17T05:55:47.661+0000] {processor.py:154} INFO - Started process (PID=3833) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:47.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:47.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:47.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:47.812+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:48.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:48.104+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:55:48.241+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:48.240+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:55:48.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.760 seconds
[2022-12-17T05:55:59.288+0000] {processor.py:154} INFO - Started process (PID=3851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:59.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:55:59.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:59.360+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:59.712+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:55:59.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:55:59.990+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:56:00.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:00.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:56:00.504+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.254 seconds
[2022-12-17T05:56:10.715+0000] {processor.py:154} INFO - Started process (PID=3861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:10.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:56:10.723+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:10.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:10.811+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:11.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:11.057+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:56:11.227+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:11.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:56:11.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.660 seconds
[2022-12-17T05:56:21.626+0000] {processor.py:154} INFO - Started process (PID=3871) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:21.671+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:56:21.675+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:21.674+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:21.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:22.504+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:56:32.995+0000] {processor.py:154} INFO - Started process (PID=3888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:33.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:56:33.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:33.020+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:33.181+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:34.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:34.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:56:34.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:34.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:56:34.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.012 seconds
[2022-12-17T05:56:45.285+0000] {processor.py:154} INFO - Started process (PID=3898) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:45.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:56:45.309+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:45.308+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:45.397+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:46.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:46.108+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:56:46.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:46.294+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:56:46.479+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.208 seconds
[2022-12-17T05:56:56.889+0000] {processor.py:154} INFO - Started process (PID=3908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:56.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:56:56.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:56.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:57.021+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:56:57.258+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:57.257+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:56:57.400+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:56:57.399+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:56:57.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.671 seconds
[2022-12-17T05:57:08.615+0000] {processor.py:154} INFO - Started process (PID=3918) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:08.643+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:57:08.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:08.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:08.767+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:08.994+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:08.993+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:57:09.129+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:09.128+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:57:09.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-17T05:57:19.732+0000] {processor.py:154} INFO - Started process (PID=3937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:19.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:57:19.788+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:19.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:20.069+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:20.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:20.322+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:57:20.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:20.603+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:57:21.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.373 seconds
[2022-12-17T05:57:31.474+0000] {processor.py:154} INFO - Started process (PID=3947) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:31.478+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:57:31.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:31.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:31.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:32.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:32.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:57:32.316+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:32.315+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:57:32.462+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.005 seconds
[2022-12-17T05:57:42.763+0000] {processor.py:154} INFO - Started process (PID=3957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:42.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:57:42.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:42.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:42.880+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:43.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:43.274+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:57:43.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:43.426+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:57:43.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.780 seconds
[2022-12-17T05:57:54.022+0000] {processor.py:154} INFO - Started process (PID=3974) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:54.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:57:54.056+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:54.055+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:54.385+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:57:54.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:54.717+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:57:55.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:57:55.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:57:55.517+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.516 seconds
[2022-12-17T05:58:06.024+0000] {processor.py:154} INFO - Started process (PID=3985) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:06.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:06.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:06.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:06.132+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:06.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:06.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:58:06.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:06.869+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:58:07.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-17T05:58:09.524+0000] {processor.py:154} INFO - Started process (PID=4000) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:09.528+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:09.533+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:09.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:09.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:10.350+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:10.349+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:58:10.937+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:10.936+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:58:11.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.715 seconds
[2022-12-17T05:58:21.496+0000] {processor.py:154} INFO - Started process (PID=4010) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:21.501+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:21.506+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:21.505+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:21.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:22.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:22.867+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:58:23.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:23.011+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:58:23.131+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.655 seconds
[2022-12-17T05:58:33.705+0000] {processor.py:154} INFO - Started process (PID=4030) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:33.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:33.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:33.752+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:34.214+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:35.046+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:58:45.730+0000] {processor.py:154} INFO - Started process (PID=4041) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:45.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:45.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:45.791+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:46.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:46.345+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:46.344+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:58:46.472+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:46.471+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:58:46.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.986 seconds
[2022-12-17T05:58:57.017+0000] {processor.py:154} INFO - Started process (PID=4051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:57.051+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:58:57.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:57.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:57.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:58:57.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:57.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:58:57.938+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:58:57.937+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:58:58.057+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.064 seconds
[2022-12-17T05:59:08.487+0000] {processor.py:154} INFO - Started process (PID=4061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:08.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:59:08.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:08.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:09.146+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:10.920+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T05:59:21.480+0000] {processor.py:154} INFO - Started process (PID=4080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:21.498+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:59:21.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:21.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:21.953+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:22.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:22.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:59:22.392+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:22.391+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:59:22.617+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.170 seconds
[2022-12-17T05:59:33.020+0000] {processor.py:154} INFO - Started process (PID=4090) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:33.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:59:33.039+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:33.038+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:33.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:33.464+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:33.463+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:59:33.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:33.585+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:59:33.733+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.744 seconds
[2022-12-17T05:59:44.094+0000] {processor.py:154} INFO - Started process (PID=4100) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:44.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:59:44.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:44.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:44.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:44.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:44.368+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:59:44.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:44.487+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:59:44.628+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-17T05:59:55.088+0000] {processor.py:154} INFO - Started process (PID=4118) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:55.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T05:59:55.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:55.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:55.446+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T05:59:56.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:56.284+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T05:59:56.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T05:59:56.506+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T05:59:56.710+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.713 seconds
[2022-12-17T06:00:07.246+0000] {processor.py:154} INFO - Started process (PID=4129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:07.270+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:00:07.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:07.273+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:07.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:07.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:07.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:00:07.652+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:07.651+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:00:07.760+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.529 seconds
[2022-12-17T06:00:18.089+0000] {processor.py:154} INFO - Started process (PID=4139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:18.152+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:00:18.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:18.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:18.448+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:19.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:19.157+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:00:19.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:19.299+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:00:19.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.386 seconds
[2022-12-17T06:00:30.315+0000] {processor.py:154} INFO - Started process (PID=4149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:30.340+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:00:30.345+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:30.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:30.441+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:30.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:30.602+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:00:30.735+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:30.734+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:00:30.909+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-17T06:00:41.466+0000] {processor.py:154} INFO - Started process (PID=4168) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:41.509+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:00:41.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:41.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:41.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:42.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:42.299+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:00:42.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:42.525+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:00:42.750+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.321 seconds
[2022-12-17T06:00:53.246+0000] {processor.py:154} INFO - Started process (PID=4178) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:53.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:00:53.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:00:53.291+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:53.417+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:00:54.630+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:01:04.974+0000] {processor.py:154} INFO - Started process (PID=4188) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:04.989+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:01:04.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:04.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:05.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:05.244+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:05.242+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:01:05.364+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:05.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:01:05.488+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.528 seconds
[2022-12-17T06:01:16.434+0000] {processor.py:154} INFO - Started process (PID=4204) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:16.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:01:16.483+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:16.482+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:16.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:18.025+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:01:28.632+0000] {processor.py:154} INFO - Started process (PID=4215) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:28.645+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:01:28.649+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:28.648+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:28.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:28.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:28.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:01:29.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:29.052+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:01:29.237+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.619 seconds
[2022-12-17T06:01:39.572+0000] {processor.py:154} INFO - Started process (PID=4225) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:39.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:01:39.608+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:39.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:39.698+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:40.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:40.457+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:01:40.588+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:40.587+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:01:40.704+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.155 seconds
[2022-12-17T06:01:51.048+0000] {processor.py:154} INFO - Started process (PID=4235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:51.096+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:01:51.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:51.099+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:51.182+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:01:51.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:51.778+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:01:51.899+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:01:51.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:01:52.005+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.976 seconds
[2022-12-17T06:02:02.141+0000] {processor.py:154} INFO - Started process (PID=4253) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:02.168+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:02.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:02.170+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:02.333+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:02.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:02.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:02:02.747+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:02.746+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:02:02.989+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.863 seconds
[2022-12-17T06:02:13.771+0000] {processor.py:154} INFO - Started process (PID=4263) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:13.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:13.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:13.803+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:13.895+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:14.065+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:14.063+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:02:14.236+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:14.235+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:02:14.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.603 seconds
[2022-12-17T06:02:24.709+0000] {processor.py:154} INFO - Started process (PID=4273) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:24.742+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:24.751+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:24.746+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:24.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:25.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:25.040+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:02:25.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:25.152+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:02:25.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.571 seconds
[2022-12-17T06:02:36.177+0000] {processor.py:154} INFO - Started process (PID=4283) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:36.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:36.209+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:36.208+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:36.346+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:36.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:36.588+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:02:36.767+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:36.766+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:02:36.887+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.727 seconds
[2022-12-17T06:02:47.296+0000] {processor.py:154} INFO - Started process (PID=4300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:47.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:47.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:47.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:47.488+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:48.192+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:02:58.534+0000] {processor.py:154} INFO - Started process (PID=4310) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:58.577+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:02:58.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:58.581+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:58.671+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:02:58.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:58.811+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:02:58.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:02:58.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:02:59.057+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.538 seconds
[2022-12-17T06:03:10.051+0000] {processor.py:154} INFO - Started process (PID=4320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:10.069+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:03:10.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:10.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:10.155+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:10.285+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:10.284+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:03:10.411+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:10.410+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:03:10.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.526 seconds
[2022-12-17T06:03:21.367+0000] {processor.py:154} INFO - Started process (PID=4339) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:21.392+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:03:21.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:21.403+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:21.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:21.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:21.670+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:03:21.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:21.795+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:03:21.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-17T06:03:32.933+0000] {processor.py:154} INFO - Started process (PID=4349) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:32.972+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:03:32.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:32.975+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:33.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:33.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:33.193+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:03:33.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:33.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:03:33.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.532 seconds
[2022-12-17T06:03:43.714+0000] {processor.py:154} INFO - Started process (PID=4359) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:43.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:03:43.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:43.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:43.869+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:44.008+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:44.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:03:44.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:44.121+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:03:44.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.597 seconds
[2022-12-17T06:03:54.518+0000] {processor.py:154} INFO - Started process (PID=4369) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:54.528+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:03:54.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:54.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:54.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:03:55.229+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:55.228+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:03:55.341+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:03:55.340+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:03:55.478+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.974 seconds
[2022-12-17T06:04:06.018+0000] {processor.py:154} INFO - Started process (PID=4387) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:06.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:04:06.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:06.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:06.210+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:06.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:06.468+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:04:06.636+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:06.635+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:04:06.846+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.874 seconds
[2022-12-17T06:04:17.177+0000] {processor.py:154} INFO - Started process (PID=4397) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:17.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:04:17.215+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:17.214+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:17.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:17.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:17.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:04:18.001+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:18.000+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:04:18.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.147 seconds
[2022-12-17T06:04:29.059+0000] {processor.py:154} INFO - Started process (PID=4407) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:29.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:04:29.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:29.090+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:29.279+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:29.927+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:29.926+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:04:30.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:30.092+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:04:30.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-17T06:04:40.573+0000] {processor.py:154} INFO - Started process (PID=4417) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:40.589+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:04:40.593+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:40.592+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:40.866+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:41.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:41.882+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:04:42.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:42.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:04:42.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.727 seconds
[2022-12-17T06:04:52.817+0000] {processor.py:154} INFO - Started process (PID=4435) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:52.899+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:04:52.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:04:52.903+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:53.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:04:54.361+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:05:04.678+0000] {processor.py:154} INFO - Started process (PID=4445) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:04.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:05:04.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:04.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:04.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:04.983+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:04.982+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:05:05.096+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:05.094+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:05:05.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-17T06:05:15.632+0000] {processor.py:154} INFO - Started process (PID=4455) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:15.636+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:05:15.640+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:15.639+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:15.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:17.038+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:05:27.409+0000] {processor.py:154} INFO - Started process (PID=4472) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:27.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:05:27.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:27.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:27.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:28.919+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:28.918+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:05:29.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:29.068+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:05:29.209+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.818 seconds
[2022-12-17T06:05:39.605+0000] {processor.py:154} INFO - Started process (PID=4482) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:39.637+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:05:39.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:39.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:39.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:40.353+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:05:51.222+0000] {processor.py:154} INFO - Started process (PID=4492) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:51.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:05:51.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:51.278+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:51.369+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:05:51.504+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:51.503+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:05:51.625+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:05:51.624+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:05:51.759+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.553 seconds
[2022-12-17T06:06:02.007+0000] {processor.py:154} INFO - Started process (PID=4502) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:02.016+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:02.020+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:02.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:02.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:02.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:02.265+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:06:02.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:02.374+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:06:02.476+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.483 seconds
[2022-12-17T06:06:12.978+0000] {processor.py:154} INFO - Started process (PID=4520) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:12.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:12.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:12.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:13.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:13.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:13.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:06:13.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:13.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:06:13.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.740 seconds
[2022-12-17T06:06:24.072+0000] {processor.py:154} INFO - Started process (PID=4530) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:24.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:24.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:24.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:24.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:24.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:24.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:06:24.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:24.669+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:06:24.778+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-17T06:06:35.052+0000] {processor.py:154} INFO - Started process (PID=4540) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:35.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:35.112+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:35.111+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:35.207+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:35.354+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:35.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:06:35.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:35.468+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:06:35.622+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.585 seconds
[2022-12-17T06:06:45.994+0000] {processor.py:154} INFO - Started process (PID=4558) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:46.022+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:46.026+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:46.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:46.222+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:47.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:47.009+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:06:47.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:47.326+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:06:47.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.733 seconds
[2022-12-17T06:06:58.287+0000] {processor.py:154} INFO - Started process (PID=4569) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:58.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:06:58.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:06:58.315+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:58.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:06:59.081+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:07:09.615+0000] {processor.py:154} INFO - Started process (PID=4579) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:09.643+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:07:09.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:09.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:09.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:09.874+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:09.873+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:07:09.995+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:09.994+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:07:10.158+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.557 seconds
[2022-12-17T06:07:20.468+0000] {processor.py:154} INFO - Started process (PID=4589) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:20.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:07:20.519+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:20.518+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:20.613+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:20.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:20.743+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:07:20.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:20.865+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:07:21.005+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-17T06:07:31.323+0000] {processor.py:154} INFO - Started process (PID=4607) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:31.351+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:07:31.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:31.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:31.617+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:32.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:32.354+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:07:32.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:32.507+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:07:32.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.358 seconds
[2022-12-17T06:07:42.961+0000] {processor.py:154} INFO - Started process (PID=4617) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:42.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:07:43.003+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:43.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:43.118+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:43.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:43.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:07:43.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:43.869+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:07:43.980+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.048 seconds
[2022-12-17T06:07:54.331+0000] {processor.py:154} INFO - Started process (PID=4627) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:54.444+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:07:54.457+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:54.456+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:54.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:07:55.611+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:55.610+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:07:55.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:07:55.725+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:07:55.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.625 seconds
[2022-12-17T06:08:06.529+0000] {processor.py:154} INFO - Started process (PID=4643) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:06.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:08:06.543+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:06.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:06.656+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:06.974+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:06.972+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:08:07.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:07.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:08:07.323+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.826 seconds
[2022-12-17T06:08:17.502+0000] {processor.py:154} INFO - Started process (PID=4654) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:17.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:08:17.516+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:17.515+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:17.622+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:18.018+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:18.017+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:08:18.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:18.318+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:08:18.469+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.998 seconds
[2022-12-17T06:08:28.668+0000] {processor.py:154} INFO - Started process (PID=4664) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:28.716+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:08:28.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:28.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:28.833+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:29.575+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:29.574+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:08:29.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:29.882+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:08:30.049+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.396 seconds
[2022-12-17T06:08:40.400+0000] {processor.py:154} INFO - Started process (PID=4674) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:40.450+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:08:40.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:40.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:40.539+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:41.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:41.625+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:08:41.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:41.748+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:08:41.858+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.473 seconds
[2022-12-17T06:08:52.311+0000] {processor.py:154} INFO - Started process (PID=4691) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:52.320+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:08:52.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:52.336+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:52.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:08:53.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:53.183+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:08:53.351+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:08:53.349+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:08:53.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.227 seconds
[2022-12-17T06:09:03.902+0000] {processor.py:154} INFO - Started process (PID=4701) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:03.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:09:03.910+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:03.909+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:04.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:05.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:05.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:09:05.299+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:05.298+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:09:05.623+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.738 seconds
[2022-12-17T06:09:16.199+0000] {processor.py:154} INFO - Started process (PID=4711) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:16.238+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:09:16.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:16.246+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:16.346+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:16.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:16.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:09:16.971+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:16.970+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:09:17.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.915 seconds
[2022-12-17T06:09:27.447+0000] {processor.py:154} INFO - Started process (PID=4721) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:27.474+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:09:27.478+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:27.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:27.571+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:28.148+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:28.147+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:09:28.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:28.323+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:09:28.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.203 seconds
[2022-12-17T06:09:39.131+0000] {processor.py:154} INFO - Started process (PID=4738) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:39.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:09:39.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:39.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:39.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:39.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:39.485+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:09:39.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:39.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:09:39.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.595 seconds
[2022-12-17T06:09:50.028+0000] {processor.py:154} INFO - Started process (PID=4748) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:50.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:09:50.044+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:50.042+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:50.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:09:50.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:50.272+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:09:50.525+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:09:50.524+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:09:50.814+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.800 seconds
[2022-12-17T06:10:01.172+0000] {processor.py:154} INFO - Started process (PID=4758) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:01.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:01.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:01.179+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:01.270+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:01.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:01.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:10:01.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:01.717+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:10:01.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-17T06:10:12.198+0000] {processor.py:154} INFO - Started process (PID=4775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:12.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:12.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:12.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:12.329+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:12.903+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:12.902+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:10:13.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:13.049+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:10:13.515+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.334 seconds
[2022-12-17T06:10:23.914+0000] {processor.py:154} INFO - Started process (PID=4785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:23.942+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:23.946+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:23.945+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:24.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:24.160+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:24.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:10:24.272+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:24.271+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:10:24.426+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.525 seconds
[2022-12-17T06:10:35.105+0000] {processor.py:154} INFO - Started process (PID=4795) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:35.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:35.117+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:35.113+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:35.198+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:36.528+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:10:46.883+0000] {processor.py:154} INFO - Started process (PID=4805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:46.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:46.917+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:46.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:47.000+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:47.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:47.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:10:48.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:48.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:10:48.257+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.390 seconds
[2022-12-17T06:10:58.735+0000] {processor.py:154} INFO - Started process (PID=4823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:58.757+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:10:58.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:58.761+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:58.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:10:59.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:59.049+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:10:59.177+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:10:59.176+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:10:59.330+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-17T06:11:09.672+0000] {processor.py:154} INFO - Started process (PID=4833) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:09.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:11:09.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:09.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:09.782+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:10.636+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:11:21.144+0000] {processor.py:154} INFO - Started process (PID=4843) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:21.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:11:21.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:21.166+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:21.261+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:21.422+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:21.421+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:11:21.580+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:21.566+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:11:21.769+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.639 seconds
[2022-12-17T06:11:31.949+0000] {processor.py:154} INFO - Started process (PID=4861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:32.004+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:11:32.011+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:32.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:32.174+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:32.363+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:32.362+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:11:32.489+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:32.488+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:11:32.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.684 seconds
[2022-12-17T06:11:42.918+0000] {processor.py:154} INFO - Started process (PID=4871) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:42.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:11:42.953+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:42.952+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:43.036+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:43.838+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:43.837+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:11:43.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:43.986+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:11:44.095+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.190 seconds
[2022-12-17T06:11:54.259+0000] {processor.py:154} INFO - Started process (PID=4881) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:54.284+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:11:54.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:54.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:54.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:11:54.541+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:54.540+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:11:54.663+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:11:54.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:11:54.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.523 seconds
[2022-12-17T06:12:05.029+0000] {processor.py:154} INFO - Started process (PID=4891) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:05.077+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:12:05.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:05.083+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:05.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:05.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:05.329+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:12:05.437+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:05.436+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:12:05.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.565 seconds
[2022-12-17T06:12:16.031+0000] {processor.py:154} INFO - Started process (PID=4909) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:16.080+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:12:16.096+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:16.088+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:16.249+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:16.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:16.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:12:16.534+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:16.533+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:12:16.729+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-17T06:12:27.164+0000] {processor.py:154} INFO - Started process (PID=4919) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:27.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:12:27.232+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:27.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:27.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:27.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:27.448+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:12:27.575+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:27.574+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:12:27.678+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.535 seconds
[2022-12-17T06:12:37.957+0000] {processor.py:154} INFO - Started process (PID=4929) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:37.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:12:37.996+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:37.995+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:38.080+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:39.115+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:39.114+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:12:39.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:39.222+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:12:39.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.412 seconds
[2022-12-17T06:12:49.735+0000] {processor.py:154} INFO - Started process (PID=4945) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:49.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:12:49.778+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:12:49.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:49.896+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:12:50.599+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:13:01.290+0000] {processor.py:154} INFO - Started process (PID=4957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:01.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:01.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:01.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:01.507+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:01.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:01.694+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:01.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:01.806+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:01.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.655 seconds
[2022-12-17T06:13:12.245+0000] {processor.py:154} INFO - Started process (PID=4967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:12.305+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:12.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:12.317+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:12.399+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:13.026+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:13.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:13.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:13.157+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:13.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.045 seconds
[2022-12-17T06:13:23.602+0000] {processor.py:154} INFO - Started process (PID=4977) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:23.655+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:23.659+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:23.658+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:23.752+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:24.025+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:24.024+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:24.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:24.155+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:24.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.095 seconds
[2022-12-17T06:13:34.889+0000] {processor.py:154} INFO - Started process (PID=4995) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:34.899+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:34.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:34.902+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:35.039+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:35.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:35.595+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:35.727+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:35.726+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:35.885+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-17T06:13:46.127+0000] {processor.py:154} INFO - Started process (PID=5005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:46.158+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:46.163+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:46.162+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:46.251+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:46.676+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:46.675+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:46.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:46.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:46.941+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.827 seconds
[2022-12-17T06:13:57.550+0000] {processor.py:154} INFO - Started process (PID=5015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:57.592+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:13:57.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:57.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:57.681+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:13:58.000+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:57.999+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:13:58.128+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:13:58.127+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:13:58.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.731 seconds
[2022-12-17T06:14:08.521+0000] {processor.py:154} INFO - Started process (PID=5025) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:08.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:14:08.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:08.544+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:08.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:08.808+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:08.808+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:14:08.932+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:08.932+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:14:09.062+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T06:14:19.608+0000] {processor.py:154} INFO - Started process (PID=5043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:19.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:14:19.650+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:19.649+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:19.853+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:20.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:20.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:14:20.703+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:20.702+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:14:20.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.295 seconds
[2022-12-17T06:14:31.809+0000] {processor.py:154} INFO - Started process (PID=5053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:31.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:14:31.835+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:31.834+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:31.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:32.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:32.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:14:32.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:32.194+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:14:32.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.544 seconds
[2022-12-17T06:14:43.070+0000] {processor.py:154} INFO - Started process (PID=5063) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:43.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:14:43.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:43.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:43.186+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:43.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:43.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:14:43.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:43.737+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:14:43.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.883 seconds
[2022-12-17T06:14:54.586+0000] {processor.py:154} INFO - Started process (PID=5081) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:54.624+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:14:54.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:14:54.626+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:54.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:14:56.287+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:15:06.864+0000] {processor.py:154} INFO - Started process (PID=5091) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:06.890+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:15:06.895+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:06.894+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:06.982+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:07.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:07.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:15:07.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:07.222+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:15:07.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.533 seconds
[2022-12-17T06:15:17.526+0000] {processor.py:154} INFO - Started process (PID=5101) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:17.572+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:15:17.577+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:17.576+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:17.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:17.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:17.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:15:17.918+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:17.917+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:15:18.037+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.524 seconds
[2022-12-17T06:15:28.334+0000] {processor.py:154} INFO - Started process (PID=5111) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:28.392+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:15:28.400+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:28.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:28.495+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:28.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:28.643+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:15:28.755+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:28.754+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:15:28.904+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.587 seconds
[2022-12-17T06:15:39.093+0000] {processor.py:154} INFO - Started process (PID=5129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:39.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:15:39.162+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:39.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:39.327+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:40.247+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:40.246+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:15:40.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:40.450+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:15:40.708+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.652 seconds
[2022-12-17T06:15:51.095+0000] {processor.py:154} INFO - Started process (PID=5139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:51.098+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:15:51.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:51.101+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:51.186+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:15:51.340+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:51.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:15:51.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:15:51.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:15:51.644+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.561 seconds
[2022-12-17T06:16:02.609+0000] {processor.py:154} INFO - Started process (PID=5149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:02.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:02.631+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:02.630+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:02.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:03.621+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:03.620+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:16:03.733+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:03.732+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:16:03.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.285 seconds
[2022-12-17T06:16:14.966+0000] {processor.py:154} INFO - Started process (PID=5167) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:14.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:15.000+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:14.999+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:15.105+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:15.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:15.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:16:15.407+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:15.406+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:16:15.548+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.595 seconds
[2022-12-17T06:16:26.006+0000] {processor.py:154} INFO - Started process (PID=5177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:26.010+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:26.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:26.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:26.106+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:26.852+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:26.842+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:16:27.011+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:27.010+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:16:27.119+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.127 seconds
[2022-12-17T06:16:37.483+0000] {processor.py:154} INFO - Started process (PID=5187) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:37.487+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:37.491+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:37.490+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:37.646+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:37.778+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:37.777+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:16:37.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:37.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:16:38.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T06:16:48.298+0000] {processor.py:154} INFO - Started process (PID=5197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:48.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:48.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:48.326+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:48.449+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:48.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:48.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:16:49.081+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:49.080+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:16:49.222+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.940 seconds
[2022-12-17T06:16:59.900+0000] {processor.py:154} INFO - Started process (PID=5214) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:16:59.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:16:59.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:16:59.983+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:00.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:00.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:00.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:17:00.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:00.595+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:17:00.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.991 seconds
[2022-12-17T06:17:11.070+0000] {processor.py:154} INFO - Started process (PID=5224) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:11.074+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:17:11.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:11.077+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:11.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:11.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:11.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:17:11.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:11.423+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:17:11.556+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.500 seconds
[2022-12-17T06:17:22.112+0000] {processor.py:154} INFO - Started process (PID=5234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:22.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:17:22.142+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:22.141+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:22.351+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:23.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:23.939+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:17:24.086+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:24.085+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:17:24.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.189 seconds
[2022-12-17T06:17:34.441+0000] {processor.py:154} INFO - Started process (PID=5251) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:34.463+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:17:34.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:34.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:34.572+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:34.951+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:17:45.763+0000] {processor.py:154} INFO - Started process (PID=5262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:45.787+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:17:45.791+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:45.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:45.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:46.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:46.275+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:17:46.398+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:46.397+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:17:46.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.754 seconds
[2022-12-17T06:17:57.145+0000] {processor.py:154} INFO - Started process (PID=5272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:57.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:17:57.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:57.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:57.323+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:17:57.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:57.504+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:17:57.632+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:17:57.631+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:17:57.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.606 seconds
[2022-12-17T06:18:08.017+0000] {processor.py:154} INFO - Started process (PID=5282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:08.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:18:08.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:08.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:08.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:09.637+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:09.636+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:18:09.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:09.750+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:18:09.889+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.887 seconds
[2022-12-17T06:18:20.227+0000] {processor.py:154} INFO - Started process (PID=5300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:20.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:18:20.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:20.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:20.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:21.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:21.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:18:21.173+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:21.172+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:18:21.361+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.149 seconds
[2022-12-17T06:18:31.662+0000] {processor.py:154} INFO - Started process (PID=5310) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:31.683+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:18:31.688+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:31.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:31.772+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:33.309+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:33.308+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:18:33.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:33.419+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:18:33.557+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.908 seconds
[2022-12-17T06:18:44.236+0000] {processor.py:154} INFO - Started process (PID=5320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:44.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:18:44.255+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:44.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:44.360+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:44.829+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:44.828+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:18:44.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:44.950+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:18:45.086+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.872 seconds
[2022-12-17T06:18:55.473+0000] {processor.py:154} INFO - Started process (PID=5337) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:55.477+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:18:55.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:55.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:55.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:18:55.859+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:55.858+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:18:56.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:18:56.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:18:56.284+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.828 seconds
[2022-12-17T06:19:06.803+0000] {processor.py:154} INFO - Started process (PID=5348) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:06.836+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:19:06.842+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:06.840+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:06.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:07.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:07.066+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:19:07.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:07.179+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:19:07.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.547 seconds
[2022-12-17T06:19:17.766+0000] {processor.py:154} INFO - Started process (PID=5358) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:17.821+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:19:17.829+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:17.828+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:17.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:18.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:18.628+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:19:18.743+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:18.742+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:19:18.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.163 seconds
[2022-12-17T06:19:29.877+0000] {processor.py:154} INFO - Started process (PID=5368) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:29.928+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:19:29.933+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:29.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:30.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:30.553+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:19:40.884+0000] {processor.py:154} INFO - Started process (PID=5386) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:40.909+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:19:40.921+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:40.920+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:41.022+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:41.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:41.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:19:41.312+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:41.311+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:19:41.664+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.834 seconds
[2022-12-17T06:19:52.430+0000] {processor.py:154} INFO - Started process (PID=5396) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:52.499+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:19:52.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:52.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:52.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:19:53.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:53.689+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:19:53.810+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:19:53.809+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:19:53.926+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.547 seconds
[2022-12-17T06:20:04.216+0000] {processor.py:154} INFO - Started process (PID=5406) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:04.244+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:20:04.249+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:04.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:04.334+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:04.466+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:04.465+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:20:04.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:04.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:20:04.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-17T06:20:15.038+0000] {processor.py:154} INFO - Started process (PID=5416) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:15.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:20:15.087+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:15.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:15.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:16.670+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:20:27.164+0000] {processor.py:154} INFO - Started process (PID=5435) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:27.181+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:20:27.185+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:27.184+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:27.274+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:27.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:27.417+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:20:27.568+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:27.567+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:20:27.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.831 seconds
[2022-12-17T06:20:38.225+0000] {processor.py:154} INFO - Started process (PID=5445) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:38.263+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:20:38.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:38.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:38.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:38.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:38.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:20:38.645+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:38.645+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:20:38.750+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.540 seconds
[2022-12-17T06:20:49.008+0000] {processor.py:154} INFO - Started process (PID=5455) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:49.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:20:49.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:49.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:49.193+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:20:49.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:49.487+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:20:49.758+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:20:49.758+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:20:49.964+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.973 seconds
[2022-12-17T06:21:00.133+0000] {processor.py:154} INFO - Started process (PID=5473) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:00.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:00.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:00.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:00.246+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:01.245+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:21:11.825+0000] {processor.py:154} INFO - Started process (PID=5483) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:11.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:11.875+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:11.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:11.973+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:12.621+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:12.620+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:21:12.875+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:12.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:21:12.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.184 seconds
[2022-12-17T06:21:23.293+0000] {processor.py:154} INFO - Started process (PID=5493) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:23.361+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:23.368+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:23.367+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:23.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:23.655+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:23.654+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:21:23.985+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:23.984+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:21:24.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.876 seconds
[2022-12-17T06:21:34.433+0000] {processor.py:154} INFO - Started process (PID=5503) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:34.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:34.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:34.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:34.523+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:34.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:34.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:21:34.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:34.778+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:21:34.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.491 seconds
[2022-12-17T06:21:45.567+0000] {processor.py:154} INFO - Started process (PID=5522) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:45.578+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:45.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:45.581+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:45.749+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:45.999+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:45.997+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:21:46.143+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:46.142+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:21:46.255+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-17T06:21:56.548+0000] {processor.py:154} INFO - Started process (PID=5532) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:56.571+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:21:56.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:56.574+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:56.690+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:21:56.844+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:56.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:21:56.963+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:21:56.962+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:21:57.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.570 seconds
[2022-12-17T06:22:08.067+0000] {processor.py:154} INFO - Started process (PID=5542) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:08.094+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:22:08.100+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:08.099+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:08.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:08.772+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:22:19.475+0000] {processor.py:154} INFO - Started process (PID=5560) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:19.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:22:19.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:19.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:19.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:20.013+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:20.012+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:22:20.135+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:20.134+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:22:20.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.843 seconds
[2022-12-17T06:22:30.937+0000] {processor.py:154} INFO - Started process (PID=5570) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:30.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:22:30.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:30.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:31.078+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:31.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:31.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:22:32.147+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:32.146+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:22:32.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.338 seconds
[2022-12-17T06:22:42.559+0000] {processor.py:154} INFO - Started process (PID=5580) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:42.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:22:42.592+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:42.591+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:42.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:43.160+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:43.159+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:22:43.270+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:43.269+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:22:43.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.926 seconds
[2022-12-17T06:22:53.777+0000] {processor.py:154} INFO - Started process (PID=5590) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:53.825+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:22:53.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:22:53.828+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:53.928+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:22:54.658+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:23:05.247+0000] {processor.py:154} INFO - Started process (PID=5609) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:05.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:23:05.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:05.260+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:05.386+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:05.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:05.800+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:23:05.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:05.977+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:23:06.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.890 seconds
[2022-12-17T06:23:16.847+0000] {processor.py:154} INFO - Started process (PID=5619) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:16.861+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:23:16.865+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:16.864+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:16.956+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:17.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:17.206+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:23:17.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:17.323+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:23:17.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.610 seconds
[2022-12-17T06:23:27.700+0000] {processor.py:154} INFO - Started process (PID=5629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:27.754+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:23:27.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:27.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:27.842+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:27.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:27.983+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:23:28.127+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:28.126+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:23:28.263+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.580 seconds
[2022-12-17T06:23:38.631+0000] {processor.py:154} INFO - Started process (PID=5647) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:38.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:23:38.652+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:38.651+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:38.756+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:38.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:38.949+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:23:39.148+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:39.147+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:23:39.268+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.653 seconds
[2022-12-17T06:23:49.570+0000] {processor.py:154} INFO - Started process (PID=5658) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:49.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:23:49.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:23:49.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:49.720+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:23:50.325+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:24:00.765+0000] {processor.py:154} INFO - Started process (PID=5668) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:00.813+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:00.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:00.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:01.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:01.210+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:01.209+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:01.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:01.329+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:01.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.766 seconds
[2022-12-17T06:24:12.076+0000] {processor.py:154} INFO - Started process (PID=5678) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:12.100+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:12.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:12.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:12.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:12.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:12.719+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:12.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:12.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:12.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.924 seconds
[2022-12-17T06:24:23.735+0000] {processor.py:154} INFO - Started process (PID=5696) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:23.756+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:23.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:23.761+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:24.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:24.534+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:24.533+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:24.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:24.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:24.976+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.257 seconds
[2022-12-17T06:24:35.355+0000] {processor.py:154} INFO - Started process (PID=5706) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:35.369+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:35.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:35.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:35.456+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:35.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:35.634+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:35.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:35.883+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:36.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.756 seconds
[2022-12-17T06:24:46.967+0000] {processor.py:154} INFO - Started process (PID=5716) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:47.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:47.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:47.021+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:47.167+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:47.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:47.538+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:47.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:47.731+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:47.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.927 seconds
[2022-12-17T06:24:58.350+0000] {processor.py:154} INFO - Started process (PID=5726) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:58.373+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:24:58.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:58.377+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:58.856+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:24:59.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:59.388+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:24:59.743+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:24:59.742+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:24:59.964+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.636 seconds
[2022-12-17T06:25:10.485+0000] {processor.py:154} INFO - Started process (PID=5744) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:10.489+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:25:10.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:10.492+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:10.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:10.722+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:10.721+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:25:10.859+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:10.858+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:25:11.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.818 seconds
[2022-12-17T06:25:21.606+0000] {processor.py:154} INFO - Started process (PID=5754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:21.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:25:21.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:21.745+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:21.830+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:22.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:22.145+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:25:22.434+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:22.433+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:25:22.711+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.122 seconds
[2022-12-17T06:25:32.999+0000] {processor.py:154} INFO - Started process (PID=5764) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:33.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:25:33.048+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:33.040+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:33.191+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:33.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:33.439+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:25:33.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:33.549+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:25:33.664+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-17T06:25:44.070+0000] {processor.py:154} INFO - Started process (PID=5783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:44.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:25:44.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:44.113+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:44.234+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:44.385+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:44.384+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:25:44.592+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:44.591+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:25:44.793+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.739 seconds
[2022-12-17T06:25:55.063+0000] {processor.py:154} INFO - Started process (PID=5793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:55.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:25:55.110+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:55.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:55.191+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:25:55.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:55.805+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:25:55.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:25:55.923+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:25:56.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.013 seconds
[2022-12-17T06:26:06.310+0000] {processor.py:154} INFO - Started process (PID=5803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:06.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:26:06.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:06.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:06.428+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:07.088+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:07.087+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:26:07.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:07.204+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:26:07.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.040 seconds
[2022-12-17T06:26:17.692+0000] {processor.py:154} INFO - Started process (PID=5813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:17.721+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:26:17.729+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:17.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:17.839+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:19.116+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:19.115+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:26:19.227+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:19.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:26:19.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.655 seconds
[2022-12-17T06:26:30.410+0000] {processor.py:154} INFO - Started process (PID=5831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:30.471+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:26:30.475+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:30.474+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:30.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:30.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:30.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:26:30.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:30.959+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:26:31.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.731 seconds
[2022-12-17T06:26:41.237+0000] {processor.py:154} INFO - Started process (PID=5841) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:41.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:26:41.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:41.292+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:41.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:42.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:42.670+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:26:42.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:42.780+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:26:42.898+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.675 seconds
[2022-12-17T06:26:53.164+0000] {processor.py:154} INFO - Started process (PID=5851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:53.212+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:26:53.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:53.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:53.301+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:26:53.722+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:53.721+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:26:53.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:26:53.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:26:53.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.815 seconds
[2022-12-17T06:27:04.419+0000] {processor.py:154} INFO - Started process (PID=5869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:04.480+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:27:04.484+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:04.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:04.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:04.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:04.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:27:05.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:05.194+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:27:05.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.049 seconds
[2022-12-17T06:27:15.683+0000] {processor.py:154} INFO - Started process (PID=5879) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:15.727+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:27:15.731+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:15.730+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:15.840+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:17.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:17.150+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:27:17.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:17.273+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:27:17.376+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.708 seconds
[2022-12-17T06:27:27.495+0000] {processor.py:154} INFO - Started process (PID=5889) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:27.550+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:27:27.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:27.554+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:27.675+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:27.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:27.811+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:27:27.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:27.933+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:27:28.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.589 seconds
[2022-12-17T06:27:38.403+0000] {processor.py:154} INFO - Started process (PID=5899) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:38.476+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:27:38.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:38.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:38.577+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:38.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:38.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:27:38.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:38.882+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:27:39.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.633 seconds
[2022-12-17T06:27:49.371+0000] {processor.py:154} INFO - Started process (PID=5916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:49.377+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:27:49.390+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:49.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:49.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:27:49.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:49.697+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:27:49.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:27:49.971+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:27:50.142+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.817 seconds
[2022-12-17T06:28:00.598+0000] {processor.py:154} INFO - Started process (PID=5926) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:00.648+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:00.656+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:00.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:00.793+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:01.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:01.426+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:28:01.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:01.543+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:28:01.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.114 seconds
[2022-12-17T06:28:12.103+0000] {processor.py:154} INFO - Started process (PID=5936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:12.147+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:12.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:12.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:12.297+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:12.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:12.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:28:12.585+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:12.584+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:28:12.729+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.641 seconds
[2022-12-17T06:28:23.104+0000] {processor.py:154} INFO - Started process (PID=5951) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:23.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:23.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:23.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:23.338+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:23.923+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:23.922+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:28:24.090+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:24.089+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:28:24.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.286 seconds
[2022-12-17T06:28:35.002+0000] {processor.py:154} INFO - Started process (PID=5963) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:35.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:35.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:35.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:35.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:35.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:35.276+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:28:35.390+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:35.389+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:28:35.590+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.609 seconds
[2022-12-17T06:28:46.058+0000] {processor.py:154} INFO - Started process (PID=5973) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:46.084+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:46.092+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:46.091+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:46.213+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:46.409+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:46.408+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:28:46.557+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:46.556+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:28:46.680+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.652 seconds
[2022-12-17T06:28:57.632+0000] {processor.py:154} INFO - Started process (PID=5983) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:57.648+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:28:57.654+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:28:57.651+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:57.782+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:28:58.780+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:29:09.312+0000] {processor.py:154} INFO - Started process (PID=6001) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:09.342+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:29:09.360+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:09.345+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:09.701+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:09.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:09.915+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:29:10.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:10.204+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:29:10.422+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.150 seconds
[2022-12-17T06:29:20.764+0000] {processor.py:154} INFO - Started process (PID=6011) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:20.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:29:20.788+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:20.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:20.884+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:21.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:21.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:29:21.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:21.174+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:29:21.317+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.567 seconds
[2022-12-17T06:29:31.961+0000] {processor.py:154} INFO - Started process (PID=6021) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:32.009+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:29:32.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:32.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:32.178+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:32.335+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:32.334+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:29:32.447+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:32.446+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:29:32.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-17T06:29:42.892+0000] {processor.py:154} INFO - Started process (PID=6031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:42.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:29:42.932+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:42.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:43.014+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:43.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:43.150+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:29:43.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:43.260+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:29:43.389+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.511 seconds
[2022-12-17T06:29:53.923+0000] {processor.py:154} INFO - Started process (PID=6048) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:53.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:29:53.996+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:53.995+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:54.160+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:29:54.340+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:54.338+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:29:54.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:29:54.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:29:54.716+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.830 seconds
[2022-12-17T06:30:04.910+0000] {processor.py:154} INFO - Started process (PID=6058) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:04.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:30:04.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:04.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:05.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:05.182+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:05.181+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:30:05.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:05.300+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:30:05.441+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-17T06:30:15.725+0000] {processor.py:154} INFO - Started process (PID=6068) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:15.779+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:30:15.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:15.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:15.890+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:16.039+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:16.038+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:30:16.173+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:16.172+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:30:16.279+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.569 seconds
[2022-12-17T06:30:26.610+0000] {processor.py:154} INFO - Started process (PID=6084) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:26.638+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:30:26.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:26.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:26.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:27.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:27.029+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:30:27.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:27.277+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:30:27.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.906 seconds
[2022-12-17T06:30:38.149+0000] {processor.py:154} INFO - Started process (PID=6095) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:38.202+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:30:38.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:38.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:38.295+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:38.731+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:38.722+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:30:38.900+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:38.900+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:30:39.015+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.880 seconds
[2022-12-17T06:30:49.401+0000] {processor.py:154} INFO - Started process (PID=6105) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:49.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:30:49.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:49.431+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:49.517+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:30:50.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:50.706+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:30:50.817+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:30:50.816+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:30:50.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.563 seconds
[2022-12-17T06:31:01.235+0000] {processor.py:154} INFO - Started process (PID=6115) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:01.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:01.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:01.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:01.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:01.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:01.956+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:31:02.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:02.068+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:31:02.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.069 seconds
[2022-12-17T06:31:13.256+0000] {processor.py:154} INFO - Started process (PID=6133) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:13.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:13.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:13.291+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:13.511+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:13.692+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:13.691+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:31:13.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:13.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:31:14.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.913 seconds
[2022-12-17T06:31:24.465+0000] {processor.py:154} INFO - Started process (PID=6143) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:24.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:24.490+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:24.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:24.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:24.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:24.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:31:24.881+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:24.880+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:31:25.007+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.556 seconds
[2022-12-17T06:31:35.303+0000] {processor.py:154} INFO - Started process (PID=6153) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:35.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:35.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:35.346+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:35.474+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:36.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:36.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:31:36.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:36.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:31:36.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.587 seconds
[2022-12-17T06:31:47.245+0000] {processor.py:154} INFO - Started process (PID=6170) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:47.268+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:47.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:47.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:47.387+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:47.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:47.596+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:31:47.729+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:47.729+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:31:47.892+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.664 seconds
[2022-12-17T06:31:58.170+0000] {processor.py:154} INFO - Started process (PID=6181) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:58.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:31:58.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:31:58.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:31:58.335+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:00.026+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:00.025+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:32:00.140+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:00.139+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:32:00.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.150 seconds
[2022-12-17T06:32:10.559+0000] {processor.py:154} INFO - Started process (PID=6191) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:10.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:32:10.586+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:10.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:10.672+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:10.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:10.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:32:10.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:10.924+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:32:11.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.535 seconds
[2022-12-17T06:32:21.450+0000] {processor.py:154} INFO - Started process (PID=6201) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:21.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:32:21.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:21.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:21.633+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:21.764+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:21.763+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:32:21.882+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:21.881+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:32:22.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-17T06:32:32.999+0000] {processor.py:154} INFO - Started process (PID=6219) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:33.030+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:32:33.077+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:33.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:33.293+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:33.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:33.457+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:32:33.847+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:33.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:32:34.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.200 seconds
[2022-12-17T06:32:44.382+0000] {processor.py:154} INFO - Started process (PID=6229) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:44.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:32:44.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:44.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:44.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:45.511+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:32:55.952+0000] {processor.py:154} INFO - Started process (PID=6239) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:56.057+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:32:56.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:32:56.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:56.146+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:32:56.486+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:33:06.949+0000] {processor.py:154} INFO - Started process (PID=6249) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:06.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:33:06.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:06.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:07.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:07.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:07.501+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:33:07.675+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:07.674+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:33:08.128+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.202 seconds
[2022-12-17T06:33:18.995+0000] {processor.py:154} INFO - Started process (PID=6267) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:19.015+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:33:19.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:19.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:19.107+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:19.237+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:19.236+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:33:19.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:19.347+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:33:19.502+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.521 seconds
[2022-12-17T06:33:29.806+0000] {processor.py:154} INFO - Started process (PID=6277) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:29.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:33:29.858+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:29.857+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:29.964+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:31.455+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:33:42.426+0000] {processor.py:154} INFO - Started process (PID=6287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:42.450+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:33:42.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:42.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:42.589+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:43.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:43.450+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:33:43.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:43.581+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:33:43.909+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.501 seconds
[2022-12-17T06:33:54.232+0000] {processor.py:154} INFO - Started process (PID=6306) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:54.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:33:54.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:54.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:54.371+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:33:54.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:54.519+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:33:54.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:33:54.723+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:33:54.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.632 seconds
[2022-12-17T06:34:05.297+0000] {processor.py:154} INFO - Started process (PID=6316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:05.321+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:34:05.326+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:05.325+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:05.408+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:06.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:06.702+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:34:07.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:07.066+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:34:07.333+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.050 seconds
[2022-12-17T06:34:17.672+0000] {processor.py:154} INFO - Started process (PID=6326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:17.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:34:17.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:17.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:17.810+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:17.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:17.988+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:34:18.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:18.101+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:34:18.213+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T06:34:28.597+0000] {processor.py:154} INFO - Started process (PID=6336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:28.622+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:34:28.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:28.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:28.708+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:28.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:28.930+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:34:29.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:29.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:34:29.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.776 seconds
[2022-12-17T06:34:40.244+0000] {processor.py:154} INFO - Started process (PID=6354) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:40.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:34:40.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:40.282+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:40.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:40.563+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:40.562+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:34:40.689+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:40.689+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:34:40.816+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.614 seconds
[2022-12-17T06:34:51.724+0000] {processor.py:154} INFO - Started process (PID=6364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:51.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:34:51.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:51.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:51.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:34:52.729+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:52.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:34:52.860+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:34:52.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:34:52.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.262 seconds
[2022-12-17T06:35:03.270+0000] {processor.py:154} INFO - Started process (PID=6374) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:03.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:03.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:03.300+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:03.385+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:03.905+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:35:14.167+0000] {processor.py:154} INFO - Started process (PID=6392) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:14.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:14.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:14.222+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:14.369+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:14.640+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:14.639+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:35:14.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:14.768+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:35:14.885+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.768 seconds
[2022-12-17T06:35:25.564+0000] {processor.py:154} INFO - Started process (PID=6402) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:25.572+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:25.576+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:25.575+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:25.669+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:26.111+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:26.110+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:35:26.220+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:26.219+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:35:26.382+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.834 seconds
[2022-12-17T06:35:36.606+0000] {processor.py:154} INFO - Started process (PID=6412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:36.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:36.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:36.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:36.752+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:36.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:36.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:35:37.098+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:37.097+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:35:37.242+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.653 seconds
[2022-12-17T06:35:47.544+0000] {processor.py:154} INFO - Started process (PID=6422) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:47.548+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:47.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:47.551+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:47.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:47.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:47.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:35:47.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:47.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:35:48.012+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.481 seconds
[2022-12-17T06:35:58.532+0000] {processor.py:154} INFO - Started process (PID=6440) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:58.541+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:35:58.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:58.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:58.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:35:59.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:59.145+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:35:59.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:35:59.529+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:35:59.750+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.265 seconds
[2022-12-17T06:36:10.098+0000] {processor.py:154} INFO - Started process (PID=6450) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:10.128+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:36:10.133+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:10.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:10.215+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:11.293+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:36:21.730+0000] {processor.py:154} INFO - Started process (PID=6460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:21.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:36:21.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:21.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:21.937+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:22.077+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:22.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:36:22.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:22.187+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:36:22.358+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.677 seconds
[2022-12-17T06:36:32.928+0000] {processor.py:154} INFO - Started process (PID=6476) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:32.954+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:36:32.958+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:32.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:33.269+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:33.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:33.959+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:36:34.207+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:34.206+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:36:34.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.481 seconds
[2022-12-17T06:36:44.715+0000] {processor.py:154} INFO - Started process (PID=6488) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:44.747+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:36:44.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:44.753+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:44.882+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:45.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:45.060+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:36:45.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:45.177+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:36:45.286+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.608 seconds
[2022-12-17T06:36:55.587+0000] {processor.py:154} INFO - Started process (PID=6498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:55.592+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:36:55.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:36:55.595+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:55.729+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:36:56.491+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:37:06.934+0000] {processor.py:154} INFO - Started process (PID=6508) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:06.984+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:37:06.988+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:06.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:07.100+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:07.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:07.374+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:37:07.534+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:07.533+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:37:07.691+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.773 seconds
[2022-12-17T06:37:18.151+0000] {processor.py:154} INFO - Started process (PID=6526) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:18.186+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:37:18.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:18.193+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:18.295+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:18.461+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:18.460+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:37:18.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:18.699+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:37:19.139+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.006 seconds
[2022-12-17T06:37:29.635+0000] {processor.py:154} INFO - Started process (PID=6536) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:29.655+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:37:29.660+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:29.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:29.744+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:30.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:30.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:37:30.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:30.289+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:37:30.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.804 seconds
[2022-12-17T06:37:40.754+0000] {processor.py:154} INFO - Started process (PID=6546) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:40.801+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:37:40.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:40.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:40.904+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:41.098+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:41.097+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:37:41.227+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:41.226+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:37:41.360+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.621 seconds
[2022-12-17T06:37:51.698+0000] {processor.py:154} INFO - Started process (PID=6556) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:51.717+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:37:51.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:51.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:51.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:37:52.006+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:52.005+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:37:52.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:37:52.125+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:37:52.274+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.591 seconds
[2022-12-17T06:38:02.824+0000] {processor.py:154} INFO - Started process (PID=6573) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:02.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:02.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:02.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:02.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:03.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:03.603+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:38:03.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:03.791+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:38:04.002+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.193 seconds
[2022-12-17T06:38:14.120+0000] {processor.py:154} INFO - Started process (PID=6583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:14.145+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:14.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:14.149+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:14.235+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:15.019+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:38:25.182+0000] {processor.py:154} INFO - Started process (PID=6593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:25.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:25.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:25.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:25.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:25.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:25.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:38:25.592+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:25.591+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:38:25.734+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.566 seconds
[2022-12-17T06:38:36.152+0000] {processor.py:154} INFO - Started process (PID=6611) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:36.199+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:36.207+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:36.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:36.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:36.464+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:36.463+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:38:36.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:36.602+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:38:36.741+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-17T06:38:47.185+0000] {processor.py:154} INFO - Started process (PID=6622) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:47.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:47.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:47.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:47.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:47.467+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:47.466+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:38:47.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:47.596+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:38:47.725+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T06:38:58.015+0000] {processor.py:154} INFO - Started process (PID=6632) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:58.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:38:58.029+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:38:58.028+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:58.169+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:38:58.690+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:39:09.512+0000] {processor.py:154} INFO - Started process (PID=6642) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:09.538+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:39:09.541+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:09.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:09.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:09.808+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:09.807+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:39:09.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:09.970+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:39:10.132+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.637 seconds
[2022-12-17T06:39:20.508+0000] {processor.py:154} INFO - Started process (PID=6660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:20.541+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:39:20.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:20.544+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:20.733+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:21.471+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:21.470+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:39:21.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:21.694+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:39:21.841+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.363 seconds
[2022-12-17T06:39:32.240+0000] {processor.py:154} INFO - Started process (PID=6670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:32.287+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:39:32.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:32.291+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:32.375+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:32.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:32.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:39:33.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:33.016+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:39:33.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.081 seconds
[2022-12-17T06:39:43.628+0000] {processor.py:154} INFO - Started process (PID=6680) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:43.655+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:39:43.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:43.658+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:43.953+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:44.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:44.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:39:44.243+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:44.242+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:39:44.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.815 seconds
[2022-12-17T06:39:54.771+0000] {processor.py:154} INFO - Started process (PID=6690) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:54.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:39:54.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:54.798+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:55.085+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:39:55.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:55.318+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:39:55.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:39:55.444+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:39:55.558+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.809 seconds
[2022-12-17T06:40:06.266+0000] {processor.py:154} INFO - Started process (PID=6708) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:06.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:40:06.308+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:06.307+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:06.433+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:06.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:06.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:40:07.165+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:07.164+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:40:07.336+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.084 seconds
[2022-12-17T06:40:17.507+0000] {processor.py:154} INFO - Started process (PID=6718) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:17.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:40:17.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:17.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:17.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:17.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:17.799+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:40:17.923+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:17.922+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:40:18.041+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-17T06:40:28.938+0000] {processor.py:154} INFO - Started process (PID=6728) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:28.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:40:28.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:28.990+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:29.080+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:29.255+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:29.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:40:29.413+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:29.412+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:40:29.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.595 seconds
[2022-12-17T06:40:39.768+0000] {processor.py:154} INFO - Started process (PID=6745) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:39.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:40:39.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:39.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:40.103+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:40.661+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:40.660+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:40:40.848+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:40.847+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:40:41.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.314 seconds
[2022-12-17T06:40:51.376+0000] {processor.py:154} INFO - Started process (PID=6755) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:51.425+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:40:51.429+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:51.428+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:51.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:40:51.732+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:51.731+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:40:51.872+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:40:51.871+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:40:51.992+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-17T06:41:02.145+0000] {processor.py:154} INFO - Started process (PID=6765) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:02.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:02.171+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:02.167+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:02.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:02.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:02.877+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:41:02.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:02.991+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:41:03.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.971 seconds
[2022-12-17T06:41:13.341+0000] {processor.py:154} INFO - Started process (PID=6775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:13.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:13.392+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:13.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:13.501+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:13.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:13.668+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:41:13.797+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:13.796+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:41:13.954+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.627 seconds
[2022-12-17T06:41:24.458+0000] {processor.py:154} INFO - Started process (PID=6793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:24.469+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:24.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:24.477+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:24.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:25.089+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:25.088+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:41:25.254+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:25.242+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:41:25.545+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.118 seconds
[2022-12-17T06:41:35.819+0000] {processor.py:154} INFO - Started process (PID=6803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:35.823+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:35.827+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:35.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:35.917+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:37.094+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:41:47.333+0000] {processor.py:154} INFO - Started process (PID=6813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:47.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:47.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:47.344+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:47.446+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:47.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:47.816+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:41:48.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:48.063+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:41:48.219+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-17T06:41:59.352+0000] {processor.py:154} INFO - Started process (PID=6831) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:59.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:41:59.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:59.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:59.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:41:59.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:41:59.884+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:42:00.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:00.081+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:42:00.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.996 seconds
[2022-12-17T06:42:10.507+0000] {processor.py:154} INFO - Started process (PID=6841) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:10.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:42:10.524+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:10.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:10.687+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:12.353+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:12.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:42:12.460+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:12.459+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:42:12.615+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.122 seconds
[2022-12-17T06:42:22.889+0000] {processor.py:154} INFO - Started process (PID=6851) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:22.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:42:22.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:22.895+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:22.978+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:23.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:23.327+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:42:23.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:23.559+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:42:23.954+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.080 seconds
[2022-12-17T06:42:34.429+0000] {processor.py:154} INFO - Started process (PID=6861) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:34.437+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:42:34.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:34.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:34.620+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:34.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:34.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:42:35.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:35.015+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:42:35.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.772 seconds
[2022-12-17T06:42:45.590+0000] {processor.py:154} INFO - Started process (PID=6879) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:45.638+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:42:45.647+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:45.646+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:45.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:46.781+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:42:57.240+0000] {processor.py:154} INFO - Started process (PID=6889) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:57.268+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:42:57.272+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:57.271+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:57.354+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:42:57.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:57.481+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:42:57.599+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:42:57.598+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:42:57.731+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.503 seconds
[2022-12-17T06:43:07.996+0000] {processor.py:154} INFO - Started process (PID=6899) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:08.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:43:08.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:08.009+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:08.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:08.223+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:08.222+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:43:08.331+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:08.330+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:43:08.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.490 seconds
[2022-12-17T06:43:18.813+0000] {processor.py:154} INFO - Started process (PID=6909) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:18.858+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:43:18.865+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:18.865+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:18.984+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:19.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:19.278+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:43:19.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:19.491+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:43:19.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.938 seconds
[2022-12-17T06:43:30.209+0000] {processor.py:154} INFO - Started process (PID=6927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:30.256+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:43:30.260+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:30.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:30.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:30.503+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:30.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:43:30.628+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:30.627+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:43:30.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.586 seconds
[2022-12-17T06:43:41.049+0000] {processor.py:154} INFO - Started process (PID=6937) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:41.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:43:41.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:41.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:41.168+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:41.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:41.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:43:41.676+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:41.674+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:43:41.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.769 seconds
[2022-12-17T06:43:52.204+0000] {processor.py:154} INFO - Started process (PID=6947) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:52.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:43:52.221+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:52.220+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:52.380+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:43:52.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:52.798+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:43:52.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:43:52.925+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:43:53.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.878 seconds
[2022-12-17T06:44:03.734+0000] {processor.py:154} INFO - Started process (PID=6964) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:03.904+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:44:03.913+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:03.907+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:04.347+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:04.684+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:04.682+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:44:04.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:04.811+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:44:04.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.333 seconds
[2022-12-17T06:44:15.427+0000] {processor.py:154} INFO - Started process (PID=6974) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:15.476+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:44:15.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:15.479+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:15.572+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:16.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:16.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:44:16.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:16.336+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:44:16.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.060 seconds
[2022-12-17T06:44:26.663+0000] {processor.py:154} INFO - Started process (PID=6984) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:26.691+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:44:26.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:26.694+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:26.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:28.019+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:28.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:44:28.164+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:28.163+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:44:28.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.627 seconds
[2022-12-17T06:44:38.595+0000] {processor.py:154} INFO - Started process (PID=6994) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:38.646+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:44:38.651+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:38.650+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:38.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:38.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:38.882+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:44:39.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:39.113+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:44:39.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.860 seconds
[2022-12-17T06:44:49.904+0000] {processor.py:154} INFO - Started process (PID=7012) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:49.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:44:49.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:49.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:50.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:44:50.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:50.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:44:50.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:44:50.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:44:50.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.554 seconds
[2022-12-17T06:45:00.762+0000] {processor.py:154} INFO - Started process (PID=7022) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:00.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:00.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:00.811+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:00.914+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:01.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:01.764+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:45:01.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:01.882+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:45:02.034+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.286 seconds
[2022-12-17T06:45:12.380+0000] {processor.py:154} INFO - Started process (PID=7032) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:12.431+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:12.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:12.434+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:12.531+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:12.781+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:45:23.733+0000] {processor.py:154} INFO - Started process (PID=7051) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:23.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:23.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:23.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:23.893+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:24.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:24.182+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:45:24.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:24.320+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:45:24.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.707 seconds
[2022-12-17T06:45:34.614+0000] {processor.py:154} INFO - Started process (PID=7061) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:34.637+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:34.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:34.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:34.731+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:34.893+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:34.892+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:45:35.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:35.033+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:45:35.170+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.571 seconds
[2022-12-17T06:45:45.287+0000] {processor.py:154} INFO - Started process (PID=7071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:45.367+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:45.371+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:45.370+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:45.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:45.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:45.989+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:45:46.108+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:46.107+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:45:46.209+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.938 seconds
[2022-12-17T06:45:56.592+0000] {processor.py:154} INFO - Started process (PID=7081) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:56.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:45:56.606+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:56.605+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:56.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:45:56.887+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:56.886+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:45:57.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:45:57.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:45:57.316+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.756 seconds
[2022-12-17T06:46:07.595+0000] {processor.py:154} INFO - Started process (PID=7099) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:07.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:46:07.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:07.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:07.879+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:08.971+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:08.970+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:46:09.219+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:09.218+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:46:09.445+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.890 seconds
[2022-12-17T06:46:19.718+0000] {processor.py:154} INFO - Started process (PID=7109) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:19.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:46:19.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:19.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:19.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:20.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:20.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:46:20.245+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:20.244+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:46:20.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.655 seconds
[2022-12-17T06:46:30.637+0000] {processor.py:154} INFO - Started process (PID=7119) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:30.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:46:30.684+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:30.683+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:30.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:31.573+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:31.572+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:46:31.710+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:31.709+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:46:31.818+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.195 seconds
[2022-12-17T06:46:42.137+0000] {processor.py:154} INFO - Started process (PID=7137) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:42.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:46:42.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:42.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:42.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:42.579+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:42.574+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:46:42.841+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:42.840+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:46:42.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.888 seconds
[2022-12-17T06:46:53.397+0000] {processor.py:154} INFO - Started process (PID=7148) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:53.411+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:46:53.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:53.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:53.539+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:46:53.708+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:53.707+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:46:53.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:46:53.836+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:46:53.989+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.612 seconds
[2022-12-17T06:47:04.344+0000] {processor.py:154} INFO - Started process (PID=7158) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:04.392+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:47:04.397+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:04.395+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:04.487+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:04.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:04.713+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:47:04.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:04.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:47:04.969+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.640 seconds
[2022-12-17T06:47:15.376+0000] {processor.py:154} INFO - Started process (PID=7168) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:15.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:47:15.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:15.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:15.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:15.958+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:15.957+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:47:16.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:16.136+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:47:16.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.965 seconds
[2022-12-17T06:47:26.663+0000] {processor.py:154} INFO - Started process (PID=7186) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:26.674+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:47:26.683+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:26.682+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:26.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:27.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:27.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:47:27.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:27.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:47:28.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.383 seconds
[2022-12-17T06:47:38.987+0000] {processor.py:154} INFO - Started process (PID=7196) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:39.015+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:47:39.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:39.024+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:39.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:40.101+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:47:50.459+0000] {processor.py:154} INFO - Started process (PID=7206) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:50.496+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:47:50.504+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:50.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:50.759+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:47:51.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:51.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:47:51.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:47:51.327+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:47:51.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.089 seconds
[2022-12-17T06:48:01.620+0000] {processor.py:154} INFO - Started process (PID=7216) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:01.675+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:48:01.679+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:01.678+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:01.836+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:02.171+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:02.170+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:48:02.379+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:02.365+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:48:02.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.367 seconds
[2022-12-17T06:48:13.258+0000] {processor.py:154} INFO - Started process (PID=7234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:13.286+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:48:13.294+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:13.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:13.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:14.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:14.720+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:48:14.833+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:14.832+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:48:14.978+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.773 seconds
[2022-12-17T06:48:25.200+0000] {processor.py:154} INFO - Started process (PID=7244) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:25.231+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:48:25.239+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:25.234+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:25.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:26.577+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:48:37.029+0000] {processor.py:154} INFO - Started process (PID=7254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:37.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:48:37.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:37.065+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:37.204+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:37.376+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:37.375+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:48:37.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:37.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:48:37.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.633 seconds
[2022-12-17T06:48:47.935+0000] {processor.py:154} INFO - Started process (PID=7272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:47.950+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:48:47.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:47.954+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:48.199+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:48:49.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:49.377+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:48:49.645+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:48:49.644+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:48:49.838+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.928 seconds
[2022-12-17T06:49:00.475+0000] {processor.py:154} INFO - Started process (PID=7282) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:00.488+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:00.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:00.496+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:00.651+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:01.648+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:49:12.041+0000] {processor.py:154} INFO - Started process (PID=7292) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:12.057+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:12.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:12.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:12.167+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:12.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:12.301+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:49:12.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:12.414+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:49:12.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-17T06:49:22.801+0000] {processor.py:154} INFO - Started process (PID=7302) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:22.872+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:22.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:22.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:22.963+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:23.189+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:23.188+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:49:23.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:23.853+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:49:24.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.452 seconds
[2022-12-17T06:49:34.817+0000] {processor.py:154} INFO - Started process (PID=7320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:34.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:34.832+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:34.831+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:34.927+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:35.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:35.102+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:49:35.384+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:35.383+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:49:35.733+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.931 seconds
[2022-12-17T06:49:46.218+0000] {processor.py:154} INFO - Started process (PID=7330) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:46.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:46.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:46.270+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:46.374+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:46.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:46.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:49:46.689+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:46.689+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:49:46.921+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.717 seconds
[2022-12-17T06:49:57.511+0000] {processor.py:154} INFO - Started process (PID=7340) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:57.554+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:49:57.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:57.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:57.652+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:49:57.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:57.814+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:49:57.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:49:57.948+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:49:58.050+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.556 seconds
[2022-12-17T06:50:08.446+0000] {processor.py:154} INFO - Started process (PID=7358) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:08.569+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:50:08.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:08.577+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:08.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:09.844+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:09.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:50:10.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:10.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:50:10.281+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.853 seconds
[2022-12-17T06:50:20.871+0000] {processor.py:154} INFO - Started process (PID=7368) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:20.922+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:50:20.927+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:20.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:21.021+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:21.312+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:50:31.729+0000] {processor.py:154} INFO - Started process (PID=7378) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:31.760+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:50:31.764+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:31.763+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:31.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:32.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:32.001+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:50:32.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:32.113+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:50:32.244+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.529 seconds
[2022-12-17T06:50:42.496+0000] {processor.py:154} INFO - Started process (PID=7388) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:42.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:50:42.573+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:42.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:42.667+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:42.827+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:42.826+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:50:42.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:42.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:50:43.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.589 seconds
[2022-12-17T06:50:53.310+0000] {processor.py:154} INFO - Started process (PID=7405) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:53.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:50:53.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:53.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:53.569+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:50:53.767+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:53.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:50:53.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:50:53.982+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:50:54.162+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.884 seconds
[2022-12-17T06:51:04.437+0000] {processor.py:154} INFO - Started process (PID=7415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:04.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:04.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:04.486+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:04.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:04.994+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:51:15.317+0000] {processor.py:154} INFO - Started process (PID=7425) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:15.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:15.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:15.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:15.463+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:15.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:15.742+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:51:15.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:15.872+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:51:16.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.704 seconds
[2022-12-17T06:51:26.388+0000] {processor.py:154} INFO - Started process (PID=7442) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:26.434+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:26.439+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:26.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:26.555+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:26.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:26.771+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:51:26.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:26.954+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:51:27.138+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.766 seconds
[2022-12-17T06:51:37.515+0000] {processor.py:154} INFO - Started process (PID=7453) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:37.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:37.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:37.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:37.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:37.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:37.805+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:51:37.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:37.930+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:51:38.045+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-17T06:51:48.380+0000] {processor.py:154} INFO - Started process (PID=7463) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:48.389+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:48.396+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:48.396+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:48.601+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:48.925+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:51:59.731+0000] {processor.py:154} INFO - Started process (PID=7473) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:59.755+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:51:59.773+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:51:59.772+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:51:59.977+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:00.204+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:00.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:52:00.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:00.317+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:52:00.441+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.756 seconds
[2022-12-17T06:52:10.825+0000] {processor.py:154} INFO - Started process (PID=7490) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:10.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:52:10.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:10.856+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:11.105+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:11.826+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:11.815+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:52:12.377+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:12.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:52:12.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.786 seconds
[2022-12-17T06:52:23.001+0000] {processor.py:154} INFO - Started process (PID=7500) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:23.034+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:52:23.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:23.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:23.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:24.006+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:52:34.482+0000] {processor.py:154} INFO - Started process (PID=7510) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:34.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:52:34.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:34.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:34.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:35.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:35.081+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:52:35.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:35.202+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:52:35.403+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.004 seconds
[2022-12-17T06:52:45.711+0000] {processor.py:154} INFO - Started process (PID=7520) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:45.739+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:52:45.743+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:45.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:45.905+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:46.242+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:46.241+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:52:46.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:46.388+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:52:46.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-17T06:52:57.029+0000] {processor.py:154} INFO - Started process (PID=7539) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:57.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:52:57.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:57.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:57.159+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:52:58.106+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:58.105+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:52:58.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:52:58.295+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:52:58.482+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.467 seconds
[2022-12-17T06:53:08.763+0000] {processor.py:154} INFO - Started process (PID=7549) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:08.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:53:08.824+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:08.823+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:08.920+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:09.086+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:09.084+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:53:09.347+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:09.346+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:53:09.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.816 seconds
[2022-12-17T06:53:19.969+0000] {processor.py:154} INFO - Started process (PID=7559) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:19.989+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:53:19.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:19.992+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:20.106+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:21.257+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:21.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:53:21.613+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:21.612+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:53:21.767+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.826 seconds
[2022-12-17T06:53:32.331+0000] {processor.py:154} INFO - Started process (PID=7578) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:32.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:53:32.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:32.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:32.497+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:33.049+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:33.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:53:33.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:33.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:53:33.925+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.609 seconds
[2022-12-17T06:53:44.332+0000] {processor.py:154} INFO - Started process (PID=7588) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:44.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:53:44.359+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:44.358+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:44.440+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:44.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:44.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:53:44.756+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:44.747+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:53:45.051+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.737 seconds
[2022-12-17T06:53:55.289+0000] {processor.py:154} INFO - Started process (PID=7598) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:55.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:53:55.341+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:55.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:55.423+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:53:56.049+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:56.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:53:56.159+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:53:56.158+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:53:56.433+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.158 seconds
[2022-12-17T06:54:06.742+0000] {processor.py:154} INFO - Started process (PID=7608) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:06.782+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:54:06.787+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:06.786+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:06.881+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:07.788+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:54:18.518+0000] {processor.py:154} INFO - Started process (PID=7626) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:18.549+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:54:18.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:18.552+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:18.658+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:19.216+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:54:29.754+0000] {processor.py:154} INFO - Started process (PID=7636) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:29.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:54:29.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:29.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:29.896+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:30.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:30.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:54:30.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:30.146+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:54:30.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.549 seconds
[2022-12-17T06:54:40.671+0000] {processor.py:154} INFO - Started process (PID=7646) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:40.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:54:40.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:40.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:40.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:40.965+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:40.964+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:54:41.084+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:41.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:54:41.342+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-17T06:54:51.980+0000] {processor.py:154} INFO - Started process (PID=7664) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:52.025+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:54:52.036+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:52.035+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:52.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:54:53.110+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:53.109+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:54:53.299+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:54:53.298+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:54:53.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.551 seconds
[2022-12-17T06:55:03.726+0000] {processor.py:154} INFO - Started process (PID=7674) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:03.781+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:55:03.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:03.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:03.882+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:04.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:04.014+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:55:04.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:04.144+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:55:04.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-17T06:55:14.522+0000] {processor.py:154} INFO - Started process (PID=7684) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:14.552+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:55:14.562+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:14.561+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:14.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:15.909+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:55:26.232+0000] {processor.py:154} INFO - Started process (PID=7694) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:26.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:55:26.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:26.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:26.366+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:27.676+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:27.675+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:55:27.787+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:27.786+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:55:27.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.685 seconds
[2022-12-17T06:55:38.401+0000] {processor.py:154} INFO - Started process (PID=7712) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:38.454+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:55:38.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:38.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:38.674+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:40.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:40.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:55:40.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:40.301+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:55:40.629+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.246 seconds
[2022-12-17T06:55:50.941+0000] {processor.py:154} INFO - Started process (PID=7722) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:50.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:55:50.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:50.969+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:51.055+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:55:51.675+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:51.674+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:55:52.029+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:55:52.028+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:55:52.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.334 seconds
[2022-12-17T06:56:02.679+0000] {processor.py:154} INFO - Started process (PID=7732) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:02.706+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:56:02.710+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:02.709+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:02.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:02.946+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:02.945+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:56:03.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:03.057+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:56:03.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.613 seconds
[2022-12-17T06:56:13.685+0000] {processor.py:154} INFO - Started process (PID=7750) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:13.732+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:56:13.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:13.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:13.860+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:14.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:14.037+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:56:14.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:14.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:56:14.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.688 seconds
[2022-12-17T06:56:24.722+0000] {processor.py:154} INFO - Started process (PID=7760) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:24.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:56:24.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:24.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:24.864+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:26.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:26.534+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:56:26.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:26.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:56:26.898+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.190 seconds
[2022-12-17T06:56:37.183+0000] {processor.py:154} INFO - Started process (PID=7770) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:37.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:56:37.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:37.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:37.379+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:37.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:37.977+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:56:38.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:38.372+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:56:38.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.712 seconds
[2022-12-17T06:56:49.050+0000] {processor.py:154} INFO - Started process (PID=7780) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:49.080+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:56:49.085+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:56:49.084+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:49.216+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:56:50.269+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:57:00.724+0000] {processor.py:154} INFO - Started process (PID=7797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:00.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:00.775+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:00.774+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:00.863+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:01.299+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:01.298+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:57:01.412+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:01.411+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:57:01.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.811 seconds
[2022-12-17T06:57:11.839+0000] {processor.py:154} INFO - Started process (PID=7807) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:11.885+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:11.890+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:11.889+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:11.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:13.200+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:13.199+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:57:13.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:13.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:57:13.582+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.759 seconds
[2022-12-17T06:57:23.936+0000] {processor.py:154} INFO - Started process (PID=7817) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:23.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:23.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:23.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:24.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:25.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:25.031+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:57:25.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:25.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:57:25.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.406 seconds
[2022-12-17T06:57:35.669+0000] {processor.py:154} INFO - Started process (PID=7834) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:35.685+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:35.689+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:35.688+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:35.804+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:36.446+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:57:47.135+0000] {processor.py:154} INFO - Started process (PID=7844) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:47.319+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:47.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:47.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:47.409+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:47.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:47.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:57:48.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:48.056+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:57:48.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.111 seconds
[2022-12-17T06:57:58.878+0000] {processor.py:154} INFO - Started process (PID=7854) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:58.897+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:57:58.901+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:58.900+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:59.001+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:57:59.129+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:59.128+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:57:59.237+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:57:59.237+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:57:59.371+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.507 seconds
[2022-12-17T06:58:09.642+0000] {processor.py:154} INFO - Started process (PID=7908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:09.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:58:09.663+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:58:09.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:09.746+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:09.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:58:09.885+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:58:10.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:58:10.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:58:57.601+0000] {processor.py:154} INFO - Started process (PID=179) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:57.634+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:58:57.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:58:57.646+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:57.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:58:59.046+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T06:59:09.444+0000] {processor.py:154} INFO - Started process (PID=189) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:09.488+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:59:09.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:09.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:09.703+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:09.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:09.992+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:59:10.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:10.211+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:59:10.669+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.240 seconds
[2022-12-17T06:59:21.042+0000] {processor.py:154} INFO - Started process (PID=202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:21.047+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:59:21.051+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:21.050+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:21.158+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:21.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:21.372+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:59:21.519+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:21.518+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:59:21.769+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.762 seconds
[2022-12-17T06:59:32.125+0000] {processor.py:154} INFO - Started process (PID=212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:32.170+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:59:32.173+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:32.173+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:32.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:32.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:32.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:59:32.795+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:32.794+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:59:32.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.843 seconds
[2022-12-17T06:59:43.302+0000] {processor.py:154} INFO - Started process (PID=230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:43.316+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:59:43.324+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:43.323+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:43.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:43.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:43.985+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:59:44.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:44.193+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:59:44.470+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.201 seconds
[2022-12-17T06:59:54.867+0000] {processor.py:154} INFO - Started process (PID=240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:54.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T06:59:54.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:54.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:54.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T06:59:55.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:55.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T06:59:55.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T06:59:55.291+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T06:59:55.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.681 seconds
[2022-12-17T07:00:05.800+0000] {processor.py:154} INFO - Started process (PID=250) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:05.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:00:05.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:05.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:05.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:06.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:06.092+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:00:06.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:06.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:00:06.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T07:00:16.726+0000] {processor.py:154} INFO - Started process (PID=264) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:16.751+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:00:16.756+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:16.755+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:16.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:17.402+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:00:28.056+0000] {processor.py:154} INFO - Started process (PID=275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:28.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:00:28.081+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:28.080+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:28.165+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:29.593+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:29.592+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:00:29.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:29.715+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:00:29.865+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.823 seconds
[2022-12-17T07:00:40.152+0000] {processor.py:154} INFO - Started process (PID=288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:40.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:00:40.171+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:40.167+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:40.266+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:40.465+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:40.459+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:00:40.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:40.670+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:00:40.801+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.664 seconds
[2022-12-17T07:00:51.112+0000] {processor.py:154} INFO - Started process (PID=300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:51.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:00:51.140+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:51.139+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:51.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:00:51.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:51.628+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:00:51.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:00:51.753+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:00:51.899+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.801 seconds
[2022-12-17T07:01:02.459+0000] {processor.py:154} INFO - Started process (PID=316) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:02.480+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:02.484+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:02.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:02.788+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:03.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:03.081+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:03.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:03.260+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:03.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-17T07:01:13.800+0000] {processor.py:154} INFO - Started process (PID=328) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:13.847+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:13.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:13.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:13.941+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:14.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:14.093+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:14.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:14.250+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:14.426+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.640 seconds
[2022-12-17T07:01:24.727+0000] {processor.py:154} INFO - Started process (PID=338) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:24.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:24.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:24.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:24.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:25.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:25.297+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:25.467+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:25.466+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:25.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.874 seconds
[2022-12-17T07:01:35.917+0000] {processor.py:154} INFO - Started process (PID=346) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:35.942+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:35.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:35.950+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:36.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:36.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:36.294+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:36.453+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:36.452+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:36.696+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.819 seconds
[2022-12-17T07:01:47.097+0000] {processor.py:154} INFO - Started process (PID=364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:47.123+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:47.128+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:47.127+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:47.211+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:47.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:47.343+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:47.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:47.457+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:47.617+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.533 seconds
[2022-12-17T07:01:58.355+0000] {processor.py:154} INFO - Started process (PID=371) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:58.384+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:01:58.388+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:58.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:58.489+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:01:58.674+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:58.673+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:01:58.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:01:58.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:01:58.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.631 seconds
[2022-12-17T07:02:09.371+0000] {processor.py:154} INFO - Started process (PID=381) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:09.398+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:02:09.409+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:09.408+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:09.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:11.249+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:02:21.620+0000] {processor.py:154} INFO - Started process (PID=403) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:21.652+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:02:21.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:21.655+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:21.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:22.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:22.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:02:22.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:22.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:02:22.957+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.368 seconds
[2022-12-17T07:02:33.141+0000] {processor.py:154} INFO - Started process (PID=415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:33.145+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:02:33.149+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:33.148+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:33.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:33.704+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:33.703+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:02:33.831+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:33.830+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:02:34.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.903 seconds
[2022-12-17T07:02:44.259+0000] {processor.py:154} INFO - Started process (PID=425) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:44.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:02:44.303+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:44.298+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:44.403+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:44.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:44.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:02:44.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:44.821+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:02:44.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.718 seconds
[2022-12-17T07:02:55.184+0000] {processor.py:154} INFO - Started process (PID=435) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:55.206+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:02:55.210+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:55.209+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:55.495+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:02:56.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:56.119+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:02:56.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:02:56.274+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:02:56.387+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.218 seconds
[2022-12-17T07:03:06.676+0000] {processor.py:154} INFO - Started process (PID=451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:06.700+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:03:06.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:06.708+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:06.967+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:07.430+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:07.429+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:03:07.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:07.950+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:03:08.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.636 seconds
[2022-12-17T07:03:18.615+0000] {processor.py:154} INFO - Started process (PID=463) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:18.618+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:03:18.622+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:18.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:18.706+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:19.099+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:19.098+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:03:19.397+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:19.396+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:03:19.704+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.103 seconds
[2022-12-17T07:03:30.093+0000] {processor.py:154} INFO - Started process (PID=473) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:30.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:03:30.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:30.179+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:30.268+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:30.422+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:30.421+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:03:30.621+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:30.620+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:03:30.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.839 seconds
[2022-12-17T07:03:41.344+0000] {processor.py:154} INFO - Started process (PID=489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:41.390+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:03:41.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:41.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:41.525+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:41.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:41.804+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:03:42.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:42.225+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:03:42.913+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.583 seconds
[2022-12-17T07:03:53.697+0000] {processor.py:154} INFO - Started process (PID=500) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:53.704+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:03:53.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:53.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:53.817+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:03:54.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:54.033+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:03:54.194+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:03:54.193+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:03:54.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.751 seconds
[2022-12-17T07:04:04.874+0000] {processor.py:154} INFO - Started process (PID=510) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:04.945+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:04:04.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:04.948+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:05.056+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:05.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:05.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:04:05.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:05.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:04:05.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.584 seconds
[2022-12-17T07:04:16.148+0000] {processor.py:154} INFO - Started process (PID=520) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:16.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:04:16.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:16.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:16.311+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:16.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:16.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:04:16.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:16.625+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:04:16.741+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.608 seconds
[2022-12-17T07:04:27.637+0000] {processor.py:154} INFO - Started process (PID=538) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:27.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:04:27.685+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:27.684+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:27.890+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:28.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:28.289+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:04:28.452+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:28.451+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:04:28.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.046 seconds
[2022-12-17T07:04:38.787+0000] {processor.py:154} INFO - Started process (PID=548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:38.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:04:38.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:38.803+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:38.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:39.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:39.060+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:04:39.175+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:39.174+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:04:39.313+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.540 seconds
[2022-12-17T07:04:49.580+0000] {processor.py:154} INFO - Started process (PID=558) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:49.590+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:04:49.594+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:49.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:49.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:04:49.858+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:49.857+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:04:49.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:04:49.988+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:04:50.141+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.583 seconds
[2022-12-17T07:05:00.389+0000] {processor.py:154} INFO - Started process (PID=568) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:00.405+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:00.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:00.412+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:00.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:00.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:00.884+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:01.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:01.194+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:01.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.057 seconds
[2022-12-17T07:05:11.920+0000] {processor.py:154} INFO - Started process (PID=586) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:11.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:11.945+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:11.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:12.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:12.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:12.450+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:12.575+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:12.574+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:12.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.824 seconds
[2022-12-17T07:05:23.028+0000] {processor.py:154} INFO - Started process (PID=594) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:23.031+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:23.035+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:23.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:23.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:23.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:23.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:23.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:23.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:23.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.979 seconds
[2022-12-17T07:05:34.232+0000] {processor.py:154} INFO - Started process (PID=601) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:34.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:34.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:34.260+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:34.385+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:35.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:35.202+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:35.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:35.322+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:35.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.222 seconds
[2022-12-17T07:05:45.598+0000] {processor.py:154} INFO - Started process (PID=619) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:45.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:45.633+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:45.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:45.830+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:46.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:46.165+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:46.390+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:46.389+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:46.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.046 seconds
[2022-12-17T07:05:56.957+0000] {processor.py:154} INFO - Started process (PID=629) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:56.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:05:56.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:56.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:57.096+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:05:57.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:57.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:05:57.988+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:05:57.987+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:05:58.108+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.172 seconds
[2022-12-17T07:06:08.298+0000] {processor.py:154} INFO - Started process (PID=639) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:08.330+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:06:08.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:08.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:08.574+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:09.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:09.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:06:09.682+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:09.681+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:06:09.816+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.532 seconds
[2022-12-17T07:06:20.088+0000] {processor.py:154} INFO - Started process (PID=652) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:20.106+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:06:20.111+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:20.110+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:20.226+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:20.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:20.529+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:06:20.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:20.718+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:06:20.824+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.750 seconds
[2022-12-17T07:06:31.413+0000] {processor.py:154} INFO - Started process (PID=670) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:31.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:06:31.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:31.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:31.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:33.006+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:33.005+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:06:33.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:33.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:06:33.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.218 seconds
[2022-12-17T07:06:44.146+0000] {processor.py:154} INFO - Started process (PID=680) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:44.198+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:06:44.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:44.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:44.302+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:45.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:45.281+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:06:45.403+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:45.402+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:06:45.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.450 seconds
[2022-12-17T07:06:55.817+0000] {processor.py:154} INFO - Started process (PID=692) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:55.865+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:06:55.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:55.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:55.958+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:06:56.118+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:56.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:06:56.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:06:56.238+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:06:56.470+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-17T07:07:06.941+0000] {processor.py:154} INFO - Started process (PID=711) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:06.956+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:07:06.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:06.959+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:07.089+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:08.118+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:07:18.648+0000] {processor.py:154} INFO - Started process (PID=721) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:18.692+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:07:18.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:18.695+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:18.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:19.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:19.030+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:07:19.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:19.154+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:07:19.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.634 seconds
[2022-12-17T07:07:29.374+0000] {processor.py:154} INFO - Started process (PID=731) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:29.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:07:29.404+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:29.403+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:29.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:29.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:29.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:07:29.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:29.821+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:07:30.041+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-17T07:07:40.483+0000] {processor.py:154} INFO - Started process (PID=739) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:40.511+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:07:40.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:40.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:40.655+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:40.860+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:40.850+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:07:41.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:41.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:07:41.362+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.909 seconds
[2022-12-17T07:07:51.692+0000] {processor.py:154} INFO - Started process (PID=754) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:51.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:07:51.711+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:51.708+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:51.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:07:52.627+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:52.626+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:07:52.816+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:07:52.816+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:07:52.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.322 seconds
[2022-12-17T07:08:03.294+0000] {processor.py:154} INFO - Started process (PID=764) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:03.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:03.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:03.318+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:03.430+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:03.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:03.642+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:08:03.936+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:03.935+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:08:04.213+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.942 seconds
[2022-12-17T07:08:14.594+0000] {processor.py:154} INFO - Started process (PID=774) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:14.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:14.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:14.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:14.735+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:14.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:14.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:08:15.059+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:15.058+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:08:15.230+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.656 seconds
[2022-12-17T07:08:25.517+0000] {processor.py:154} INFO - Started process (PID=793) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:25.522+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:25.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:25.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:25.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:26.559+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:08:36.802+0000] {processor.py:154} INFO - Started process (PID=803) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:36.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:36.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:36.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:36.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:37.128+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:37.127+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:08:37.260+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:37.259+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:08:37.409+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.627 seconds
[2022-12-17T07:08:47.681+0000] {processor.py:154} INFO - Started process (PID=813) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:47.690+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:47.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:47.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:47.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:48.165+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:48.164+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:08:48.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:48.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:08:48.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.801 seconds
[2022-12-17T07:08:58.882+0000] {processor.py:154} INFO - Started process (PID=823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:58.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:08:58.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:58.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:59.033+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:08:59.684+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:59.683+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:08:59.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:08:59.895+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:00.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.361 seconds
[2022-12-17T07:09:10.810+0000] {processor.py:154} INFO - Started process (PID=844) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:10.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:09:10.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:10.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:11.166+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:11.528+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:11.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:09:11.767+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:11.766+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:11.955+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.164 seconds
[2022-12-17T07:09:22.272+0000] {processor.py:154} INFO - Started process (PID=856) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:22.275+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:09:22.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:22.278+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:22.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:22.512+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:22.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:09:22.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:22.642+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:22.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.568 seconds
[2022-12-17T07:09:33.010+0000] {processor.py:154} INFO - Started process (PID=866) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:33.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:09:33.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:33.021+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:33.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:33.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:33.697+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:09:33.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:33.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:34.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.156 seconds
[2022-12-17T07:09:44.652+0000] {processor.py:154} INFO - Started process (PID=880) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:44.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:09:44.697+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:44.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:44.844+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:45.291+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:45.290+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:09:45.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:45.461+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:45.671+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.042 seconds
[2022-12-17T07:09:56.113+0000] {processor.py:154} INFO - Started process (PID=893) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:56.117+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:09:56.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:56.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:56.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:09:56.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:56.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:09:56.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:09:56.924+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:09:57.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.974 seconds
[2022-12-17T07:10:07.356+0000] {processor.py:154} INFO - Started process (PID=903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:07.506+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:10:07.510+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:07.509+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:07.618+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:08.672+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:10:18.874+0000] {processor.py:154} INFO - Started process (PID=913) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:18.880+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:10:18.884+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:18.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:18.972+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:20.089+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:20.088+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:10:20.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:20.267+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:10:20.390+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.531 seconds
[2022-12-17T07:10:31.172+0000] {processor.py:154} INFO - Started process (PID=931) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:31.178+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:10:31.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:31.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:31.395+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:31.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:31.737+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:10:32.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:32.070+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:10:32.253+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.104 seconds
[2022-12-17T07:10:42.589+0000] {processor.py:154} INFO - Started process (PID=941) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:42.596+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:10:42.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:42.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:42.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:42.848+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:42.847+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:10:42.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:42.980+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:10:43.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.535 seconds
[2022-12-17T07:10:53.368+0000] {processor.py:154} INFO - Started process (PID=951) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:53.492+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:10:53.496+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:53.495+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:53.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:10:53.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:53.818+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:10:53.969+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:10:53.968+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:10:54.111+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.757 seconds
[2022-12-17T07:11:04.466+0000] {processor.py:154} INFO - Started process (PID=968) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:04.469+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:11:04.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:04.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:04.635+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:04.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:04.974+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:11:05.196+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:05.195+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:11:05.382+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.950 seconds
[2022-12-17T07:11:15.844+0000] {processor.py:154} INFO - Started process (PID=979) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:15.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:11:15.890+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:15.889+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:15.978+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:16.649+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:16.648+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:11:16.812+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:16.811+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:11:17.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.192 seconds
[2022-12-17T07:11:27.302+0000] {processor.py:154} INFO - Started process (PID=989) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:27.355+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:11:27.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:27.357+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:27.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:27.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:27.615+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:11:27.757+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:27.756+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:11:27.926+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.639 seconds
[2022-12-17T07:11:38.936+0000] {processor.py:154} INFO - Started process (PID=999) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:38.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:11:38.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:38.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:39.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:39.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:39.168+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:11:39.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:39.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:11:39.470+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.546 seconds
[2022-12-17T07:11:49.885+0000] {processor.py:154} INFO - Started process (PID=1017) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:49.915+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:11:49.919+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:49.918+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:50.046+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:11:50.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:50.768+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:11:50.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:11:50.924+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:11:51.088+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.238 seconds
[2022-12-17T07:12:01.500+0000] {processor.py:154} INFO - Started process (PID=1027) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:01.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:01.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:01.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:01.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:02.581+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:12:13.055+0000] {processor.py:154} INFO - Started process (PID=1037) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:13.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:13.062+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:13.062+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:13.153+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:13.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:13.799+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:12:14.001+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:14.000+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:12:14.115+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.074 seconds
[2022-12-17T07:12:24.496+0000] {processor.py:154} INFO - Started process (PID=1047) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:24.506+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:24.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:24.510+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:24.633+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:25.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:25.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:12:25.312+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:25.306+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:12:25.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.133 seconds
[2022-12-17T07:12:35.909+0000] {processor.py:154} INFO - Started process (PID=1065) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:35.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:35.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:35.946+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:36.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:37.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:37.604+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:12:37.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:37.727+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:12:37.858+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.966 seconds
[2022-12-17T07:12:48.135+0000] {processor.py:154} INFO - Started process (PID=1075) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:48.187+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:48.191+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:48.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:48.290+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:48.448+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:48.447+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:12:48.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:48.629+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:12:48.738+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.618 seconds
[2022-12-17T07:12:59.313+0000] {processor.py:154} INFO - Started process (PID=1085) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:59.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:12:59.342+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:59.341+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:59.431+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:12:59.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:59.604+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:12:59.722+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:12:59.721+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:12:59.900+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.601 seconds
[2022-12-17T07:13:10.312+0000] {processor.py:154} INFO - Started process (PID=1103) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:10.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:13:10.439+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:10.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:10.539+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:10.782+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:10.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:13:11.024+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:11.023+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:13:11.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.965 seconds
[2022-12-17T07:13:21.864+0000] {processor.py:154} INFO - Started process (PID=1113) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:21.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:13:21.920+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:21.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:22.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:22.257+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:22.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:13:22.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:22.388+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:13:22.516+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.711 seconds
[2022-12-17T07:13:32.769+0000] {processor.py:154} INFO - Started process (PID=1123) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:32.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:13:32.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:32.811+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:32.913+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:33.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:33.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:13:33.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:33.334+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:13:33.584+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.829 seconds
[2022-12-17T07:13:43.927+0000] {processor.py:154} INFO - Started process (PID=1133) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:43.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:13:43.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:43.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:44.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:44.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:44.453+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:13:44.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:44.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:13:44.746+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.841 seconds
[2022-12-17T07:13:55.419+0000] {processor.py:154} INFO - Started process (PID=1151) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:55.447+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:13:55.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:13:55.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:55.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:13:56.752+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:14:07.236+0000] {processor.py:154} INFO - Started process (PID=1161) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:07.285+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:14:07.289+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:07.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:07.394+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:07.538+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:07.537+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:14:07.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:07.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:14:07.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.560 seconds
[2022-12-17T07:14:18.041+0000] {processor.py:154} INFO - Started process (PID=1171) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:18.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:14:18.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:18.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:18.151+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:19.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:19.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:14:20.003+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:20.002+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:14:20.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.302 seconds
[2022-12-17T07:14:30.723+0000] {processor.py:154} INFO - Started process (PID=1189) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:30.749+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:14:30.758+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:30.757+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:30.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:32.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:32.066+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:14:32.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:32.313+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:14:32.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.734 seconds
[2022-12-17T07:14:42.707+0000] {processor.py:154} INFO - Started process (PID=1199) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:42.728+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:14:42.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:42.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:42.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:43.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:43.065+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:14:43.185+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:43.183+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:14:43.507+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.815 seconds
[2022-12-17T07:14:53.967+0000] {processor.py:154} INFO - Started process (PID=1209) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:54.008+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:14:54.013+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:54.012+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:54.122+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:14:55.272+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:55.271+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:14:55.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:14:55.381+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:14:55.496+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.543 seconds
[2022-12-17T07:15:05.747+0000] {processor.py:154} INFO - Started process (PID=1219) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:05.775+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:15:05.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:05.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:05.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:06.167+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:06.166+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:15:06.332+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:06.331+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:15:06.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.901 seconds
[2022-12-17T07:15:17.272+0000] {processor.py:154} INFO - Started process (PID=1237) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:17.321+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:15:17.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:17.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:17.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:17.917+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:15:28.271+0000] {processor.py:154} INFO - Started process (PID=1247) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:28.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:15:28.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:28.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:28.389+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:28.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:28.519+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:15:28.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:28.641+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:15:28.933+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.676 seconds
[2022-12-17T07:15:39.206+0000] {processor.py:154} INFO - Started process (PID=1257) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:39.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:15:39.254+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:39.253+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:39.349+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:39.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:39.479+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:15:39.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:39.600+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:15:39.736+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.546 seconds
[2022-12-17T07:15:50.095+0000] {processor.py:154} INFO - Started process (PID=1274) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:50.143+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:15:50.147+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:50.146+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:50.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:15:50.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:50.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:15:50.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:15:50.529+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:15:50.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.671 seconds
[2022-12-17T07:16:00.966+0000] {processor.py:154} INFO - Started process (PID=1284) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:01.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:01.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:01.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:01.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:01.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:01.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:16:01.395+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:01.394+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:16:01.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.579 seconds
[2022-12-17T07:16:11.769+0000] {processor.py:154} INFO - Started process (PID=1294) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:11.817+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:11.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:11.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:11.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:12.895+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:16:23.098+0000] {processor.py:154} INFO - Started process (PID=1304) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:23.126+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:23.130+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:23.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:23.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:23.359+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:23.358+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:16:23.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:23.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:16:23.644+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-17T07:16:34.105+0000] {processor.py:154} INFO - Started process (PID=1322) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:34.135+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:34.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:34.138+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:34.312+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:34.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:34.565+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:16:34.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:34.715+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:16:34.902+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.828 seconds
[2022-12-17T07:16:45.337+0000] {processor.py:154} INFO - Started process (PID=1332) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:45.370+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:45.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:45.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:45.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:45.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:45.658+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:16:45.877+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:45.876+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:16:45.987+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.666 seconds
[2022-12-17T07:16:56.367+0000] {processor.py:154} INFO - Started process (PID=1342) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:56.420+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:16:56.427+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:56.425+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:56.625+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:16:56.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:56.896+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:16:57.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:16:57.062+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:16:57.183+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.857 seconds
[2022-12-17T07:17:07.468+0000] {processor.py:154} INFO - Started process (PID=1352) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:07.488+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:17:07.492+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:07.492+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:07.640+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:07.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:07.958+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:17:08.353+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:08.352+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:17:08.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.183 seconds
[2022-12-17T07:17:18.876+0000] {processor.py:154} INFO - Started process (PID=1370) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:18.890+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:17:18.894+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:18.893+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:18.982+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:20.326+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:20.325+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:17:20.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:20.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:17:20.836+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.975 seconds
[2022-12-17T07:17:31.240+0000] {processor.py:154} INFO - Started process (PID=1380) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:31.255+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:17:31.259+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:31.258+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:31.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:31.787+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:31.758+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:17:32.165+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:32.164+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:17:32.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.189 seconds
[2022-12-17T07:17:42.870+0000] {processor.py:154} INFO - Started process (PID=1390) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:42.901+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:17:42.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:42.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:43.072+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:43.258+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:43.257+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:17:43.637+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:43.623+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:17:43.919+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.100 seconds
[2022-12-17T07:17:54.182+0000] {processor.py:154} INFO - Started process (PID=1408) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:54.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:17:54.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:54.217+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:54.389+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:17:54.636+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:54.634+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:17:54.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:17:54.818+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:17:55.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.934 seconds
[2022-12-17T07:18:05.686+0000] {processor.py:154} INFO - Started process (PID=1418) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:05.716+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:18:05.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:05.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:05.818+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:06.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:06.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:18:06.307+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:06.306+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:18:06.422+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.766 seconds
[2022-12-17T07:18:16.737+0000] {processor.py:154} INFO - Started process (PID=1428) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:16.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:18:16.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:16.791+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:16.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:17.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:17.066+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:18:17.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:17.225+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:18:17.384+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-17T07:18:28.353+0000] {processor.py:154} INFO - Started process (PID=1438) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:28.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:18:28.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:28.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:28.481+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:28.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:28.956+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:18:29.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:29.074+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:18:29.205+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.867 seconds
[2022-12-17T07:18:39.729+0000] {processor.py:154} INFO - Started process (PID=1456) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:39.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:18:39.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:39.788+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:39.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:41.013+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:18:51.572+0000] {processor.py:154} INFO - Started process (PID=1466) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:51.622+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:18:51.628+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:51.626+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:51.723+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:18:52.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:52.029+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:18:52.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:18:52.174+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:18:52.411+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.883 seconds
[2022-12-17T07:19:02.600+0000] {processor.py:154} INFO - Started process (PID=1476) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:02.648+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:19:02.655+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:02.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:02.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:03.114+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:03.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:19:03.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:03.299+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:19:03.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.852 seconds
[2022-12-17T07:19:14.257+0000] {processor.py:154} INFO - Started process (PID=1494) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:14.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:19:14.297+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:14.297+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:14.435+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:14.850+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:14.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:19:15.005+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:15.004+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:19:15.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.972 seconds
[2022-12-17T07:19:25.771+0000] {processor.py:154} INFO - Started process (PID=1504) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:25.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:19:25.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:25.798+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:25.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:26.624+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:19:37.386+0000] {processor.py:154} INFO - Started process (PID=1514) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:37.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:19:37.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:37.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:37.626+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:37.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:37.854+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:19:38.118+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:38.117+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:19:38.310+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.984 seconds
[2022-12-17T07:19:48.697+0000] {processor.py:154} INFO - Started process (PID=1524) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:48.729+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:19:48.741+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:48.735+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:48.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:19:49.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:49.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:19:49.380+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:19:49.376+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:19:49.543+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-17T07:20:00.242+0000] {processor.py:154} INFO - Started process (PID=1540) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:00.261+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:00.298+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:00.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:00.677+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:02.277+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:20:12.636+0000] {processor.py:154} INFO - Started process (PID=1552) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:12.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:12.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:12.663+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:12.798+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:13.127+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:13.126+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:20:13.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:13.275+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:20:13.597+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.976 seconds
[2022-12-17T07:20:24.246+0000] {processor.py:154} INFO - Started process (PID=1562) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:24.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:24.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:24.326+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:24.570+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:24.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:24.765+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:20:24.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:24.912+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:20:25.054+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-17T07:20:35.477+0000] {processor.py:154} INFO - Started process (PID=1572) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:35.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:35.538+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:35.538+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:35.862+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:36.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:36.125+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:20:36.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:36.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:20:36.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.967 seconds
[2022-12-17T07:20:46.886+0000] {processor.py:154} INFO - Started process (PID=1588) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:46.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:46.956+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:46.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:47.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:48.165+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:48.164+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:20:48.403+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:48.402+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:20:48.579+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.723 seconds
[2022-12-17T07:20:58.972+0000] {processor.py:154} INFO - Started process (PID=1598) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:58.992+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:20:58.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:20:58.996+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:20:59.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:00.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:00.096+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:21:00.209+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:00.208+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:21:00.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.423 seconds
[2022-12-17T07:21:10.758+0000] {processor.py:154} INFO - Started process (PID=1610) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:10.797+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:21:10.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:10.817+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:11.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:11.246+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:11.245+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:21:11.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:11.372+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:21:11.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.761 seconds
[2022-12-17T07:21:21.928+0000] {processor.py:154} INFO - Started process (PID=1626) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:21.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:21:22.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:22.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:22.451+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:23.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:23.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:21:23.430+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:23.428+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:21:23.654+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.767 seconds
[2022-12-17T07:21:34.188+0000] {processor.py:154} INFO - Started process (PID=1637) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:34.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:21:34.196+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:34.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:34.478+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:35.806+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:21:46.653+0000] {processor.py:154} INFO - Started process (PID=1647) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:46.679+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:21:46.693+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:46.683+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:46.834+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:47.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:47.037+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:21:47.216+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:47.215+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:21:47.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.689 seconds
[2022-12-17T07:21:57.775+0000] {processor.py:154} INFO - Started process (PID=1657) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:57.814+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:21:57.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:57.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:58.018+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:21:58.613+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:58.612+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:21:58.780+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:21:58.779+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:21:59.079+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.339 seconds
[2022-12-17T07:22:09.542+0000] {processor.py:154} INFO - Started process (PID=1676) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:09.579+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:22:09.600+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:09.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:09.954+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:10.791+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:10.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:22:11.005+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:11.004+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:22:11.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.775 seconds
[2022-12-17T07:22:21.941+0000] {processor.py:154} INFO - Started process (PID=1686) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:21.970+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:22:22.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:21.981+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:22.495+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:23.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:23.785+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:22:23.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:23.984+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:22:24.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.301 seconds
[2022-12-17T07:22:34.631+0000] {processor.py:154} INFO - Started process (PID=1696) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:34.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:22:34.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:34.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:34.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:34.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:34.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:22:35.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:35.212+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:22:35.468+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.858 seconds
[2022-12-17T07:22:45.866+0000] {processor.py:154} INFO - Started process (PID=1713) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:45.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:22:45.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:45.915+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:46.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:46.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:46.760+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:22:47.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:47.039+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:22:47.261+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.432 seconds
[2022-12-17T07:22:57.687+0000] {processor.py:154} INFO - Started process (PID=1724) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:57.740+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:22:57.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:57.763+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:58.139+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:22:58.434+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:58.433+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:22:58.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:22:58.706+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:22:59.053+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.455 seconds
[2022-12-17T07:23:09.458+0000] {processor.py:154} INFO - Started process (PID=1734) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:09.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:23:09.627+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:09.626+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:09.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:10.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:10.207+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:23:10.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:10.324+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:23:10.489+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.047 seconds
[2022-12-17T07:23:20.958+0000] {processor.py:154} INFO - Started process (PID=1744) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:20.991+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:23:20.995+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:20.994+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:21.443+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:21.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:21.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:23:21.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:21.985+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:23:22.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.240 seconds
[2022-12-17T07:23:32.475+0000] {processor.py:154} INFO - Started process (PID=1761) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:32.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:23:32.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:32.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:32.640+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:32.995+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:32.994+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:23:33.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:33.382+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:23:33.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.303 seconds
[2022-12-17T07:23:44.219+0000] {processor.py:154} INFO - Started process (PID=1772) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:44.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:23:44.264+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:44.263+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:44.351+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:44.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:44.507+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:23:44.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:44.697+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:23:44.820+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.615 seconds
[2022-12-17T07:23:54.996+0000] {processor.py:154} INFO - Started process (PID=1782) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:55.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:23:55.057+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:55.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:55.162+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:23:55.400+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:55.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:23:55.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:23:55.586+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:23:55.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.737 seconds
[2022-12-17T07:24:05.922+0000] {processor.py:154} INFO - Started process (PID=1792) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:05.929+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:24:05.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:05.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:06.034+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:06.297+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:06.296+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:24:06.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:06.439+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:24:06.549+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T07:24:16.950+0000] {processor.py:154} INFO - Started process (PID=1810) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:16.965+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:24:16.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:16.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:17.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:17.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:17.336+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:24:17.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:17.552+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:24:17.790+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-17T07:24:28.436+0000] {processor.py:154} INFO - Started process (PID=1820) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:28.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:24:28.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:28.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:28.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:28.791+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:28.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:24:28.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:28.922+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:24:29.146+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.727 seconds
[2022-12-17T07:24:39.579+0000] {processor.py:154} INFO - Started process (PID=1830) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:39.587+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:24:39.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:39.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:39.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:41.117+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:41.116+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:24:41.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:41.252+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:24:41.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.894 seconds
[2022-12-17T07:24:51.960+0000] {processor.py:154} INFO - Started process (PID=1840) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:52.008+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:24:52.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:52.011+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:52.149+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:24:52.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:52.325+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:24:52.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:24:52.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:24:52.766+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.827 seconds
[2022-12-17T07:25:03.169+0000] {processor.py:154} INFO - Started process (PID=1858) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:03.178+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:25:03.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:03.188+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:03.553+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:05.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:05.372+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:25:05.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:05.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:25:06.046+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.923 seconds
[2022-12-17T07:25:16.353+0000] {processor.py:154} INFO - Started process (PID=1868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:16.357+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:25:16.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:16.365+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:16.509+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:16.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:16.793+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:25:17.081+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:17.080+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:25:17.242+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.909 seconds
[2022-12-17T07:25:27.570+0000] {processor.py:154} INFO - Started process (PID=1878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:27.600+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:25:27.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:27.604+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:27.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:27.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:27.946+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:25:28.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:28.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:25:28.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.791 seconds
[2022-12-17T07:25:38.758+0000] {processor.py:154} INFO - Started process (PID=1888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:38.802+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:25:38.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:38.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:38.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:39.111+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:39.110+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:25:39.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:39.267+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:25:39.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.706 seconds
[2022-12-17T07:25:50.086+0000] {processor.py:154} INFO - Started process (PID=1906) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:50.106+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:25:50.119+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:50.117+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:50.756+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:25:51.393+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:51.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:25:51.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:25:51.720+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:25:51.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.991 seconds
[2022-12-17T07:26:02.353+0000] {processor.py:154} INFO - Started process (PID=1916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:02.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:26:02.379+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:02.378+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:02.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:02.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:02.770+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:26:03.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:03.013+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:26:03.238+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.906 seconds
[2022-12-17T07:26:13.868+0000] {processor.py:154} INFO - Started process (PID=1926) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:13.910+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:26:13.914+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:13.913+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:14.140+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:14.489+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:14.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:26:15.056+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:15.046+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:26:15.650+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.819 seconds
[2022-12-17T07:26:26.341+0000] {processor.py:154} INFO - Started process (PID=1936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:26.344+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:26:26.352+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:26.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:26.503+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:26.786+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:26.784+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:26:27.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:27.074+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:26:27.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-17T07:26:37.993+0000] {processor.py:154} INFO - Started process (PID=1953) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:38.020+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:26:38.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:38.027+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:38.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:39.992+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:26:51.480+0000] {processor.py:154} INFO - Started process (PID=1963) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:51.483+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:26:51.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:51.490+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:51.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:26:52.116+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:52.102+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:26:52.674+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:26:52.663+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:26:53.081+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.639 seconds
[2022-12-17T07:27:03.730+0000] {processor.py:154} INFO - Started process (PID=1973) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:03.742+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:27:03.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:03.767+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:04.033+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:04.201+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:04.199+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:27:04.351+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:04.350+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:27:04.595+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.961 seconds
[2022-12-17T07:27:15.130+0000] {processor.py:154} INFO - Started process (PID=1990) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:15.154+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:27:15.158+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:15.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:15.464+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:16.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:16.800+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:27:17.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:17.432+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:27:17.656+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.583 seconds
[2022-12-17T07:27:27.972+0000] {processor.py:154} INFO - Started process (PID=2001) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:27.979+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:27:27.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:27.982+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:28.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:28.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:28.344+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:27:28.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:28.733+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:27:29.070+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.130 seconds
[2022-12-17T07:27:39.342+0000] {processor.py:154} INFO - Started process (PID=2011) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:39.345+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:27:39.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:39.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:39.526+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:40.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:40.164+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:27:40.421+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:40.420+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:27:40.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.560 seconds
[2022-12-17T07:27:51.286+0000] {processor.py:154} INFO - Started process (PID=2021) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:51.342+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:27:51.349+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:51.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:51.614+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:27:51.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:51.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:27:52.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:27:52.033+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:27:52.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.038 seconds
[2022-12-17T07:28:02.903+0000] {processor.py:154} INFO - Started process (PID=2039) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:02.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:28:02.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:02.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:03.128+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:03.561+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:03.554+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:28:03.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:03.782+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:28:04.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.362 seconds
[2022-12-17T07:28:14.967+0000] {processor.py:154} INFO - Started process (PID=2049) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:14.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:28:14.977+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:14.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:15.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:15.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:15.324+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:28:15.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:15.486+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:28:15.754+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.806 seconds
[2022-12-17T07:28:26.041+0000] {processor.py:154} INFO - Started process (PID=2059) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:26.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:28:26.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:26.049+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:26.160+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:26.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:26.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:28:26.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:26.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:28:26.644+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.619 seconds
[2022-12-17T07:28:37.189+0000] {processor.py:154} INFO - Started process (PID=2069) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:37.194+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:28:37.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:37.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:37.306+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:37.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:37.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:28:37.607+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:37.606+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:28:37.811+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-17T07:28:48.685+0000] {processor.py:154} INFO - Started process (PID=2087) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:48.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:28:48.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:48.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:49.069+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:28:49.646+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:49.643+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:28:49.925+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:28:49.924+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:28:50.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.621 seconds
[2022-12-17T07:29:01.340+0000] {processor.py:154} INFO - Started process (PID=2097) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:01.347+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:01.350+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:01.350+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:01.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:01.693+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:01.692+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:29:01.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:01.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:29:02.047+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.730 seconds
[2022-12-17T07:29:12.716+0000] {processor.py:154} INFO - Started process (PID=2107) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:12.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:12.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:12.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:13.113+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:13.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:13.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:29:13.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:13.699+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:29:13.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.235 seconds
[2022-12-17T07:29:24.412+0000] {processor.py:154} INFO - Started process (PID=2117) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:24.422+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:24.434+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:24.433+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:24.696+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:25.602+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:29:36.488+0000] {processor.py:154} INFO - Started process (PID=2135) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:36.496+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:36.528+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:36.508+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:36.826+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:37.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:37.388+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:29:37.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:37.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:29:38.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.729 seconds
[2022-12-17T07:29:48.697+0000] {processor.py:154} INFO - Started process (PID=2145) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:48.701+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:48.705+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:48.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:48.860+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:49.050+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:49.049+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:29:49.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:49.191+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:29:49.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.698 seconds
[2022-12-17T07:29:59.895+0000] {processor.py:154} INFO - Started process (PID=2155) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:29:59.902+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:29:59.906+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:29:59.905+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:00.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:00.490+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:00.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:30:00.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:00.930+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:30:01.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.203 seconds
[2022-12-17T07:30:11.232+0000] {processor.py:154} INFO - Started process (PID=2165) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:11.241+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:30:11.245+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:11.244+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:11.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:11.706+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:11.703+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:30:12.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:12.167+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:30:12.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.300 seconds
[2022-12-17T07:30:23.184+0000] {processor.py:154} INFO - Started process (PID=2182) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:23.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:30:23.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:23.196+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:23.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:23.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:23.907+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:30:24.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:24.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:30:25.042+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.887 seconds
[2022-12-17T07:30:35.646+0000] {processor.py:154} INFO - Started process (PID=2192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:35.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:30:35.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:35.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:35.837+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:36.110+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:36.107+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:30:36.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:36.378+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:30:36.709+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.089 seconds
[2022-12-17T07:30:47.193+0000] {processor.py:154} INFO - Started process (PID=2202) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:47.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:30:47.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:47.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:47.337+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:48.509+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:30:59.135+0000] {processor.py:154} INFO - Started process (PID=2212) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:59.143+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:30:59.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:59.146+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:59.296+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:30:59.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:59.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:30:59.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:30:59.745+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:31:00.095+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.989 seconds
[2022-12-17T07:31:11.155+0000] {processor.py:154} INFO - Started process (PID=2230) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:11.171+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:31:11.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:11.178+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:11.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:12.176+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:12.175+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:31:12.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:12.497+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:31:12.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.934 seconds
[2022-12-17T07:31:23.455+0000] {processor.py:154} INFO - Started process (PID=2240) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:23.483+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:31:23.487+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:23.486+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:23.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:24.293+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:24.292+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:31:24.626+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:24.625+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:31:24.990+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.583 seconds
[2022-12-17T07:31:35.508+0000] {processor.py:154} INFO - Started process (PID=2250) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:35.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:31:35.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:35.519+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:35.660+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:36.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:36.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:31:36.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:36.956+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:31:37.222+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.747 seconds
[2022-12-17T07:31:48.094+0000] {processor.py:154} INFO - Started process (PID=2260) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:48.102+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:31:48.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:31:48.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:48.299+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:31:49.147+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:32:00.232+0000] {processor.py:154} INFO - Started process (PID=2278) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:00.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:32:00.286+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:00.285+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:00.549+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:01.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:01.357+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:32:01.993+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:01.992+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:32:02.511+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.312 seconds
[2022-12-17T07:32:13.274+0000] {processor.py:154} INFO - Started process (PID=2288) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:13.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:32:13.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:13.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:13.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:14.484+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:14.483+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:32:14.660+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:14.659+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:32:15.091+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.910 seconds
[2022-12-17T07:32:26.246+0000] {processor.py:154} INFO - Started process (PID=2298) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:26.417+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:32:26.423+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:26.422+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:26.934+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:27.289+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:27.288+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:32:27.491+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:27.490+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:32:27.756+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.627 seconds
[2022-12-17T07:32:38.162+0000] {processor.py:154} INFO - Started process (PID=2315) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:38.241+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:32:38.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:38.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:38.497+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:38.868+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:38.867+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:32:39.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:39.108+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:32:39.587+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.445 seconds
[2022-12-17T07:32:50.683+0000] {processor.py:154} INFO - Started process (PID=2326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:50.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:32:50.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:50.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:51.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:32:52.367+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:52.363+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:32:52.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:32:52.532+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:32:52.709+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.129 seconds
[2022-12-17T07:33:03.077+0000] {processor.py:154} INFO - Started process (PID=2336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:03.086+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:33:03.093+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:03.092+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:03.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:03.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:03.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:33:03.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:03.571+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:33:03.906+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.859 seconds
[2022-12-17T07:33:15.033+0000] {processor.py:154} INFO - Started process (PID=2346) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:15.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:33:15.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:15.073+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:15.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:15.994+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:15.993+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:33:16.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:16.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:33:16.708+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.768 seconds
[2022-12-17T07:33:27.624+0000] {processor.py:154} INFO - Started process (PID=2364) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:27.652+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:33:27.666+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:27.665+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:28.194+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:29.168+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:33:40.061+0000] {processor.py:154} INFO - Started process (PID=2374) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:40.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:33:40.072+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:40.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:40.178+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:41.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:41.543+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:33:42.088+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:42.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:33:42.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.469 seconds
[2022-12-17T07:33:53.043+0000] {processor.py:154} INFO - Started process (PID=2384) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:53.070+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:33:53.073+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:53.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:53.393+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:33:54.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:54.081+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:33:54.371+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:33:54.370+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:33:54.680+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.675 seconds
[2022-12-17T07:34:04.940+0000] {processor.py:154} INFO - Started process (PID=2394) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:04.957+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:34:04.969+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:04.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:05.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:06.997+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:06.996+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:34:07.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:07.888+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:34:08.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.295 seconds
[2022-12-17T07:34:18.737+0000] {processor.py:154} INFO - Started process (PID=2413) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:18.757+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:34:18.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:18.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:19.245+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:21.179+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:21.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:34:21.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:21.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:34:22.238+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.595 seconds
[2022-12-17T07:34:32.778+0000] {processor.py:154} INFO - Started process (PID=2423) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:32.823+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:34:32.828+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:32.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:32.996+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:33.445+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:33.444+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:34:33.847+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:33.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:34:34.088+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.394 seconds
[2022-12-17T07:34:44.400+0000] {processor.py:154} INFO - Started process (PID=2433) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:44.413+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:34:44.423+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:44.422+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:44.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:44.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:44.941+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:34:45.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:45.096+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:34:45.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.991 seconds
[2022-12-17T07:34:55.994+0000] {processor.py:154} INFO - Started process (PID=2450) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:56.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:34:56.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:56.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:56.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:34:57.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:57.364+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:34:57.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:34:57.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:34:58.089+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.170 seconds
[2022-12-17T07:35:08.945+0000] {processor.py:154} INFO - Started process (PID=2461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:09.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:35:09.019+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:09.018+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:09.342+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:10.202+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:10.201+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:35:10.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:10.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:35:10.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.989 seconds
[2022-12-17T07:35:21.276+0000] {processor.py:154} INFO - Started process (PID=2471) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:21.294+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:35:21.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:21.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:21.689+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:21.922+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:21.921+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:35:22.086+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:22.085+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:35:22.299+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.163 seconds
[2022-12-17T07:35:32.840+0000] {processor.py:154} INFO - Started process (PID=2481) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:32.868+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:35:32.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:32.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:33.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:33.206+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:33.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:35:33.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:33.357+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:35:33.604+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-17T07:35:44.252+0000] {processor.py:154} INFO - Started process (PID=2499) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:44.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:35:44.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:44.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:44.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:44.938+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:44.937+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:35:45.325+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:45.319+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:35:45.628+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.423 seconds
[2022-12-17T07:35:56.287+0000] {processor.py:154} INFO - Started process (PID=2509) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:56.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:35:56.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:56.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:56.443+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:35:56.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:56.760+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:35:56.910+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:35:56.909+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:35:57.038+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.775 seconds
[2022-12-17T07:36:07.274+0000] {processor.py:154} INFO - Started process (PID=2519) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:07.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:36:07.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:07.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:07.414+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:07.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:07.964+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:36:08.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:08.265+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:36:08.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.231 seconds
[2022-12-17T07:36:19.013+0000] {processor.py:154} INFO - Started process (PID=2529) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:19.066+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:36:19.082+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:19.081+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:19.297+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:19.523+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:19.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:36:19.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:19.693+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:36:19.898+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.945 seconds
[2022-12-17T07:36:30.405+0000] {processor.py:154} INFO - Started process (PID=2547) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:30.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:36:30.417+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:30.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:30.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:31.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:31.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:36:31.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:31.813+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:36:32.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.698 seconds
[2022-12-17T07:36:42.548+0000] {processor.py:154} INFO - Started process (PID=2557) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:42.552+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:36:42.557+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:42.554+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:42.781+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:43.849+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:43.847+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:36:43.999+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:43.998+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:36:44.177+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.645 seconds
[2022-12-17T07:36:54.528+0000] {processor.py:154} INFO - Started process (PID=2567) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:54.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:36:54.564+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:54.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:54.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:36:55.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:55.501+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:36:55.778+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:36:55.775+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:36:55.965+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.476 seconds
[2022-12-17T07:37:06.872+0000] {processor.py:154} INFO - Started process (PID=2577) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:06.875+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:37:06.894+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:06.886+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:07.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:07.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:07.911+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:37:08.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:08.099+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:37:08.287+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.443 seconds
[2022-12-17T07:37:18.789+0000] {processor.py:154} INFO - Started process (PID=2595) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:18.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:37:18.828+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:18.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:19.181+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:20.309+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:20.305+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:37:20.715+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:20.714+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:37:21.045+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.324 seconds
[2022-12-17T07:37:31.584+0000] {processor.py:154} INFO - Started process (PID=2605) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:31.634+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:37:31.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:31.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:32.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:32.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:32.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:37:33.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:33.119+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:37:33.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.731 seconds
[2022-12-17T07:37:43.716+0000] {processor.py:154} INFO - Started process (PID=2615) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:43.725+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:37:43.733+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:43.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:43.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:44.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:44.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:37:44.847+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:44.842+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:37:45.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.560 seconds
[2022-12-17T07:37:55.599+0000] {processor.py:154} INFO - Started process (PID=2625) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:55.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:37:55.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:37:55.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:55.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:37:56.487+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:38:07.291+0000] {processor.py:154} INFO - Started process (PID=2643) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:07.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:38:07.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:07.320+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:07.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:08.883+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:38:19.420+0000] {processor.py:154} INFO - Started process (PID=2653) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:19.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:38:19.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:19.437+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:19.583+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:19.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:19.855+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:38:20.034+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:20.032+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:38:20.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.875 seconds
[2022-12-17T07:38:30.791+0000] {processor.py:154} INFO - Started process (PID=2663) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:30.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:38:30.828+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:30.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:30.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:31.154+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:31.153+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:38:31.292+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:31.292+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:38:31.465+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.699 seconds
[2022-12-17T07:38:41.688+0000] {processor.py:154} INFO - Started process (PID=2673) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:41.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:38:41.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:41.701+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:41.821+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:42.087+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:42.086+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:38:42.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:42.356+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:38:42.517+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-17T07:38:53.285+0000] {processor.py:154} INFO - Started process (PID=2689) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:53.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:38:53.316+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:38:53.301+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:53.548+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:38:55.218+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:39:05.968+0000] {processor.py:154} INFO - Started process (PID=2701) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:05.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:39:05.980+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:05.979+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:06.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:06.334+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:06.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:39:06.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:06.516+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:39:06.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.760 seconds
[2022-12-17T07:39:17.514+0000] {processor.py:154} INFO - Started process (PID=2709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:17.572+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:39:17.581+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:17.580+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:17.832+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:18.581+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:39:29.308+0000] {processor.py:154} INFO - Started process (PID=2727) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:29.311+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:39:29.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:29.320+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:29.786+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:30.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:30.461+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:39:30.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:30.811+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:39:31.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.887 seconds
[2022-12-17T07:39:41.888+0000] {processor.py:154} INFO - Started process (PID=2738) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:41.896+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:39:41.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:41.899+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:42.561+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:43.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:43.534+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:39:43.838+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:43.837+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:39:44.125+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.343 seconds
[2022-12-17T07:39:54.770+0000] {processor.py:154} INFO - Started process (PID=2748) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:54.779+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:39:54.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:54.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:55.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:39:56.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:56.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:39:56.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:39:56.317+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:39:56.481+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.754 seconds
[2022-12-17T07:40:06.947+0000] {processor.py:154} INFO - Started process (PID=2760) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:06.956+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:40:06.961+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:06.960+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:07.114+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:07.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:07.357+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:40:07.586+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:07.584+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:40:07.884+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.966 seconds
[2022-12-17T07:40:18.686+0000] {processor.py:154} INFO - Started process (PID=2775) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:18.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:40:18.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:18.753+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:19.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:20.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:20.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:40:20.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:20.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:40:20.792+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.252 seconds
[2022-12-17T07:40:31.635+0000] {processor.py:154} INFO - Started process (PID=2785) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:31.676+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:40:31.697+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:31.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:32.040+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:33.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:33.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:40:34.159+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:34.158+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:40:34.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.802 seconds
[2022-12-17T07:40:44.979+0000] {processor.py:154} INFO - Started process (PID=2797) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:45.027+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:40:45.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:45.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:45.196+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:45.657+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:45.656+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:40:45.784+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:45.783+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:40:45.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.035 seconds
[2022-12-17T07:40:56.345+0000] {processor.py:154} INFO - Started process (PID=2805) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:56.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:40:56.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:56.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:56.554+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:40:56.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:56.805+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:40:56.977+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:40:56.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:40:57.152+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.891 seconds
[2022-12-17T07:41:07.951+0000] {processor.py:154} INFO - Started process (PID=2823) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:07.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:41:07.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:07.983+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:08.372+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:09.641+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:41:20.417+0000] {processor.py:154} INFO - Started process (PID=2833) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:20.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:41:20.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:20.430+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:20.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:21.610+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:21.609+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:41:21.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:21.782+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:41:21.986+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.646 seconds
[2022-12-17T07:41:32.655+0000] {processor.py:154} INFO - Started process (PID=2843) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:32.659+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:41:32.702+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:32.701+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:33.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:33.407+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:33.406+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:41:33.561+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:33.560+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:41:33.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.179 seconds
[2022-12-17T07:41:44.245+0000] {processor.py:154} INFO - Started process (PID=2853) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:44.267+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:41:44.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:44.278+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:44.548+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:45.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:45.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:41:45.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:45.557+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:41:45.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.503 seconds
[2022-12-17T07:41:55.997+0000] {processor.py:154} INFO - Started process (PID=2868) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:56.008+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:41:56.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:56.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:56.359+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:41:57.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:57.530+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:41:58.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:41:58.029+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:41:58.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.832 seconds
[2022-12-17T07:42:09.829+0000] {processor.py:154} INFO - Started process (PID=2878) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:09.869+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:42:09.879+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:09.878+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:10.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:10.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:10.377+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:42:10.595+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:10.594+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:42:10.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.137 seconds
[2022-12-17T07:42:21.502+0000] {processor.py:154} INFO - Started process (PID=2888) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:21.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:42:21.538+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:21.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:21.758+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:22.625+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:22.615+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:42:22.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:22.859+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:42:23.089+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.620 seconds
[2022-12-17T07:42:33.622+0000] {processor.py:154} INFO - Started process (PID=2908) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:33.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:42:33.633+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:33.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:33.965+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:34.397+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:34.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:42:34.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:34.643+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:42:34.909+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.327 seconds
[2022-12-17T07:42:45.642+0000] {processor.py:154} INFO - Started process (PID=2916) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:45.671+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:42:45.681+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:45.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:45.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:46.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:46.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:42:47.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:47.136+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:42:47.481+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.963 seconds
[2022-12-17T07:42:58.006+0000] {processor.py:154} INFO - Started process (PID=2926) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:58.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:42:58.037+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:58.036+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:58.176+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:42:59.023+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:59.022+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:42:59.181+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:42:59.180+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:42:59.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.355 seconds
[2022-12-17T07:43:10.290+0000] {processor.py:154} INFO - Started process (PID=2936) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:10.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:43:10.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:10.357+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:10.491+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:10.841+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:10.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:43:11.123+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:11.122+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:43:11.446+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.180 seconds
[2022-12-17T07:43:21.866+0000] {processor.py:154} INFO - Started process (PID=2952) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:21.892+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:43:21.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:21.895+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:22.175+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:22.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:22.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:43:22.829+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:22.822+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:43:23.196+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.395 seconds
[2022-12-17T07:43:33.699+0000] {processor.py:154} INFO - Started process (PID=2963) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:33.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:43:33.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:33.760+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:33.975+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:34.788+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:34.787+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:43:35.080+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:35.074+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:43:35.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.641 seconds
[2022-12-17T07:43:45.708+0000] {processor.py:154} INFO - Started process (PID=2976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:45.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:43:45.724+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:45.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:45.914+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:46.708+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:46.702+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:43:46.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:46.884+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:43:47.033+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.374 seconds
[2022-12-17T07:43:57.570+0000] {processor.py:154} INFO - Started process (PID=2986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:57.598+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:43:57.606+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:57.605+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:57.915+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:43:58.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:58.295+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:43:58.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:43:58.476+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:43:58.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.121 seconds
[2022-12-17T07:44:09.385+0000] {processor.py:154} INFO - Started process (PID=3004) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:09.409+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:44:09.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:09.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:09.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:10.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:10.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:44:10.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:10.706+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:44:11.054+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.751 seconds
[2022-12-17T07:44:21.501+0000] {processor.py:154} INFO - Started process (PID=3011) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:21.505+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:44:21.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:21.508+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:21.683+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:22.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:22.811+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:44:23.048+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:23.047+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:44:23.324+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.845 seconds
[2022-12-17T07:44:33.726+0000] {processor.py:154} INFO - Started process (PID=3024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:33.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:44:33.784+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:33.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:33.932+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:34.335+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:34.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:44:34.563+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:34.562+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:44:34.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.073 seconds
[2022-12-17T07:44:45.201+0000] {processor.py:154} INFO - Started process (PID=3031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:45.227+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:44:45.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:45.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:45.430+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:45.730+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:45.729+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:44:46.025+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:46.023+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:44:46.253+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.109 seconds
[2022-12-17T07:44:56.998+0000] {processor.py:154} INFO - Started process (PID=3049) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:57.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:44:57.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:44:57.035+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:57.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:44:58.768+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:45:09.245+0000] {processor.py:154} INFO - Started process (PID=3059) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:09.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:45:09.285+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:09.284+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:09.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:10.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:10.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:45:10.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:10.393+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:45:10.629+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.405 seconds
[2022-12-17T07:45:20.979+0000] {processor.py:154} INFO - Started process (PID=3069) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:20.984+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:45:20.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:20.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:21.120+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:21.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:21.752+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:45:21.895+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:21.894+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:45:22.025+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.063 seconds
[2022-12-17T07:45:32.480+0000] {processor.py:154} INFO - Started process (PID=3086) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:32.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:45:32.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:32.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:32.640+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:34.570+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:34.569+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:45:34.774+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:34.774+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:45:35.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.683 seconds
[2022-12-17T07:45:45.697+0000] {processor.py:154} INFO - Started process (PID=3097) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:45.706+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:45:45.713+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:45.709+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:45.823+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:46.013+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:46.012+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:45:46.200+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:46.199+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:45:46.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-17T07:45:57.445+0000] {processor.py:154} INFO - Started process (PID=3107) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:57.506+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:45:57.518+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:57.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:57.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:45:58.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:58.031+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:45:58.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:45:58.281+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:45:59.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.239 seconds
[2022-12-17T07:46:09.911+0000] {processor.py:154} INFO - Started process (PID=3117) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:09.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:46:09.969+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:09.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:10.221+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:10.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:10.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:46:11.026+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:11.025+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:46:11.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.403 seconds
[2022-12-17T07:46:21.840+0000] {processor.py:154} INFO - Started process (PID=3135) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:21.860+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:46:21.864+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:21.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:22.034+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:22.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:22.345+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:46:22.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:22.664+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:46:23.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.309 seconds
[2022-12-17T07:46:33.632+0000] {processor.py:154} INFO - Started process (PID=3145) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:33.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:46:33.700+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:33.694+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:33.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:34.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:34.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:46:35.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:35.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:46:35.396+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.792 seconds
[2022-12-17T07:46:45.782+0000] {processor.py:154} INFO - Started process (PID=3158) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:45.806+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:46:45.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:45.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:45.976+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:46.571+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:46.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:46:46.739+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:46.738+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:46:46.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.117 seconds
[2022-12-17T07:46:57.090+0000] {processor.py:154} INFO - Started process (PID=3170) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:57.093+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:46:57.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:57.096+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:57.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:46:57.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:57.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:46:57.577+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:46:57.575+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:46:57.919+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.860 seconds
[2022-12-17T07:47:08.687+0000] {processor.py:154} INFO - Started process (PID=3186) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:08.690+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:47:08.718+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:08.717+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:08.884+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:09.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:09.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:47:09.471+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:09.470+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:47:09.957+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.317 seconds
[2022-12-17T07:47:20.507+0000] {processor.py:154} INFO - Started process (PID=3197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:20.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:47:20.534+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:20.533+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:20.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:21.149+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:21.148+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:47:21.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:21.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:47:21.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.282 seconds
[2022-12-17T07:47:32.288+0000] {processor.py:154} INFO - Started process (PID=3206) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:32.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:47:32.306+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:32.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:32.558+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:32.888+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:32.887+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:47:33.051+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:33.050+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:47:33.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-17T07:47:43.914+0000] {processor.py:154} INFO - Started process (PID=3216) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:44.001+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:47:44.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:44.008+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:44.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:45.014+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:47:55.745+0000] {processor.py:154} INFO - Started process (PID=3234) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:55.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:47:55.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:47:55.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:56.002+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:47:57.051+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:48:07.588+0000] {processor.py:154} INFO - Started process (PID=3244) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:07.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:48:07.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:07.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:07.827+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:08.171+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:08.170+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:48:08.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:08.372+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:48:08.646+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.104 seconds
[2022-12-17T07:48:19.119+0000] {processor.py:154} INFO - Started process (PID=3254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:19.122+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:48:19.130+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:19.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:19.294+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:19.484+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:19.482+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:48:19.687+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:19.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:48:19.941+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.838 seconds
[2022-12-17T07:48:30.399+0000] {processor.py:154} INFO - Started process (PID=3270) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:30.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:48:30.425+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:30.424+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:30.769+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:31.874+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:31.866+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:48:32.120+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:32.119+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:48:32.364+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.992 seconds
[2022-12-17T07:48:42.973+0000] {processor.py:154} INFO - Started process (PID=3281) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:42.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:48:43.024+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:43.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:43.143+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:44.115+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T07:48:54.371+0000] {processor.py:154} INFO - Started process (PID=3291) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:54.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:48:54.399+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:54.398+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:54.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:48:55.059+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:55.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:48:55.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:48:55.205+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:48:55.368+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.019 seconds
[2022-12-17T07:49:05.996+0000] {processor.py:154} INFO - Started process (PID=3301) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:06.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:49:06.048+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:06.031+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:06.248+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:07.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:07.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:49:07.673+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:07.672+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:49:09.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.181 seconds
[2022-12-17T07:49:19.739+0000] {processor.py:154} INFO - Started process (PID=3319) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:19.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:49:19.784+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:19.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:20.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:20.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:20.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:49:21.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:21.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:49:21.605+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.977 seconds
[2022-12-17T07:49:32.056+0000] {processor.py:154} INFO - Started process (PID=3329) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:32.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:49:32.117+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:32.116+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:32.291+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:32.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:32.529+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:49:32.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:32.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:49:33.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.019 seconds
[2022-12-17T07:49:43.431+0000] {processor.py:154} INFO - Started process (PID=3336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:43.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:49:43.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:43.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:43.638+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:43.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:43.906+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:49:44.065+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:44.064+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:49:44.281+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.931 seconds
[2022-12-17T07:49:54.734+0000] {processor.py:154} INFO - Started process (PID=3346) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:54.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:49:54.785+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:54.784+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:54.888+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:49:55.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:55.045+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:49:55.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:49:55.304+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:49:55.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.809 seconds
[2022-12-17T07:50:06.088+0000] {processor.py:154} INFO - Started process (PID=3365) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:06.097+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:50:06.101+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:06.100+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:06.285+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:08.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:08.068+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:50:08.234+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:08.233+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:50:08.458+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.411 seconds
[2022-12-17T07:50:18.703+0000] {processor.py:154} INFO - Started process (PID=3380) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:18.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:50:18.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:18.734+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:18.842+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:19.293+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:19.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:50:19.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:19.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:50:19.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.940 seconds
[2022-12-17T07:50:30.032+0000] {processor.py:154} INFO - Started process (PID=3390) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:30.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:50:30.043+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:30.042+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:30.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:30.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:30.328+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:50:30.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:30.497+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:50:30.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.669 seconds
[2022-12-17T07:50:41.236+0000] {processor.py:154} INFO - Started process (PID=3405) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:41.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:50:41.263+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:41.262+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:41.631+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:42.243+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:42.242+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:50:42.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:42.521+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:50:42.853+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.649 seconds
[2022-12-17T07:50:53.441+0000] {processor.py:154} INFO - Started process (PID=3416) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:53.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:50:53.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:53.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:53.587+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:50:53.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:53.865+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:50:54.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:50:54.112+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:50:54.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.887 seconds
[2022-12-17T07:51:04.577+0000] {processor.py:154} INFO - Started process (PID=3423) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:04.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:51:04.598+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:04.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:04.698+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:04.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:04.875+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:51:05.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:05.075+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:51:05.287+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.744 seconds
[2022-12-17T07:51:15.916+0000] {processor.py:154} INFO - Started process (PID=3433) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:15.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:51:15.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:15.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:16.037+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:16.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:16.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:51:16.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:16.304+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:51:16.439+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.560 seconds
[2022-12-17T07:51:26.904+0000] {processor.py:154} INFO - Started process (PID=3451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:26.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:51:26.958+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:26.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:27.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:28.617+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:28.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:51:28.803+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:28.802+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:51:28.974+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.101 seconds
[2022-12-17T07:51:39.750+0000] {processor.py:154} INFO - Started process (PID=3461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:39.779+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:51:39.783+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:39.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:39.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:40.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:40.067+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:51:40.213+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:40.211+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:51:40.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.723 seconds
[2022-12-17T07:51:50.760+0000] {processor.py:154} INFO - Started process (PID=3471) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:50.817+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:51:50.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:50.825+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:51.137+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:51:51.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:51.614+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:51:51.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:51:51.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:51:52.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.460 seconds
[2022-12-17T07:52:02.535+0000] {processor.py:154} INFO - Started process (PID=3481) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:02.583+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:52:02.595+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:02.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:02.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:03.578+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:03.574+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:52:03.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:03.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:52:03.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.373 seconds
[2022-12-17T07:52:14.349+0000] {processor.py:154} INFO - Started process (PID=3500) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:14.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:52:14.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:14.360+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:14.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:15.674+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:15.673+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:52:15.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:15.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:52:16.255+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.940 seconds
[2022-12-17T07:52:26.542+0000] {processor.py:154} INFO - Started process (PID=3510) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:26.562+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:52:26.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:26.565+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:26.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:26.790+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:26.788+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:52:26.945+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:26.944+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:52:28.030+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.502 seconds
[2022-12-17T07:52:38.293+0000] {processor.py:154} INFO - Started process (PID=3520) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:38.340+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:52:38.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:38.343+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:38.488+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:38.778+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:38.777+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:52:38.980+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:38.979+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:52:39.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.434 seconds
[2022-12-17T07:52:50.250+0000] {processor.py:154} INFO - Started process (PID=3538) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:50.297+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:52:50.311+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:50.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:50.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:52:50.881+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:50.880+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T07:52:51.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:52:51.189+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T07:52:51.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.307 seconds
[2022-12-17T07:53:02.722+0000] {processor.py:154} INFO - Started process (PID=3548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:53:02.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T07:53:02.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T07:53:02.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:53:03.100+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T07:53:04.067+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T11:59:01.750+0000] {processor.py:154} INFO - Started process (PID=201) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:01.884+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T11:59:01.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:01.888+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:04.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:04.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:04.852+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T11:59:05.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:05.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T11:59:05.426+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.703 seconds
[2022-12-17T11:59:15.845+0000] {processor.py:154} INFO - Started process (PID=211) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:15.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T11:59:15.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:15.875+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:16.202+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:17.364+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T11:59:28.218+0000] {processor.py:154} INFO - Started process (PID=221) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:28.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T11:59:28.229+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:28.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:28.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:29.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:29.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T11:59:29.620+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:29.619+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T11:59:29.771+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.573 seconds
[2022-12-17T11:59:40.345+0000] {processor.py:154} INFO - Started process (PID=242) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:40.396+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T11:59:40.416+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:40.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:40.667+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:42.255+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T11:59:52.596+0000] {processor.py:154} INFO - Started process (PID=254) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:52.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T11:59:52.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:52.602+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:52.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T11:59:53.518+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:53.517+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T11:59:53.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T11:59:53.640+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T11:59:53.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.196 seconds
[2022-12-17T12:00:04.078+0000] {processor.py:154} INFO - Started process (PID=262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:04.081+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:00:04.085+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:04.084+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:04.174+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:04.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:04.739+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:00:04.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:04.929+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:00:05.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.021 seconds
[2022-12-17T12:00:15.501+0000] {processor.py:154} INFO - Started process (PID=280) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:15.520+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:00:15.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:15.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:15.718+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:16.703+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:16.702+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:00:16.846+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:16.845+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:00:17.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.613 seconds
[2022-12-17T12:00:27.418+0000] {processor.py:154} INFO - Started process (PID=290) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:27.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:00:27.434+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:27.433+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:27.573+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:28.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:28.178+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:00:28.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:28.317+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:00:28.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.106 seconds
[2022-12-17T12:00:38.812+0000] {processor.py:154} INFO - Started process (PID=300) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:38.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:00:38.820+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:38.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:38.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:40.191+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:40.190+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:00:40.329+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:40.328+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:00:40.455+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.658 seconds
[2022-12-17T12:00:51.342+0000] {processor.py:154} INFO - Started process (PID=312) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:51.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:00:51.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:51.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:51.509+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:00:52.850+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:52.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:00:53.022+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:00:53.021+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:00:53.189+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.861 seconds
[2022-12-17T12:01:03.515+0000] {processor.py:154} INFO - Started process (PID=329) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:03.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:01:03.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:03.551+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:03.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:04.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:04.520+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:01:04.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:04.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:01:05.128+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.659 seconds
[2022-12-17T12:01:15.500+0000] {processor.py:154} INFO - Started process (PID=339) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:15.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:01:15.560+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:15.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:15.916+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:16.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:16.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:01:16.875+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:16.874+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:01:17.088+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.648 seconds
[2022-12-17T12:01:27.674+0000] {processor.py:154} INFO - Started process (PID=349) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:27.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:01:27.703+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:27.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:27.833+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:28.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:28.450+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:01:28.646+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:28.645+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:01:28.980+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.342 seconds
[2022-12-17T12:01:39.731+0000] {processor.py:154} INFO - Started process (PID=359) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:39.753+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:01:39.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:39.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:40.002+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:40.309+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:40.308+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:01:40.758+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:40.757+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:01:41.040+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.355 seconds
[2022-12-17T12:01:51.389+0000] {processor.py:154} INFO - Started process (PID=377) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:51.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:01:51.491+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:51.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:51.941+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:01:53.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:53.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:01:53.602+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:01:53.601+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:01:53.920+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.571 seconds
[2022-12-17T12:02:04.191+0000] {processor.py:154} INFO - Started process (PID=387) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:04.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:02:04.224+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:04.223+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:04.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:04.607+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:04.606+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:02:04.735+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:04.734+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:02:04.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.693 seconds
[2022-12-17T12:02:15.092+0000] {processor.py:154} INFO - Started process (PID=397) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:15.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:02:15.140+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:15.139+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:15.227+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:16.420+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:16.420+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:02:16.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:16.530+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:02:16.718+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.640 seconds
[2022-12-17T12:02:26.940+0000] {processor.py:154} INFO - Started process (PID=407) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:26.970+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:02:26.974+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:26.973+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:27.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:27.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:27.204+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:02:27.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:27.329+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:02:27.513+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.586 seconds
[2022-12-17T12:02:37.995+0000] {processor.py:154} INFO - Started process (PID=425) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:38.041+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:02:38.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:38.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:38.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:38.732+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:38.731+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:02:38.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:38.856+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:02:39.237+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.259 seconds
[2022-12-17T12:02:49.739+0000] {processor.py:154} INFO - Started process (PID=435) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:49.775+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:02:49.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:49.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:49.875+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:02:50.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:50.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:02:50.135+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:02:50.134+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:02:50.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.534 seconds
[2022-12-17T12:03:01.105+0000] {processor.py:154} INFO - Started process (PID=445) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:01.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:01.134+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:01.132+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:01.212+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:01.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:01.356+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:01.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:01.476+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:01.585+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.493 seconds
[2022-12-17T12:03:12.080+0000] {processor.py:154} INFO - Started process (PID=461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:12.121+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:12.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:12.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:12.560+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:12.772+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:12.771+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:12.893+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:12.892+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:13.061+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.023 seconds
[2022-12-17T12:03:23.521+0000] {processor.py:154} INFO - Started process (PID=473) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:23.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:23.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:23.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:23.633+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:23.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:23.860+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:24.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:24.009+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:24.176+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.669 seconds
[2022-12-17T12:03:34.465+0000] {processor.py:154} INFO - Started process (PID=483) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:34.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:34.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:34.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:34.611+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:34.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:34.788+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:34.923+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:34.921+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:35.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.714 seconds
[2022-12-17T12:03:46.088+0000] {processor.py:154} INFO - Started process (PID=493) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:46.141+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:46.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:46.148+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:46.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:46.996+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:46.995+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:47.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:47.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:47.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.402 seconds
[2022-12-17T12:03:58.144+0000] {processor.py:154} INFO - Started process (PID=512) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:58.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:03:58.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:58.211+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:58.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:03:58.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:58.954+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:03:59.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:03:59.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:03:59.652+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.550 seconds
[2022-12-17T12:04:10.337+0000] {processor.py:154} INFO - Started process (PID=522) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:10.363+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:04:10.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:10.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:10.790+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:12.454+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:12.442+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:04:13.124+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:13.123+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:04:13.400+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.096 seconds
[2022-12-17T12:04:23.867+0000] {processor.py:154} INFO - Started process (PID=532) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:23.891+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:04:23.901+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:23.900+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:23.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:25.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:25.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:04:25.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:25.953+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:04:26.139+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.287 seconds
[2022-12-17T12:04:36.950+0000] {processor.py:154} INFO - Started process (PID=542) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:36.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:04:37.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:37.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:37.369+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:38.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:38.014+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:04:38.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:38.481+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:04:39.116+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.241 seconds
[2022-12-17T12:04:49.644+0000] {processor.py:154} INFO - Started process (PID=558) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:49.778+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:04:49.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:49.780+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:50.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:04:51.376+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:51.375+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:04:52.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:04:52.027+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:04:52.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.321 seconds
[2022-12-17T12:05:03.569+0000] {processor.py:154} INFO - Started process (PID=569) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:03.582+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:05:03.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:03.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:03.829+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:04.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:04.485+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:05:04.607+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:04.606+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:05:04.745+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.249 seconds
[2022-12-17T12:05:15.011+0000] {processor.py:154} INFO - Started process (PID=579) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:15.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:05:15.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:15.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:15.102+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:15.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:15.744+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:05:15.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:15.860+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:05:16.018+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.021 seconds
[2022-12-17T12:05:26.357+0000] {processor.py:154} INFO - Started process (PID=589) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:26.377+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:05:26.381+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:26.380+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:26.500+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:26.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:26.716+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:05:26.864+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:26.863+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:05:26.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.646 seconds
[2022-12-17T12:05:38.215+0000] {processor.py:154} INFO - Started process (PID=607) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:38.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:05:38.250+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:38.249+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:39.236+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:40.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:40.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:05:41.149+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:41.148+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:05:41.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.611 seconds
[2022-12-17T12:05:52.433+0000] {processor.py:154} INFO - Started process (PID=618) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:52.443+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:05:52.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:52.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:52.904+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:05:53.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:53.364+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:05:54.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:05:54.009+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:05:54.656+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.296 seconds
[2022-12-17T12:06:05.783+0000] {processor.py:154} INFO - Started process (PID=628) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:05.809+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:06:05.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:05.817+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:06.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:08.614+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:08.613+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:06:09.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:09.904+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:06:11.266+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 5.544 seconds
[2022-12-17T12:06:22.738+0000] {processor.py:154} INFO - Started process (PID=638) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:22.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:06:22.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:22.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:22.851+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:22.998+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:22.997+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:06:23.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:23.125+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:06:23.283+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.568 seconds
[2022-12-17T12:06:33.909+0000] {processor.py:154} INFO - Started process (PID=648) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:33.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:06:33.954+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:33.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:34.153+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:35.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:35.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:06:35.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:35.765+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:06:36.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.268 seconds
[2022-12-17T12:06:46.813+0000] {processor.py:154} INFO - Started process (PID=666) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:46.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:06:46.858+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:46.857+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:47.039+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:47.214+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:47.213+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:06:47.480+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:47.479+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:06:47.732+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.975 seconds
[2022-12-17T12:06:58.161+0000] {processor.py:154} INFO - Started process (PID=676) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:58.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:06:58.169+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:58.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:58.272+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:06:58.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:58.434+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:06:58.567+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:06:58.565+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:06:58.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.601 seconds
[2022-12-17T12:07:09.204+0000] {processor.py:154} INFO - Started process (PID=686) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:09.207+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:07:09.211+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:09.210+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:09.541+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:10.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:10.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:07:10.485+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:10.484+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:07:10.638+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.456 seconds
[2022-12-17T12:07:21.280+0000] {processor.py:154} INFO - Started process (PID=702) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:21.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:07:21.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:21.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:22.028+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:23.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:23.330+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:07:23.833+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:23.832+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:07:24.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.203 seconds
[2022-12-17T12:07:35.201+0000] {processor.py:154} INFO - Started process (PID=713) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:35.240+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:07:35.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:35.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:35.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:36.818+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:07:47.439+0000] {processor.py:154} INFO - Started process (PID=723) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:47.447+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:07:47.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:47.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:47.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:47.901+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:47.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:07:48.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:48.106+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:07:48.384+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.990 seconds
[2022-12-17T12:07:58.682+0000] {processor.py:154} INFO - Started process (PID=733) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:58.708+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:07:58.711+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:58.711+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:58.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:07:59.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:59.283+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:07:59.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:07:59.418+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:07:59.570+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-17T12:08:10.169+0000] {processor.py:154} INFO - Started process (PID=749) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:10.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:08:10.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:10.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:10.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:11.467+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:08:22.502+0000] {processor.py:154} INFO - Started process (PID=761) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:22.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:08:22.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:22.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:22.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:22.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:22.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:08:22.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:22.974+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:08:23.125+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.640 seconds
[2022-12-17T12:08:33.369+0000] {processor.py:154} INFO - Started process (PID=771) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:33.456+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:08:33.460+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:33.459+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:33.552+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:34.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:34.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:08:35.060+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:35.059+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:08:35.207+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.854 seconds
[2022-12-17T12:08:45.478+0000] {processor.py:154} INFO - Started process (PID=784) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:45.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:08:45.537+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:45.536+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:45.648+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:46.734+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:08:57.231+0000] {processor.py:154} INFO - Started process (PID=804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:57.284+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:08:57.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:08:57.300+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:57.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:08:59.034+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:09:09.520+0000] {processor.py:154} INFO - Started process (PID=814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:09.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:09:09.537+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:09.536+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:09.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:09.770+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:09.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:09:09.893+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:09.892+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:09:10.125+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.619 seconds
[2022-12-17T12:09:20.424+0000] {processor.py:154} INFO - Started process (PID=824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:20.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:09:20.456+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:20.455+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:20.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:20.832+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:20.831+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:09:21.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:21.009+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:09:21.280+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-17T12:09:31.864+0000] {processor.py:154} INFO - Started process (PID=842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:31.894+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:09:31.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:31.897+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:32.222+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:33.018+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:33.017+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:09:33.151+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:33.147+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:09:33.404+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.581 seconds
[2022-12-17T12:09:43.645+0000] {processor.py:154} INFO - Started process (PID=853) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:43.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:09:43.688+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:43.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:43.773+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:43.926+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:43.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:09:44.096+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:44.095+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:09:44.205+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.574 seconds
[2022-12-17T12:09:54.517+0000] {processor.py:154} INFO - Started process (PID=863) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:54.544+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:09:54.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:54.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:54.633+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:09:54.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:54.804+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:09:54.929+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:09:54.928+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:09:55.075+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.579 seconds
[2022-12-17T12:10:05.367+0000] {processor.py:154} INFO - Started process (PID=873) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:05.381+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:10:05.385+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:05.384+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:05.469+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:06.434+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:06.433+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:10:06.550+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:06.549+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:10:06.668+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.317 seconds
[2022-12-17T12:10:17.121+0000] {processor.py:154} INFO - Started process (PID=890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:17.148+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:10:17.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:17.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:17.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:17.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:17.501+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:10:17.682+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:17.681+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:10:17.902+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.811 seconds
[2022-12-17T12:10:28.238+0000] {processor.py:154} INFO - Started process (PID=900) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:28.445+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:10:28.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:28.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:28.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:28.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:28.700+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:10:28.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:28.821+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:10:28.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.769 seconds
[2022-12-17T12:10:39.246+0000] {processor.py:154} INFO - Started process (PID=910) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:39.249+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:10:39.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:39.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:39.340+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:39.488+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:39.487+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:10:39.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:39.605+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:10:39.772+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-17T12:10:50.048+0000] {processor.py:154} INFO - Started process (PID=920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:50.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:10:50.080+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:50.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:50.164+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:10:50.333+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:50.332+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:10:50.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:10:50.473+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:10:50.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.570 seconds
[2022-12-17T12:11:00.977+0000] {processor.py:154} INFO - Started process (PID=938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:01.081+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:01.110+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:01.102+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:01.277+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:02.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:02.272+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:02.401+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:02.400+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:02.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.646 seconds
[2022-12-17T12:11:12.770+0000] {processor.py:154} INFO - Started process (PID=948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:12.802+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:12.806+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:12.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:12.977+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:13.586+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:13.585+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:13.708+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:13.707+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:13.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.110 seconds
[2022-12-17T12:11:24.182+0000] {processor.py:154} INFO - Started process (PID=958) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:24.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:24.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:24.206+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:24.394+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:24.764+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:24.763+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:24.904+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:24.903+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:25.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.889 seconds
[2022-12-17T12:11:35.373+0000] {processor.py:154} INFO - Started process (PID=976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:35.510+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:35.514+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:35.513+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:35.750+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:35.956+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:35.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:36.275+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:36.274+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:36.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.165 seconds
[2022-12-17T12:11:46.879+0000] {processor.py:154} INFO - Started process (PID=986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:46.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:46.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:46.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:46.997+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:47.157+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:47.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:47.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:47.267+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:47.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-17T12:11:57.797+0000] {processor.py:154} INFO - Started process (PID=996) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:57.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:11:57.851+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:57.850+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:57.962+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:11:58.108+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:58.107+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:11:58.219+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:11:58.218+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:11:58.319+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.536 seconds
[2022-12-17T12:12:08.609+0000] {processor.py:154} INFO - Started process (PID=1006) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:08.660+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:12:08.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:08.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:08.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:08.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:08.930+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:12:09.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:09.063+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:12:09.203+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.607 seconds
[2022-12-17T12:12:19.545+0000] {processor.py:154} INFO - Started process (PID=1023) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:19.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:12:19.594+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:19.593+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:19.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:20.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:20.716+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:12:20.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:20.897+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:12:21.122+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.593 seconds
[2022-12-17T12:12:32.065+0000] {processor.py:154} INFO - Started process (PID=1033) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:32.093+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:12:32.117+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:32.116+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:32.328+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:32.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:32.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:12:32.576+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:32.575+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:12:32.692+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.670 seconds
[2022-12-17T12:12:42.951+0000] {processor.py:154} INFO - Started process (PID=1043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:42.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:12:43.008+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:43.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:43.099+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:43.249+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:43.248+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:12:43.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:43.357+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:12:43.497+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.560 seconds
[2022-12-17T12:12:54.303+0000] {processor.py:154} INFO - Started process (PID=1060) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:54.330+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:12:54.335+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:54.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:54.575+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:12:54.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:54.884+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:12:55.015+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:12:55.014+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:12:55.162+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.886 seconds
[2022-12-17T12:13:05.772+0000] {processor.py:154} INFO - Started process (PID=1071) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:05.788+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:13:05.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:05.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:05.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:07.041+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:07.040+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:13:07.156+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:07.155+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:13:07.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.529 seconds
[2022-12-17T12:13:17.564+0000] {processor.py:154} INFO - Started process (PID=1081) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:17.610+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:13:17.615+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:17.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:17.693+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:17.822+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:17.821+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:13:17.932+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:17.931+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:13:18.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.519 seconds
[2022-12-17T12:13:28.329+0000] {processor.py:154} INFO - Started process (PID=1091) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:28.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:13:28.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:28.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:28.438+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:28.610+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:28.609+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:13:28.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:28.813+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:13:28.951+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.636 seconds
[2022-12-17T12:13:39.241+0000] {processor.py:154} INFO - Started process (PID=1109) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:39.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:13:39.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:39.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:39.459+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:39.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:39.747+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:13:39.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:39.908+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:13:40.132+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.907 seconds
[2022-12-17T12:13:50.819+0000] {processor.py:154} INFO - Started process (PID=1119) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:50.848+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:13:50.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:50.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:50.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:13:51.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:51.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:13:51.177+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:13:51.176+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:13:51.309+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.506 seconds
[2022-12-17T12:14:01.479+0000] {processor.py:154} INFO - Started process (PID=1129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:01.497+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:01.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:01.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:01.601+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:01.834+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:01.833+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:14:01.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:01.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:14:02.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.651 seconds
[2022-12-17T12:14:12.439+0000] {processor.py:154} INFO - Started process (PID=1139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:12.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:12.471+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:12.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:12.575+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:12.733+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:12.732+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:14:12.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:12.870+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:14:13.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.643 seconds
[2022-12-17T12:14:23.532+0000] {processor.py:154} INFO - Started process (PID=1156) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:23.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:23.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:23.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:23.933+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:24.421+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:24.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:14:24.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:24.565+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:14:24.732+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.238 seconds
[2022-12-17T12:14:35.074+0000] {processor.py:154} INFO - Started process (PID=1166) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:35.117+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:35.126+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:35.125+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:35.296+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:35.656+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:35.655+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:14:35.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:35.798+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:14:35.924+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-17T12:14:46.843+0000] {processor.py:154} INFO - Started process (PID=1176) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:46.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:46.918+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:46.917+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:47.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:47.909+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:14:58.404+0000] {processor.py:154} INFO - Started process (PID=1192) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:58.492+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:14:58.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:58.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:58.656+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:14:59.125+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:59.123+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:14:59.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:14:59.251+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:14:59.409+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.036 seconds
[2022-12-17T12:15:09.918+0000] {processor.py:154} INFO - Started process (PID=1203) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:09.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:15:09.979+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:09.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:10.253+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:10.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:10.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:15:10.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:10.549+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:15:10.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.778 seconds
[2022-12-17T12:15:20.932+0000] {processor.py:154} INFO - Started process (PID=1213) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:20.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:15:20.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:20.990+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:21.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:21.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:21.516+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:15:21.746+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:21.744+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:15:21.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.076 seconds
[2022-12-17T12:15:32.292+0000] {processor.py:154} INFO - Started process (PID=1223) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:32.344+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:15:32.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:32.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:32.485+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:33.807+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:33.806+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:15:33.915+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:33.914+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:15:34.054+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.775 seconds
[2022-12-17T12:15:44.691+0000] {processor.py:154} INFO - Started process (PID=1242) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:44.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:15:44.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:44.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:44.949+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:45.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:45.191+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:15:45.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:45.313+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:15:45.725+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.063 seconds
[2022-12-17T12:15:56.045+0000] {processor.py:154} INFO - Started process (PID=1252) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:56.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:15:56.072+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:56.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:56.155+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:15:56.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:56.355+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:15:56.479+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:15:56.478+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:15:56.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.770 seconds
[2022-12-17T12:16:06.912+0000] {processor.py:154} INFO - Started process (PID=1262) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:06.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:16:06.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:06.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:07.033+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:07.176+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:07.175+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:16:07.285+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:07.284+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:16:07.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.496 seconds
[2022-12-17T12:16:17.698+0000] {processor.py:154} INFO - Started process (PID=1272) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:17.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:16:17.732+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:17.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:17.955+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:18.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:18.167+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:16:18.287+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:18.286+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:16:18.543+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.890 seconds
[2022-12-17T12:16:29.016+0000] {processor.py:154} INFO - Started process (PID=1289) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:29.055+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:16:29.060+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:29.059+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:29.164+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:29.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:29.322+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:16:29.435+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:29.435+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:16:29.664+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.662 seconds
[2022-12-17T12:16:39.886+0000] {processor.py:154} INFO - Started process (PID=1299) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:39.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:16:39.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:39.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:40.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:40.228+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:40.227+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:16:40.349+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:40.348+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:16:40.469+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.607 seconds
[2022-12-17T12:16:50.662+0000] {processor.py:154} INFO - Started process (PID=1309) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:50.730+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:16:50.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:16:50.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:50.821+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:16:51.783+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:17:02.198+0000] {processor.py:154} INFO - Started process (PID=1327) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:02.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:02.214+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:02.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:02.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:02.877+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:17:13.259+0000] {processor.py:154} INFO - Started process (PID=1337) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:13.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:13.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:13.320+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:13.398+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:13.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:13.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:17:13.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:13.642+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:17:13.784+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.539 seconds
[2022-12-17T12:17:24.834+0000] {processor.py:154} INFO - Started process (PID=1347) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:24.837+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:24.841+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:24.840+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:24.921+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:25.427+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:25.426+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:17:25.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:25.543+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:17:25.649+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.831 seconds
[2022-12-17T12:17:36.082+0000] {processor.py:154} INFO - Started process (PID=1357) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:36.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:36.141+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:36.140+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:36.230+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:36.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:36.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:17:36.491+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:36.490+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:17:36.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-17T12:17:47.240+0000] {processor.py:154} INFO - Started process (PID=1376) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:47.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:47.291+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:47.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:47.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:47.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:47.721+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:17:47.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:47.949+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:17:48.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-17T12:17:58.489+0000] {processor.py:154} INFO - Started process (PID=1386) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:58.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:17:58.555+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:58.522+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:58.642+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:17:58.798+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:58.797+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:17:58.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:17:58.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:17:59.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-17T12:18:09.516+0000] {processor.py:154} INFO - Started process (PID=1396) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:09.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:18:09.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:09.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:09.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:09.960+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:09.959+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:18:10.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:10.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:18:10.248+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.786 seconds
[2022-12-17T12:18:20.595+0000] {processor.py:154} INFO - Started process (PID=1412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:20.637+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:18:20.640+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:20.639+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:21.198+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:21.610+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:21.601+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:18:21.854+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:21.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:18:22.035+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.474 seconds
[2022-12-17T12:18:32.224+0000] {processor.py:154} INFO - Started process (PID=1423) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:32.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:18:32.281+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:32.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:32.370+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:33.248+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:18:43.520+0000] {processor.py:154} INFO - Started process (PID=1433) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:43.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:18:43.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:43.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:43.657+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:44.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:44.369+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:18:44.478+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:44.477+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:18:44.648+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.142 seconds
[2022-12-17T12:18:54.952+0000] {processor.py:154} INFO - Started process (PID=1443) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:54.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:18:54.981+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:54.978+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:55.068+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:18:55.225+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:55.224+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:18:55.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:18:55.347+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:18:55.477+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.540 seconds
[2022-12-17T12:19:05.809+0000] {processor.py:154} INFO - Started process (PID=1461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:05.868+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:19:05.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:05.877+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:06.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:06.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:06.304+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:19:06.512+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:06.511+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:19:06.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.005 seconds
[2022-12-17T12:19:17.253+0000] {processor.py:154} INFO - Started process (PID=1471) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:17.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:19:17.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:17.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:17.380+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:18.451+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:19:28.738+0000] {processor.py:154} INFO - Started process (PID=1481) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:28.790+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:19:28.797+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:28.796+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:28.886+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:29.629+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:19:39.986+0000] {processor.py:154} INFO - Started process (PID=1491) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:40.042+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:19:40.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:40.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:40.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:40.250+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:40.250+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:19:40.358+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:40.357+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:19:40.535+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.563 seconds
[2022-12-17T12:19:50.982+0000] {processor.py:154} INFO - Started process (PID=1510) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:51.042+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:19:51.046+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:19:51.045+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:51.261+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:19:52.037+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:20:02.482+0000] {processor.py:154} INFO - Started process (PID=1520) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:02.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:02.490+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:02.489+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:02.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:02.719+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:02.718+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:20:02.835+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:02.834+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:20:02.939+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.472 seconds
[2022-12-17T12:20:13.671+0000] {processor.py:154} INFO - Started process (PID=1530) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:13.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:13.723+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:13.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:13.801+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:13.927+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:13.926+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:20:14.052+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:14.051+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:20:14.198+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-17T12:20:24.377+0000] {processor.py:154} INFO - Started process (PID=1549) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:24.445+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:24.449+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:24.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:24.574+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:25.038+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:20:35.466+0000] {processor.py:154} INFO - Started process (PID=1560) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:35.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:35.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:35.499+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:35.605+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:36.497+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:20:46.908+0000] {processor.py:154} INFO - Started process (PID=1570) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:46.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:46.936+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:46.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:47.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:47.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:47.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:20:47.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:47.261+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:20:47.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.500 seconds
[2022-12-17T12:20:57.712+0000] {processor.py:154} INFO - Started process (PID=1580) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:57.744+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:20:57.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:57.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:57.828+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:20:57.961+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:57.960+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:20:58.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:20:58.073+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:20:58.231+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.533 seconds
[2022-12-17T12:21:08.709+0000] {processor.py:154} INFO - Started process (PID=1598) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:08.739+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:21:08.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:08.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:09.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:10.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:10.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:21:10.272+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:10.271+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:21:10.467+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.822 seconds
[2022-12-17T12:21:20.691+0000] {processor.py:154} INFO - Started process (PID=1608) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:20.713+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:21:20.721+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:20.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:20.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:22.318+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:22.317+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:21:22.459+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:22.458+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:21:22.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.976 seconds
[2022-12-17T12:21:32.803+0000] {processor.py:154} INFO - Started process (PID=1618) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:32.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:21:32.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:32.852+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:32.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:33.265+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:33.264+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:21:33.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:33.377+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:21:33.668+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.879 seconds
[2022-12-17T12:21:44.405+0000] {processor.py:154} INFO - Started process (PID=1635) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:44.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:21:44.447+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:44.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:44.603+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:44.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:44.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:21:44.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:44.875+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:21:45.021+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.675 seconds
[2022-12-17T12:21:55.409+0000] {processor.py:154} INFO - Started process (PID=1646) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:55.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:21:55.461+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:55.460+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:55.570+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:21:56.092+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:56.091+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:21:56.205+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:21:56.204+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:21:56.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.959 seconds
[2022-12-17T12:22:06.634+0000] {processor.py:154} INFO - Started process (PID=1656) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:06.657+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:22:06.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:06.667+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:06.770+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:06.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:06.956+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:22:07.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:07.066+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:22:07.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.562 seconds
[2022-12-17T12:22:17.456+0000] {processor.py:154} INFO - Started process (PID=1666) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:17.475+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:22:17.482+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:17.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:17.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:18.317+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:18.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:22:18.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:18.425+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:22:18.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.121 seconds
[2022-12-17T12:22:29.001+0000] {processor.py:154} INFO - Started process (PID=1684) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:29.018+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:22:29.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:29.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:29.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:30.008+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:30.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:22:30.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:30.409+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:22:30.580+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.596 seconds
[2022-12-17T12:22:40.911+0000] {processor.py:154} INFO - Started process (PID=1694) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:40.962+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:22:40.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:40.970+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:41.080+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:41.653+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:41.652+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:22:41.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:41.764+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:22:41.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.983 seconds
[2022-12-17T12:22:52.121+0000] {processor.py:154} INFO - Started process (PID=1704) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:52.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:22:52.181+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:52.180+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:52.280+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:22:52.711+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:52.710+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:22:53.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:22:53.060+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:22:53.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.087 seconds
[2022-12-17T12:23:03.396+0000] {processor.py:154} INFO - Started process (PID=1714) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:03.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:03.427+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:03.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:03.511+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:03.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:03.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:03.774+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:03.773+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:03.974+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-17T12:23:14.226+0000] {processor.py:154} INFO - Started process (PID=1732) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:14.249+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:14.253+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:14.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:14.337+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:14.505+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:14.504+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:14.692+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:14.691+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:14.830+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.618 seconds
[2022-12-17T12:23:25.479+0000] {processor.py:154} INFO - Started process (PID=1742) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:25.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:25.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:25.510+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:25.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:25.744+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:25.743+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:25.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:25.882+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:26.016+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-17T12:23:36.268+0000] {processor.py:154} INFO - Started process (PID=1752) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:36.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:36.282+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:36.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:36.366+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:36.515+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:36.514+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:36.692+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:36.691+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:36.808+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T12:23:47.187+0000] {processor.py:154} INFO - Started process (PID=1770) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:47.191+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:47.199+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:47.194+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:47.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:47.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:47.571+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:47.890+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:47.890+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:48.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-17T12:23:58.645+0000] {processor.py:154} INFO - Started process (PID=1780) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:58.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:23:58.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:58.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:59.026+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:23:59.239+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:59.238+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:23:59.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:23:59.405+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:23:59.536+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.904 seconds
[2022-12-17T12:24:09.813+0000] {processor.py:154} INFO - Started process (PID=1790) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:09.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:24:09.936+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:09.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:10.058+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:10.308+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:10.308+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:24:10.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:10.443+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:24:10.550+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.750 seconds
[2022-12-17T12:24:21.286+0000] {processor.py:154} INFO - Started process (PID=1800) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:21.290+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:24:21.293+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:21.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:21.377+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:21.514+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:21.513+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:24:21.653+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:21.652+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:24:21.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.547 seconds
[2022-12-17T12:24:32.217+0000] {processor.py:154} INFO - Started process (PID=1818) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:32.270+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:24:32.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:32.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:32.506+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:33.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:33.883+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:24:34.242+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:34.238+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:24:34.609+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.432 seconds
[2022-12-17T12:24:45.006+0000] {processor.py:154} INFO - Started process (PID=1828) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:45.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:24:45.037+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:45.036+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:45.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:45.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:45.689+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:24:46.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:46.027+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:24:46.176+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.184 seconds
[2022-12-17T12:24:56.542+0000] {processor.py:154} INFO - Started process (PID=1838) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:56.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:24:56.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:56.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:56.657+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:24:56.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:56.795+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:24:56.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:24:56.904+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:24:57.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.521 seconds
[2022-12-17T12:25:07.421+0000] {processor.py:154} INFO - Started process (PID=1854) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:07.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:25:07.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:07.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:07.586+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:07.868+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:07.867+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:25:08.000+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:07.999+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:25:08.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.899 seconds
[2022-12-17T12:25:18.539+0000] {processor.py:154} INFO - Started process (PID=1865) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:18.553+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:25:18.556+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:18.556+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:18.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:18.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:18.901+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:25:19.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:19.011+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:25:19.117+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-17T12:25:29.408+0000] {processor.py:154} INFO - Started process (PID=1875) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:29.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:25:29.429+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:29.428+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:29.603+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:29.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:29.990+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:25:30.124+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:30.123+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:25:30.243+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.854 seconds
[2022-12-17T12:25:40.524+0000] {processor.py:154} INFO - Started process (PID=1885) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:40.549+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:25:40.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:40.552+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:40.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:41.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:41.074+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:25:41.196+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:41.196+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:25:41.370+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.864 seconds
[2022-12-17T12:25:52.026+0000] {processor.py:154} INFO - Started process (PID=1903) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:52.095+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:25:52.099+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:52.098+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:52.344+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:25:52.923+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:52.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:25:53.222+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:25:53.221+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:25:53.404+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.396 seconds
[2022-12-17T12:26:04.342+0000] {processor.py:154} INFO - Started process (PID=1913) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:04.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:26:04.419+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:04.418+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:04.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:05.633+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:26:15.995+0000] {processor.py:154} INFO - Started process (PID=1923) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:16.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:26:16.044+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:16.043+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:16.145+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:16.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:16.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:26:16.388+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:16.387+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:26:16.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.559 seconds
[2022-12-17T12:26:27.020+0000] {processor.py:154} INFO - Started process (PID=1938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:27.048+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:26:27.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:27.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:27.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:27.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:27.793+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:26:28.137+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:28.133+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:26:28.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.368 seconds
[2022-12-17T12:26:38.834+0000] {processor.py:154} INFO - Started process (PID=1950) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:38.877+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:26:38.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:38.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:39.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:39.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:39.283+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:26:39.459+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:39.457+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:26:39.602+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.795 seconds
[2022-12-17T12:26:49.868+0000] {processor.py:154} INFO - Started process (PID=1960) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:49.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:26:49.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:49.906+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:49.987+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:26:50.603+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:50.602+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:26:50.739+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:26:50.738+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:26:50.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.022 seconds
[2022-12-17T12:27:01.148+0000] {processor.py:154} INFO - Started process (PID=1970) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:01.172+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:01.177+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:01.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:01.255+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:01.558+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:27:12.371+0000] {processor.py:154} INFO - Started process (PID=1988) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:12.411+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:12.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:12.414+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:12.510+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:12.683+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:12.682+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:27:12.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:12.809+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:27:12.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-17T12:27:23.311+0000] {processor.py:154} INFO - Started process (PID=1998) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:23.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:23.340+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:23.338+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:23.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:23.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:23.941+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:27:24.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:24.075+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:27:24.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.008 seconds
[2022-12-17T12:27:34.550+0000] {processor.py:154} INFO - Started process (PID=2008) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:34.604+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:34.609+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:34.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:34.687+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:34.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:34.820+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:27:34.928+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:34.927+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:27:35.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.655 seconds
[2022-12-17T12:27:45.508+0000] {processor.py:154} INFO - Started process (PID=2018) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:45.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:45.523+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:45.522+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:45.608+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:45.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:45.906+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:27:46.163+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:46.162+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:27:46.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.790 seconds
[2022-12-17T12:27:56.630+0000] {processor.py:154} INFO - Started process (PID=2035) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:56.665+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:27:56.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:56.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:56.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:27:57.596+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:57.595+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:27:57.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:27:57.801+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:27:57.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.381 seconds
[2022-12-17T12:28:08.263+0000] {processor.py:154} INFO - Started process (PID=2045) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:08.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:28:08.316+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:08.315+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:08.397+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:08.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:08.533+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:28:08.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:08.668+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:28:08.817+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.568 seconds
[2022-12-17T12:28:19.085+0000] {processor.py:154} INFO - Started process (PID=2055) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:19.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:28:19.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:19.108+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:19.189+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:19.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:19.318+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:28:19.429+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:19.428+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:28:19.560+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.489 seconds
[2022-12-17T12:28:29.819+0000] {processor.py:154} INFO - Started process (PID=2072) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:29.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:28:29.872+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:29.871+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:29.970+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:31.337+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:31.336+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:28:31.495+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:31.494+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:28:31.618+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.815 seconds
[2022-12-17T12:28:41.753+0000] {processor.py:154} INFO - Started process (PID=2083) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:41.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:28:41.781+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:41.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:41.866+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:41.994+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:41.993+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:28:42.104+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:42.103+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:28:42.242+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.503 seconds
[2022-12-17T12:28:52.523+0000] {processor.py:154} INFO - Started process (PID=2093) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:52.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:28:52.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:28:52.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:52.621+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:28:53.447+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:29:03.269+0000] {processor.py:154} INFO - Started process (PID=2108) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:03.300+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:29:03.307+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:03.306+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:03.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:04.040+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:29:14.443+0000] {processor.py:154} INFO - Started process (PID=2129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:14.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:29:14.468+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:14.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:14.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:16.262+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:29:26.708+0000] {processor.py:154} INFO - Started process (PID=2141) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:26.713+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:29:26.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:26.716+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:26.812+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:26.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:26.940+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:29:27.142+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:27.142+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:29:27.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.570 seconds
[2022-12-17T12:29:37.666+0000] {processor.py:154} INFO - Started process (PID=2149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:37.692+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:29:37.705+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:37.704+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:37.862+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:38.821+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:29:49.049+0000] {processor.py:154} INFO - Started process (PID=2161) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:49.079+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:29:49.087+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:49.082+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:49.189+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:29:49.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:49.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:29:50.139+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:29:50.138+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:29:50.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.293 seconds
[2022-12-17T12:30:00.606+0000] {processor.py:154} INFO - Started process (PID=2177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:00.610+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:00.614+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:00.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:00.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:01.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:01.425+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:30:01.599+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:01.598+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:30:01.719+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.127 seconds
[2022-12-17T12:30:11.961+0000] {processor.py:154} INFO - Started process (PID=2184) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:11.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:12.006+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:12.005+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:12.113+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:12.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:12.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:30:12.446+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:12.445+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:30:12.568+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.635 seconds
[2022-12-17T12:30:22.950+0000] {processor.py:154} INFO - Started process (PID=2194) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:22.979+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:22.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:22.982+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:23.200+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:23.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:23.329+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:30:23.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:23.439+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:30:23.557+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.647 seconds
[2022-12-17T12:30:33.916+0000] {processor.py:154} INFO - Started process (PID=2213) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:33.939+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:33.952+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:33.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:34.363+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:35.344+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:35.332+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:30:35.540+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:35.539+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:30:35.816+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.936 seconds
[2022-12-17T12:30:46.562+0000] {processor.py:154} INFO - Started process (PID=2223) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:46.566+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:46.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:46.573+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:46.668+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:47.724+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:30:57.948+0000] {processor.py:154} INFO - Started process (PID=2233) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:57.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:30:57.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:57.983+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:58.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:30:58.217+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:58.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:30:58.330+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:30:58.329+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:30:58.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.550 seconds
[2022-12-17T12:31:09.228+0000] {processor.py:154} INFO - Started process (PID=2243) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:09.282+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:31:09.286+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:09.285+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:09.382+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:10.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:10.060+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:31:10.372+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:10.371+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:31:10.609+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.395 seconds
[2022-12-17T12:31:21.021+0000] {processor.py:154} INFO - Started process (PID=2263) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:21.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:31:21.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:21.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:21.183+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:21.393+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:21.391+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:31:21.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:21.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:31:21.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.636 seconds
[2022-12-17T12:31:31.901+0000] {processor.py:154} INFO - Started process (PID=2273) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:31.905+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:31:31.909+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:31.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:32.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:32.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:32.196+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:31:32.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:32.326+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:31:32.476+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-17T12:31:42.731+0000] {processor.py:154} INFO - Started process (PID=2283) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:42.736+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:31:42.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:42.739+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:42.847+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:44.332+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:44.331+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:31:44.493+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:44.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:31:44.698+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.984 seconds
[2022-12-17T12:31:55.089+0000] {processor.py:154} INFO - Started process (PID=2305) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:55.108+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:31:55.115+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:55.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:55.311+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:31:55.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:55.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:31:55.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:31:55.869+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:31:56.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.012 seconds
[2022-12-17T12:32:06.328+0000] {processor.py:154} INFO - Started process (PID=2315) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:06.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:32:06.336+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:06.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:06.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:07.329+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:32:17.548+0000] {processor.py:154} INFO - Started process (PID=2325) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:17.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:32:17.571+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:17.570+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:17.679+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:17.820+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:17.819+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:32:17.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:17.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:32:18.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.555 seconds
[2022-12-17T12:32:28.459+0000] {processor.py:154} INFO - Started process (PID=2335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:28.464+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:32:28.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:28.468+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:28.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:28.775+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:28.774+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:32:28.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:28.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:32:29.140+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.718 seconds
[2022-12-17T12:32:39.480+0000] {processor.py:154} INFO - Started process (PID=2353) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:39.491+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:32:39.495+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:39.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:39.761+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:40.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:40.192+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:32:40.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:40.361+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:32:40.526+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.063 seconds
[2022-12-17T12:32:50.865+0000] {processor.py:154} INFO - Started process (PID=2363) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:50.959+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:32:50.963+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:50.962+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:51.046+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:32:51.176+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:51.175+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:32:51.289+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:32:51.288+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:32:51.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.757 seconds
[2022-12-17T12:33:01.891+0000] {processor.py:154} INFO - Started process (PID=2373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:01.920+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:01.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:01.923+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:02.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:02.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:02.237+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:02.416+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:02.415+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:02.522+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.646 seconds
[2022-12-17T12:33:12.669+0000] {processor.py:154} INFO - Started process (PID=2388) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:12.724+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:12.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:12.739+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:12.988+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:14.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:14.191+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:14.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:14.508+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:14.663+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.011 seconds
[2022-12-17T12:33:25.017+0000] {processor.py:154} INFO - Started process (PID=2403) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:25.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:25.036+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:25.036+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:25.177+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:25.322+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:25.322+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:25.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:25.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:25.698+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.707 seconds
[2022-12-17T12:33:35.960+0000] {processor.py:154} INFO - Started process (PID=2413) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:35.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:35.967+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:35.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:36.050+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:36.685+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:36.685+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:36.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:36.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:36.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.051 seconds
[2022-12-17T12:33:47.305+0000] {processor.py:154} INFO - Started process (PID=2423) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:47.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:47.312+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:47.311+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:47.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:47.539+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:47.538+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:47.683+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:47.682+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:47.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.534 seconds
[2022-12-17T12:33:58.234+0000] {processor.py:154} INFO - Started process (PID=2441) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:58.242+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:33:58.246+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:58.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:58.345+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:33:59.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:59.090+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:33:59.418+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:33:59.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:33:59.680+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.470 seconds
[2022-12-17T12:34:10.074+0000] {processor.py:154} INFO - Started process (PID=2451) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:10.098+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:34:10.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:10.101+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:10.190+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:10.354+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:10.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:34:10.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:10.529+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:34:10.641+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.581 seconds
[2022-12-17T12:34:20.953+0000] {processor.py:154} INFO - Started process (PID=2461) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:21.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:34:21.011+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:21.009+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:21.113+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:21.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:21.697+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:34:21.833+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:21.832+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:34:21.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.023 seconds
[2022-12-17T12:34:32.320+0000] {processor.py:154} INFO - Started process (PID=2478) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:32.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:34:32.362+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:32.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:32.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:32.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:32.886+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:34:33.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:33.022+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:34:33.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.047 seconds
[2022-12-17T12:34:43.904+0000] {processor.py:154} INFO - Started process (PID=2489) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:43.950+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:34:43.955+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:43.953+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:44.044+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:44.725+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:44.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:34:44.855+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:44.854+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:34:44.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.088 seconds
[2022-12-17T12:34:55.220+0000] {processor.py:154} INFO - Started process (PID=2499) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:55.263+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:34:55.271+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:55.266+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:55.367+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:34:55.538+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:55.537+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:34:55.687+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:34:55.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:34:55.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-17T12:35:06.056+0000] {processor.py:154} INFO - Started process (PID=2509) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:06.134+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:35:06.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:06.137+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:06.265+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:06.516+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:06.515+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:35:06.638+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:06.637+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:35:06.765+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.728 seconds
[2022-12-17T12:35:17.225+0000] {processor.py:154} INFO - Started process (PID=2527) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:17.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:35:17.285+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:17.284+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:17.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:18.500+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:18.498+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:35:18.633+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:18.632+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:35:18.851+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.658 seconds
[2022-12-17T12:35:29.206+0000] {processor.py:154} INFO - Started process (PID=2537) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:29.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:35:29.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:29.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:29.317+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:30.481+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:35:40.812+0000] {processor.py:154} INFO - Started process (PID=2547) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:40.895+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:35:40.899+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:40.898+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:40.985+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:41.378+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:41.377+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:35:41.513+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:41.512+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:35:41.684+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.885 seconds
[2022-12-17T12:35:51.909+0000] {processor.py:154} INFO - Started process (PID=2557) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:51.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:35:51.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:51.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:52.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:35:52.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:52.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:35:52.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:35:52.647+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:35:52.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.080 seconds
[2022-12-17T12:36:03.520+0000] {processor.py:154} INFO - Started process (PID=2576) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:03.565+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:36:03.569+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:03.568+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:03.653+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:03.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:03.800+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:36:03.966+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:03.965+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:36:04.356+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.850 seconds
[2022-12-17T12:36:15.190+0000] {processor.py:154} INFO - Started process (PID=2586) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:15.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:36:15.225+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:15.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:15.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:15.465+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:15.464+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:36:15.585+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:15.584+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:36:15.723+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.548 seconds
[2022-12-17T12:36:25.945+0000] {processor.py:154} INFO - Started process (PID=2596) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:25.970+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:36:25.974+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:25.973+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:26.065+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:26.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:26.629+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:36:26.761+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:26.760+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:36:26.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-17T12:36:37.335+0000] {processor.py:154} INFO - Started process (PID=2614) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:37.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:36:37.354+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:37.353+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:37.574+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:39.113+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:36:49.628+0000] {processor.py:154} INFO - Started process (PID=2624) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:49.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:36:49.654+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:36:49.653+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:49.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:36:50.526+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:37:00.911+0000] {processor.py:154} INFO - Started process (PID=2634) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:00.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:00.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:00.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:01.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:01.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:01.454+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:37:01.568+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:01.567+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:37:01.696+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.801 seconds
[2022-12-17T12:37:12.520+0000] {processor.py:154} INFO - Started process (PID=2644) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:12.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:12.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:12.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:12.647+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:13.629+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:37:24.179+0000] {processor.py:154} INFO - Started process (PID=2661) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:24.230+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:24.235+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:24.234+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:24.315+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:24.444+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:24.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:37:24.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:24.557+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:37:24.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.526 seconds
[2022-12-17T12:37:34.825+0000] {processor.py:154} INFO - Started process (PID=2671) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:34.857+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:34.861+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:34.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:34.946+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:35.293+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:35.292+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:37:35.452+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:35.451+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:37:35.603+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.794 seconds
[2022-12-17T12:37:45.923+0000] {processor.py:154} INFO - Started process (PID=2681) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:45.973+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:45.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:45.977+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:46.166+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:46.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:46.689+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:37:46.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:46.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:37:46.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.008 seconds
[2022-12-17T12:37:57.242+0000] {processor.py:154} INFO - Started process (PID=2699) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:57.264+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:37:57.268+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:57.267+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:57.423+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:37:58.184+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:58.183+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:37:58.315+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:37:58.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:37:58.436+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.208 seconds
[2022-12-17T12:38:08.588+0000] {processor.py:154} INFO - Started process (PID=2709) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:08.610+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:38:08.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:08.615+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:08.697+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:08.826+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:08.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:38:08.940+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:08.939+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:38:09.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.496 seconds
[2022-12-17T12:38:19.813+0000] {processor.py:154} INFO - Started process (PID=2719) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:19.858+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:38:19.863+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:19.862+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:19.945+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:21.318+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:38:31.614+0000] {processor.py:154} INFO - Started process (PID=2729) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:31.690+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:38:31.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:31.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:31.785+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:32.673+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:38:42.899+0000] {processor.py:154} INFO - Started process (PID=2747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:42.908+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:38:42.912+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:42.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:43.128+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:43.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:43.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:38:44.086+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:44.085+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:38:44.624+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.754 seconds
[2022-12-17T12:38:54.874+0000] {processor.py:154} INFO - Started process (PID=2757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:54.904+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:38:54.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:54.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:54.991+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:38:55.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:55.207+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:38:55.316+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:38:55.315+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:38:55.452+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.592 seconds
[2022-12-17T12:39:05.972+0000] {processor.py:154} INFO - Started process (PID=2767) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:05.985+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:39:05.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:05.988+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:06.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:07.032+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:07.031+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:39:07.161+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:07.160+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:39:07.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.467 seconds
[2022-12-17T12:39:17.673+0000] {processor.py:154} INFO - Started process (PID=2783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:17.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:39:17.735+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:17.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:17.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:18.185+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:18.184+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:39:18.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:18.356+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:39:18.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.870 seconds
[2022-12-17T12:39:28.885+0000] {processor.py:154} INFO - Started process (PID=2794) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:28.933+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:39:28.938+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:28.936+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:29.027+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:29.673+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:39:39.795+0000] {processor.py:154} INFO - Started process (PID=2804) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:40.026+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:39:40.031+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:40.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:40.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:40.263+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:40.262+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:39:40.379+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:40.377+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:39:40.543+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.761 seconds
[2022-12-17T12:39:51.409+0000] {processor.py:154} INFO - Started process (PID=2814) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:51.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:39:51.416+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:51.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:51.501+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:39:51.970+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:51.969+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:39:52.148+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:39:52.147+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:39:52.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.934 seconds
[2022-12-17T12:40:02.564+0000] {processor.py:154} INFO - Started process (PID=2832) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:02.577+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:02.585+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:02.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:02.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:03.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:03.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:03.835+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:03.834+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:04.110+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.571 seconds
[2022-12-17T12:40:14.436+0000] {processor.py:154} INFO - Started process (PID=2842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:14.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:14.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:14.468+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:14.553+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:15.133+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:15.132+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:15.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:15.265+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:15.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.969 seconds
[2022-12-17T12:40:25.688+0000] {processor.py:154} INFO - Started process (PID=2852) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:25.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:25.738+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:25.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:25.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:25.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:25.975+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:26.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:26.090+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:26.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-17T12:40:36.553+0000] {processor.py:154} INFO - Started process (PID=2869) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:36.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:36.619+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:36.612+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:36.776+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:36.951+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:36.942+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:37.254+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:37.253+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:37.388+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.876 seconds
[2022-12-17T12:40:47.871+0000] {processor.py:154} INFO - Started process (PID=2880) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:47.896+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:47.899+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:47.898+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:47.983+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:48.152+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:48.150+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:48.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:48.282+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:48.429+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.574 seconds
[2022-12-17T12:40:58.719+0000] {processor.py:154} INFO - Started process (PID=2890) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:58.767+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:40:58.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:58.769+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:58.856+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:40:59.460+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:59.459+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:40:59.569+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:40:59.569+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:40:59.723+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.018 seconds
[2022-12-17T12:41:09.965+0000] {processor.py:154} INFO - Started process (PID=2900) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:10.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:41:10.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:10.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:10.116+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:10.331+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:10.330+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:41:10.469+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:10.468+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:41:10.574+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.624 seconds
[2022-12-17T12:41:20.702+0000] {processor.py:154} INFO - Started process (PID=2918) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:20.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:41:20.817+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:20.816+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:21.022+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:21.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:21.197+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:41:21.317+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:21.316+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:41:21.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.818 seconds
[2022-12-17T12:41:32.457+0000] {processor.py:154} INFO - Started process (PID=2928) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:32.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:41:32.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:32.510+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:32.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:33.745+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:33.744+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:41:33.858+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:33.857+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:41:33.960+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.515 seconds
[2022-12-17T12:41:44.245+0000] {processor.py:154} INFO - Started process (PID=2938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:44.297+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:41:44.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:44.301+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:44.384+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:44.527+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:44.526+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:41:44.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:44.662+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:41:44.857+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.623 seconds
[2022-12-17T12:41:55.128+0000] {processor.py:154} INFO - Started process (PID=2948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:55.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:41:55.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:55.186+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:55.267+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:41:56.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:56.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:41:56.177+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:41:56.176+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:41:56.347+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.236 seconds
[2022-12-17T12:42:06.492+0000] {processor.py:154} INFO - Started process (PID=2966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:06.511+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:42:06.518+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:06.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:06.614+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:07.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:07.440+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:42:07.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:07.572+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:42:07.692+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.215 seconds
[2022-12-17T12:42:17.952+0000] {processor.py:154} INFO - Started process (PID=2976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:18.009+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:42:18.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:18.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:18.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:18.756+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:18.756+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:42:18.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:18.868+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:42:19.004+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.065 seconds
[2022-12-17T12:42:29.261+0000] {processor.py:154} INFO - Started process (PID=2986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:29.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:42:29.294+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:29.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:29.374+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:29.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:29.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:42:29.808+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:29.807+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:42:29.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.696 seconds
[2022-12-17T12:42:40.287+0000] {processor.py:154} INFO - Started process (PID=3004) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:40.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:42:40.348+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:40.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:40.560+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:41.556+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:41.555+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:42:41.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:41.700+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:42:41.915+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.663 seconds
[2022-12-17T12:42:52.278+0000] {processor.py:154} INFO - Started process (PID=3014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:52.304+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:42:52.308+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:52.307+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:52.389+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:42:53.526+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:53.525+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:42:53.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:42:53.634+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:42:53.774+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.509 seconds
[2022-12-17T12:43:04.018+0000] {processor.py:154} INFO - Started process (PID=3024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:04.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:43:04.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:04.063+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:04.144+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:04.274+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:04.274+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:43:04.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:04.381+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:43:04.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.524 seconds
[2022-12-17T12:43:14.813+0000] {processor.py:154} INFO - Started process (PID=3034) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:14.852+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:43:14.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:14.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:14.994+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:15.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:15.551+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:43:15.660+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:15.659+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:43:15.806+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.062 seconds
[2022-12-17T12:43:26.288+0000] {processor.py:154} INFO - Started process (PID=3053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:26.307+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:43:26.311+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:26.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:26.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:27.799+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:27.798+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:43:27.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:27.961+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:43:28.171+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.918 seconds
[2022-12-17T12:43:38.440+0000] {processor.py:154} INFO - Started process (PID=3063) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:38.472+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:43:38.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:38.476+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:38.556+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:38.921+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:38.920+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:43:39.092+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:39.091+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:43:39.290+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.867 seconds
[2022-12-17T12:43:49.486+0000] {processor.py:154} INFO - Started process (PID=3073) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:49.609+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:43:49.615+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:49.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:49.777+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:43:50.167+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:50.166+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:43:50.279+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:43:50.278+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:43:50.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.938 seconds
[2022-12-17T12:44:01.055+0000] {processor.py:154} INFO - Started process (PID=3091) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:01.066+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:01.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:01.073+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:01.190+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:02.128+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:44:12.773+0000] {processor.py:154} INFO - Started process (PID=3101) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:12.785+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:12.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:12.788+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:12.894+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:13.063+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:13.062+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:44:13.172+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:13.171+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:44:13.281+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.537 seconds
[2022-12-17T12:44:23.397+0000] {processor.py:154} INFO - Started process (PID=3111) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:23.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:23.416+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:23.415+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:23.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:23.638+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:23.637+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:44:23.764+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:23.763+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:44:24.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.685 seconds
[2022-12-17T12:44:34.318+0000] {processor.py:154} INFO - Started process (PID=3121) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:34.338+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:34.343+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:34.342+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:34.424+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:35.514+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:44:45.928+0000] {processor.py:154} INFO - Started process (PID=3139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:45.982+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:45.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:45.985+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:46.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:46.360+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:46.359+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:44:46.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:46.485+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:44:46.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.963 seconds
[2022-12-17T12:44:57.330+0000] {processor.py:154} INFO - Started process (PID=3149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:57.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:44:57.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:57.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:57.453+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:44:57.587+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:57.586+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:44:57.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:44:57.694+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:44:57.804+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.491 seconds
[2022-12-17T12:45:08.053+0000] {processor.py:154} INFO - Started process (PID=3159) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:08.075+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:45:08.080+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:08.079+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:08.161+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:08.288+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:08.287+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:45:08.396+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:08.395+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:45:08.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.492 seconds
[2022-12-17T12:45:19.307+0000] {processor.py:154} INFO - Started process (PID=3169) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:19.359+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:45:19.363+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:19.362+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:19.465+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:19.652+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:19.651+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:45:19.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:19.793+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:45:19.960+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.667 seconds
[2022-12-17T12:45:30.786+0000] {processor.py:154} INFO - Started process (PID=3187) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:30.806+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:45:30.811+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:30.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:30.891+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:31.180+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:31.179+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:45:31.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:31.289+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:45:31.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.652 seconds
[2022-12-17T12:45:41.710+0000] {processor.py:154} INFO - Started process (PID=3197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:41.754+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:45:41.759+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:41.757+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:41.839+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:41.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:41.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:45:42.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:42.075+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:45:42.216+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.520 seconds
[2022-12-17T12:45:52.526+0000] {processor.py:154} INFO - Started process (PID=3207) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:52.550+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:45:52.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:52.553+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:52.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:45:54.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:54.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:45:54.161+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:45:54.160+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:45:54.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.770 seconds
[2022-12-17T12:46:04.435+0000] {processor.py:154} INFO - Started process (PID=3225) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:04.462+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:46:04.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:04.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:04.572+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:04.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:04.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:46:04.845+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:04.844+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:46:04.991+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.573 seconds
[2022-12-17T12:46:15.140+0000] {processor.py:154} INFO - Started process (PID=3235) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:15.178+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:46:15.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:15.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:15.262+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:15.667+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:15.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:46:15.788+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:15.787+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:46:15.947+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.819 seconds
[2022-12-17T12:46:26.366+0000] {processor.py:154} INFO - Started process (PID=3245) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:26.392+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:46:26.396+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:26.395+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:26.478+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:27.051+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:27.050+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:46:27.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:27.167+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:46:27.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.955 seconds
[2022-12-17T12:46:37.548+0000] {processor.py:154} INFO - Started process (PID=3255) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:37.573+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:46:37.578+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:37.576+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:37.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:37.790+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:37.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:46:37.906+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:37.905+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:46:38.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.544 seconds
[2022-12-17T12:46:48.550+0000] {processor.py:154} INFO - Started process (PID=3273) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:48.590+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:46:48.598+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:48.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:48.824+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:46:49.196+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:49.196+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:46:49.502+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:46:49.501+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:46:49.840+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.394 seconds
[2022-12-17T12:47:00.725+0000] {processor.py:154} INFO - Started process (PID=3283) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:00.756+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:00.760+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:00.759+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:00.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:01.021+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:01.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:01.136+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:01.135+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:01.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.545 seconds
[2022-12-17T12:47:11.604+0000] {processor.py:154} INFO - Started process (PID=3293) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:11.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:11.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:11.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:11.786+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:12.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:12.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:12.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:12.872+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:13.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.421 seconds
[2022-12-17T12:47:23.453+0000] {processor.py:154} INFO - Started process (PID=3309) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:23.500+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:23.523+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:23.522+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:23.658+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:23.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:23.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:23.937+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:23.936+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:24.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.665 seconds
[2022-12-17T12:47:34.426+0000] {processor.py:154} INFO - Started process (PID=3320) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:34.438+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:34.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:34.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:34.523+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:34.907+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:34.906+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:35.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:35.121+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:35.323+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.915 seconds
[2022-12-17T12:47:45.596+0000] {processor.py:154} INFO - Started process (PID=3330) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:45.619+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:45.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:45.623+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:45.703+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:45.844+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:45.843+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:45.963+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:45.962+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:46.084+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.503 seconds
[2022-12-17T12:47:56.420+0000] {processor.py:154} INFO - Started process (PID=3340) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:56.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:47:56.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:56.482+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:56.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:47:56.715+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:56.714+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:47:56.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:47:56.836+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:47:56.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.543 seconds
[2022-12-17T12:48:07.255+0000] {processor.py:154} INFO - Started process (PID=3358) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:07.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:48:07.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:07.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:07.423+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:07.972+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:07.971+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:48:08.302+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:08.301+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:48:08.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.290 seconds
[2022-12-17T12:48:18.990+0000] {processor.py:154} INFO - Started process (PID=3368) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:19.050+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:48:19.055+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:19.054+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:19.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:19.266+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:19.265+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:48:19.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:19.373+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:48:19.532+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.556 seconds
[2022-12-17T12:48:29.795+0000] {processor.py:154} INFO - Started process (PID=3378) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:29.821+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:48:29.825+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:29.824+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:29.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:30.037+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:30.036+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:48:30.225+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:30.224+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:48:30.359+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.578 seconds
[2022-12-17T12:48:40.621+0000] {processor.py:154} INFO - Started process (PID=3388) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:40.681+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:48:40.685+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:40.684+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:40.764+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:41.803+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:41.802+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:48:41.914+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:41.913+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:48:42.025+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.419 seconds
[2022-12-17T12:48:52.487+0000] {processor.py:154} INFO - Started process (PID=3405) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:52.536+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:48:52.544+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:52.540+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:52.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:48:52.914+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:52.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:48:53.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:48:53.203+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:48:53.366+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.908 seconds
[2022-12-17T12:49:03.679+0000] {processor.py:154} INFO - Started process (PID=3415) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:03.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:03.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:03.765+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:03.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:03.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:03.974+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:04.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:04.082+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:04.208+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.543 seconds
[2022-12-17T12:49:14.962+0000] {processor.py:154} INFO - Started process (PID=3425) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:15.008+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:15.012+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:15.011+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:15.105+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:15.379+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:15.379+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:15.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:15.497+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:15.647+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.700 seconds
[2022-12-17T12:49:25.865+0000] {processor.py:154} INFO - Started process (PID=3442) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:25.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:25.916+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:25.915+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:26.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:26.264+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:26.263+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:26.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:26.388+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:26.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.682 seconds
[2022-12-17T12:49:36.906+0000] {processor.py:154} INFO - Started process (PID=3453) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:36.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:36.943+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:36.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:37.023+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:37.694+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:37.693+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:37.805+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:37.804+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:37.919+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-17T12:49:48.221+0000] {processor.py:154} INFO - Started process (PID=3463) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:48.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:48.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:48.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:48.360+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:48.490+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:48.489+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:48.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:48.600+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:48.747+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-17T12:49:59.100+0000] {processor.py:154} INFO - Started process (PID=3473) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:59.144+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:49:59.148+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:59.147+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:59.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:49:59.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:59.728+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:49:59.843+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:49:59.842+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:49:59.980+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.906 seconds
[2022-12-17T12:50:10.375+0000] {processor.py:154} INFO - Started process (PID=3491) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:10.402+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:50:10.407+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:10.404+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:10.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:11.251+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:11.250+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:50:11.426+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:11.425+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:50:11.640+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.310 seconds
[2022-12-17T12:50:22.037+0000] {processor.py:154} INFO - Started process (PID=3501) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:22.081+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:50:22.110+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:22.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:22.239+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:23.351+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:23.350+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:50:23.552+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:23.551+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:50:23.692+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.682 seconds
[2022-12-17T12:50:33.972+0000] {processor.py:154} INFO - Started process (PID=3511) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:33.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:50:34.004+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:34.003+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:34.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:34.243+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:34.242+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:50:34.356+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:34.355+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:50:34.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.505 seconds
[2022-12-17T12:50:44.700+0000] {processor.py:154} INFO - Started process (PID=3521) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:44.727+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:50:44.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:44.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:44.840+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:45.737+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:45.736+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:50:45.849+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:45.848+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:50:45.993+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.313 seconds
[2022-12-17T12:50:56.616+0000] {processor.py:154} INFO - Started process (PID=3538) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:56.659+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:50:56.664+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:56.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:56.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:50:57.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:57.529+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:50:57.638+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:50:57.637+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:50:57.787+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.239 seconds
[2022-12-17T12:51:08.719+0000] {processor.py:154} INFO - Started process (PID=3548) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:08.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:51:08.753+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:08.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:08.838+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:09.262+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:09.261+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:51:09.372+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:09.372+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:51:09.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.798 seconds
[2022-12-17T12:51:19.789+0000] {processor.py:154} INFO - Started process (PID=3558) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:19.792+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:51:19.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:19.795+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:19.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:20.871+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:20.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:51:20.990+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:20.989+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:51:21.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.360 seconds
[2022-12-17T12:51:31.452+0000] {processor.py:154} INFO - Started process (PID=3576) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:31.474+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:51:31.481+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:31.480+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:31.579+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:31.749+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:31.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:51:31.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:31.897+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:51:32.072+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.635 seconds
[2022-12-17T12:51:42.226+0000] {processor.py:154} INFO - Started process (PID=3586) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:42.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:51:42.249+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:42.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:42.330+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:43.029+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:43.016+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:51:43.240+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:43.239+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:51:43.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.208 seconds
[2022-12-17T12:51:53.595+0000] {processor.py:154} INFO - Started process (PID=3596) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:53.636+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:51:53.642+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:53.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:53.757+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:51:54.748+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:54.747+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:51:54.911+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:51:54.910+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:51:55.086+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.504 seconds
[2022-12-17T12:52:05.344+0000] {processor.py:154} INFO - Started process (PID=3606) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:05.370+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:52:05.375+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:05.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:05.460+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:05.911+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:52:16.371+0000] {processor.py:154} INFO - Started process (PID=3624) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:16.381+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:52:16.385+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:16.384+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:16.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:17.113+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:17.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:52:17.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:17.224+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:52:17.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.151 seconds
[2022-12-17T12:52:27.849+0000] {processor.py:154} INFO - Started process (PID=3634) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:27.873+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:52:27.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:27.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:27.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:28.087+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:28.086+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:52:28.195+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:28.194+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:52:28.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.494 seconds
[2022-12-17T12:52:38.577+0000] {processor.py:154} INFO - Started process (PID=3644) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:38.624+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:52:38.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:38.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:38.712+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:38.838+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:38.837+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:52:38.949+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:38.948+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:52:39.089+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.526 seconds
[2022-12-17T12:52:49.380+0000] {processor.py:154} INFO - Started process (PID=3662) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:49.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:52:49.436+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:49.435+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:49.545+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:52:49.699+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:49.698+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:52:49.824+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:52:49.823+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:52:49.991+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.627 seconds
[2022-12-17T12:53:00.328+0000] {processor.py:154} INFO - Started process (PID=3672) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:00.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:00.381+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:00.380+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:00.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:01.932+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:53:12.251+0000] {processor.py:154} INFO - Started process (PID=3682) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:12.288+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:12.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:12.294+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:12.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:12.830+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:12.829+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:53:13.143+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:13.142+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:53:13.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.070 seconds
[2022-12-17T12:53:23.762+0000] {processor.py:154} INFO - Started process (PID=3692) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:23.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:23.809+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:23.808+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:23.969+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:24.465+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:53:35.239+0000] {processor.py:154} INFO - Started process (PID=3710) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:35.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:35.300+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:35.299+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:35.479+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:35.769+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:35.768+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:53:35.991+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:35.990+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:53:36.162+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.965 seconds
[2022-12-17T12:53:46.494+0000] {processor.py:154} INFO - Started process (PID=3720) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:46.508+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:46.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:46.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:46.603+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:47.319+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:53:57.465+0000] {processor.py:154} INFO - Started process (PID=3730) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:57.508+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:53:57.512+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:57.511+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:57.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:53:58.928+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:58.927+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:53:59.039+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:53:59.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:53:59.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.773 seconds
[2022-12-17T12:54:09.562+0000] {processor.py:154} INFO - Started process (PID=3747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:09.685+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:54:09.688+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:09.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:09.785+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:10.009+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:10.008+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:54:10.236+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:10.235+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:54:10.469+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.937 seconds
[2022-12-17T12:54:20.956+0000] {processor.py:154} INFO - Started process (PID=3758) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:20.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:54:20.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:20.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:21.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:22.234+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:54:32.586+0000] {processor.py:154} INFO - Started process (PID=3768) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:32.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:54:32.634+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:32.633+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:32.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:33.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:33.506+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:54:33.617+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:33.616+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:54:33.752+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.182 seconds
[2022-12-17T12:54:43.994+0000] {processor.py:154} INFO - Started process (PID=3778) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:44.043+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:54:44.048+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:44.047+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:44.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:44.261+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:44.260+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:54:44.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:44.368+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:54:44.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.521 seconds
[2022-12-17T12:54:54.882+0000] {processor.py:154} INFO - Started process (PID=3796) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:54.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:54:54.939+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:54.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:55.179+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:54:55.412+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:55.411+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:54:55.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:54:55.535+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:54:55.697+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.851 seconds
[2022-12-17T12:55:06.338+0000] {processor.py:154} INFO - Started process (PID=3806) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:06.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:55:06.389+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:06.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:06.469+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:06.601+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:06.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:55:06.709+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:06.708+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:55:06.828+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-17T12:55:17.592+0000] {processor.py:154} INFO - Started process (PID=3816) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:17.610+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:55:17.615+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:17.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:17.700+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:18.120+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:55:28.425+0000] {processor.py:154} INFO - Started process (PID=3826) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:28.447+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:55:28.451+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:28.450+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:28.535+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:29.281+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:29.280+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:55:29.415+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:29.415+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:55:29.602+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.190 seconds
[2022-12-17T12:55:40.062+0000] {processor.py:154} INFO - Started process (PID=3843) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:40.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:55:40.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:40.096+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:40.181+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:40.308+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:40.307+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:55:40.417+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:40.417+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:55:40.559+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.510 seconds
[2022-12-17T12:55:50.811+0000] {processor.py:154} INFO - Started process (PID=3853) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:50.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:55:50.848+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:50.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:50.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:55:51.060+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:51.059+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:55:51.168+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:55:51.168+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:55:51.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.487 seconds
[2022-12-17T12:56:01.547+0000] {processor.py:154} INFO - Started process (PID=3863) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:01.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:01.573+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:01.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:01.672+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:02.016+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:02.015+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:56:02.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:02.154+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:56:02.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.804 seconds
[2022-12-17T12:56:13.503+0000] {processor.py:154} INFO - Started process (PID=3881) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:13.517+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:13.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:13.520+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:13.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:14.296+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:14.295+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:56:14.422+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:14.421+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:56:14.588+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.183 seconds
[2022-12-17T12:56:25.021+0000] {processor.py:154} INFO - Started process (PID=3891) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:25.054+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:25.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:25.057+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:25.191+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:25.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:25.940+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:56:26.061+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:26.060+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:56:26.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.203 seconds
[2022-12-17T12:56:37.191+0000] {processor.py:154} INFO - Started process (PID=3901) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:37.235+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:37.240+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:37.239+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:37.336+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:37.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:37.634+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:56:37.766+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:37.765+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:56:37.899+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.723 seconds
[2022-12-17T12:56:48.218+0000] {processor.py:154} INFO - Started process (PID=3911) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:48.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:48.258+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:48.257+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:48.349+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:48.476+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:48.475+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:56:48.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:48.589+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:56:48.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.545 seconds
[2022-12-17T12:56:59.140+0000] {processor.py:154} INFO - Started process (PID=3928) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:59.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:56:59.201+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:56:59.200+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:56:59.764+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:00.931+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:00.930+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:01.089+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:01.088+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:01.205+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.096 seconds
[2022-12-17T12:57:11.511+0000] {processor.py:154} INFO - Started process (PID=3938) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:11.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:57:11.535+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:11.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:11.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:12.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:12.077+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:12.187+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:12.186+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:12.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.853 seconds
[2022-12-17T12:57:22.612+0000] {processor.py:154} INFO - Started process (PID=3948) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:22.633+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:57:22.638+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:22.637+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:22.723+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:22.853+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:22.852+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:22.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:22.961+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:23.090+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.492 seconds
[2022-12-17T12:57:33.595+0000] {processor.py:154} INFO - Started process (PID=3966) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:33.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:57:33.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:33.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:33.826+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:34.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:34.074+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:34.201+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:34.200+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:34.538+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.013 seconds
[2022-12-17T12:57:44.744+0000] {processor.py:154} INFO - Started process (PID=3976) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:44.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:57:44.777+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:44.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:44.863+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:45.003+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:45.002+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:45.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:45.202+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:45.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.642 seconds
[2022-12-17T12:57:56.134+0000] {processor.py:154} INFO - Started process (PID=3986) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:56.186+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:57:56.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:56.189+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:56.317+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:57:56.571+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:56.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:57:56.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:57:56.749+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:57:56.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.837 seconds
[2022-12-17T12:58:07.234+0000] {processor.py:154} INFO - Started process (PID=3996) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:07.289+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:58:07.294+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:07.293+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:07.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:07.981+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:58:18.716+0000] {processor.py:154} INFO - Started process (PID=4014) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:18.768+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:58:18.779+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:18.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:18.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:19.442+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:19.441+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:58:19.896+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:19.868+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:58:20.304+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.613 seconds
[2022-12-17T12:58:30.636+0000] {processor.py:154} INFO - Started process (PID=4024) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:30.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:58:30.663+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:30.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:30.748+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:30.883+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:30.882+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:58:31.065+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:31.065+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:58:31.332+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.712 seconds
[2022-12-17T12:58:41.578+0000] {processor.py:154} INFO - Started process (PID=4034) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:41.628+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:58:41.633+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:41.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:41.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:41.844+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:41.844+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:58:41.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:41.961+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:58:42.397+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.833 seconds
[2022-12-17T12:58:52.823+0000] {processor.py:154} INFO - Started process (PID=4052) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:52.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:58:52.864+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:52.863+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:53.000+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:58:53.369+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:53.366+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:58:53.566+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:58:53.565+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:58:53.912+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.106 seconds
[2022-12-17T12:59:04.440+0000] {processor.py:154} INFO - Started process (PID=4067) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:04.466+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:59:04.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:04.469+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:04.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:05.620+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T12:59:15.910+0000] {processor.py:154} INFO - Started process (PID=4080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:15.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:59:15.935+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:15.934+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:16.020+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:16.522+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:16.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:59:16.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:16.642+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:59:16.853+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.960 seconds
[2022-12-17T12:59:27.140+0000] {processor.py:154} INFO - Started process (PID=4087) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:27.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:59:27.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:27.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:27.306+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:27.510+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:27.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:59:27.632+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:27.631+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:59:27.735+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.612 seconds
[2022-12-17T12:59:38.566+0000] {processor.py:154} INFO - Started process (PID=4104) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:38.584+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:59:38.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:38.586+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:38.680+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:38.842+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:38.841+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:59:39.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:39.065+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:59:39.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-17T12:59:49.626+0000] {processor.py:154} INFO - Started process (PID=4114) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:49.675+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T12:59:49.680+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:49.679+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:49.765+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T12:59:50.393+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:50.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T12:59:50.506+0000] {logging_mixin.py:137} INFO - [2022-12-17T12:59:50.505+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T12:59:50.640+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.026 seconds
[2022-12-17T13:00:00.887+0000] {processor.py:154} INFO - Started process (PID=4124) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:00.890+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:00.895+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:00.893+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:00.976+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:01.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:01.104+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:01.221+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:01.220+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:01.355+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.482 seconds
[2022-12-17T13:00:11.597+0000] {processor.py:154} INFO - Started process (PID=4134) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:11.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:11.620+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:11.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:11.706+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:11.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:11.865+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:11.976+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:11.975+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:12.081+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.497 seconds
[2022-12-17T13:00:22.342+0000] {processor.py:154} INFO - Started process (PID=4152) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:22.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:22.401+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:22.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:22.595+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:22.754+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:22.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:22.865+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:22.864+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:22.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.645 seconds
[2022-12-17T13:00:33.252+0000] {processor.py:154} INFO - Started process (PID=4162) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:33.275+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:33.280+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:33.279+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:33.365+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:33.548+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:33.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:33.661+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:33.660+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:33.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.530 seconds
[2022-12-17T13:00:44.043+0000] {processor.py:154} INFO - Started process (PID=4172) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:44.090+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:44.094+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:44.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:44.330+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:44.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:44.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:44.687+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:44.686+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:44.811+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.782 seconds
[2022-12-17T13:00:55.102+0000] {processor.py:154} INFO - Started process (PID=4190) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:55.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:00:55.131+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:55.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:55.229+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:00:55.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:55.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:00:55.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:00:55.741+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:00:55.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.885 seconds
[2022-12-17T13:01:06.786+0000] {processor.py:154} INFO - Started process (PID=4200) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:06.820+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:01:06.824+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:06.823+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:06.922+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:07.161+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:07.160+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:01:07.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:07.409+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:01:07.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.752 seconds
[2022-12-17T13:01:17.668+0000] {processor.py:154} INFO - Started process (PID=4210) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:17.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:01:17.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:17.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:17.811+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:17.948+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:17.947+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:01:18.058+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:18.057+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:01:18.158+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.504 seconds
[2022-12-17T13:01:28.421+0000] {processor.py:154} INFO - Started process (PID=4220) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:28.447+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:01:28.452+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:28.451+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:28.534+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:28.663+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:28.662+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:01:28.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:28.770+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:01:28.908+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.501 seconds
[2022-12-17T13:01:39.299+0000] {processor.py:154} INFO - Started process (PID=4239) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:39.318+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:01:39.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:39.322+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:39.498+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:40.665+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:40.664+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:01:40.876+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:40.875+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:01:41.060+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.779 seconds
[2022-12-17T13:01:51.267+0000] {processor.py:154} INFO - Started process (PID=4249) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:51.318+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:01:51.322+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:51.321+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:51.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:01:51.530+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:51.530+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:01:51.641+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:01:51.640+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:01:51.805+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.551 seconds
[2022-12-17T13:02:02.132+0000] {processor.py:154} INFO - Started process (PID=4259) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:02.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:02.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:02.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:02.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:02.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:02.439+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:02.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:02.552+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:02.658+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.541 seconds
[2022-12-17T13:02:12.912+0000] {processor.py:154} INFO - Started process (PID=4269) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:12.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:12.941+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:12.940+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:13.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:13.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:13.191+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:13.323+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:13.314+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:13.466+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.571 seconds
[2022-12-17T13:02:24.103+0000] {processor.py:154} INFO - Started process (PID=4287) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:24.140+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:24.145+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:24.144+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:24.362+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:24.985+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:24.984+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:25.108+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:25.108+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:25.252+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.164 seconds
[2022-12-17T13:02:35.491+0000] {processor.py:154} INFO - Started process (PID=4297) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:35.542+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:35.547+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:35.545+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:35.627+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:35.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:35.788+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:35.902+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:35.901+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:36.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.537 seconds
[2022-12-17T13:02:46.739+0000] {processor.py:154} INFO - Started process (PID=4307) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:46.767+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:46.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:46.770+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:46.859+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:46.992+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:46.991+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:47.107+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:47.106+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:47.239+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.518 seconds
[2022-12-17T13:02:57.565+0000] {processor.py:154} INFO - Started process (PID=4325) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:57.593+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:02:57.597+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:57.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:57.704+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:02:57.863+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:57.862+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:02:57.989+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:02:57.988+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:02:58.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.594 seconds
[2022-12-17T13:03:08.592+0000] {processor.py:154} INFO - Started process (PID=4335) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:08.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:03:08.669+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:08.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:08.796+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:10.190+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:10.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:03:10.303+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:10.302+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:03:10.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.877 seconds
[2022-12-17T13:03:21.055+0000] {processor.py:154} INFO - Started process (PID=4345) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:21.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:03:21.109+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:21.108+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:21.189+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:22.071+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:22.070+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:03:22.181+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:22.180+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:03:22.319+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.278 seconds
[2022-12-17T13:03:32.574+0000] {processor.py:154} INFO - Started process (PID=4355) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:32.618+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:03:32.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:32.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:32.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:32.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:32.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:03:32.947+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:32.946+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:03:33.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.517 seconds
[2022-12-17T13:03:43.521+0000] {processor.py:154} INFO - Started process (PID=4373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:43.545+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:03:43.585+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:43.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:43.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:45.124+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:03:55.490+0000] {processor.py:154} INFO - Started process (PID=4383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:55.512+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:03:55.517+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:03:55.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:55.598+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:03:56.268+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:04:06.775+0000] {processor.py:154} INFO - Started process (PID=4393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:06.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:04:06.930+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:06.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:07.019+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:08.140+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:08.139+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:04:08.256+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:08.255+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:04:08.416+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.664 seconds
[2022-12-17T13:04:18.849+0000] {processor.py:154} INFO - Started process (PID=4412) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:18.882+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:04:18.886+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:18.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:19.103+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:19.246+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:19.245+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:04:19.374+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:19.373+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:04:19.529+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.731 seconds
[2022-12-17T13:04:29.829+0000] {processor.py:154} INFO - Started process (PID=4422) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:29.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:04:29.885+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:29.884+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:29.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:30.519+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:30.518+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:04:30.647+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:30.646+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:04:30.778+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.963 seconds
[2022-12-17T13:04:41.377+0000] {processor.py:154} INFO - Started process (PID=4432) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:41.398+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:04:41.402+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:41.401+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:41.493+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:41.975+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:41.966+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:04:42.431+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:42.430+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:04:42.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.282 seconds
[2022-12-17T13:04:53.013+0000] {processor.py:154} INFO - Started process (PID=4442) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:53.033+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:04:53.044+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:53.042+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:53.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:04:53.616+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:53.615+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:04:53.790+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:04:53.789+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:04:53.922+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.949 seconds
[2022-12-17T13:05:04.264+0000] {processor.py:154} INFO - Started process (PID=4460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:04.312+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:05:04.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:04.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:04.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:04.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:04.581+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:05:04.726+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:04.725+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:05:05.144+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.895 seconds
[2022-12-17T13:05:15.473+0000] {processor.py:154} INFO - Started process (PID=4470) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:15.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:05:15.509+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:15.508+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:15.589+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:16.818+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:05:27.130+0000] {processor.py:154} INFO - Started process (PID=4480) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:27.150+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:05:27.155+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:27.154+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:27.234+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:27.826+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:27.825+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:05:27.964+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:27.964+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:05:28.100+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.984 seconds
[2022-12-17T13:05:38.286+0000] {processor.py:154} INFO - Started process (PID=4498) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:38.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:05:38.339+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:38.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:38.442+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:38.625+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:38.624+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:05:39.138+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:39.137+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:05:39.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.135 seconds
[2022-12-17T13:05:49.782+0000] {processor.py:154} INFO - Started process (PID=4508) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:49.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:05:49.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:05:49.789+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:49.869+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:05:51.066+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:06:01.327+0000] {processor.py:154} INFO - Started process (PID=4518) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:01.367+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:01.371+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:01.370+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:01.452+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:02.599+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:06:13.616+0000] {processor.py:154} INFO - Started process (PID=4528) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:13.644+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:13.648+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:13.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:13.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:13.881+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:13.880+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:06:14.016+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:14.015+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:06:14.176+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.587 seconds
[2022-12-17T13:06:24.837+0000] {processor.py:154} INFO - Started process (PID=4545) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:24.868+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:24.873+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:24.872+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:25.159+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:25.317+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:25.316+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:06:25.445+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:25.444+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:06:25.575+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.859 seconds
[2022-12-17T13:06:35.957+0000] {processor.py:154} INFO - Started process (PID=4555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:35.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:36.003+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:35.986+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:36.173+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:36.370+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:36.369+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:06:36.493+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:36.492+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:06:36.675+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.733 seconds
[2022-12-17T13:06:46.969+0000] {processor.py:154} INFO - Started process (PID=4565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:46.998+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:47.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:47.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:47.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:48.070+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:06:58.396+0000] {processor.py:154} INFO - Started process (PID=4582) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:58.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:06:58.458+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:58.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:58.556+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:06:59.220+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:59.219+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:06:59.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:06:59.792+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:06:59.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.536 seconds
[2022-12-17T13:07:10.404+0000] {processor.py:154} INFO - Started process (PID=4593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:10.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:07:10.440+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:10.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:10.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:10.713+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:10.712+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:07:10.923+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:10.922+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:07:11.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.764 seconds
[2022-12-17T13:07:21.624+0000] {processor.py:154} INFO - Started process (PID=4603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:21.672+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:07:21.677+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:21.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:21.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:22.602+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:07:32.892+0000] {processor.py:154} INFO - Started process (PID=4613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:32.919+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:07:32.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:32.923+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:33.006+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:33.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:33.345+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:07:33.716+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:33.715+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:07:33.866+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.988 seconds
[2022-12-17T13:07:44.333+0000] {processor.py:154} INFO - Started process (PID=4631) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:44.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:07:44.360+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:44.359+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:44.599+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:46.221+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:46.220+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:07:46.558+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:46.557+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:07:46.684+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.396 seconds
[2022-12-17T13:07:57.008+0000] {processor.py:154} INFO - Started process (PID=4641) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:57.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:07:57.045+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:07:57.044+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:57.150+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:07:58.480+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:08:08.934+0000] {processor.py:154} INFO - Started process (PID=4651) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:08.962+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:08:08.966+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:08.965+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:09.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:09.657+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:09.656+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:08:09.768+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:09.767+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:08:09.907+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.996 seconds
[2022-12-17T13:08:20.368+0000] {processor.py:154} INFO - Started process (PID=4667) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:20.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:08:20.427+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:20.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:20.727+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:20.906+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:20.905+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:08:21.091+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:21.089+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:08:21.300+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.995 seconds
[2022-12-17T13:08:31.742+0000] {processor.py:154} INFO - Started process (PID=4678) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:31.777+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:08:31.796+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:31.786+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:32.069+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:33.230+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:08:43.580+0000] {processor.py:154} INFO - Started process (PID=4688) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:43.611+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:08:43.615+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:43.614+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:43.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:44.197+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:44.196+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:08:44.305+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:44.305+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:08:44.441+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.877 seconds
[2022-12-17T13:08:54.762+0000] {processor.py:154} INFO - Started process (PID=4698) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:54.800+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:08:54.804+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:54.803+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:54.902+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:08:55.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:55.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:08:55.149+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:08:55.148+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:08:55.258+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.509 seconds
[2022-12-17T13:09:05.577+0000] {processor.py:154} INFO - Started process (PID=4715) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:05.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:09:05.630+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:05.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:05.723+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:05.953+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:05.952+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:09:06.686+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:06.685+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:09:07.007+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.445 seconds
[2022-12-17T13:09:17.515+0000] {processor.py:154} INFO - Started process (PID=4725) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:17.541+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:09:17.545+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:17.544+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:17.653+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:18.624+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:18.623+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:09:18.741+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:18.740+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:09:18.937+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.436 seconds
[2022-12-17T13:09:29.219+0000] {processor.py:154} INFO - Started process (PID=4735) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:29.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:09:29.226+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:29.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:29.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:29.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:29.454+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:09:29.697+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:29.696+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:09:29.853+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.648 seconds
[2022-12-17T13:09:40.260+0000] {processor.py:154} INFO - Started process (PID=4749) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:40.286+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:09:40.290+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:40.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:40.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:41.393+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:41.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:09:41.707+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:41.706+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:09:41.904+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.709 seconds
[2022-12-17T13:09:52.295+0000] {processor.py:154} INFO - Started process (PID=4763) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:52.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:09:52.346+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:52.345+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:52.465+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:09:52.742+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:52.741+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:09:53.074+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:09:53.073+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:09:53.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.964 seconds
[2022-12-17T13:10:03.785+0000] {processor.py:154} INFO - Started process (PID=4773) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:03.832+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:10:03.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:03.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:03.920+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:04.581+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:04.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:10:04.728+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:04.728+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:10:04.870+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.099 seconds
[2022-12-17T13:10:15.184+0000] {processor.py:154} INFO - Started process (PID=4783) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:15.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:10:15.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:15.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:15.292+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:15.445+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:15.444+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:10:15.573+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:15.572+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:10:15.952+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.783 seconds
[2022-12-17T13:10:26.981+0000] {processor.py:154} INFO - Started process (PID=4802) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:27.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:10:27.045+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:27.044+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:27.339+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:27.950+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:27.942+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:10:28.301+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:28.300+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:10:28.419+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.490 seconds
[2022-12-17T13:10:38.712+0000] {processor.py:154} INFO - Started process (PID=4812) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:38.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:10:38.727+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:38.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:39.083+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:39.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:39.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:10:39.968+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:39.966+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:10:40.110+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.420 seconds
[2022-12-17T13:10:50.575+0000] {processor.py:154} INFO - Started process (PID=4825) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:50.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:10:50.598+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:50.597+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:50.794+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:10:51.122+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:51.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:10:51.250+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:10:51.249+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:10:51.384+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.871 seconds
[2022-12-17T13:11:02.005+0000] {processor.py:154} INFO - Started process (PID=4842) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:02.062+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:11:02.076+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:02.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:02.415+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:02.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:02.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:11:03.069+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:03.068+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:11:03.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.319 seconds
[2022-12-17T13:11:13.509+0000] {processor.py:154} INFO - Started process (PID=4850) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:13.528+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:11:13.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:13.531+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:13.628+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:13.956+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:13.949+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:11:14.183+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:14.182+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:11:14.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.956 seconds
[2022-12-17T13:11:24.823+0000] {processor.py:154} INFO - Started process (PID=4860) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:24.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:11:24.831+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:24.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:24.910+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:25.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:25.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:11:25.147+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:25.146+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:11:25.386+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.576 seconds
[2022-12-17T13:11:36.449+0000] {processor.py:154} INFO - Started process (PID=4870) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:36.464+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:11:36.473+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:36.472+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:36.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:36.730+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:36.729+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:11:36.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:36.855+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:11:37.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.724 seconds
[2022-12-17T13:11:48.000+0000] {processor.py:154} INFO - Started process (PID=4887) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:48.029+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:11:48.033+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:48.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:48.203+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:11:49.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:49.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:11:49.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:11:49.574+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:11:49.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.976 seconds
[2022-12-17T13:12:00.212+0000] {processor.py:154} INFO - Started process (PID=4897) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:00.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:00.276+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:00.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:00.373+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:00.929+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:00.927+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:12:01.244+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:01.243+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:12:01.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.291 seconds
[2022-12-17T13:12:11.761+0000] {processor.py:154} INFO - Started process (PID=4907) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:11.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:11.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:11.770+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:11.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:12.673+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:12.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:12:12.816+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:12.814+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:12:13.103+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.358 seconds
[2022-12-17T13:12:23.417+0000] {processor.py:154} INFO - Started process (PID=4927) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:23.420+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:23.428+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:23.427+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:23.522+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:24.481+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:24.478+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:12:24.864+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:24.863+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:12:24.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.600 seconds
[2022-12-17T13:12:35.404+0000] {processor.py:154} INFO - Started process (PID=4935) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:35.409+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:35.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:35.412+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:35.523+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:35.763+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:35.762+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:12:35.895+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:35.894+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:12:36.042+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.657 seconds
[2022-12-17T13:12:46.424+0000] {processor.py:154} INFO - Started process (PID=4945) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:46.448+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:46.453+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:46.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:46.610+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:46.770+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:46.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:12:46.905+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:46.904+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:12:47.019+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.611 seconds
[2022-12-17T13:12:57.288+0000] {processor.py:154} INFO - Started process (PID=4955) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:57.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:12:57.295+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:12:57.294+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:57.379+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:12:57.779+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:13:08.769+0000] {processor.py:154} INFO - Started process (PID=4972) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:08.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:13:08.838+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:08.834+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:09.217+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:10.996+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:10.992+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:13:11.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:11.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:13:11.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 3.195 seconds
[2022-12-17T13:13:22.265+0000] {processor.py:154} INFO - Started process (PID=4987) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:22.470+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:13:22.483+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:22.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:22.896+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:23.508+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:23.507+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:13:23.635+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:23.634+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:13:23.754+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.534 seconds
[2022-12-17T13:13:34.109+0000] {processor.py:154} INFO - Started process (PID=4995) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:34.203+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:13:34.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:34.206+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:34.474+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:34.814+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:34.813+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:13:34.929+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:34.928+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:13:35.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.975 seconds
[2022-12-17T13:13:45.433+0000] {processor.py:154} INFO - Started process (PID=5015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:45.455+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:13:45.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:45.466+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:45.881+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:46.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:46.078+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:13:46.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:46.437+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:13:46.691+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.302 seconds
[2022-12-17T13:13:56.985+0000] {processor.py:154} INFO - Started process (PID=5025) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:57.008+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:13:57.014+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:57.012+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:57.096+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:13:57.232+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:57.231+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:13:57.477+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:13:57.477+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:13:57.836+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.866 seconds
[2022-12-17T13:14:08.166+0000] {processor.py:154} INFO - Started process (PID=5032) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:08.195+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:14:08.203+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:08.198+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:08.300+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:08.685+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:08.684+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:14:09.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:09.077+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:14:09.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.157 seconds
[2022-12-17T13:14:19.710+0000] {processor.py:154} INFO - Started process (PID=5042) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:19.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:14:19.752+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:19.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:19.905+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:20.090+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:20.089+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:14:20.231+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:20.230+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:14:20.573+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.885 seconds
[2022-12-17T13:14:31.126+0000] {processor.py:154} INFO - Started process (PID=5060) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:31.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:14:31.178+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:31.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:31.292+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:31.815+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:31.814+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:14:32.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:32.001+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:14:32.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.284 seconds
[2022-12-17T13:14:42.626+0000] {processor.py:154} INFO - Started process (PID=5070) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:42.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:14:42.646+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:42.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:42.725+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:42.857+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:42.856+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:14:42.965+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:42.964+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:14:43.066+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.453 seconds
[2022-12-17T13:14:53.159+0000] {processor.py:154} INFO - Started process (PID=5080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:53.199+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:14:53.204+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:53.202+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:53.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:14:53.413+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:53.412+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:14:53.520+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:14:53.520+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:14:53.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.492 seconds
[2022-12-17T13:15:04.383+0000] {processor.py:154} INFO - Started process (PID=5097) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:04.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:15:04.439+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:04.438+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:04.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:05.666+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:15:16.117+0000] {processor.py:154} INFO - Started process (PID=5108) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:16.120+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:15:16.124+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:16.123+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:16.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:16.734+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:16.733+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:15:16.844+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:16.844+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:15:16.960+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.856 seconds
[2022-12-17T13:15:27.742+0000] {processor.py:154} INFO - Started process (PID=5118) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:27.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:15:27.750+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:27.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:27.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:27.957+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:27.956+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:15:28.064+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:28.063+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:15:28.197+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.470 seconds
[2022-12-17T13:15:38.544+0000] {processor.py:154} INFO - Started process (PID=5128) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:38.564+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:15:38.568+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:38.567+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:38.649+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:38.854+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:15:49.422+0000] {processor.py:154} INFO - Started process (PID=5146) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:49.489+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:15:49.497+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:15:49.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:49.641+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:15:50.707+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:16:00.902+0000] {processor.py:154} INFO - Started process (PID=5156) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:00.947+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:00.958+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:00.950+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:01.067+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:01.196+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:01.195+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:16:01.310+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:01.309+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:16:01.480+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.593 seconds
[2022-12-17T13:16:12.304+0000] {processor.py:154} INFO - Started process (PID=5166) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:12.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:12.398+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:12.396+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:12.483+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:13.586+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:16:24.069+0000] {processor.py:154} INFO - Started process (PID=5183) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:24.091+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:24.099+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:24.094+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:24.319+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:24.654+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:24.653+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:16:24.898+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:24.897+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:16:25.096+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.071 seconds
[2022-12-17T13:16:35.717+0000] {processor.py:154} INFO - Started process (PID=5194) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:35.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:35.727+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:35.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:35.846+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:36.078+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:36.077+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:16:36.278+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:36.277+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:16:36.556+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.868 seconds
[2022-12-17T13:16:46.736+0000] {processor.py:154} INFO - Started process (PID=5204) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:46.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:46.777+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:46.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:46.974+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:47.714+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:47.713+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:16:47.866+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:47.865+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:16:48.095+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.399 seconds
[2022-12-17T13:16:58.263+0000] {processor.py:154} INFO - Started process (PID=5214) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:58.275+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:16:58.283+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:58.282+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:58.456+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:16:58.736+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:58.735+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:16:58.867+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:16:58.865+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:16:59.045+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.797 seconds
[2022-12-17T13:17:09.644+0000] {processor.py:154} INFO - Started process (PID=5231) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:09.647+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:17:09.651+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:09.650+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:09.927+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:10.916+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:17:21.655+0000] {processor.py:154} INFO - Started process (PID=5241) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:21.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:17:21.671+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:21.670+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:21.760+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:21.917+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:21.916+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:17:22.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:22.029+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:17:22.165+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.525 seconds
[2022-12-17T13:17:32.462+0000] {processor.py:154} INFO - Started process (PID=5251) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:32.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:17:32.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:32.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:32.582+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:32.755+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:32.754+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:17:32.878+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:32.877+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:17:33.040+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.601 seconds
[2022-12-17T13:17:43.375+0000] {processor.py:154} INFO - Started process (PID=5261) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:43.390+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:17:43.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:43.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:43.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:44.320+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:44.319+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:17:44.441+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:44.440+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:17:44.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.224 seconds
[2022-12-17T13:17:54.817+0000] {processor.py:154} INFO - Started process (PID=5279) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:54.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:17:54.848+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:17:54.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:55.024+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:17:55.704+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:18:06.538+0000] {processor.py:154} INFO - Started process (PID=5289) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:06.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:18:06.701+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:06.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:06.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:06.942+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:06.941+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:18:07.055+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:07.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:18:07.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.810 seconds
[2022-12-17T13:18:17.678+0000] {processor.py:154} INFO - Started process (PID=5299) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:17.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:18:17.720+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:17.714+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:17.857+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:18.028+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:18.027+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:18:18.146+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:18.145+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:18:18.320+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.690 seconds
[2022-12-17T13:18:28.931+0000] {processor.py:154} INFO - Started process (PID=5309) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:28.959+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:18:28.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:28.961+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:29.048+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:30.213+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:18:41.042+0000] {processor.py:154} INFO - Started process (PID=5326) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:41.049+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:18:41.053+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:41.052+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:41.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:41.463+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:41.462+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:18:41.629+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:41.628+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:18:42.220+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.235 seconds
[2022-12-17T13:18:52.529+0000] {processor.py:154} INFO - Started process (PID=5336) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:52.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:18:52.565+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:52.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:52.707+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:18:53.521+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:53.519+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:18:53.687+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:18:53.685+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:18:53.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.372 seconds
[2022-12-17T13:19:04.747+0000] {processor.py:154} INFO - Started process (PID=5346) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:04.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:19:04.777+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:04.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:04.873+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:05.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:05.016+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:19:05.144+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:05.143+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:19:05.279+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.544 seconds
[2022-12-17T13:19:16.122+0000] {processor.py:154} INFO - Started process (PID=5363) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:16.176+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:19:16.188+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:16.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:16.449+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:16.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:16.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:19:16.899+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:16.898+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:19:17.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.994 seconds
[2022-12-17T13:19:27.319+0000] {processor.py:154} INFO - Started process (PID=5373) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:27.368+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:19:27.373+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:27.372+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:27.456+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:27.598+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:27.597+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:19:27.752+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:27.751+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:19:27.892+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.598 seconds
[2022-12-17T13:19:38.304+0000] {processor.py:154} INFO - Started process (PID=5383) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:38.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:19:38.357+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:38.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:38.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:38.813+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:38.812+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:19:39.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:39.016+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:19:39.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.884 seconds
[2022-12-17T13:19:49.454+0000] {processor.py:154} INFO - Started process (PID=5393) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:49.458+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:19:49.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:49.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:49.572+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:19:50.083+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:50.082+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:19:50.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:19:50.413+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:19:50.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.379 seconds
[2022-12-17T13:20:01.288+0000] {processor.py:154} INFO - Started process (PID=5411) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:01.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:01.299+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:01.294+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:01.519+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:01.817+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:01.816+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:02.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:02.605+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:02.882+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.628 seconds
[2022-12-17T13:20:13.409+0000] {processor.py:154} INFO - Started process (PID=5421) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:13.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:13.432+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:13.431+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:13.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:13.696+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:13.695+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:13.847+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:13.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:14.284+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.889 seconds
[2022-12-17T13:20:24.636+0000] {processor.py:154} INFO - Started process (PID=5431) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:24.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:24.668+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:24.667+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:24.756+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:24.986+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:24.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:25.097+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:25.096+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:25.277+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-17T13:20:35.735+0000] {processor.py:154} INFO - Started process (PID=5449) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:35.755+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:35.771+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:35.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:36.106+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:36.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:36.657+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:36.846+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:36.846+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:37.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.591 seconds
[2022-12-17T13:20:47.779+0000] {processor.py:154} INFO - Started process (PID=5460) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:47.833+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:47.837+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:47.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:47.923+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:48.077+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:48.076+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:48.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:48.283+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:48.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.629 seconds
[2022-12-17T13:20:59.236+0000] {processor.py:154} INFO - Started process (PID=5470) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:59.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:20:59.284+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:59.283+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:59.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:20:59.495+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:59.494+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:20:59.604+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:20:59.603+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:20:59.783+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.564 seconds
[2022-12-17T13:21:10.544+0000] {processor.py:154} INFO - Started process (PID=5480) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:10.615+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:21:10.619+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:10.618+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:10.742+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:11.980+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:21:22.485+0000] {processor.py:154} INFO - Started process (PID=5497) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:22.540+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:21:22.549+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:22.546+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:22.732+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:22.983+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:22.982+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:21:23.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:23.493+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:21:23.902+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.450 seconds
[2022-12-17T13:21:34.398+0000] {processor.py:154} INFO - Started process (PID=5507) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:34.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:21:34.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:34.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:34.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:35.623+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:35.622+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:21:35.740+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:35.739+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:21:35.919+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.539 seconds
[2022-12-17T13:21:46.631+0000] {processor.py:154} INFO - Started process (PID=5517) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:46.651+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:21:46.658+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:46.657+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:46.755+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:47.105+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:47.105+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:21:47.238+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:47.237+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:21:47.452+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.834 seconds
[2022-12-17T13:21:58.376+0000] {processor.py:154} INFO - Started process (PID=5534) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:58.402+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:21:58.410+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:21:58.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:21:58.763+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:00.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:00.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:22:00.478+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:00.477+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:22:00.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.361 seconds
[2022-12-17T13:22:11.100+0000] {processor.py:154} INFO - Started process (PID=5545) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:11.126+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:22:11.130+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:11.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:11.226+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:11.470+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:11.469+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:22:11.717+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:11.716+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:22:12.004+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.923 seconds
[2022-12-17T13:22:22.813+0000] {processor.py:154} INFO - Started process (PID=5555) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:22.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:22:22.879+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:22.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:23.076+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:23.455+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:23.454+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:22:23.919+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:23.918+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:22:24.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.420 seconds
[2022-12-17T13:22:34.814+0000] {processor.py:154} INFO - Started process (PID=5565) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:34.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:22:34.836+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:34.834+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:35.278+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:35.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:35.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:22:36.059+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:36.054+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:22:36.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.508 seconds
[2022-12-17T13:22:47.038+0000] {processor.py:154} INFO - Started process (PID=5583) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:47.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:22:47.080+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:47.080+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:47.584+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:48.452+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:48.451+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:22:48.818+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:48.817+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:22:49.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.171 seconds
[2022-12-17T13:22:59.624+0000] {processor.py:154} INFO - Started process (PID=5593) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:22:59.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:22:59.644+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:22:59.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:00.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:00.926+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:00.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:23:01.343+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:01.338+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:23:01.790+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.242 seconds
[2022-12-17T13:23:12.376+0000] {processor.py:154} INFO - Started process (PID=5603) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:12.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:23:12.394+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:12.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:12.685+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:13.102+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:13.100+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:23:13.321+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:13.320+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:23:13.605+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.313 seconds
[2022-12-17T13:23:23.990+0000] {processor.py:154} INFO - Started process (PID=5613) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:24.040+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:23:24.047+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:24.046+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:24.229+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:24.510+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:24.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:23:24.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:24.801+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:23:25.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.123 seconds
[2022-12-17T13:23:35.448+0000] {processor.py:154} INFO - Started process (PID=5630) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:35.463+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:23:35.474+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:35.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:35.771+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:36.170+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:36.168+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:23:36.496+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:36.496+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:23:36.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.507 seconds
[2022-12-17T13:23:47.546+0000] {processor.py:154} INFO - Started process (PID=5640) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:47.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:23:47.577+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:47.576+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:48.165+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:48.486+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:48.485+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:23:48.743+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:48.738+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:23:49.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.532 seconds
[2022-12-17T13:23:59.306+0000] {processor.py:154} INFO - Started process (PID=5650) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:59.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:23:59.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:23:59.359+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:23:59.634+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:00.510+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:24:11.060+0000] {processor.py:154} INFO - Started process (PID=5660) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:11.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:24:11.067+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:11.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:11.231+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:11.998+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:11.996+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:24:12.405+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:12.404+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:24:12.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.732 seconds
[2022-12-17T13:24:23.429+0000] {processor.py:154} INFO - Started process (PID=5678) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:23.460+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:24:23.494+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:23.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:23.879+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:24.377+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:24.375+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:24:24.688+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:24.687+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:24:24.939+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.673 seconds
[2022-12-17T13:24:35.390+0000] {processor.py:154} INFO - Started process (PID=5688) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:35.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:24:35.447+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:35.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:35.576+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:36.756+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:36.755+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:24:36.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:36.933+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:24:37.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.823 seconds
[2022-12-17T13:24:47.665+0000] {processor.py:154} INFO - Started process (PID=5698) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:47.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:24:47.690+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:47.689+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:47.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:49.217+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:24:59.748+0000] {processor.py:154} INFO - Started process (PID=5708) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:59.753+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:24:59.758+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:24:59.757+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:24:59.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:00.230+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:00.229+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:00.422+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:00.421+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:00.666+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.963 seconds
[2022-12-17T13:25:10.991+0000] {processor.py:154} INFO - Started process (PID=5727) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:11.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:25:11.030+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:11.029+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:11.267+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:11.693+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:11.692+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:11.962+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:11.962+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:12.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.161 seconds
[2022-12-17T13:25:22.571+0000] {processor.py:154} INFO - Started process (PID=5737) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:22.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:25:22.610+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:22.609+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:22.715+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:22.892+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:22.890+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:23.066+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:23.065+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:23.368+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.813 seconds
[2022-12-17T13:25:33.778+0000] {processor.py:154} INFO - Started process (PID=5747) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:34.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:25:34.075+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:34.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:34.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:34.414+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:34.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:34.605+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:34.604+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:34.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.112 seconds
[2022-12-17T13:25:45.406+0000] {processor.py:154} INFO - Started process (PID=5757) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:45.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:25:45.537+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:45.536+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:45.649+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:46.512+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:46.511+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:46.672+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:46.670+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:46.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.515 seconds
[2022-12-17T13:25:57.201+0000] {processor.py:154} INFO - Started process (PID=5776) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:57.214+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:25:57.222+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:57.221+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:57.428+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:25:58.802+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:58.801+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:25:59.150+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:25:59.150+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:25:59.447+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.295 seconds
[2022-12-17T13:26:09.948+0000] {processor.py:154} INFO - Started process (PID=5786) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:09.952+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:26:09.956+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:09.955+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:10.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:11.253+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:26:21.903+0000] {processor.py:154} INFO - Started process (PID=5796) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:21.937+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:26:21.953+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:21.952+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:22.361+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:23.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:23.210+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:26:23.529+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:23.528+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:26:23.722+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.927 seconds
[2022-12-17T13:26:34.303+0000] {processor.py:154} INFO - Started process (PID=5806) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:34.316+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:26:34.343+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:34.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:34.858+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:35.922+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:26:47.219+0000] {processor.py:154} INFO - Started process (PID=5824) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:47.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:26:47.236+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:47.235+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:47.565+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:48.730+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:26:59.487+0000] {processor.py:154} INFO - Started process (PID=5834) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:59.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:26:59.524+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:59.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:59.642+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:26:59.776+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:59.776+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:26:59.891+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:26:59.890+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:26:59.999+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.529 seconds
[2022-12-17T13:27:10.392+0000] {processor.py:154} INFO - Started process (PID=5844) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:10.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:27:10.433+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:10.431+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:10.518+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:10.651+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:10.650+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:27:10.762+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:10.761+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:27:10.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.558 seconds
[2022-12-17T13:27:21.155+0000] {processor.py:154} INFO - Started process (PID=5854) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:21.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:27:21.193+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:21.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:21.280+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:21.422+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:21.421+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:27:21.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:21.573+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:27:22.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.019 seconds
[2022-12-17T13:27:32.636+0000] {processor.py:154} INFO - Started process (PID=5872) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:32.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:27:32.662+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:32.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:32.787+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:34.115+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:27:44.989+0000] {processor.py:154} INFO - Started process (PID=5882) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:45.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:27:45.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:45.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:45.184+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:45.889+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:45.888+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:27:46.010+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:46.010+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:27:46.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.155 seconds
[2022-12-17T13:27:56.545+0000] {processor.py:154} INFO - Started process (PID=5892) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:56.575+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:27:56.582+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:56.581+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:56.689+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:27:57.002+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:57.001+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:27:57.166+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:27:57.165+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:27:57.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.941 seconds
[2022-12-17T13:28:07.962+0000] {processor.py:154} INFO - Started process (PID=5910) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:07.978+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:28:07.982+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:07.981+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:08.187+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:09.595+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:09.594+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:28:10.038+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:10.037+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:28:10.356+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.420 seconds
[2022-12-17T13:28:20.777+0000] {processor.py:154} INFO - Started process (PID=5920) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:20.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:28:20.821+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:20.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:21.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:21.722+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:21.721+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:28:21.856+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:21.855+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:28:22.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.339 seconds
[2022-12-17T13:28:32.448+0000] {processor.py:154} INFO - Started process (PID=5930) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:32.499+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:28:32.507+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:32.502+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:32.753+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:33.054+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:33.053+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:28:33.174+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:33.173+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:28:33.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.865 seconds
[2022-12-17T13:28:43.513+0000] {processor.py:154} INFO - Started process (PID=5940) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:43.543+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:28:43.553+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:43.549+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:43.645+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:44.257+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:44.256+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:28:44.387+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:44.386+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:28:44.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.032 seconds
[2022-12-17T13:28:54.946+0000] {processor.py:154} INFO - Started process (PID=5957) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:54.990+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:28:55.020+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:55.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:55.126+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:28:55.591+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:55.590+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:28:55.801+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:28:55.800+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:28:56.115+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.194 seconds
[2022-12-17T13:29:06.312+0000] {processor.py:154} INFO - Started process (PID=5967) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:06.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:29:06.327+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:06.326+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:06.418+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:07.796+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:29:18.220+0000] {processor.py:154} INFO - Started process (PID=5977) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:18.283+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:29:18.286+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:18.285+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:18.485+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:19.800+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:19.799+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:29:19.959+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:19.957+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:29:20.181+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.976 seconds
[2022-12-17T13:29:30.509+0000] {processor.py:154} INFO - Started process (PID=5995) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:30.556+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:29:30.564+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:30.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:30.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:32.381+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:32.380+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:29:32.574+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:32.573+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:29:32.770+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.280 seconds
[2022-12-17T13:29:43.437+0000] {processor.py:154} INFO - Started process (PID=6005) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:43.477+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:29:43.499+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:43.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:43.692+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:44.464+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:44.463+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:29:44.583+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:44.582+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:29:44.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.429 seconds
[2022-12-17T13:29:55.274+0000] {processor.py:154} INFO - Started process (PID=6015) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:55.302+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:29:55.314+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:55.313+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:55.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:29:56.695+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:56.694+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:29:56.809+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:29:56.808+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:29:57.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.060 seconds
[2022-12-17T13:30:07.718+0000] {processor.py:154} INFO - Started process (PID=6031) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:07.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:30:07.764+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:07.763+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:08.090+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:08.438+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:08.437+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:30:08.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:08.764+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:30:08.883+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.201 seconds
[2022-12-17T13:30:19.559+0000] {processor.py:154} INFO - Started process (PID=6043) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:19.568+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:30:19.590+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:19.584+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:19.813+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:21.070+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:30:31.640+0000] {processor.py:154} INFO - Started process (PID=6053) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:31.688+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:30:31.698+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:31.697+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:31.981+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:32.328+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:32.326+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:30:32.475+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:32.474+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:30:32.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.028 seconds
[2022-12-17T13:30:42.996+0000] {processor.py:154} INFO - Started process (PID=6063) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:43.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:30:43.047+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:43.046+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:43.482+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:43.765+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:43.763+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:30:43.924+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:43.918+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:30:44.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.177 seconds
[2022-12-17T13:30:54.510+0000] {processor.py:154} INFO - Started process (PID=6080) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:54.523+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:30:54.532+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:54.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:54.838+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:30:55.782+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:55.781+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:30:56.236+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:30:56.235+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:30:56.669+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.221 seconds
[2022-12-17T13:31:07.387+0000] {processor.py:154} INFO - Started process (PID=6091) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:07.401+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:31:07.424+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:07.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:07.871+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:08.498+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:08.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:31:09.040+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:09.037+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:31:09.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.909 seconds
[2022-12-17T13:31:19.843+0000] {processor.py:154} INFO - Started process (PID=6101) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:19.866+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:31:19.870+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:19.869+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:20.224+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:20.789+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:20.788+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:31:21.044+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:21.038+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:31:21.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.551 seconds
[2022-12-17T13:31:32.292+0000] {processor.py:154} INFO - Started process (PID=6111) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:32.307+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:31:32.366+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:32.336+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:32.889+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:33.267+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:33.265+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:31:33.462+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:33.461+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:31:33.699+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.546 seconds
[2022-12-17T13:31:43.997+0000] {processor.py:154} INFO - Started process (PID=6129) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:44.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:31:44.017+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:44.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:44.230+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:44.978+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:44.977+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:31:45.610+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:45.609+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:31:46.105+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 2.139 seconds
[2022-12-17T13:31:56.557+0000] {processor.py:154} INFO - Started process (PID=6139) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:56.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:31:56.572+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:56.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:56.701+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:31:57.819+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:57.818+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:31:58.007+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:31:58.006+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:31:58.131+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.624 seconds
[2022-12-17T13:32:08.476+0000] {processor.py:154} INFO - Started process (PID=6149) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:08.528+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:32:08.536+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:08.534+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:08.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:08.792+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:08.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:32:08.953+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:08.952+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:32:09.242+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.783 seconds
[2022-12-17T13:32:19.772+0000] {processor.py:154} INFO - Started process (PID=6159) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:19.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:32:19.832+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:19.831+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:19.929+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:20.612+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:20.611+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:32:20.733+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:20.732+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:32:20.848+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.091 seconds
[2022-12-17T13:32:31.219+0000] {processor.py:154} INFO - Started process (PID=6177) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:31.240+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:32:31.244+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:31.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:31.410+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:31.934+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:31.933+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:32:32.355+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:32.354+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:32:32.575+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.397 seconds
[2022-12-17T13:32:42.859+0000] {processor.py:154} INFO - Started process (PID=6187) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:42.864+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:32:42.869+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:42.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:42.980+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:43.186+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:43.185+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:32:43.365+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:43.364+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:32:43.506+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.661 seconds
[2022-12-17T13:32:54.135+0000] {processor.py:154} INFO - Started process (PID=6197) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:54.225+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:32:54.229+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:54.228+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:54.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:32:54.793+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:54.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:32:55.027+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:32:55.026+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:32:55.357+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.247 seconds
[2022-12-17T13:33:05.489+0000] {processor.py:154} INFO - Started process (PID=6207) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:05.585+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:33:05.589+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:05.588+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:05.711+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:05.987+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:05.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:33:06.125+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:06.124+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:33:06.243+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.771 seconds
[2022-12-17T13:33:16.602+0000] {processor.py:154} INFO - Started process (PID=6226) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:16.624+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:33:16.631+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:16.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:16.815+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:17.212+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:17.211+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:33:17.386+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:17.386+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:33:17.694+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.145 seconds
[2022-12-17T13:33:28.176+0000] {processor.py:154} INFO - Started process (PID=6236) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:28.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:33:28.208+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:28.207+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:28.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:28.546+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:28.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:33:28.680+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:28.679+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:33:28.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.691 seconds
[2022-12-17T13:33:39.169+0000] {processor.py:154} INFO - Started process (PID=6246) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:39.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:33:39.192+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:39.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:39.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:39.542+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:39.541+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:33:39.670+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:39.669+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:33:39.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.658 seconds
[2022-12-17T13:33:50.262+0000] {processor.py:154} INFO - Started process (PID=6260) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:50.315+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:33:50.319+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:33:50.318+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:50.593+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:33:51.968+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:34:02.597+0000] {processor.py:154} INFO - Started process (PID=6275) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:02.620+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:02.632+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:02.631+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:02.769+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:03.711+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-12-17T13:34:13.951+0000] {processor.py:154} INFO - Started process (PID=6285) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:13.980+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:13.984+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:13.983+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:14.086+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:14.248+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:14.247+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:34:14.381+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:14.380+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:34:14.516+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.580 seconds
[2022-12-17T13:34:24.767+0000] {processor.py:154} INFO - Started process (PID=6295) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:24.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:24.794+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:24.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:24.889+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:25.121+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:25.120+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:34:25.273+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:25.272+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:34:25.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.644 seconds
[2022-12-17T13:34:35.742+0000] {processor.py:154} INFO - Started process (PID=6313) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:35.781+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:35.785+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:35.784+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:36.142+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:36.361+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:36.360+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:34:36.511+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:36.510+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:34:36.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.996 seconds
[2022-12-17T13:34:47.083+0000] {processor.py:154} INFO - Started process (PID=6323) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:47.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:47.139+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:47.138+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:47.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:47.528+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:47.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:34:47.763+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:47.762+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:34:48.300+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 1.232 seconds
[2022-12-17T13:34:59.415+0000] {processor.py:154} INFO - Started process (PID=6333) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:59.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:34:59.472+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:59.471+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:59.562+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:34:59.770+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:59.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:34:59.946+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:34:59.946+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:35:00.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.676 seconds
[2022-12-17T13:35:10.338+0000] {processor.py:154} INFO - Started process (PID=6343) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:10.378+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:35:10.382+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:35:10.381+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:10.475+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:10.643+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:35:10.642+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-17T13:35:10.777+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:35:10.776+0000] {dag.py:3336} INFO - Setting next_dagrun for mongo_etl to None, run_after=None
[2022-12-17T13:35:10.906+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/mongo_etl/mongo_dags.py took 0.585 seconds
[2022-12-17T13:35:22.269+0000] {processor.py:154} INFO - Started process (PID=6362) to work on /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:22.305+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/mongo_etl/mongo_dags.py for tasks to queue
[2022-12-17T13:35:22.313+0000] {logging_mixin.py:137} INFO - [2022-12-17T13:35:22.312+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:22.604+0000] {processor.py:766} INFO - DAG(s) dict_keys(['mongo_etl']) retrieved from /opt/airflow/dags/mongo_etl/mongo_dags.py
[2022-12-17T13:35:23.050+0000] {processor.py:179} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 175, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 156, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 781, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 644, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 362, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 195, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 656, in sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 627, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 146, in write_dag
    session.query(literal(True))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2810, in first
    return self.limit(1)._iter().first()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2894, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1529, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3246, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2100, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.3), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
